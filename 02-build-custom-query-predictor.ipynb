{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8757f6-8f36-4b0d-8c37-ba31a1773f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform[prediction]>=1.16.0 fastapi nvtabular git+https://github.com/NVIDIA-Merlin/models.git --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Buidling a custom Vertex AI endpoint for Merlin Query Tower\n",
    "\n",
    "**IMPORTANT** Make sure you are running this notebook in a DLVM (e.g. tensorflow enterprise 2.8) to build the image\n",
    "\n",
    "________\n",
    "**This will not work in the training container**\n",
    "________\n",
    "\n",
    "Your output should look like this - you are going to use the query model endpoint to create a custom container\n",
    "\n",
    "![](img/merlin-bucket.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab54b25-8a22-43d4-a4ef-f85020547df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4e0f4c-ed8f-4ee5-9019-97c750bbef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp -r $workflow_uri local_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fe439a-395b-4ba9-9eb8-c21f60b9cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp -r gs://spotify-beam-v3/merlin-processed/workflow/query-tower-model-22-12 local_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d3d11-9718-4301-928e-3a3b38de202e",
   "metadata": {},
   "source": [
    "#### END DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PROJECT = 'wortz-project-352116'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1'\n",
    "REGION = 'us-central1'\n",
    "# path = 'gs://two-tower-models' #TODO change to your model directory\n",
    "BUCKET = 'gs://spotify-jsw-mpd-2023'\n",
    "REPOSITORY = 'merlin-spotify-cpr'\n",
    "ARTIFACT_URI = f'{BUCKET}'\n",
    "MODEL_DIR = f'{BUCKET}/query_model_merlin'\n",
    "PREFIX = 'merlin-spotify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9fbdbe-c2ad-4299-b48a-b0fa5dc369f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one time to locally copy the workflow for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d89e9cd-654d-44e4-a076-739d95c8cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir workflow\n",
    "# !gsutil cp -r $BUCKET/workflow workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b65e26b-31d7-459e-8f80-92e2c206fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://wortz-project-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5075f2f7-c075-4e56-a188-4adfee578a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !echo y | docker container prune\n",
    "# !echo y | docker image prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045aab2-d485-4bf1-9319-b7afc5cccb34",
   "metadata": {},
   "source": [
    "### Set up repo and configure Docker (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72acda9-ae76-4ce9-8600-71238d545f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# Create the repo if needed for the artifacts\n",
    "\n",
    "! gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1858a130-739b-4752-bf02-d0e8356a0829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf app\n",
    "! mkdir app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd404ace-87cc-4614-9bd0-cdd8f060ba51",
   "metadata": {},
   "source": [
    "### Dependency file\n",
    "The first few are for the server handling traffic\n",
    "Nvtabular was downgraded for this example, it may not be necessary in future versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/requirements.txt\n",
    "uvicorn[standard]==0.15.0\n",
    "gunicorn==20.1.0\n",
    "fastapi==0.68.1\n",
    "google-cloud-aiplatform\n",
    "merlin-models\n",
    "nvtabular\n",
    "gcsfs\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608f690-037f-4607-87cd-5ba72bd3dd16",
   "metadata": {},
   "source": [
    "### Predictor module and class\n",
    "This is an adaptation of the CPR examples\n",
    "\n",
    "This was locally tested and created shortly after model creation in the [tensorflow-predict](tensorflow-predict.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53bfc90-6ab4-40f0-9c06-53a8620eea07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/dataset_to_tensors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/dataset_to_tensors.py\n",
    "\n",
    "try:\n",
    "    import cudf\n",
    "except ImportError:\n",
    "    cudf = None\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Dict\n",
    "from merlin.io import Dataset\n",
    "import itertools\n",
    "\n",
    "\n",
    "def cupy_array_to_tensor(array):\n",
    "    return tf.experimental.dlpack.from_dlpack(array.reshape(-1, 1).toDlpack())\n",
    "\n",
    "def numpy_array_to_tensor(array):\n",
    "    return tf.convert_to_tensor(array.reshape(-1, 1))\n",
    "\n",
    "def cudf_series_to_tensor(col) -> tf.Tensor:\n",
    "    \"Convert a cudf.Series to a TensorFlow Tensor with DLPack\"\n",
    "    if isinstance(col.dtype, cudf.ListDtype):\n",
    "        values = col.list.leaves.values\n",
    "        offsets = col.list._column.offsets.values\n",
    "        row_lengths = offsets[1:] - offsets[:-1]\n",
    "        return cupy_array_to_tensor(values), cupy_array_to_tensor(row_lengths)\n",
    "    else:\n",
    "        return cupy_array_to_tensor(col.values)\n",
    "\n",
    "def pandas_series_to_tensor(col) -> tf.Tensor:\n",
    "    if len(col) and pd.api.types.is_list_like(col.values[0]):\n",
    "        values = pd.Series(itertools.chain(*col)).values\n",
    "        row_lengths = col.map(len).values\n",
    "        return numpy_array_to_tensor(values), numpy_array_to_tensor(row_lengths)\n",
    "    else:\n",
    "        return numpy_array_to_tensor(col.values)\n",
    "        \n",
    "    \n",
    "def dataset_to_tensors(dataset: Dataset) -> Dict[str, tf.Tensor]:\n",
    "    \"\"\"Convert a DataFrame to Dict of Tensors\"\"\"\n",
    "    df = dataset.to_ddf().compute()\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        col_to_tensor = pandas_series_to_tensor\n",
    "    else:\n",
    "        col_to_tensor = cudf_series_to_tensor\n",
    "    return {\n",
    "        column: col_to_tensor(df[column])\n",
    "        for column in df.columns\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d80c477-d403-4d39-9220-98d90511a180",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/predictor.py\n",
    "\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from dataset_to_tensors import *\n",
    "import time\n",
    "\n",
    "\n",
    "# These are helper functions that ensure the dictionary input is in a certain order and types are preserved\n",
    "# this is to get scalar values to appear first in the dict to not confuse pandas with lists https://github.com/pandas-dev/pandas/issues/46092\n",
    "reordered_keys = ['collaborative', 'album_name_pl', 'artist_genres_pl', \n",
    "                  'artist_name_pl', 'artist_pop_can', 'description_pl', \n",
    "                  'duration_ms_songs_pl', 'n_songs_pl', 'name', 'num_albums_pl', \n",
    "                  'num_artists_pl', 'track_name_pl', 'track_pop_pl', \n",
    "                  'duration_ms_seed_pl', 'pid', 'track_uri_pl']  \n",
    "\n",
    "float_num_fix = ['n_songs_pl','num_albums_pl','num_artists_pl','duration_ms_seed_pl']\n",
    "float_list_fix = ['track_pop_pl', 'duration_ms_songs_pl']\n",
    "    \n",
    "def fix_list_num_dtypes(num_list):\n",
    "    \"this fixes lists of ints to list of floats converted in json input\"\n",
    "    return [float(x) for x in num_list]\n",
    "\n",
    "def fix_num_dtypes(num):\n",
    "    \"this fixes ints and casts to floats\"\n",
    "    return float(num)\n",
    "\n",
    "def fix_types(k, v):\n",
    "    if k in float_num_fix:\n",
    "        return fix_num_dtypes(v)\n",
    "    if k in float_list_fix:\n",
    "        return fix_list_num_dtypes(v)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def create_pandas_instance(inputs):\n",
    "    \"\"\"\n",
    "    Helper function to reorder the input to have a sclar first for pandas\n",
    "    And fix the types converted when data is imported by fastAPI\n",
    "    \"\"\"\n",
    "    if type(inputs) == list:\n",
    "        header = inputs[0]\n",
    "        reordered_header_dict = {k: fix_types(k,header[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_header_dict, orient='index').T\n",
    "        if len(inputs) > 1:\n",
    "            for ti in inputs[1:]:\n",
    "                reordered_dict = {k: fix_types(k,ti[k]) for k in reordered_keys}\n",
    "                pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(reordered_dict, orient='index').T)\n",
    "    else:\n",
    "        reordered_dict = {k: fix_types(k,inputs[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_dict, orient='index').T\n",
    "    return pandas_instance\n",
    "\n",
    "class Predictor():\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri):\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        logging.info(\"loading model and workflow\")\n",
    "        start_init = time.process_time()\n",
    "        \n",
    "        #test_bucket = 'gs://jt-merlin-scaling'\n",
    "        self.model = tf.keras.models.load_model(f\"{artifacts_uri}/query_model_merlin\")\n",
    "        # self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\")) # TODO: parameterize\n",
    "        self.workflow = nvt.Workflow.load(\"/docker_workflow/2t-spotify-workflow\")\n",
    "        # self.workflow = nvt.Workflow.load('gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed') # TODO: parametrize\n",
    "        self.workflow = self.workflow.remove_inputs(\n",
    "            [\n",
    "                'track_pop_can', \n",
    "                'track_uri_can', \n",
    "                'duration_ms_can', \n",
    "                'track_name_can', \n",
    "                'artist_name_can',\n",
    "                'album_name_can',\n",
    "                'album_uri_can',\n",
    "                'artist_followers_can', \n",
    "                'artist_genres_can',\n",
    "                'artist_name_can', \n",
    "                'artist_pop_can',\n",
    "                'artist_pop_pl',\n",
    "                'artist_uri_can', \n",
    "                'artists_followers_pl'\n",
    "            ]\n",
    "        )\n",
    "        return self\n",
    "        \n",
    "    def predict(self, prediction_input):\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        # handle different input types, can take a dict or list of dicts\n",
    "        self.n_rows = len(prediction_input)\n",
    "        start = time.process_time()\n",
    "        pandas_instance = create_pandas_instance(prediction_input[0])\n",
    "        #logging.info(f\"Pandas conversion took {time.process_time() - start} seconds\")\n",
    "        print(f\"Pandas conversion took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        #logging.info(f\"NVT data loading took {time.process_time() - start} seconds\")\n",
    "        print(f\"NVT data loading took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        transformed_instance = self.workflow.transform(transformed_inputs)\n",
    "        print(f\"Workflow transformation took {time.process_time() - start} seconds\")\n",
    "\n",
    "        # def predict(self, instances):\n",
    "        start = time.process_time()\n",
    "        \n",
    "        batch = dataset_to_tensors(transformed_instance)\n",
    "        print(f\"converting to dict_tensors took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        output = self.model(batch)\n",
    "        print(f\"Generating query embeddings took {time.process_time() - start} seconds\")\n",
    "        return transformed_instance, output, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9a8771-cae3-494d-a56b-060616889463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "from predictor import Predictor\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "predictor_instance = Predictor()\n",
    "loaded_predictor = predictor_instance.load(artifacts_uri = os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    outputs = loaded_predictor.predict(instances)\n",
    "\n",
    "    return {\"predictions\": outputs[1].numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dfde697-cec3-470c-9c6d-3be275ce6b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486a3c72-75d0-45be-98e3-b8451ea7f8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/instances.json\n",
    "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"album_uri_can\": \"spotify:album:5l83t3mbVgCrIe1VU9uJZR\", \"artist_followers_can\": 4339757.0, \"artist_genres_can\": \"'hawaiian hip hop', 'rap'\", \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_can\": \"Russ\", \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"artist_pop_pl\": [82.0, 80.0, 90.0, 87.0, 65.0], \"artist_uri_can\": \"spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS\", \"artists_followers_pl\": [4339757.0, 5611842.0, 15046756.0, 30713126.0, 603837.0], \"description_pl\": \"\", \"duration_ms_can\": 237322.0, \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_can\": \"We Just Havent Met Yet\", \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_can\": 57.0, \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_can\": \"spotify:track:0VzDv4wiuZsLsNOmfaUy2W\", \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "970ed68e-37f6-406c-9615-3aab9570daeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make it a package\n",
    "!touch app/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb65bef-d269-4f80-a40b-e0b43f844c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:23.02\n",
    "WORKDIR /app \n",
    "\n",
    "COPY ./app/requirements.txt /requirements.txt\n",
    "RUN pip install -r /requirements.txt\n",
    "#DEBUG CHANGES!!\n",
    "RUN mkdir /docker_workflow\n",
    "# RUN mkdir /docker_model\n",
    "# ADD local_model /docker_model\n",
    "ADD workflow /docker_workflow\n",
    "#END DEBUG!\n",
    "\n",
    "\n",
    "COPY ./app /app\n",
    "EXPOSE 80\n",
    "    \n",
    "CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22af2064-0460-4dd5-b352-180f33fbdd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  39.73GB\n",
      "Step 1/9 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:23.02\n",
      " ---> 7f446a9c1777\n",
      "Step 2/9 : WORKDIR /app\n",
      " ---> Running in f309967bed21\n",
      "Removing intermediate container f309967bed21\n",
      " ---> c52121bfbe68\n",
      "Step 3/9 : COPY ./app/requirements.txt /requirements.txt\n",
      " ---> 61eb04deb584\n",
      "Step 4/9 : RUN pip install -r /requirements.txt\n",
      " ---> Running in d8344678f9b1\n",
      "Collecting uvicorn[standard]==0.15.0\n",
      "  Downloading uvicorn-0.15.0-py3-none-any.whl (54 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting fastapi==0.68.1\n",
      "  Downloading fastapi-0.68.1-py3-none-any.whl (52 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.23.0-py2.py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: merlin-models in /usr/local/lib/python3.8/dist-packages (from -r /requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: nvtabular in /usr/local/lib/python3.8/dist-packages (from -r /requirements.txt (line 6)) (23.2.0)\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2023.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.8.0-py2.py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (8.1.3)\n",
      "Collecting asgiref>=3.4.0\n",
      "  Downloading asgiref-3.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1; extra == \"standard\" in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (6.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0; (sys_platform != \"win32\" and (sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\")) and extra == \"standard\"\n",
      "  Downloading uvloop-0.17.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting websockets>=9.1; extra == \"standard\"\n",
      "  Downloading websockets-11.0.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Collecting httptools==0.2.*; extra == \"standard\"\n",
      "  Downloading httptools-0.2.0-cp38-cp38-manylinux1_x86_64.whl (354 kB)\n",
      "Collecting watchgod>=0.6; extra == \"standard\"\n",
      "  Downloading watchgod-0.8.2-py3-none-any.whl (12 kB)\n",
      "Collecting python-dotenv>=0.13; extra == \"standard\"\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/lib/python3/dist-packages (from gunicorn==20.1.0->-r /requirements.txt (line 2)) (45.2.0)\n",
      "Collecting starlette==0.14.2\n",
      "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
      "  Downloading pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting shapely<2.0.0\n",
      "  Downloading Shapely-1.8.5.post1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-3.9.0-py2.py3-none-any.whl (217 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "  Downloading proto_plus-1.22.2-py3-none-any.whl (47 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.9.1-py2.py3-none-any.whl (276 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform->-r /requirements.txt (line 4)) (3.20.3)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "Collecting packaging<22.0.0dev,>=14.3\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: merlin-core>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models->-r /requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: merlin-dataloader>=0.0.2 in /usr/local/lib/python3.8/dist-packages (from merlin-models->-r /requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nvtabular->-r /requirements.txt (line 6)) (1.10.1)\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 7)) (3.8.4)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 7)) (0.4.6)\n",
      "Collecting fsspec==2023.3.0\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 7)) (2.28.2)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 7)) (2.16.2)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.4.1-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (3.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.68.1->-r /requirements.txt (line 3)) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /requirements.txt (line 4)) (2.8.2)\n",
      "Collecting grpcio<2.0dev,>=1.47.0\n",
      "  Downloading grpcio-1.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r /requirements.txt (line 4)) (1.58.0)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2; extra == \"grpc\"\n",
      "  Downloading grpcio_status-1.53.0-py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform->-r /requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: pandas<1.6.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.3.5)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (0.56.4)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.12.0)\n",
      "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2022.7.1)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (4.65.0)\n",
      "Requirement already satisfied: distributed>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2022.7.1)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (8.0.0)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.2.5)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy->nvtabular->-r /requirements.txt (line 6)) (1.22.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 7)) (22.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib->gcsfs->-r /requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->gcsfs->-r /requirements.txt (line 7)) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->gcsfs->-r /requirements.txt (line 7)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->gcsfs->-r /requirements.txt (line 7)) (2019.11.28)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 7)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 7)) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 7)) (4.9)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.0.0->watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2022.7.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (6.0.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (0.39.1)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (5.9.4)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: tornado<6.2,>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->-r /requirements.txt (line 7)) (3.2.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->-r /requirements.txt (line 7)) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models->-r /requirements.txt (line 5)) (6.0.1)\n",
      "\u001b[91mERROR: dask-cudf 22.8.0a0+304.g6ca81bbc78.dirty requires cupy-cuda118<12,>=9.5.0, which is not installed.\n",
      "ERROR: cudf 22.8.0a0+304.g6ca81bbc78.dirty requires cupy-cuda118<12,>=9.5.0, which is not installed.\n",
      "ERROR: tensorflow 2.10.1+nv22.12 has requirement flatbuffers>=2.0, but you'll have flatbuffers 1.12 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: tensorflow 2.10.1+nv22.12 has requirement tensorboard<2.11,>=2.10, but you'll have tensorboard 2.9.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: tensorflow 2.10.1+nv22.12 has requirement tensorflow-estimator<2.11,>=2.10.0, but you'll have tensorflow-estimator 2.9.0 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: tensorboard 2.9.1 has requirement protobuf<3.20,>=3.9.2, but you'll have protobuf 3.20.3 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: merlin-core 23.2.0 has requirement fsspec==2022.5.0, but you'll have fsspec 2023.3.0 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: jupyter-server 2.4.0 has requirement tornado>=6.2.0, but you'll have tornado 6.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: grpcio-channelz 1.51.3 has requirement protobuf>=4.21.6, but you'll have protobuf 3.20.3 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: cudf 22.8.0a0+304.g6ca81bbc78.dirty has requirement cuda-python<11.7.1,>=11.5, but you'll have cuda-python 11.8.1 which is incompatible.\n",
      "\u001b[0m\u001b[91mERROR: grpcio-status 1.53.0 has requirement protobuf>=4.21.6, but you'll have protobuf 3.20.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: asgiref, h11, uvloop, websockets, httptools, watchgod, python-dotenv, uvicorn, gunicorn, starlette, pydantic, fastapi, shapely, proto-plus, grpcio, grpcio-status, google-api-core, google-cloud-core, google-crc32c, google-resumable-media, packaging, google-cloud-bigquery, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-storage, google-cloud-aiplatform, fsspec, gcsfs\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.5.0\n",
      "    Uninstalling fsspec-2022.5.0:\n",
      "      Successfully uninstalled fsspec-2022.5.0\n",
      "Successfully installed asgiref-3.6.0 fastapi-0.68.1 fsspec-2023.3.0 gcsfs-2023.3.0 google-api-core-2.11.0 google-cloud-aiplatform-1.23.0 google-cloud-bigquery-3.9.0 google-cloud-core-2.3.2 google-cloud-resource-manager-1.9.1 google-cloud-storage-2.8.0 google-crc32c-1.5.0 google-resumable-media-2.4.1 grpc-google-iam-v1-0.12.6 grpcio-1.53.0 grpcio-status-1.53.0 gunicorn-20.1.0 h11-0.14.0 httptools-0.2.0 packaging-21.3 proto-plus-1.22.2 pydantic-1.10.7 python-dotenv-1.0.0 shapely-1.8.5.post1 starlette-0.14.2 uvicorn-0.15.0 uvloop-0.17.0 watchgod-0.8.2 websockets-11.0.1\n",
      "Removing intermediate container d8344678f9b1\n",
      " ---> 44ad63d3bdbc\n",
      "Step 5/9 : RUN mkdir /docker_workflow\n",
      " ---> Running in 54d4b4f35be6\n",
      "Removing intermediate container 54d4b4f35be6\n",
      " ---> 2736dfc6ffe5\n",
      "Step 6/9 : ADD workflow /docker_workflow\n",
      " ---> 3001d4d4673c\n",
      "Step 7/9 : COPY ./app /app\n",
      " ---> 49a9af9fd4c3\n",
      "Step 8/9 : EXPOSE 80\n",
      " ---> Running in 9f2fbfc4b367\n",
      "Removing intermediate container 9f2fbfc4b367\n",
      " ---> 0ebaece1206e\n",
      "Step 9/9 : CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]\n",
      " ---> Running in 14d44baa68e2\n",
      "Removing intermediate container 14d44baa68e2\n",
      " ---> e7d759b2369c\n",
      "Successfully built e7d759b2369c\n",
      "Successfully tagged us-central1-docker.pkg.dev/wortz-project-352116/merlin-spotify-cpr/merlin-prediction-cpr:latest\n"
     ]
    }
   ],
   "source": [
    "SERVER_IMAGE = \"merlin-prediction-cpr\"  # @param {type:\"string\"} \n",
    "REMOTE_IMAGE_NAME=f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{SERVER_IMAGE}\"\n",
    "\n",
    "!docker build -t $REMOTE_IMAGE_NAME .\n",
    "# !gcloud builds submit -t $REMOTE_IMAGE_NAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db156d-4675-43cc-ac8f-305d5fc79230",
   "metadata": {},
   "source": [
    "#### If you are debugging, be sure to set `-d` detached flag off and run the commands in console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b2c6d-add5-4753-9069-8499b09ba5c6",
   "metadata": {},
   "source": [
    "us-central1-docker.pkg.dev/wortz-project-352116/merlin-spotify-cpr/merlin-prediction-cp### Copy/paste if you want to run from console for testing\n",
    "```python\n",
    "docker run --gpus all -p 80:8080 \\\n",
    "            --name=merlin-prediction-cpr \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=gs://spotify-jsw-mpd-2023 \\\n",
    "            us-central1-docker.pkg.dev/wortz-project-352116/merlin-spotify-cpr/merlin-prediction-cpr\n",
    "```\n",
    "\n",
    "##### No GPU:\n",
    "```python\n",
    "docker run -p 80:8080 \\\n",
    "            --name=merlin-prediction-cpr \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=gs://spotify-jsw-mpd-2023 \\\n",
    "            us-central1-docker.pkg.dev/wortz-project-352116/merlin-spotify-cpr/merlin-prediction-cpr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53532f-5b5a-4f70-9172-27347571c812",
   "metadata": {},
   "source": [
    "#### Test the health route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae9f6a29-7e69-4bf6-bb22-926578ff1181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "! curl localhost/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fae134d5-92da-48b5-afdb-7a330c88ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ground truth candidate:\n",
    "    # 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "    # 'artist_name_can': 'Russ', \n",
    "    # 'track_name_can': 'We Just Havent Met Yet', \n",
    "## TODO - we have to overload with candidate data because of the workflow transform, add overloaded values in the predictor\n",
    "TEST_INSTANCE = {'collaborative': 'false',\n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_songs_pl': [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_pl': [79.0, 58.0, 83.0, 71.0, 57.0],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acde41b9-5025-4d57-80a9-b9f0213c2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": [{\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"description_pl\": \"\", \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "json_instance = json.dumps({\"instances\": [TEST_INSTANCE]})\n",
    "print(json_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea4b39-7a0c-4417-afc9-72681f24a910",
   "metadata": {},
   "source": [
    "### Test the predict route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68c98f55-2f05-497d-b129-86b3c33a935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.13 ms, sys: 153 µs, total: 5.28 ms\n",
      "Wall time: 535 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.3048475682735443,\n",
       "   0.0,\n",
       "   1.2088731527328491,\n",
       "   0.05392572283744812,\n",
       "   0.0,\n",
       "   0.27251535654067993,\n",
       "   0.9764062166213989,\n",
       "   0.4936431646347046,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.5621760487556458,\n",
       "   0.0,\n",
       "   0.569015383720398,\n",
       "   0.1336423009634018,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.9370920062065125,\n",
       "   1.1970816850662231,\n",
       "   0.35134124755859375,\n",
       "   0.0,\n",
       "   0.19488777220249176,\n",
       "   1.8816297054290771,\n",
       "   0.05862294137477875,\n",
       "   0.0,\n",
       "   0.86396723985672,\n",
       "   0.31114858388900757,\n",
       "   0.0,\n",
       "   0.18993006646633148,\n",
       "   0.0,\n",
       "   0.00311265978962183,\n",
       "   0.1541297435760498,\n",
       "   0.6337419152259827,\n",
       "   0.2538793087005615,\n",
       "   0.0,\n",
       "   0.7494783401489258,\n",
       "   0.0,\n",
       "   1.2598177194595337,\n",
       "   0.023529257625341415,\n",
       "   0.0,\n",
       "   0.008459048345685005,\n",
       "   0.18115344643592834,\n",
       "   0.6338210105895996,\n",
       "   0.0,\n",
       "   0.09700655937194824,\n",
       "   0.008082836866378784,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.20535233616828918,\n",
       "   0.0,\n",
       "   0.19821757078170776,\n",
       "   0.0,\n",
       "   0.9934800863265991,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.9782758951187134,\n",
       "   0.30045604705810547,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.30164632201194763,\n",
       "   0.0,\n",
       "   0.026768449693918228,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.7641364932060242,\n",
       "   3.0250837802886963,\n",
       "   0.0,\n",
       "   0.2146276831626892,\n",
       "   0.07093317806720734,\n",
       "   1.6155332326889038,\n",
       "   0.1265367567539215,\n",
       "   0.5842933058738708,\n",
       "   0.0,\n",
       "   0.17361202836036682,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.054256461560726166,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.38404640555381775,\n",
       "   0.005389826372265816,\n",
       "   0.0,\n",
       "   0.40743303298950195,\n",
       "   0.23483781516551971,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.17311787605285645,\n",
       "   0.0,\n",
       "   2.5818049907684326,\n",
       "   0.316681832075119,\n",
       "   0.37106025218963623,\n",
       "   0.6145275831222534,\n",
       "   0.6449677348136902,\n",
       "   0.4809104800224304,\n",
       "   2.7978355884552,\n",
       "   1.341815710067749,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.5630662441253662,\n",
       "   0.0,\n",
       "   0.05789777263998985,\n",
       "   0.0,\n",
       "   0.9206647872924805,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.4432970881462097,\n",
       "   2.4027366638183594,\n",
       "   0.0,\n",
       "   1.2658443450927734,\n",
       "   0.0,\n",
       "   1.9305765628814697,\n",
       "   0.0,\n",
       "   0.953567385673523]]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "requests.post('http://localhost/predict', data=json_instance).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b95e4a-2bf2-4659-9dbe-435571bd6b13",
   "metadata": {},
   "source": [
    "## Stop the images if they are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e52cf577-dcb3-4534-87a1-5acb460d9302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merlin-prediction-cpr\n",
      "merlin-prediction-cpr\n"
     ]
    }
   ],
   "source": [
    "! docker stop $SERVER_IMAGE\n",
    "! docker rm $SERVER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd45707-2c87-4148-bf69-25feb40a74a3",
   "metadata": {},
   "source": [
    "### Push the container once ready and testing is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9cf27ed-0c42-4cee-8116-44962bb57c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr]\n",
      "\n",
      "\u001b[1Bd3c4334f: Preparing \n",
      "\u001b[1Be72fcee7: Preparing \n",
      "\u001b[1Bb1721332: Preparing \n",
      "\u001b[1B22aee77e: Preparing \n",
      "\u001b[1B0d58e7c2: Preparing \n",
      "\u001b[1B6878a4fe: Preparing \n",
      "\u001b[1B2e747ad7: Preparing \n",
      "\u001b[1B46caf956: Preparing \n",
      "\u001b[1Bc4f4a731: Preparing \n",
      "\u001b[1B6f8ac904: Preparing \n",
      "\u001b[1B55970ccc: Preparing \n",
      "\u001b[1B1e82e910: Preparing \n",
      "\u001b[1B7c23e98f: Preparing \n",
      "\u001b[1B70ded861: Preparing \n",
      "\u001b[1Bda794091: Preparing \n",
      "\u001b[1B493f5d44: Preparing \n",
      "\u001b[1Bcaa9de82: Preparing \n",
      "\u001b[1B03ad2a31: Preparing \n",
      "\u001b[1B5e1b9e48: Preparing \n",
      "\u001b[1Bf4addbfc: Preparing \n",
      "\u001b[1B81e7ae87: Preparing \n",
      "\u001b[1B3d5ddcb4: Preparing \n",
      "\u001b[1Ba992b719: Preparing \n",
      "\u001b[1Bf10e020a: Preparing \n",
      "\u001b[1B7f70fff9: Preparing \n",
      "\u001b[1B2562fda1: Preparing \n",
      "\u001b[1Bdecbb6f6: Preparing \n",
      "\u001b[1B1cea2b76: Preparing \n",
      "\u001b[1Bfcaf77a9: Preparing \n",
      "\u001b[1Be31ca3c7: Preparing \n",
      "\u001b[1Bf58ddb35: Preparing \n",
      "\u001b[1B61786022: Preparing \n",
      "\u001b[1B1f7b3d75: Preparing \n",
      "\u001b[1Be5c17b0b: Preparing \n",
      "\u001b[1B15f32335: Preparing \n",
      "\u001b[1Bfb54d10a: Preparing \n",
      "\u001b[1B90be1950: Preparing \n",
      "\u001b[1B84fa095a: Preparing \n",
      "\u001b[1Bcab8959e: Preparing \n",
      "\u001b[1B7d764727: Preparing \n",
      "\u001b[1Bd4d05916: Preparing \n",
      "\u001b[1B34553782: Preparing \n",
      "\u001b[1Be86689d1: Preparing \n",
      "\u001b[1B6055545b: Preparing \n",
      "\u001b[1B1f9c0e0a: Preparing \n",
      "\u001b[1B75a3e25e: Preparing \n",
      "\u001b[1Bee8ae666: Preparing \n",
      "\u001b[1B64ca1ed9: Preparing \n",
      "\u001b[1B0b4929c1: Preparing \n",
      "\u001b[1Bd49243b5: Preparing \n",
      "\u001b[1B34ceba88: Preparing \n",
      "\u001b[1B0f0c03c7: Preparing \n",
      "\u001b[1B125f046a: Preparing \n",
      "\u001b[1Bbd207a0a: Preparing \n",
      "\u001b[1Bbc892765: Preparing \n",
      "\u001b[1B1eae2464: Preparing \n",
      "\u001b[1Bdf2e75c1: Preparing \n",
      "\u001b[1B7ce50d4c: Preparing \n",
      "\u001b[1B19fd6cda: Preparing \n",
      "\u001b[1Becf416c0: Preparing \n",
      "\u001b[1B279686b3: Preparing \n",
      "\u001b[1B9d3ddcc4: Preparing \n",
      "\u001b[1B337e69bc: Preparing \n",
      "\u001b[1Bd165751d: Preparing \n",
      "\u001b[1Bb4761a81: Preparing \n",
      "\u001b[1B72edea27: Preparing \n",
      "\u001b[1Ba215c94e: Preparing \n",
      "\u001b[1B811a91ed: Preparing \n",
      "\u001b[1B0409a05c: Preparing \n",
      "\u001b[1Bc13a8afd: Preparing \n",
      "\u001b[1Be8f11c1c: Preparing \n",
      "\u001b[1B4afe53fd: Preparing \n",
      "\u001b[1B130153a1: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1Bbbe6139c: Preparing \n",
      "\u001b[1B6d2c79f0: Preparing \n",
      "\u001b[1B31ee03b7: Preparing \n",
      "\u001b[1Bea05bcc3: Preparing \n",
      "\u001b[1Bb933fb0b: Preparing \n",
      "\u001b[1B162d4e6a: Preparing \n",
      "\u001b[1Bc5ba8f95: Preparing \n",
      "\u001b[1Bbe4d1ae6: Preparing \n",
      "\u001b[1B2e76641b: Preparing \n",
      "\u001b[1B925be13d: Preparing \n",
      "\u001b[1B7d9e38c0: Preparing \n",
      "\u001b[1Bb95254ee: Preparing \n",
      "\u001b[2Bb95254ee: Layer already exists kB84A\u001b[2K\u001b[82A\u001b[2K\u001b[78A\u001b[2K\u001b[74A\u001b[2K\u001b[70A\u001b[2K\u001b[67A\u001b[2K\u001b[64A\u001b[2K\u001b[87A\u001b[2K\u001b[58A\u001b[2K\u001b[53A\u001b[2K\u001b[50A\u001b[2K\u001b[49A\u001b[2K\u001b[45A\u001b[2K\u001b[43A\u001b[2K\u001b[37A\u001b[2K\u001b[38A\u001b[2K\u001b[31A\u001b[2K\u001b[28A\u001b[2K\u001b[21A\u001b[2K\u001b[20A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2Klatest: digest: sha256:bc2940aa3d063a294eb68a81092b3ef8af2132d80be26ec02924c0029e8f5235 size: 18617\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "!docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9a707-6965-4b6f-a3fe-7312dfddbf24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy to Vertex AI\n",
    "\n",
    "After the serving metadata is set below, the model is properly abstracted for use on Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166b499-b407-4e3e-99f3-da3f3031a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/1394482010205978624/operations/2804597770088873984\n"
     ]
    }
   ],
   "source": [
    "MODEL_DISPLAY_NAME = \"Merlin Spotify Query Tower Model - Workflow Local\"\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "#DEBUG FOR HARDCODING\n",
    "ARTIFACT_URI = 'gs://spotify-beam-v3/merlin-processed/workflow/query-tower-model-22-12'\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "        display_name=MODEL_DISPLAY_NAME,\n",
    "        artifact_uri=ARTIFACT_URI,\n",
    "        serving_container_image_uri=REMOTE_IMAGE_NAME,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        serving_container_command=[\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80231d-0430-478e-989a-4802adca17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-8\",\n",
    "                        accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "                        accelerator_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8b8fa58-c587-4b5d-9958-8ed904e0c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.3048475384712219, 0.0, 1.20887303352356, 0.05392575263977051, 0.0, 0.2725152969360352, 0.9764063954353333, 0.493643045425415, 0.0, 0.0, 0.5621761679649353, 0.0, 0.5690153241157532, 0.1336423009634018, 0.0, 0.0, 0.0, 0.0, 0.9370918273925781, 1.197081804275513, 0.3513412773609161, 0.0, 0.1948878020048141, 1.881629586219788, 0.05862289667129517, 0.0, 0.86396723985672, 0.3111485242843628, 0.0, 0.1899300664663315, 0.0, 0.003112689591944218, 0.1541297435760498, 0.6337419748306274, 0.2538793385028839, 0.0, 0.749478280544281, 0.0, 1.259817719459534, 0.02352931722998619, 0.0, 0.00845898874104023, 0.1811534762382507, 0.6338210105895996, 0.0, 0.09700654447078705, 0.008082814514636993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2053523659706116, 0.0, 0.1982176005840302, 0.0, 0.9934801459312439, 0.0, 0.0, 0.9782760143280029, 0.3004560768604279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30164635181427, 0.0, 0.02676838636398315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7641364932060242, 3.025083541870117, 0.0, 0.2146276980638504, 0.07093311846256256, 1.615533232688904, 0.1265367567539215, 0.5842932462692261, 0.0, 0.1736120879650116, 0.0, 0.0, 0.0, 0.05425655096769333, 0.0, 0.0, 0.3840464651584625, 0.005389871075749397, 0.0, 0.4074330925941467, 0.2348377555608749, 0.0, 0.0, 0.1731178909540176, 0.0, 2.581804990768433, 0.316681832075119, 0.3710601925849915, 0.6145276427268982, 0.6449678540229797, 0.4809104204177856, 2.7978355884552, 1.341815710067749, 0.0, 0.0, 0.0, 0.0, 1.563066482543945, 0.0, 0.05789778009057045, 0.0, 0.9206648468971252, 0.0, 0.0, 0.4432970583438873, 2.402736902236938, 0.0, 1.265844464302063, 0.0, 1.93057656288147, 0.0, 0.9535673260688782], [0.3048475384712219, 0.0, 1.20887303352356, 0.05392575263977051, 0.0, 0.2725152969360352, 0.9764063954353333, 0.493643045425415, 0.0, 0.0, 0.5621761679649353, 0.0, 0.5690153241157532, 0.1336423009634018, 0.0, 0.0, 0.0, 0.0, 0.9370918273925781, 1.197081804275513, 0.3513412773609161, 0.0, 0.1948878020048141, 1.881629586219788, 0.05862289667129517, 0.0, 0.86396723985672, 0.3111485242843628, 0.0, 0.1899300664663315, 0.0, 0.003112689591944218, 0.1541297435760498, 0.6337419748306274, 0.2538793385028839, 0.0, 0.749478280544281, 0.0, 1.259817719459534, 0.02352931722998619, 0.0, 0.00845898874104023, 0.1811534762382507, 0.6338210105895996, 0.0, 0.09700654447078705, 0.008082814514636993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2053523659706116, 0.0, 0.1982176005840302, 0.0, 0.9934801459312439, 0.0, 0.0, 0.9782760143280029, 0.3004560768604279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30164635181427, 0.0, 0.02676838636398315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7641364932060242, 3.025083541870117, 0.0, 0.2146276980638504, 0.07093311846256256, 1.615533232688904, 0.1265367567539215, 0.5842932462692261, 0.0, 0.1736120879650116, 0.0, 0.0, 0.0, 0.05425655096769333, 0.0, 0.0, 0.3840464651584625, 0.005389871075749397, 0.0, 0.4074330925941467, 0.2348377555608749, 0.0, 0.0, 0.1731178909540176, 0.0, 2.581804990768433, 0.316681832075119, 0.3710601925849915, 0.6145276427268982, 0.6449678540229797, 0.4809104204177856, 2.7978355884552, 1.341815710067749, 0.0, 0.0, 0.0, 0.0, 1.563066482543945, 0.0, 0.05789778009057045, 0.0, 0.9206648468971252, 0.0, 0.0, 0.4432970583438873, 2.402736902236938, 0.0, 1.265844464302063, 0.0, 1.93057656288147, 0.0, 0.9535673260688782]], deployed_model_id='679687301965545472', model_version_id='1', model_resource_name='projects/934903580331/locations/us-central1/models/1394482010205978624', explanations=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a prediction\n",
    "\n",
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c6edc-5687-47ea-871b-ac0b4bee1339",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finished - now go on to the next notebook to create a [matching engine notebook](03-matching-engine.ipynb) and test out the first end to end recommendation\n",
    "\n",
    "Be sure to use the output of the endpoint logs above to save the endpoint for use in the matching engine notebook\n",
    "\n",
    "e.g.:\n",
    "\n",
    "```python\n",
    "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
    "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/494907775848022016')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8835a-6d97-4458-9922-6dc8a7611939",
   "metadata": {},
   "source": [
    "### Timing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d09216e2-08fa-4519-b1f2-d2b9c04149ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 ms ± 33.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79cd6b35-6b3d-492b-9b8e-9f378098a60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 ms ± 17.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "endpoint.predict(instances=[[TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9cca042-9d79-4b66-835b-05935101babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/934903580331/locations/us-central1/endpoints/4736674102226452480\n",
      "Undeploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/4736674102226452480/operations/6606761755496415232\n",
      "Endpoint model undeployed. Resource name: projects/934903580331/locations/us-central1/endpoints/4736674102226452480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f0d1434ad10> \n",
       "resource name: projects/934903580331/locations/us-central1/endpoints/4736674102226452480"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.undeploy_all()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
