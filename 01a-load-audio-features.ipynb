{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVKyuWRezBGF"
   },
   "source": [
    "# Spotify API Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgGWdClhze9D"
   },
   "source": [
    "* Spotify Mlllion Playlist Dataset Challenge [Homepage](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n",
    "* [Spotify Web API docs](https://developer.spotify.com/documentation/web-api/reference/#/)\n",
    "\n",
    "**Community Examples**\n",
    "* [Extracting song lists](https://github.com/tojhe/recsys-spotify/blob/master/processing/songlist_extraction.py)\n",
    "* [construct audio features with Spotify API](https://github.com/tojhe/recsys-spotify/blob/master/processing/audio_features_construction.py)\n",
    "* [Using Spotify API](https://towardsdatascience.com/extracting-song-data-from-the-spotify-api-using-python-b1e79388d50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCbr2tLuzTJK"
   },
   "source": [
    "### pip & package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wwktfnCyzWO",
    "outputId": "6afe4a17-ebc2-40dc-d23a-1f447f394046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'jtotten-project' #update\n",
    "# PROJECT_ID = 'matching-engine-playlist'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0EYoIoQy8xq"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khc39YNHy98Z"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    USER_FLAG = ''\n",
    "else:\n",
    "    USER_FLAG = '--user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "RRSdCB_HSBSl",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b272ec83-d189-4a22-da3e-5ef650c574b7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotipy\n",
      "  Downloading spotipy-2.19.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spotipy) (1.15.0)\n",
      "Collecting requests>=2.25.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
      "\u001b[?25hCollecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 19.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
      "Installing collected packages: urllib3, requests, spotipy\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed requests-2.27.1 spotipy-2.19.0 urllib3-1.26.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "requests",
         "urllib3"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.2.1-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 10.4 MB/s \n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.7.1-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 50.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
      "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-2.2.3-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.3.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 4.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.56.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
      "Installing collected packages: google-crc32c, google-api-core, google-resumable-media, google-cloud-core, google-cloud-storage\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.26.3\n",
      "    Uninstalling google-api-core-1.26.3:\n",
      "      Successfully uninstalled google-api-core-1.26.3\n",
      "  Attempting uninstall: google-resumable-media\n",
      "    Found existing installation: google-resumable-media 0.4.1\n",
      "    Uninstalling google-resumable-media-0.4.1:\n",
      "      Successfully uninstalled google-resumable-media-0.4.1\n",
      "  Attempting uninstall: google-cloud-core\n",
      "    Found existing installation: google-cloud-core 1.0.3\n",
      "    Uninstalling google-cloud-core-1.0.3:\n",
      "      Successfully uninstalled google-cloud-core-1.0.3\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 1.18.1\n",
      "    Uninstalling google-cloud-storage-1.18.1:\n",
      "      Successfully uninstalled google-cloud-storage-1.18.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.2 which is incompatible.\n",
      "google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-api-core-2.7.1 google-cloud-core-2.2.3 google-cloud-storage-2.2.1 google-crc32c-1.3.0 google-resumable-media-2.3.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp\n",
      "  Downloading kfp-1.8.12.tar.gz (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 8.5 MB/s \n",
      "\u001b[?25hCollecting google-cloud-pipeline-components\n",
      "  Downloading google_cloud_pipeline_components-1.0.2-py3-none-any.whl (375 kB)\n",
      "\u001b[K     |████████████████████████████████| 375 kB 47.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.7/dist-packages (from kfp) (1.0.0)\n",
      "Collecting PyYAML<6,>=5.3\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 49.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from kfp) (2.7.1)\n",
      "Collecting google-cloud-storage<2,>=1.20.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 55.9 MB/s \n",
      "\u001b[?25hCollecting kubernetes<19,>=8.0.0\n",
      "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 57.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.7/dist-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from kfp) (1.35.0)\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
      "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.1.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
      "\u001b[?25hCollecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from kfp) (7.1.2)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.13.tar.gz (23 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.14\n",
      "  Downloading kfp_pipeline_spec-0.1.14-py3-none-any.whl (18 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 6.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from kfp) (3.17.3)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kfp) (3.0.1)\n",
      "Collecting pydantic<2,>=1.8.2\n",
      "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9 MB 47.5 MB/s \n",
      "\u001b[?25hCollecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py<2,>=0.9->kfp) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated<2,>=1.2.7->kfp) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.56.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.0.4)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.17.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (57.4.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.2.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp) (4.11.3)\n",
      "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.9)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.10)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Collecting google-cloud-notebooks>=0.4.0\n",
      "  Downloading google_cloud_notebooks-1.2.1-py2.py3-none-any.whl (343 kB)\n",
      "\u001b[K     |████████████████████████████████| 343 kB 68.9 MB/s \n",
      "\u001b[?25hCollecting google-cloud-aiplatform<2,>=1.11.0\n",
      "  Downloading google_cloud_aiplatform-1.11.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 43.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components) (1.21.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components) (21.3)\n",
      "Collecting proto-plus>=1.15.0\n",
      "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
      "\u001b[?25hCollecting grpcio-status<2.0dev,>=1.33.2\n",
      "  Downloading grpcio_status-1.44.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.44.0)\n",
      "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-2.34.3-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 49.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components) (3.0.7)\n",
      "Collecting protobuf<4,>=3.13.0\n",
      "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 57.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Building wheels for collected packages: kfp, docstring-parser, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kfp: filename=kfp-1.8.12-py3-none-any.whl size=419048 sha256=257d2efbc97c3c72a6dd15d544082bb7317c843433008010aed336e0da0ae5ed\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/0c/4a/3fc55077bc88cc17eacaae34c5fd3f6178c1d16d2ee3b0afdf\n",
      "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docstring-parser: filename=docstring_parser-0.13-py3-none-any.whl size=31866 sha256=b5255b4375974b284e2edfb1423d6f6638882ff0d6fec0e2b9e876728e3d47a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/88/3c/d1aa049309f7945178cac9fbe6561a86424f432da57c18ca0f\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=cf4c44139ac32a245d1406a50bf3f7a277e38c107db9ad75882a9661c15afb99\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.1-py3-none-any.whl size=95549 sha256=26ca0354d0825750b00d23e424bffd62cecc671eec075bada58b30c8a2d67a05\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/4e/2e/6795bd3ed456a43652e7de100aca275ec179c9a8dfbcc65626\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=9808eea00d34249ee71ed880ceb1dfeaab97528db959b6b1cc2eef42d488636f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
      "Successfully built kfp docstring-parser fire kfp-server-api strip-hints\n",
      "Installing collected packages: protobuf, grpcio-status, websocket-client, PyYAML, proto-plus, typer, strip-hints, requests-toolbelt, pydantic, kubernetes, kfp-server-api, kfp-pipeline-spec, jsonschema, google-cloud-storage, google-cloud-bigquery, fire, docstring-parser, Deprecated, cloudpickle, kfp, google-cloud-notebooks, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.3\n",
      "    Uninstalling protobuf-3.17.3:\n",
      "      Successfully uninstalled protobuf-3.17.3\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.3.3\n",
      "    Uninstalling jsonschema-4.3.3:\n",
      "      Successfully uninstalled jsonschema-4.3.3\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.2.1\n",
      "    Uninstalling google-cloud-storage-2.2.1:\n",
      "      Successfully uninstalled google-cloud-storage-2.2.1\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 1.21.0\n",
      "    Uninstalling google-cloud-bigquery-1.21.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.3.0\n",
      "    Uninstalling cloudpickle-1.3.0:\n",
      "      Successfully uninstalled cloudpickle-1.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.34.3 which is incompatible.\n",
      "nbclient 0.5.13 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
      "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed Deprecated-1.2.13 PyYAML-5.4.1 cloudpickle-2.0.0 docstring-parser-0.13 fire-0.4.0 google-cloud-aiplatform-1.11.0 google-cloud-bigquery-2.34.3 google-cloud-notebooks-1.2.1 google-cloud-pipeline-components-1.0.2 google-cloud-storage-1.44.0 grpcio-status-1.44.0 jsonschema-3.2.0 kfp-1.8.12 kfp-pipeline-spec-0.1.14 kfp-server-api-1.8.1 kubernetes-18.20.0 proto-plus-1.20.3 protobuf-3.20.0 pydantic-1.9.0 requests-toolbelt-0.9.1 strip-hints-0.1.10 typer-0.4.1 websocket-client-1.3.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (2.34.3)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (3.20.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.56.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.27.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-aiplatform) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.10)\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2022.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.44.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.35.0)\n",
      "Collecting aiohttp<4\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 12.2 MB/s \n",
      "\u001b[?25hCollecting fsspec==2022.3.0\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 57.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.6)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 45.3 MB/s \n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (3.10.0.2)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 59.4 MB/s \n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (2.0.12)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4->gcsfs) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.10.8)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (2.3.2)\n",
      "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (2.7.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (2.2.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (3.20.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage->gcsfs) (1.56.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage->gcsfs) (1.3.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, gcsfs\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 gcsfs-2022.3.0 multidict-6.0.2 yarl-1.7.2\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (2022.3.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'restart': True, 'status': 'ok'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spotify\n",
    "!pip install spotipy\n",
    "\n",
    "! pip3 install -U google-cloud-storage $USER_FLAG\n",
    "! pip3 install $USER kfp google-cloud-pipeline-components --upgrade\n",
    "# !git clone https://github.com/kubeflow/pipelines.git\n",
    "# !pip install pipelines/components/google-cloud/.\n",
    "\n",
    "# stable Vertex SDK\n",
    "!pip install google-cloud-aiplatform\n",
    "\n",
    "!pip install gcsfs\n",
    "!pip install fsspec\n",
    "\n",
    "# Download and install latest (preview) version of Vertex SDK\n",
    "# !pip install -U git+https://github.com/ivanmkc/python-aiplatform.git@imkc--matching-engine\n",
    "\n",
    "# OSS Scann for testing (OSS)\n",
    "# !pip install scann\n",
    "\n",
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irhbKrY3fcG8",
    "outputId": "2008a7ca-303d-4943-e56b-a57040c9abd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.12\n",
      "google_cloud_pipeline_components version: 1.0.2\n",
      "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
      "aiplatform SDK version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFyXP0_gYsGl",
    "outputId": "ea6ccb30-12b1-4537-efe3-acd3eeaa3fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [jtotten-project] or it does not exist.\n",
      "Are you sure you wish to set property [core/project] to jtotten-project?\n",
      "\n",
      "Do you want to continue (Y/n)?  Y\n",
      "\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "LOCATION = 'us-central1'\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "# PROJECT_ID = 'matching-engine-playlist'\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "\n",
    "import os\n",
    "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID\n",
    "\n",
    "# Required Pipeline Parameters\n",
    "PIPE_USER = 'jtott'  #  {type: 'string'} <--- TODO: CHANGE THIS\n",
    "\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "# BUCKET_NAME = 'spotify-million-playlists'\n",
    "\n",
    "GS_PIPELINE_ROOT_PATH = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, PIPE_USER)\n",
    "\n",
    "from google.colab import auth as colab_auth\n",
    "colab_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqhJlsodR-xX"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from io import BytesIO\n",
    "\n",
    "import time\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "# GCP\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rWNU-8n8__I"
   },
   "source": [
    "### clients & credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuJk9A5I9ZfF"
   },
   "source": [
    "GCP clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCbHe1G_gICe",
    "outputId": "c3f7d046-4997-4b59-9bcc-44df8feba2ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Setup clients\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID\n",
    ")\n",
    "\n",
    "pipeline_client = pipelines_client.AIPlatformClient(\n",
    "  project_id=PROJECT_ID,\n",
    "  region=LOCATION,\n",
    ")\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvxKv0M49cMR"
   },
   "source": [
    "Pipeline setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMPDTywpgpu-",
    "outputId": "37f31e4a-65d0-465e-cfda-7c9610d9aad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINES_FILEPATH: gs://matching-engine-content/pipelines/pipelines.json\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Stuff\n",
    "import os\n",
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = f'gs://{BUCKET_NAME}/pipelines/pipelines.json' # <--- TODO: CHANGE THIS; can be blank json file\n",
    "print(\"PIPELINES_FILEPATH:\", PIPELINES_FILEPATH)\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbeNm6_whXMG"
   },
   "source": [
    "# Create Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_EBGIHEh08d"
   },
   "source": [
    "### Union all the slices for single artist and audio feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "id": "VKyD_HCnhWCy",
    "outputId": "8c5fc121-01cb-4165-d548-6a567e47e3ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 3/3 [00:00<00:00, 559.29query/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f4561587-c234-463e-a476-db7d1403f1f5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4561587-c234-463e-a476-db7d1403f1f5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f4561587-c234-463e-a476-db7d1403f1f5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f4561587-c234-463e-a476-db7d1403f1f5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `jtotten-project.spotify_mpd.artists` as \n",
    "(select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_1`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_2`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_3`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_4`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_5`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_6`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_7`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_8`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_9`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_10`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_11`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMg7EesFolfc"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Split tracks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZnuGrDFLKS7"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                        #  'spotipy',\n",
    "                         'numpy','pandas','pyarrow',\n",
    "                         'absl-py',],\n",
    ")\n",
    "def split_tracks_data(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    all_tracks_filename: str,\n",
    ") -> NamedTuple('Outputs', [('all_tracks_split_1_gcs_uri', str),\n",
    "                            ('all_tracks_split_2_gcs_uri', str),\n",
    "                            ('all_tracks_split_3_gcs_uri', str),\n",
    "                            ('all_tracks_split_4_gcs_uri', str),\n",
    "                            ('all_tracks_split_5_gcs_uri', str),\n",
    "                            ('all_tracks_split_6_gcs_uri', str),\n",
    "                            ('all_tracks_split_7_gcs_uri', str),\n",
    "                            ('all_tracks_split_8_gcs_uri', str),\n",
    "                            ('all_tracks_split_9_gcs_uri', str),\n",
    "                            ('all_tracks_split_10_gcs_uri', str),\n",
    "                            ('all_tracks_split_11_gcs_uri', str),\n",
    "                            ]):\n",
    "  \n",
    "  import os\n",
    "  # import spotipy\n",
    "  # from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from absl import logging\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "\n",
    "  df = pd.read_csv(f'gs://{gcs_bucket}/{gcs_prefix_eda}/{all_tracks_filename}')\n",
    "  # print(f'Shape of {all_tracks_filename}: {df.shape}')\n",
    "  logging.info(f'Shape of {all_tracks_filename}: {df.shape}')\n",
    "  \n",
    "  all_tracks_split_1, all_tracks_split_2, all_tracks_split_3, all_tracks_split_4, all_tracks_split_5, all_tracks_split_6, all_tracks_split_7, all_tracks_split_8, all_tracks_split_9, all_tracks_split_10, all_tracks_split_11 = np.array_split(df, 11)#turning up to 11\n",
    "\n",
    "  # upload split to GCS\n",
    "  bucket = storage_client.get_bucket(f'{gcs_bucket}')\n",
    "\n",
    "  # ONE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_1.csv').upload_from_string(\n",
    "      all_tracks_split_1.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_1_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_1.csv'\n",
    "\n",
    "  # TWO\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_2.csv').upload_from_string(\n",
    "      all_tracks_split_2.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_2_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_2.csv'\n",
    "\n",
    "  # THREE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_3.csv').upload_from_string(\n",
    "      all_tracks_split_3.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_3_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_3.csv'\n",
    "\n",
    "  # FOUR\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_4.csv').upload_from_string(\n",
    "      all_tracks_split_4.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_4_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_4.csv'\n",
    "\n",
    "  logging.info(f'all_tracks_split_1_gcs_uri {all_tracks_split_1_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_2_gcs_uri {all_tracks_split_2_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_3_gcs_uri {all_tracks_split_3_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_4_gcs_uri {all_tracks_split_4_gcs_uri}')\n",
    "\n",
    "    # FIVE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_5.csv').upload_from_string(\n",
    "      all_tracks_split_5.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_5_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_5.csv'\n",
    "\n",
    "  # SIX\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_6.csv').upload_from_string(\n",
    "      all_tracks_split_6.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_6_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_6.csv'\n",
    "\n",
    "  # SEVEN\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_7.csv').upload_from_string(\n",
    "      all_tracks_split_7.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_7_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_7.csv'\n",
    "\n",
    "  # EIGHT\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_8.csv').upload_from_string(\n",
    "      all_tracks_split_8.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_8_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_8.csv'\n",
    "\n",
    "  logging.info(f'all_tracks_split_5_gcs_uri {all_tracks_split_5_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_6_gcs_uri {all_tracks_split_6_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_7_gcs_uri {all_tracks_split_7_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_8_gcs_uri {all_tracks_split_8_gcs_uri}')\n",
    "\n",
    "  # NINE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_9.csv').upload_from_string(\n",
    "      all_tracks_split_9.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_9_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_9.csv'\n",
    "\n",
    "  # TEN\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_10.csv').upload_from_string(\n",
    "      all_tracks_split_10.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_10_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_10.csv'\n",
    "\n",
    "  # ELEVEN\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_11.csv').upload_from_string(\n",
    "      all_tracks_split_11.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_11_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_11.csv'\n",
    "\n",
    "\n",
    "  logging.info(f'all_tracks_split_9_gcs_uri {all_tracks_split_9_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_10_gcs_uri {all_tracks_split_10_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_11_gcs_uri {all_tracks_split_11_gcs_uri}')\n",
    "\n",
    "\n",
    "  return(\n",
    "      f'{all_tracks_split_1_gcs_uri}',\n",
    "      f'{all_tracks_split_2_gcs_uri}',\n",
    "      f'{all_tracks_split_3_gcs_uri}',\n",
    "      f'{all_tracks_split_4_gcs_uri}',\n",
    "      f'{all_tracks_split_5_gcs_uri}',\n",
    "      f'{all_tracks_split_6_gcs_uri}',\n",
    "      f'{all_tracks_split_7_gcs_uri}',\n",
    "      f'{all_tracks_split_8_gcs_uri}',\n",
    "      f'{all_tracks_split_9_gcs_uri}',\n",
    "      f'{all_tracks_split_10_gcs_uri}',\n",
    "      f'{all_tracks_split_11_gcs_uri}',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz3gXiBZo-s2"
   },
   "source": [
    "## Call Spotify Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m3D974DjTbE"
   },
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86ZuQqElhZrS"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec', 'google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4'])\n",
    "def call_spotify_api_split_audio(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    all_tracks_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: int,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_feat_split_1_gcs_uri', str),]):\n",
    "  print(f'pip install complete')\n",
    "  import os\n",
    "  import spotipy\n",
    "  from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import warnings\n",
    "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "  from absl import logging\n",
    "  from google.cloud import bigquery\n",
    "  import pandas_gbq\n",
    "\n",
    "  # print(f'package import complete')\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "  logging.info(f'package import complete')\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "  split=f'split_{split_id}'\n",
    "\n",
    "  logging.info(f'Extracting audio features and recommendations for {split} \\n')\n",
    "\n",
    "\n",
    "  logging.info(f'spotipy auth complete')\n",
    "  def spot_audio_features(uri, client_id, client_secret):\n",
    "    \n",
    "    # Authenticate\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=client_id, \n",
    "        client_secret=client_secret\n",
    "    )\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager = client_credentials_manager, \n",
    "        requests_timeout=10, \n",
    "        retries=10 )\n",
    "    ############################################################################\n",
    "    # Create Track Audio Features DF for Split\n",
    "    ############################################################################\n",
    "\n",
    "    #Audio features\n",
    "    uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "    a_feats = sp.audio_features(uri)\n",
    "    features = pd.json_normalize(a_feats, ).to_dict('list')\n",
    "    if features is None:\n",
    "      features = {}\n",
    "    #Artist of the track, for genres and popularity\n",
    "    popularity = []\n",
    "    #tracks API call\n",
    "    tracks = sp.tracks(uri)\n",
    "    # if tracks:\n",
    "    for track in tracks['tracks']:\n",
    "      if track is not None:\n",
    "        popularity.append(track['popularity'])\n",
    "      else:\n",
    "        popularity.append(-1)\n",
    "\n",
    "    audio_df = pd.DataFrame(features)\n",
    "    audio_df['popularity'] = popularity\n",
    "    audio_df['track_uri'] = uri\n",
    "    return audio_df\n",
    "\n",
    "  bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "  )\n",
    "\n",
    "  audio_featureDF = pd.DataFrame()\n",
    " \n",
    "  query = f\"\"\"select count(1) as count from `jtotten-project.spotify_mpd.unique_tracks` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.track_uri NOT IN (SELECT track_uri FROM `jtotten-project.spotify_mpd.track_audio_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "  uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "  uri_list_length = uri_list_length_df['count'][0]\n",
    "  \n",
    "  count = 1\n",
    "  uri_batch = []\n",
    "  # handling bad track/artist_uris\n",
    "\n",
    "  #refactor\n",
    "  schema = [{'name':'danceability', 'type': 'FLOAT'},\t\n",
    "            {'name':'energy', 'type': 'FLOAT'},\t\n",
    "            {'name':'key', 'type': 'FLOAT'},\t\n",
    "            {'name':'loudness', 'type': 'FLOAT'},\t\n",
    "            {'name':'mode', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'speechiness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'acousticness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'instrumentalness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'liveness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'valence', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'followers', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'tempo', 'type': 'FLOAT'},\n",
    "            {'name':'type', 'type': 'STRING'},\n",
    "            {'name':'id', 'type': 'STRING'},\n",
    "            {'name':'uri', 'type': 'STRING'},\n",
    "            {'name':'track_href', 'type': 'STRING'},\n",
    "            {'name':'analysis_url', 'type': 'STRING'},\n",
    "            {'name':'duration_ms_y', 'type': 'FLOAT'},\n",
    "            {'name':'time_signature', 'type': 'FLOAT'},\n",
    "            {'name':'popularity', 'type': 'INT64'},\n",
    "            {'name':'track_uri', 'type': 'STRING'},\n",
    "  ]\n",
    "  query = f\"\"\"select track_uri from `jtotten-project.spotify_mpd.unique_tracks` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.track_uri NOT IN (SELECT track_uri FROM `jtotten-project.spotify_mpd.track_audio_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "\n",
    "  tracks = bq_client.query(query).result().to_dataframe()\n",
    "  track_list = tracks.track_uri.to_list()\n",
    "  for uri in track_list:\n",
    "    if count % 50 == 0 or uri_list_length == count: #grab a batch of 50 songs\n",
    "      uri_batch.append(uri)\n",
    "      ### Try catch block for function\n",
    "      try:\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "        \n",
    "      except ReadTimeout:\n",
    "        logging.info(\"'Spotify timed out... trying again...'\")\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "      except HTTPError as err: #JW ADDED\n",
    "        logging.info(f\"HTTP Error: {err}\")\n",
    "      except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "        logging.info(f\"Spotify error: {spotify_error}\")\n",
    "      try:\n",
    "        audio_featureDF.to_gbq(\n",
    "            destination_table=f'spotify_mpd.track_audio_{split_id}', \n",
    "            project_id=f'{project}', # TODO: param\n",
    "            location='us-central1', \n",
    "            # table_schema=schema,\n",
    "            progress_bar=False, \n",
    "            reauth=False, \n",
    "            if_exists='append'\n",
    "            )\n",
    "      except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "        logging.info('invalid schema, skipping')\n",
    "        pass\n",
    "      logging.info(f'{count} of {uri_list_length} complete!')\n",
    "      uri_batch = []\n",
    "      count += 1\n",
    "      time.sleep(sleep_param)\n",
    "    else:\n",
    "      uri_batch.append(uri)\n",
    "      count += 1\n",
    "      \n",
    "      \n",
    "  logging.info(f'audio features appended')\n",
    "\n",
    "  return (\n",
    "      f'DONE',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hppPSwkh1x2"
   },
   "source": [
    "### Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYbgsLrtxPHl"
   },
   "outputs": [],
   "source": [
    "### Artist racks api call\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',' google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4'])\n",
    "def call_spotify_api_split_artist(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    all_tracks_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: int,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_feat_split_1_gcs_uri', str),]):\n",
    "  print(f'pip install complete')\n",
    "  import os\n",
    "  import spotipy\n",
    "  from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import warnings\n",
    "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "  from absl import logging\n",
    "  from google.cloud import bigquery\n",
    "  import pandas_gbq\n",
    "  # print(f'package import complete')\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "  logging.info(f'package import complete')\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "  split='split_1'\n",
    "\n",
    "  # print(f'Extracting audio features and recommendations for {split} \\n')\n",
    "  logging.info(f'Extracting audio features and recommendations for {split} \\n')\n",
    "\n",
    "  # client_id='2dce494e64a74be980138668f4402b97'\n",
    "  # client_secret='1706fc14574a4fef9132aaaacb31aa1c'\n",
    "\n",
    "  logging.info(f'spotipy auth complete')\n",
    "  def spot_audio_features(uri, client_id, client_secret):\n",
    "    \n",
    "    # Authenticate\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=client_id, \n",
    "        client_secret=client_secret\n",
    "    )\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager = client_credentials_manager, \n",
    "        requests_timeout=10, \n",
    "        retries=10 )\n",
    "    ############################################################################\n",
    "    # Create Track Audio Features DF for Split\n",
    "    ############################################################################\n",
    "\n",
    "    #Audio features\n",
    "\n",
    "    #Artist of the track, for genres and popularity\n",
    "    features = {}\n",
    "    #tracks API call\n",
    "    # if tracks:\n",
    "\n",
    "    #artists api call\n",
    "    uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "    artists = sp.artists(uri)\n",
    "\n",
    "    artist_pop = []\n",
    "    artist_genres = []\n",
    "    followers = []\n",
    "    id_list = uri\n",
    "    for artist in artists['artists']:\n",
    "      if artist is not None:\n",
    "        artist_pop.append(artist['popularity'])\n",
    "        artist_genres.append(artist['genres'])\n",
    "        # if artist['followers']['total'] is None:\n",
    "        followers.append(artist['followers']['total'])\n",
    "        # else:\n",
    "        #   followers.append(-1)\n",
    "      else:\n",
    "        artist_pop.append(-1)\n",
    "        artist_genres.append('unknown')\n",
    "\n",
    "    # logging.info(print(f\"artist: {artist_pop}\"))\n",
    "    # logging.info(print(f\"genres: {artist_genres}\"))\n",
    "    # logging.info(print(f\"followers: {followers}\"))\n",
    "    features[\"artist_pop\"] = artist_pop\n",
    "    features[\"genres\"] = artist_genres\n",
    "    features['followers'] = followers\n",
    "    features['artist_uri'] = id_list\n",
    "    audio_df = pd.DataFrame(features)\n",
    "    audio_df['genres'] = audio_df['genres'].astype(str)\n",
    "    # logging.info(print(audio_df)) #logging\n",
    "    return audio_df\n",
    "\n",
    "  bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "  )\n",
    "\n",
    "  \n",
    "\n",
    "  logging.info(f'finished downloading tracks for split {split_id}')\n",
    "  query = f\"\"\"select count(1) as count from `jtotten-project.spotify_mpd.unique_artists` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.artist_uri NOT IN (SELECT artist_uri FROM `jtotten-project.spotify_mpd.track_artist_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "  uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "  n_artists = uri_list_length_df['count'][0]\n",
    "  logging.info(f'number of distinct artists: {n_artists}')\n",
    "  audio_featureDF = pd.DataFrame()\n",
    "  uri_list_length = n_artists\n",
    "  \n",
    "\n",
    "  schema = [{'name': 'artist_pop', 'type': \t'INTEGER'\t},\t\n",
    "            {'name':'genres', 'type': \t'STRING'\t},\t\n",
    "            {'name':'followers', 'type': \t'INTEGER'\t},\t\n",
    "            {'name':'artist_uri', 'type': 'STRING'}\n",
    "  ]\n",
    "  count = 1\n",
    "  uri_batch = []\n",
    "  # handling bad track/artist_uris\n",
    "  query = f\"\"\"select artist_uri from `jtotten-project.spotify_mpd.unique_artists` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.artist_uri NOT IN (SELECT artist_uri FROM `jtotten-project.spotify_mpd.track_artist_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "\n",
    "  ats = bq_client.query(query).result().to_dataframe()\n",
    "  artist_set = ats.artist_uri.to_list()\n",
    "  for uri in artist_set:\n",
    "    if count % 50 == 0 or uri_list_length == count: #grab a batch of 50 artists\n",
    "      uri_batch.append(uri)\n",
    "      ### Try catch block for function\n",
    "      try:\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "      except ReadTimeout:\n",
    "        logging.info(\"'Spotify timed out... trying again...'\")\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "      except HTTPError as err: #JW ADDED\n",
    "        logging.info(f\"HTTP Error: {err}\")\n",
    "      except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "        logging.info(f\"Spotify error: {spotify_error}\")\n",
    "      try:\n",
    "        audio_featureDF.to_gbq(\n",
    "            destination_table=f'spotify_mpd.track_artist_{split_id}', \n",
    "            project_id=f'{project}', # TODO: param\n",
    "            location='us-central1', \n",
    "            # table_schema=schema,\n",
    "            progress_bar=False, \n",
    "            reauth=False, \n",
    "            if_exists='append'\n",
    "            )\n",
    "      except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "        logging.info('invalid schema, skipping')\n",
    "        pass\n",
    "      logging.info(f'{count} of {uri_list_length} complete!')\n",
    "      uri_batch = []\n",
    "      count += 1\n",
    "\n",
    "      time.sleep(sleep_param)\n",
    "\n",
    "    else:\n",
    "      uri_batch.append(uri)\n",
    "      count += 1\n",
    "\n",
    "  return (\n",
    "      f'DONE',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma5qzpGkuYhD"
   },
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EFH8b10ucf3",
    "outputId": "44cd822f-2097-42ca-941b-d0a7ffb2a970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: v3-spotify-feature-enrich\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'jtotten-project'\n",
    "# PROJECT_ID = 'matching-engine-playlist'\n",
    "LOCATION = 'us-central1'\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "# BUCKET_NAME = 'spotify-million-playlists'\n",
    "\n",
    "PIPELINE_VERSION = 'v3' # pipeline code\n",
    "PIPELINE_TAG = f'{PIPELINE_VERSION}-spotify-feature-enrich'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)\n",
    "\n",
    "VERSION = 'v5' # general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Buwtyt7rugt4"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    all_tracks_filename: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    sleep_param: int = 10,\n",
    "    parallel_creds: str = json.dumps([\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_1.csv',\n",
    "                                          'api_key': '3ab5af00e21b44b0bee976289d9da168',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 1\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_2.csv',\n",
    "                                          'api_key': '52ca2066dfeb434ab832e6e9c709b9e7',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 2\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_3.csv',\n",
    "                                          'api_key': '127935a08a294e5292a79cf54a4fcce2',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 3\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_4.csv',\n",
    "                                          'api_key': 'bc5bde5fae56491c997fb1e351560335',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 4\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_5.csv',\n",
    "                                          'api_key': 'f6f2bc364a7b49bab47c1d6df9f1882a',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 5\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_6.csv',\n",
    "                                          'api_key': '7283d7c69e2f49dfbe81a07266e512e7',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 6\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_7.csv',\n",
    "                                          'api_key': '4ff7390e97f643c3a0b4ebc2fa7d9c99',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 7\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_8.csv',\n",
    "                                          'api_key': '8bf5485e4ee843da80c67da2906b616c',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 8\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_9.csv',\n",
    "                                          'api_key': '963f4982976443d89b7f052293f6e590',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 9\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_10.csv',\n",
    "                                          'api_key': '49efce4863e140c4944da92e53ac1200',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 10\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_11.csv',\n",
    "                                          'api_key': '8cc933ca4892433b92d0478ee4a123e6',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 11\n",
    "                                      }\n",
    "                                      ],\n",
    "                                     sort_keys=True)\n",
    "):\n",
    "\n",
    "    split_tracks_data_op = split_tracks_data(\n",
    "      project=project,\n",
    "      location=location,\n",
    "      gcs_bucket=gcs_bucket,\n",
    "      gcs_prefix_eda=gcs_prefix_eda,\n",
    "      all_tracks_filename=all_tracks_filename,\n",
    "    )\n",
    "\n",
    "\n",
    "  with dsl.ParallelFor(parallel_creds) as item:\n",
    "    call_spotify_api_split_artist_op = call_spotify_api_split_artist(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        all_tracks_split_1_gcs_uri=item.data,\n",
    "        gcs_bucket=gcs_bucket,\n",
    "        gcs_prefix_eda=gcs_prefix_eda,\n",
    "        client_id=item.api_key,\n",
    "        client_secret=item.secret_,\n",
    "        sleep_param=3,\n",
    "        split_id=item.split\n",
    "    )\n",
    "\n",
    "    call_spotify_api_split_audio_op = call_spotify_api_split_audio(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        all_tracks_split_1_gcs_uri=item.data,\n",
    "        gcs_bucket=gcs_bucket,\n",
    "        gcs_prefix_eda=gcs_prefix_eda,\n",
    "        client_id=item.api_key,\n",
    "        client_secret=item.secret_,\n",
    "        sleep_param=3,\n",
    "        split_id=item.split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoBsfT1IyIXd",
    "outputId": "50a65461-1c7c-44c0-9362-5524aaac21c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evUgOHllykr5"
   },
   "outputs": [],
   "source": [
    "# jtotten-project #\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "LOCATION = 'us-central1'\n",
    "GCS_BUCKET = 'matching-engine-content'\n",
    "GCS_PREFIX_EDA = 'spotify-million-playlist/eda'\n",
    "ALL_TRACKS_FILENAME = 'all_tracks_v2.csv'\n",
    "BQ_PROJECT = 'jtotten-project' \n",
    "BQ_DATASET = 'spotify_mpd' # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTCHINT_1uti",
    "outputId": "c96f1c21-612f-4e5d-d33a-fd4d236e7b2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/v5-v3-spotify-feature-enrich-20220406144428?project=jtotten-project\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overwrite = True\n",
    "# overwrite = False\n",
    "\n",
    "if not PIPELINES.get('train') or overwrite:\n",
    "  response = pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path='custom_container_pipeline_spec.json',\n",
    "    parameter_values={\n",
    "        'project': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'gcs_bucket': GCS_BUCKET,\n",
    "        'gcs_prefix_eda': GCS_PREFIX_EDA,\n",
    "        'all_tracks_filename': ALL_TRACKS_FILENAME,\n",
    "        'bq_project': BQ_PROJECT,\n",
    "        'bq_dataset': BQ_DATASET,\n",
    "    },\n",
    "    pipeline_root=f'{GS_PIPELINE_ROOT_PATH}/{VERSION}',\n",
    "  )\n",
    "  PIPELINES['train'] = response['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TB4IIjC0rI_"
   },
   "source": [
    "# README"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract-spotify-features-pipeline-parallel-for.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
