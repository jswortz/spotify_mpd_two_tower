{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def6ede0-6b1f-4fcf-a63e-be0cf6771472",
   "metadata": {},
   "source": [
    "# Scaling TFRS Ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776115df-133d-4c8b-940a-127ef69b6041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.26.1\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85405e2a-9f5b-4b8f-9e51-cc7562d2e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/jw-repo2/spotify_mpd_two_tower'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/home/jupyter/jw-repo2/spotify_mpd_two_tower'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627eafc-c4de-4c7b-a5b1-0eabc8c1c8f0",
   "metadata": {},
   "source": [
    "## Load env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199107d-83e4-45cd-b77c-1a3d6f4efe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # naming convention for all cloud resources\n",
    "# VERSION        = \"v1\"                  # TODO\n",
    "# PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "# print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159fe93-e9fc-4d7f-8fef-38940e70232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # staging GCS\n",
    "# GCP_PROJECTS             = !gcloud config get-value project\n",
    "# PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# # GCS bucket and paths\n",
    "# BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "# BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "# config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "# print(config.n)\n",
    "# exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817c1d1-6bfb-42f1-9c87-226a082e1ecc",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91225b3b-51f3-4109-b62c-27ab47a3acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID     = hybrid-vertex\n",
      "PROJECT_NUM    = 934903580331\n",
      "VERTEX_SA      = 934903580331-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# creds, PROJECT_ID = google.auth.default()\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com' # 934903580331\n",
    "REGION                   = 'us-central1'\n",
    "\n",
    "print(f\"PROJECT_ID     = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM    = {PROJECT_NUM}\")\n",
    "print(f\"VERTEX_SA      = {VERTEX_SA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3f3418-cb9f-4463-9758-dce34c7f9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import logging\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5608eb33-fefc-474c-a5a6-5f3fcd809b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52184e20-264c-4983-840e-5bfb3c32f140",
   "metadata": {},
   "source": [
    "### update vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cfad4a-a2e3-4e96-b2c9-80b23d0ec8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME        = Dockerfile_rank\n"
     ]
    }
   ],
   "source": [
    "# DOCKERNAME                = 'rank'\n",
    "# print(f\"DOCKERNAME        = {DOCKERNAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4cfc4e-b43d-4ca0-97b0-80ddbccbca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_ROOT_NAME: sp-rank-tfrs-v11\n"
     ]
    }
   ],
   "source": [
    "# VERSION                   = \"v11\"\n",
    "# APP                       = 'sp'\n",
    "MODEL_TYPE                = 'rank'\n",
    "# FRAMEWORK                 = 'tfrs'\n",
    "MODEL_ROOT_NAME           = f'{APP}-{MODEL_TYPE}-{FRAMEWORK}-{VERSION}'\n",
    "\n",
    "print(f\"MODEL_ROOT_NAME: {MODEL_ROOT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd0d64-e573-41d4-bc07-aa7704dd119b",
   "metadata": {},
   "source": [
    "## Create training package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fdd1c7a-533a-41d9-96e9-b782660993cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "TRAIN_SUBFOLDER = 'ranking'\n",
    "\n",
    "# ! rm -rf $REPO_DOCKER_PATH_PREFIX/$TRAIN_SUBFOLDER\n",
    "# ! mkdir -p $REPO_DOCKER_PATH_PREFIX/$TRAIN_SUBFOLDER\n",
    "# ! touch $REPO_DOCKER_PATH_PREFIX/$TRAIN_SUBFOLDER/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b04eb-3f50-4f98-8b6e-6f40f1cc5972",
   "metadata": {},
   "source": [
    "### train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f8b760-ca79-49f9-b2fa-e0bd063fe7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ranking/train_config.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/{TRAIN_SUBFOLDER}/train_config.py\n",
    "# PROJECT_ID='hybrid-vertex'\n",
    "# MAX_PLAYLIST_LENGTH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0525ab2-80f8-4b4d-ac65-fc165f5e8bab",
   "metadata": {},
   "source": [
    "### requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ca2bc37-ee81-4ce3-8738-9b311346f2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ranking/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/{TRAIN_SUBFOLDER}/requirements.txt\n",
    "# google-cloud-aiplatform>=1.26.1\n",
    "# tensorflow-recommenders==0.7.2\n",
    "# tensorboard==2.10.1\n",
    "# tensorboard-data-server==0.6.1\n",
    "# tensorboard-plugin-profile==2.11.1\n",
    "# tensorflow-io==0.27.0\n",
    "# google-cloud-aiplatform[cloud_profiler]>=1.26.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bf10a-253e-4c9e-878f-69bd41a2294d",
   "metadata": {},
   "source": [
    "### dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ef06c6-28d4-4ccf-9f77-974994bcedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "# docker rm $(docker ps -aq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0fbe385-c753-4d0c-8c8c-b38fb2ed5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/Dockerfile_rank\n"
     ]
    }
   ],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/{DOCKERNAME}\n",
    "\n",
    "# # FROM tensorflow/tensorflow:2.10.1-gpu\n",
    "# FROM gcr.io/deeplearning-platform-release/tf-gpu.2-11\n",
    "\n",
    "# ENV PYTHONUNBUFFERED True\n",
    "\n",
    "# # Copies the trainer code to the docker image.\n",
    "# # COPY ranking/* ./\n",
    "# COPY ranking /ranking\n",
    "\n",
    "# WORKDIR /ranking\n",
    "\n",
    "# RUN pip install --upgrade pip\n",
    "# # RUN pip install --no-cache-dir -r ./requirements.txt\n",
    "# RUN pip install -r ./requirements.txt\n",
    "\n",
    "# RUN apt update && apt -y install nvtop\n",
    "\n",
    "# # RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96344aef-627a-4425-9246-a6337748b73f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Optional) Build Training image with Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9593b794-3dec-4b29-be78-b9ce4560934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY        = tfrs-ranking\n",
      "IMAGE_NAME        = sp-rank-tfrs-v11\n",
      "REMOTE_IMAGE_NAME = us-central1-docker.pkg.dev/hybrid-vertex/tfrs-ranking/sp-rank-tfrs-v11\n"
     ]
    }
   ],
   "source": [
    "# REPOSITORY                = \"tfrs-ranking\"  # f'{APP}-{FRAMEWORK}'\n",
    "# IMAGE_NAME                = f'{MODEL_ROOT_NAME}'\n",
    "\n",
    "# REMOTE_IMAGE_NAME         = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME}\"\n",
    "\n",
    "# print(f\"REPOSITORY        = {REPOSITORY}\")\n",
    "# print(f\"IMAGE_NAME        = {IMAGE_NAME}\")\n",
    "# print(f\"REMOTE_IMAGE_NAME = {REMOTE_IMAGE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee875ac-3a83-45ed-95af-4469a0eb9fe3",
   "metadata": {},
   "source": [
    "#### Create Artifact Repository\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c915d1b5-1f7b-4395-aabd-d9504d6ae7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48081c82-f673-417d-af3b-dfca82470624",
   "metadata": {},
   "source": [
    "#### config docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2299b27a-705d-4323-8d45-d24c3582c76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "# ! gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8883d6a-e5e5-49d7-b842-43a52f98c039",
   "metadata": {},
   "source": [
    "#### local build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df449b4c-6cdf-4084-a078-cee921455233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy these commands into terminal:\n",
      "\n",
      "export REMOTE_IMAGE_NAME=us-central1-docker.pkg.dev/hybrid-vertex/tfrs-ranking/sp-rank-tfrs-v11\n",
      "export DOCKERNAME=Dockerfile_rank\n",
      "docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME .\n"
     ]
    }
   ],
   "source": [
    "# # # set variables if running in terminal\n",
    "# print(\"copy these commands into terminal:\\n\")\n",
    "# print(f\"export REMOTE_IMAGE_NAME={REMOTE_IMAGE_NAME}\")\n",
    "# print(f\"export DOCKERNAME={DOCKERNAME}\")\n",
    "# print(f\"docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME .\")\n",
    "\n",
    "# # ! docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6b514-eccc-4c59-ace3-3c92b4301896",
   "metadata": {},
   "source": [
    "### Push image to registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e23bea8-a0d7-4347-aa44-623a94ed9f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy this command into terminal:\n",
      "\n",
      "docker push $REMOTE_IMAGE_NAME\n"
     ]
    }
   ],
   "source": [
    "# print(\"copy this command into terminal:\\n\")\n",
    "# print(f\"docker push $REMOTE_IMAGE_NAME\")\n",
    "\n",
    "# # ! docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c9616-ac61-4ec2-8fef-58db5482a9e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Optional) Build Training image with Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912ea065-ff16-4526-9ab1-853e949efff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME       : Dockerfile_rank\n",
      "IMAGE_URI        : gcr.io/hybrid-vertex/sp-rank-tfrs-v6\n",
      "MACHINE_TYPE     : e2-highcpu-32\n",
      "FILE_LOCATION    : ./src\n"
     ]
    }
   ],
   "source": [
    "# # Docker definitions for training\n",
    "# IMAGE_NAME               = f'{MODEL_ROOT_NAME}'\n",
    "# IMAGE_URI                = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "\n",
    "# DOCKERNAME               = 'Dockerfile_rank'\n",
    "# MACHINE_TYPE             = 'e2-highcpu-32'\n",
    "# FILE_LOCATION            = './src'\n",
    "\n",
    "# print(f\"DOCKERNAME       : {DOCKERNAME}\")\n",
    "# print(f\"IMAGE_URI        : {IMAGE_URI}\")\n",
    "# print(f\"MACHINE_TYPE     : {MACHINE_TYPE}\")\n",
    "# print(f\"FILE_LOCATION    : {FILE_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d71f3-b392-4856-8988-fee7307f5f6b",
   "metadata": {},
   "source": [
    "### CloudBuild YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8d2df-a14d-4e25-a055-f0c4796f4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile {REPO_DOCKER_PATH_PREFIX}/cloudbuild.yaml\n",
    "\n",
    "# steps:\n",
    "# - name: 'gcr.io/cloud-builders/docker'\n",
    "#   args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/Dockerfile.$_DOCKERNAME']\n",
    "# images:\n",
    "# - '$_IMAGE_URI'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7535d5a-410b-4281-9cda-1603d07d4339",
   "metadata": {},
   "source": [
    "### set gcloudignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a19a91b-603a-4b72-823e-8fd44aa90824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gcloud config set gcloudignore/enabled true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a2d47cc-7910-4929-96f6-da0e9fd05798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d94248a4-704a-451c-98d3-1acf4b6d428b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gcloud builds submit --config src/cloudbuild.yaml \\\n",
    "#     --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "#     --timeout=2h \\\n",
    "#     --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5adf4-a7fe-478b-9233-5b128f22a179",
   "metadata": {},
   "source": [
    "## Prepare Train Job Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b4f8399-1ab4-4960-97d6-2ce0e7bbd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('vocab_dict.pkl', 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5ddcc94-265e-4516-abbe-cf265f1100a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_name_src\n",
      "track_name_pl\n",
      "artist_name_pl\n",
      "album_name_pl\n",
      "artist_genres_pl\n",
      "tracks_playlist_titles_pl\n",
      "track_name_can\n",
      "artist_name_can\n",
      "album_name_can\n",
      "artist_genres_can\n",
      "track_pl_titles_can\n"
     ]
    }
   ],
   "source": [
    "for keys in vocab_dict:\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42084abc-38f4-4f5c-b492-bd6ab92e5212",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Accelerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0e93842-78dd-40fc-a85a-fc558e48c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A100 (40GB)\n",
    "# WORKER_MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "# REPLICA_COUNT = 1\n",
    "# ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "# PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "# REDUCTION_SERVER_COUNT = 0                                                      \n",
    "# REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "# DISTRIBUTE_STRATEGY = 'single'\n",
    "\n",
    "### A100 (80GB)\n",
    "# WORKER_MACHINE_TYPE = 'a2-ultragpu-1g'\n",
    "# REPLICA_COUNT = 1\n",
    "# ACCELERATOR_TYPE = 'NVIDIA_A100_80GB'\n",
    "# PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "# REDUCTION_SERVER_COUNT = 0                                                      \n",
    "# REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "# DISTRIBUTE_STRATEGY = 'single'\n",
    "\n",
    "### Tesla T4\n",
    "WORKER_MACHINE_TYPE = 'n1-standard-16'\n",
    "REPLICA_COUNT = 1\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_T4' # NVIDIA_TESLA_T4 NVIDIA_TESLA_V100\n",
    "PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "DISTRIBUTE_STRATEGY = 'single'\n",
    "REDUCTION_SERVER_COUNT = 0                                                      \n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "REGION = \"asia-southeast1\"  # \"us-east1\" | \"us-central1\" | europe-west4 | asia-southeast1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0afb97-e578-4d12-96f5-a5d64434b2d8",
   "metadata": {},
   "source": [
    "### Vertex Experiments\n",
    "create an experiemnt and experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff97719d-6676-4a9d-a9a2-d5c03e736b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: audio-ranker-opt-v11\n",
      "RUN_NAME: run-20230703-155351\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_PREFIX = 'audio-ranker-opt'\n",
    "EXPERIMENT_NAME=f'{EXPERIMENT_PREFIX}-{VERSION}'\n",
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab8f61-97e3-449a-aa0a-88eddb36518c",
   "metadata": {},
   "source": [
    "### create Managed TensorBoard instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ab7fca7-1939-4814-bf4b-62e3786f45c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME: projects/934903580331/locations/asia-southeast1/tensorboards/7334674943126274048\n",
      "TB display name: audio-ranker-opt-v11-akd\n"
     ]
    }
   ],
   "source": [
    "SESSION_id = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=3))\n",
    "\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}-{SESSION_id}\"\n",
    "\n",
    "# create new TB instance\n",
    "tensorboard = vertex_ai.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_DISPLAY_NAME\n",
    "    , project=PROJECT_ID\n",
    "    , location=REGION\n",
    ")\n",
    "\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "# use existing TB instance\n",
    "# TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/6924469145035603968'\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")\n",
    "print(f\"TB display name: {tensorboard.display_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de1000-a25a-4771-ae15-d597290faee0",
   "metadata": {},
   "source": [
    "### training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cab2373b-c933-431f-9cb5-f2a63e41c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "# =================================================\n",
    "# trainconfig: GPU related\n",
    "# =================================================\n",
    "TF_GPU_THREAD_COUNT='8'      # '1' | '4' | '8'\n",
    "\n",
    "# =================================================\n",
    "# trainconfig: data input pipeline\n",
    "# =================================================\n",
    "BLOCK_LENGTH = 64            # 1, 8, 16, 32, 64\n",
    "NUM_DATA_SHARDS = 4          # 2, 4, 8, 16, 32, 64\n",
    "# TRAIN_PREFETCH=3\n",
    "\n",
    "# =================================================\n",
    "# trainconfig: training hparams\n",
    "# =================================================\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 1024           # 8192, 4096, 2048, 1024, 512 \n",
    "DROPOUT_RATE = 0.33\n",
    "\n",
    "# model size\n",
    "EMBEDDING_DIM = 256\n",
    "PROJECTION_DIM = 50\n",
    "LAYER_SIZES = '[512,256,128]' # '[512,256,128]' '[256,128]'\n",
    "MAX_TOKENS = 20000     # vocab\n",
    "\n",
    "# =================================================\n",
    "# trainconfig: tensorboard\n",
    "# =================================================\n",
    "EMBED_FREQUENCY=0\n",
    "HISTOGRAM_FREQUENCY=1\n",
    "CHECKPOINT_FREQ='epoch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95ddb99d-eb88-42ea-9cc6-9124383ef601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID_STEPS: 81\n",
      "EPOCH_STEPS: 8012\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# trainconfig: train & valid steps\n",
    "# =================================================\n",
    "train_sample_cnt = 8_205_265 # 8_205_265\n",
    "valid_samples_cnt = 82_959\n",
    "\n",
    "# validation & evaluation\n",
    "VALID_FREQUENCY = 30\n",
    "VALID_STEPS = valid_samples_cnt // BATCH_SIZE # 100\n",
    "EPOCH_STEPS = train_sample_cnt // BATCH_SIZE\n",
    "\n",
    "print(f\"VALID_STEPS: {VALID_STEPS}\")\n",
    "print(f\"EPOCH_STEPS: {EPOCH_STEPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8e759-4d25-4a18-8bd8-f5c94b2caaed",
   "metadata": {},
   "source": [
    "### data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b18c839b-f05d-4162-add6-4b8202fe49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# trainconfig: gcs locations\n",
    "# =================================================\n",
    "OUTPUT_BUCKET = 'jt-tfrs-central-v4' # TODO: change this\n",
    "OUTPUT_GCS_URI =f'gs://{OUTPUT_BUCKET}'\n",
    "\n",
    "# create bucket if needed:\n",
    "# ! gsutil mb -l $REGION $OUTPUT_GCS_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b9c4b68-14da-4047-bdf0-6d80447bba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# trainconfig: Data sources\n",
    "# =================================================\n",
    "# BUCKET_DATA_DIR = 'spotify-data-regimes' \n",
    "# # data strategy: 08m\n",
    "# CANDIDATE_PREFIX = 'jtv15-8m/candidates'\n",
    "# TRAIN_DIR_PREFIX = 'jtv15-8m/train'     # train | train_v14\n",
    "# VALID_DIR_PREFIX = 'jtv15-8m/valid'     # valid_v14\n",
    "\n",
    "BUCKET_DATA_DIR = 'matching-engine-content'\n",
    "DATA_VERSION = 'v2-0-0'\n",
    "\n",
    "TRAIN_DIR_PREFIX = f'{DATA_VERSION}/train' # subset: valid_v9 | train_v9\n",
    "VALID_DIR_PREFIX = f'{DATA_VERSION}/valid' # valid_v9 | train_v9\n",
    "CANDIDATE_PREFIX = f'{DATA_VERSION}/candidates' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ef59f-488a-44c9-95de-a7b16eecca2f",
   "metadata": {},
   "source": [
    "### training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94f49017-a9cd-40f3-b93c-86411e1ac41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKER_CMD = [\"python\", \"./task.py\"]\n",
    "# WORKER_CMD = [\"python\", \"-m\", \"task\"]\n",
    "WORKER_CMD = [\"python\", \"task.py\"]\n",
    "\n",
    "WORKER_ARGS = [\n",
    "    f'--project={PROJECT_ID}',\n",
    "    f'--train_output_gcs_bucket={OUTPUT_BUCKET}',\n",
    "    f'--train_dir={BUCKET_DATA_DIR}',\n",
    "    f'--train_dir_prefix={TRAIN_DIR_PREFIX}',\n",
    "    f'--valid_dir={BUCKET_DATA_DIR}',\n",
    "    f'--valid_dir_prefix={VALID_DIR_PREFIX}',\n",
    "    f'--candidate_file_dir={BUCKET_DATA_DIR}',\n",
    "    f'--candidate_files_prefix={CANDIDATE_PREFIX}',\n",
    "    f'--experiment_name={EXPERIMENT_NAME}',\n",
    "    f'--experiment_run={RUN_NAME}',\n",
    "    f'--num_epochs={NUM_EPOCHS}',\n",
    "    f'--batch_size={BATCH_SIZE}',\n",
    "    f'--embedding_dim={EMBEDDING_DIM}',\n",
    "    f'--projection_dim={PROJECTION_DIM}',\n",
    "    f'--layer_sizes={LAYER_SIZES}',\n",
    "    f'--learning_rate={LEARNING_RATE}',\n",
    "    f'--valid_frequency={VALID_FREQUENCY}',\n",
    "    f'--valid_steps={VALID_STEPS}',\n",
    "    f'--epoch_steps={EPOCH_STEPS}',\n",
    "    f'--distribute={DISTRIBUTE_STRATEGY}',\n",
    "    f'--model_version={VERSION}',\n",
    "    f'--pipeline_version={VERSION}',\n",
    "    f'--seed={SEED}',\n",
    "    f'--max_tokens={MAX_TOKENS}',\n",
    "    f'--tb_resource_name={TB_RESOURCE_NAME}',\n",
    "    f'--embed_frequency={EMBED_FREQUENCY}',\n",
    "    f'--hist_frequency={HISTOGRAM_FREQUENCY}',\n",
    "    f'--tf_gpu_thread_count={TF_GPU_THREAD_COUNT}',\n",
    "    f'--block_length={BLOCK_LENGTH}',\n",
    "    f'--num_data_shards={NUM_DATA_SHARDS}',\n",
    "    f'--chkpt_freq={CHECKPOINT_FREQ}',\n",
    "    f'--dropout_rate={DROPOUT_RATE}',\n",
    "    # uncomment these to pass value of True (bool)\n",
    "    # f'--cache_train',                                # caches train_dataset\n",
    "    f'--evaluate_model',                              # runs model.eval()\n",
    "    # f'--profiler',                                   # runs TB profiler\n",
    "    # f'--set_jit',                                  # enables XLA\n",
    "    # f'--compute_batch_metrics'\n",
    "    f'--use_dropout',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6fce38ce-6ea0-40f0-80d9-3d86920e7ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--project=hybrid-vertex',\n",
      "                              '--train_output_gcs_bucket=jt-tfrs-central-v4',\n",
      "                              '--train_dir=matching-engine-content',\n",
      "                              '--train_dir_prefix=v2-0-0/train',\n",
      "                              '--valid_dir=matching-engine-content',\n",
      "                              '--valid_dir_prefix=v2-0-0/valid',\n",
      "                              '--candidate_file_dir=matching-engine-content',\n",
      "                              '--candidate_files_prefix=v2-0-0/candidates',\n",
      "                              '--experiment_name=audio-ranker-opt-v11',\n",
      "                              '--experiment_run=run-20230703-155351',\n",
      "                              '--num_epochs=20',\n",
      "                              '--batch_size=1024',\n",
      "                              '--embedding_dim=256',\n",
      "                              '--projection_dim=50',\n",
      "                              '--layer_sizes=[512,256,128]',\n",
      "                              '--learning_rate=0.01',\n",
      "                              '--valid_frequency=30',\n",
      "                              '--valid_steps=81',\n",
      "                              '--epoch_steps=8012',\n",
      "                              '--distribute=single',\n",
      "                              '--model_version=v11',\n",
      "                              '--pipeline_version=v11',\n",
      "                              '--seed=1234',\n",
      "                              '--max_tokens=20000',\n",
      "                              '--tb_resource_name=projects/934903580331/locations/asia-southeast1/tensorboards/7334674943126274048',\n",
      "                              '--embed_frequency=0',\n",
      "                              '--hist_frequency=1',\n",
      "                              '--tf_gpu_thread_count=8',\n",
      "                              '--block_length=64',\n",
      "                              '--num_data_shards=4',\n",
      "                              '--chkpt_freq=epoch',\n",
      "                              '--dropout_rate=0.33',\n",
      "                              '--evaluate_model',\n",
      "                              '--use_dropout'],\n",
      "                     'command': ['python', 'task.py'],\n",
      "                     'image_uri': 'us-central1-docker.pkg.dev/hybrid-vertex/tfrs-ranking/sp-rank-tfrs-v11:latest'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_A100',\n",
      "                   'machine_type': 'a2-highgpu-1g'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "from util import workerpool_specs\n",
    "\n",
    "WORKER_POOL_SPECS = workerpool_specs.prepare_worker_pool_specs(\n",
    "    image_uri=f\"{REMOTE_IMAGE_NAME}:latest\" # IMAGE_URI\n",
    "    , args=WORKER_ARGS\n",
    "    , cmd=WORKER_CMD\n",
    "    , replica_count=REPLICA_COUNT\n",
    "    , machine_type=WORKER_MACHINE_TYPE\n",
    "    , accelerator_count=PER_MACHINE_ACCELERATOR_COUNT\n",
    "    , accelerator_type=ACCELERATOR_TYPE\n",
    "    , reduction_server_count=REDUCTION_SERVER_COUNT\n",
    "    , reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de60076-66cd-4e2a-9add-2f031a911ec7",
   "metadata": {},
   "source": [
    "## copy training package to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccc2b17b-1331-4b14-9fb3-af950b33750b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://src/cloudbuild.yaml [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  178.0 B/  178.0 B]                                                \n",
      "Operation completed over 1 objects/178.0 B.                                      \n",
      "Copying file://src/Dockerfile_rank [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  446.0 B/  446.0 B]                                                \n",
      "Operation completed over 1 objects/446.0 B.                                      \n",
      "Copying file://vocab_dict.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 18.5 MiB/ 18.5 MiB]                                                \n",
      "Operation completed over 1 objects/18.5 MiB.                                     \n",
      "Copying file://src/ranking/__init__.py [Content-Type=text/x-python]...\n",
      "Copying file://src/ranking/__pycache__/__init__.cpython-37.pyc [Content-Type=application/x-python-code]...\n",
      "Copying file://src/ranking/__pycache__/train_utils.cpython-37.pyc [Content-Type=application/x-python-code]...\n",
      "Copying file://src/ranking/__pycache__/tf_ranking_model.cpython-37.pyc [Content-Type=application/x-python-code]...\n",
      "Copying file://src/ranking/__pycache__/build_audio_ranker.cpython-37.pyc [Content-Type=application/x-python-code]...\n",
      "Copying file://src/ranking/__pycache__/train_config.cpython-37.pyc [Content-Type=application/x-python-code]...\n",
      "Copying file://src/ranking/task.py [Content-Type=text/x-python]...              \n",
      "Copying file://src/ranking/__pycache__/feature_sets.cpython-37.pyc [Content-Type=application/x-python-code]...\n",
      "Copying file://src/ranking/build_audio_ranker.py [Content-Type=text/x-python]...\n",
      "Copying file://src/ranking/train_config.py [Content-Type=text/x-python]...      \n",
      "Copying file://src/ranking/feature_sets.py [Content-Type=text/x-python]...      \n",
      "Copying file://src/ranking/tf_ranking_model.py [Content-Type=text/x-python]...  \n",
      "Copying file://src/ranking/requirements.txt [Content-Type=text/plain]...\n",
      "Copying file://src/ranking/train_utils.py [Content-Type=text/x-python]...       \n",
      "/ [14/14 files][134.8 KiB/134.8 KiB] 100% Done                                  \n",
      "Operation completed over 14 objects/134.8 KiB.                                   \n",
      "\n",
      " Copied training package and Dockerfile to gs://jt-tfrs-central-v4/audio-ranker-opt-v11/run-20230703-155351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASE_OUTPUT_DIR = f'gs://{OUTPUT_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "\n",
    "# copy training Dockerfile\n",
    "! gsutil cp $REPO_DOCKER_PATH_PREFIX/cloudbuild.yaml $BASE_OUTPUT_DIR/cloudbuild.yaml\n",
    "! gsutil cp $REPO_DOCKER_PATH_PREFIX/Dockerfile_rank $BASE_OUTPUT_DIR/Dockerfile_rank\n",
    "! gsutil cp vocab_dict.pkl $BASE_OUTPUT_DIR/vocab_dict.pkl\n",
    "\n",
    "# # # copy training application code\n",
    "! gsutil -m cp -r $REPO_DOCKER_PATH_PREFIX/ranking/* $BASE_OUTPUT_DIR/ranking\n",
    "\n",
    "print(f\"\\n Copied training package and Dockerfile to {BASE_OUTPUT_DIR}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67614e43-351d-4aab-84de-91fb1912ff53",
   "metadata": {},
   "source": [
    "## submit training job to Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40c759a4-4b04-4947-9243-054536cd182b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME: train-sp-rank-tfrs-v11-20230703-155412\n"
     ]
    }
   ],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID\n",
    "    , location=REGION\n",
    "    , experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "JOB_NAME = f'train-{MODEL_ROOT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f\"JOB_NAME: {JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "299e5377-b780-4572-a04a-c6be897ae970",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = vertex_ai.CustomJob(\n",
    "    display_name=JOB_NAME\n",
    "    , worker_pool_specs=WORKER_POOL_SPECS\n",
    "    , base_output_dir=BASE_OUTPUT_DIR\n",
    "    , staging_bucket=f\"{BASE_OUTPUT_DIR}/staging\"\n",
    "    # , location=\"us-east4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676d001-1f78-45bd-938b-a64855b5d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.run(\n",
    "    tensorboard=TB_RESOURCE_NAME,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False,\n",
    "    enable_web_access=True,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e5647a-67bc-4852-b083-da8d018a29b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TODO: \n",
    "\n",
    "> see [create_custom_job with experiments autologging](https://cloud.google.com/vertex-ai/docs/training/create-custom-job#create_custom_job-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6e263-ae27-4c7a-a6be-8f7808417a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_custom_job_with_experiment_autologging_sample(\n",
    "#     project: str,\n",
    "#     location: str,\n",
    "#     staging_bucket: str,\n",
    "#     display_name: str,\n",
    "#     script_path: str,\n",
    "#     container_uri: str,\n",
    "#     service_account: str,\n",
    "#     experiment: str,\n",
    "#     experiment_run: Optional[str] = None,\n",
    "# ) -> None:\n",
    "#     aiplatform.init(project=project, location=location, staging_bucket=staging_bucket)\n",
    "\n",
    "#     # Ignore the next two lines of code if the experiment you are using already\n",
    "#     # has backing tensorboard instance.\n",
    "#     tb_instance = aiplatform.Tensorboard.create()\n",
    "#     aiplatform.init(experiment=experiment, experiment_tensorboard=tb_instance)\n",
    "\n",
    "#     job = aiplatform.CustomJob.from_local_script(\n",
    "#         display_name=display_name,\n",
    "#         script_path=script_path,\n",
    "#         container_uri=container_uri,\n",
    "#         enable_autolog=True,\n",
    "#     )\n",
    "\n",
    "#     job.run(\n",
    "#         service_account=service_account,\n",
    "#         experiment=experiment,\n",
    "#         experiment_run=experiment_run,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185ae51-8642-4579-9a93-68537b285aec",
   "metadata": {},
   "source": [
    "## TensorBoard Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a67ac96-5f32-401f-abd0-4a2ad20413e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_LOGS_PATH: gs://jt-tfrs-central-v4/audio-ranker-opt-v11/run-20230703-152341/logs\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "TB_LOGS_PATH = f'{BASE_OUTPUT_DIR}/logs' # \n",
    "print(f\"TB_LOGS_PATH: {TB_LOGS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eac15c0-af53-4ec7-9157-9657b94eaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be93237f-8b42-43ea-9507-783d2912a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6ba5f8e3b7cd2d48\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6ba5f8e3b7cd2d48\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$TB_LOGS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd30e860-1ab7-46ed-bf05-381d920029f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .gitignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gitignore\n",
    "*.cpython-310.pyc\n",
    "*checkpoint*\n",
    "*.ipynb_checkpoints\n",
    "# .gcloudignore\n",
    "# .git\n",
    "# .github\n",
    "# .ipynb_checkpoints/*\n",
    "# *__pycache__\n",
    "# *cpython-37.pyc\n",
    "# .gitignore\n",
    "# .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803db53-8e14-431f-aa4a-e2c62a0b7296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bd6bd-8847-43fb-9f6c-130a0c4fec57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04946572-790a-4e27-9610-2f9293c5ab96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
