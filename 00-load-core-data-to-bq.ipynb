{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "## In this notebook we will load the songs from the zip file, and perform transformations to prepare the data for two-tower training\n",
    "Steps\n",
    "1. Create a bq dataset\n",
    "2. Load the million playlist data to Big Query\n",
    "3. Create pipelines to download audio and artist features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set your variables for your project, region, and dataset name\n",
    "SOURCE_BUCKET = 'spotify-million-playlist-dataset'\n",
    "PROJECT_ID = 'wortz-project-352116'\n",
    "REGION = 'us-central1'\n",
    "BQ_DATASET = 'spotify_e2e_test'\n",
    "\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bigquery_client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a bigquery dataset (one time operation)\n",
    "# # Construct a full Dataset object to send to the API.\n",
    "# dataset = bigquery.Dataset(f\"`{PROJECT_ID}.{BQ_DATASET}`\")\n",
    "\n",
    "# # TODO(developer): Specify the geographic location where the dataset should reside.\n",
    "# dataset.location = REGION\n",
    "\n",
    "# # Send the dataset to the API for creation, with an explicit timeout.\n",
    "# # Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# # exists within the project.\n",
    "# dataset = bigquery_client.create_dataset(BQ_DATASET, timeout=30)  # Make an API request.\n",
    "# print(\"Created dataset {}.{}\".format(bigquery_client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data \n",
    "(also `curl` from source, see readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  spotify_million_playlist_dataset.zip\n",
      "  inflating: md5sums                 \n",
      "  inflating: stats.txt               \n",
      "  inflating: license.txt             \n",
      "   creating: data/\n",
      "  inflating: data/mpd.slice.549000-549999.json  \n",
      "  inflating: data/mpd.slice.613000-613999.json  \n",
      "  inflating: data/mpd.slice.115000-115999.json  \n",
      "  inflating: data/mpd.slice.778000-778999.json  \n",
      "  inflating: data/mpd.slice.290000-290999.json  \n",
      "  inflating: data/mpd.slice.596000-596999.json  \n",
      "  inflating: data/mpd.slice.324000-324999.json  \n",
      "  inflating: data/mpd.slice.422000-422999.json  \n",
      "  inflating: data/mpd.slice.974000-974999.json  \n",
      "  inflating: data/mpd.slice.679000-679999.json  \n",
      "  inflating: data/mpd.slice.7000-7999.json  \n",
      "  inflating: data/mpd.slice.391000-391999.json  \n",
      "  inflating: data/mpd.slice.497000-497999.json  \n",
      "  inflating: data/mpd.slice.225000-225999.json  \n",
      "  inflating: data/mpd.slice.523000-523999.json  \n",
      "  inflating: data/mpd.slice.875000-875999.json  \n",
      "  inflating: data/mpd.slice.448000-448999.json  \n",
      "  inflating: data/mpd.slice.712000-712999.json  \n",
      "  inflating: data/mpd.slice.193000-193999.json  \n",
      "  inflating: data/mpd.slice.38000-38999.json  \n",
      "  inflating: data/mpd.slice.695000-695999.json  \n",
      "  inflating: data/mpd.slice.899000-899999.json  \n",
      "  inflating: data/mpd.slice.721000-721999.json  \n",
      "  inflating: data/mpd.slice.510000-510999.json  \n",
      "  inflating: data/mpd.slice.846000-846999.json  \n",
      "  inflating: data/mpd.slice.216000-216999.json  \n",
      "  inflating: data/mpd.slice.411000-411999.json  \n",
      "  inflating: data/mpd.slice.947000-947999.json  \n",
      "  inflating: data/mpd.slice.317000-317999.json  \n",
      "  inflating: data/mpd.slice.22000-22999.json  \n",
      "  inflating: data/mpd.slice.794000-794999.json  \n",
      "  inflating: data/mpd.slice.126000-126999.json  \n",
      "  inflating: data/mpd.slice.998000-998999.json  \n",
      "  inflating: data/mpd.slice.620000-620999.json  \n",
      "  inflating: data/mpd.slice.3000-3999.json  \n",
      "  inflating: data/mpd.slice.70000-70999.json  \n",
      "  inflating: data/mpd.slice.597000-597999.json  \n",
      "  inflating: data/mpd.slice.291000-291999.json  \n",
      "  inflating: data/mpd.slice.779000-779999.json  \n",
      "  inflating: data/mpd.slice.423000-423999.json  \n",
      "  inflating: data/mpd.slice.975000-975999.json  \n",
      "  inflating: data/mpd.slice.325000-325999.json  \n",
      "  inflating: data/mpd.slice.548000-548999.json  \n",
      "  inflating: data/mpd.slice.114000-114999.json  \n",
      "  inflating: data/mpd.slice.612000-612999.json  \n",
      "  inflating: data/mpd.slice.449000-449999.json  \n",
      "  inflating: data/mpd.slice.713000-713999.json  \n",
      "  inflating: data/mpd.slice.496000-496999.json  \n",
      "  inflating: data/mpd.slice.390000-390999.json  \n",
      "  inflating: data/mpd.slice.678000-678999.json  \n",
      "  inflating: data/mpd.slice.522000-522999.json  \n",
      "  inflating: data/mpd.slice.874000-874999.json  \n",
      "  inflating: data/mpd.slice.224000-224999.json  \n",
      "  inflating: data/mpd.slice.81000-81999.json  \n",
      "  inflating: data/mpd.slice.217000-217999.json  \n",
      "  inflating: data/mpd.slice.511000-511999.json  \n",
      "  inflating: data/mpd.slice.847000-847999.json  \n",
      "  inflating: data/mpd.slice.694000-694999.json  \n",
      "  inflating: data/mpd.slice.192000-192999.json  \n",
      "  inflating: data/mpd.slice.720000-720999.json  \n",
      "  inflating: data/mpd.slice.898000-898999.json  \n",
      "  inflating: data/mpd.slice.54000-54999.json  \n",
      "  inflating: data/mpd.slice.795000-795999.json  \n",
      "  inflating: data/mpd.slice.621000-621999.json  \n",
      "  inflating: data/mpd.slice.999000-999999.json  \n",
      "  inflating: data/mpd.slice.127000-127999.json  \n",
      "  inflating: data/mpd.slice.316000-316999.json  \n",
      "  inflating: data/mpd.slice.410000-410999.json  \n",
      "  inflating: data/mpd.slice.946000-946999.json  \n",
      "  inflating: data/mpd.slice.227000-227999.json  \n",
      "  inflating: data/mpd.slice.84000-84999.json  \n",
      "  inflating: data/mpd.slice.877000-877999.json  \n",
      "  inflating: data/mpd.slice.521000-521999.json  \n",
      "  inflating: data/mpd.slice.393000-393999.json  \n",
      "  inflating: data/mpd.slice.495000-495999.json  \n",
      "  inflating: data/mpd.slice.710000-710999.json  \n",
      "  inflating: data/mpd.slice.611000-611999.json  \n",
      "  inflating: data/mpd.slice.117000-117999.json  \n",
      "  inflating: data/mpd.slice.51000-51999.json  \n",
      "  inflating: data/mpd.slice.326000-326999.json  \n",
      "  inflating: data/mpd.slice.976000-976999.json  \n",
      "  inflating: data/mpd.slice.420000-420999.json  \n",
      "  inflating: data/mpd.slice.292000-292999.json  \n",
      "  inflating: data/mpd.slice.594000-594999.json  \n",
      "  inflating: data/mpd.slice.945000-945999.json  \n",
      "  inflating: data/mpd.slice.413000-413999.json  \n",
      "  inflating: data/mpd.slice.75000-75999.json  \n",
      "  inflating: data/mpd.slice.315000-315999.json  \n",
      "  inflating: data/mpd.slice.749000-749999.json  \n",
      "  inflating: data/mpd.slice.124000-124999.json  \n",
      "  inflating: data/mpd.slice.622000-622999.json  \n",
      "  inflating: data/mpd.slice.578000-578999.json  \n",
      "  inflating: data/mpd.slice.796000-796999.json  \n",
      "  inflating: data/mpd.slice.723000-723999.json  \n",
      "  inflating: data/mpd.slice.191000-191999.json  \n",
      "  inflating: data/mpd.slice.479000-479999.json  \n",
      "  inflating: data/mpd.slice.697000-697999.json  \n",
      "  inflating: data/mpd.slice.844000-844999.json  \n",
      "  inflating: data/mpd.slice.512000-512999.json  \n",
      "  inflating: data/mpd.slice.214000-214999.json  \n",
      "  inflating: data/mpd.slice.648000-648999.json  \n",
      "  inflating: data/mpd.slice.711000-711999.json  \n",
      "  inflating: data/mpd.slice.876000-876999.json  \n",
      "  inflating: data/mpd.slice.520000-520999.json  \n",
      "  inflating: data/mpd.slice.226000-226999.json  \n",
      "  inflating: data/mpd.slice.494000-494999.json  \n",
      "  inflating: data/mpd.slice.392000-392999.json  \n",
      "  inflating: data/mpd.slice.977000-977999.json  \n",
      "  inflating: data/mpd.slice.421000-421999.json  \n",
      "  inflating: data/mpd.slice.327000-327999.json  \n",
      "  inflating: data/mpd.slice.595000-595999.json  \n",
      "  inflating: data/mpd.slice.293000-293999.json  \n",
      "  inflating: data/mpd.slice.116000-116999.json  \n",
      "  inflating: data/mpd.slice.610000-610999.json  \n",
      "  inflating: data/mpd.slice.27000-27999.json  \n",
      "  inflating: data/mpd.slice.6000-6999.json  \n",
      "  inflating: data/mpd.slice.623000-623999.json  \n",
      "  inflating: data/mpd.slice.125000-125999.json  \n",
      "  inflating: data/mpd.slice.797000-797999.json  \n",
      "  inflating: data/mpd.slice.579000-579999.json  \n",
      "  inflating: data/mpd.slice.314000-314999.json  \n",
      "  inflating: data/mpd.slice.944000-944999.json  \n",
      "  inflating: data/mpd.slice.412000-412999.json  \n",
      "  inflating: data/mpd.slice.748000-748999.json  \n",
      "  inflating: data/mpd.slice.215000-215999.json  \n",
      "  inflating: data/mpd.slice.19000-19999.json  \n",
      "  inflating: data/mpd.slice.845000-845999.json  \n",
      "  inflating: data/mpd.slice.513000-513999.json  \n",
      "  inflating: data/mpd.slice.2000-2999.json  \n",
      "  inflating: data/mpd.slice.649000-649999.json  \n",
      "  inflating: data/mpd.slice.722000-722999.json  \n",
      "  inflating: data/mpd.slice.696000-696999.json  \n",
      "  inflating: data/mpd.slice.478000-478999.json  \n",
      "  inflating: data/mpd.slice.190000-190999.json  \n",
      "  inflating: data/mpd.slice.540000-540999.json  \n",
      "  inflating: data/mpd.slice.816000-816999.json  \n",
      "  inflating: data/mpd.slice.246000-246999.json  \n",
      "  inflating: data/mpd.slice.37000-37999.json  \n",
      "  inflating: data/mpd.slice.299000-299999.json  \n",
      "  inflating: data/mpd.slice.771000-771999.json  \n",
      "  inflating: data/mpd.slice.176000-176999.json  \n",
      "  inflating: data/mpd.slice.398000-398999.json  \n",
      "  inflating: data/mpd.slice.670000-670999.json  \n",
      "  inflating: data/mpd.slice.441000-441999.json  \n",
      "  inflating: data/mpd.slice.917000-917999.json  \n",
      "  inflating: data/mpd.slice.347000-347999.json  \n",
      "  inflating: data/mpd.slice.374000-374999.json  \n",
      "  inflating: data/mpd.slice.472000-472999.json  \n",
      "  inflating: data/mpd.slice.924000-924999.json  \n",
      "  inflating: data/mpd.slice.728000-728999.json  \n",
      "  inflating: data/mpd.slice.890000-890999.json  \n",
      "  inflating: data/mpd.slice.643000-643999.json  \n",
      "  inflating: data/mpd.slice.145000-145999.json  \n",
      "  inflating: data/mpd.slice.519000-519999.json  \n",
      "  inflating: data/mpd.slice.742000-742999.json  \n",
      "  inflating: data/mpd.slice.13000-13999.json  \n",
      "  inflating: data/mpd.slice.418000-418999.json  \n",
      "  inflating: data/mpd.slice.8000-8999.json  \n",
      "  inflating: data/mpd.slice.275000-275999.json  \n",
      "  inflating: data/mpd.slice.573000-573999.json  \n",
      "  inflating: data/mpd.slice.825000-825999.json  \n",
      "  inflating: data/mpd.slice.629000-629999.json  \n",
      "  inflating: data/mpd.slice.991000-991999.json  \n",
      "  inflating: data/mpd.slice.770000-770999.json  \n",
      "  inflating: data/mpd.slice.298000-298999.json  \n",
      "  inflating: data/mpd.slice.247000-247999.json  \n",
      "  inflating: data/mpd.slice.541000-541999.json  \n",
      "  inflating: data/mpd.slice.817000-817999.json  \n",
      "  inflating: data/mpd.slice.41000-41999.json  \n",
      "  inflating: data/mpd.slice.346000-346999.json  \n",
      "  inflating: data/mpd.slice.440000-440999.json  \n",
      "  inflating: data/mpd.slice.916000-916999.json  \n",
      "  inflating: data/mpd.slice.671000-671999.json  \n",
      "  inflating: data/mpd.slice.399000-399999.json  \n",
      "  inflating: data/mpd.slice.177000-177999.json  \n",
      "  inflating: data/mpd.slice.94000-94999.json  \n",
      "  inflating: data/mpd.slice.144000-144999.json  \n",
      "  inflating: data/mpd.slice.642000-642999.json  \n",
      "  inflating: data/mpd.slice.518000-518999.json  \n",
      "  inflating: data/mpd.slice.473000-473999.json  \n",
      "  inflating: data/mpd.slice.925000-925999.json  \n",
      "  inflating: data/mpd.slice.375000-375999.json  \n",
      "  inflating: data/mpd.slice.891000-891999.json  \n",
      "  inflating: data/mpd.slice.729000-729999.json  \n",
      "  inflating: data/mpd.slice.572000-572999.json  \n",
      "  inflating: data/mpd.slice.824000-824999.json  \n",
      "  inflating: data/mpd.slice.274000-274999.json  \n",
      "  inflating: data/mpd.slice.990000-990999.json  \n",
      "  inflating: data/mpd.slice.628000-628999.json  \n",
      "  inflating: data/mpd.slice.743000-743999.json  \n",
      "  inflating: data/mpd.slice.419000-419999.json  \n",
      "  inflating: data/mpd.slice.65000-65999.json  \n",
      "  inflating: data/mpd.slice.528000-528999.json  \n",
      "  inflating: data/mpd.slice.174000-174999.json  \n",
      "  inflating: data/mpd.slice.672000-672999.json  \n",
      "  inflating: data/mpd.slice.719000-719999.json  \n",
      "  inflating: data/mpd.slice.915000-915999.json  \n",
      "  inflating: data/mpd.slice.443000-443999.json  \n",
      "  inflating: data/mpd.slice.345000-345999.json  \n",
      "  inflating: data/mpd.slice.618000-618999.json  \n",
      "  inflating: data/mpd.slice.814000-814999.json  \n",
      "  inflating: data/mpd.slice.542000-542999.json  \n",
      "  inflating: data/mpd.slice.244000-244999.json  \n",
      "  inflating: data/mpd.slice.429000-429999.json  \n",
      "  inflating: data/mpd.slice.773000-773999.json  \n",
      "  inflating: data/mpd.slice.60000-60999.json  \n",
      "  inflating: data/mpd.slice.740000-740999.json  \n",
      "  inflating: data/mpd.slice.993000-993999.json  \n",
      "  inflating: data/mpd.slice.277000-277999.json  \n",
      "  inflating: data/mpd.slice.827000-827999.json  \n",
      "  inflating: data/mpd.slice.571000-571999.json  \n",
      "  inflating: data/mpd.slice.44000-44999.json  \n",
      "  inflating: data/mpd.slice.892000-892999.json  \n",
      "  inflating: data/mpd.slice.376000-376999.json  \n",
      "  inflating: data/mpd.slice.926000-926999.json  \n",
      "  inflating: data/mpd.slice.470000-470999.json  \n",
      "  inflating: data/mpd.slice.198000-198999.json  \n",
      "  inflating: data/mpd.slice.91000-91999.json  \n",
      "  inflating: data/mpd.slice.641000-641999.json  \n",
      "  inflating: data/mpd.slice.147000-147999.json  \n",
      "  inflating: data/mpd.slice.718000-718999.json  \n",
      "  inflating: data/mpd.slice.344000-344999.json  \n",
      "  inflating: data/mpd.slice.914000-914999.json  \n",
      "  inflating: data/mpd.slice.442000-442999.json  \n",
      "  inflating: data/mpd.slice.529000-529999.json  \n",
      "  inflating: data/mpd.slice.673000-673999.json  \n",
      "  inflating: data/mpd.slice.175000-175999.json  \n",
      "  inflating: data/mpd.slice.428000-428999.json  \n",
      "  inflating: data/mpd.slice.772000-772999.json  \n",
      "  inflating: data/mpd.slice.16000-16999.json  \n",
      "  inflating: data/mpd.slice.619000-619999.json  \n",
      "  inflating: data/mpd.slice.245000-245999.json  \n",
      "  inflating: data/mpd.slice.815000-815999.json  \n",
      "  inflating: data/mpd.slice.543000-543999.json  \n",
      "  inflating: data/mpd.slice.992000-992999.json  \n",
      "  inflating: data/mpd.slice.826000-826999.json  \n",
      "  inflating: data/mpd.slice.570000-570999.json  \n",
      "  inflating: data/mpd.slice.32000-32999.json  \n",
      "  inflating: data/mpd.slice.276000-276999.json  \n",
      "  inflating: data/mpd.slice.741000-741999.json  \n",
      "  inflating: data/mpd.slice.146000-146999.json  \n",
      "  inflating: data/mpd.slice.640000-640999.json  \n",
      "  inflating: data/mpd.slice.893000-893999.json  \n",
      "  inflating: data/mpd.slice.9000-9999.json  \n",
      "  inflating: data/mpd.slice.199000-199999.json  \n",
      "  inflating: data/mpd.slice.927000-927999.json  \n",
      "  inflating: data/mpd.slice.471000-471999.json  \n",
      "  inflating: data/mpd.slice.28000-28999.json  \n",
      "  inflating: data/mpd.slice.377000-377999.json  \n",
      "  inflating: data/mpd.slice.880000-880999.json  \n",
      "  inflating: data/mpd.slice.738000-738999.json  \n",
      "  inflating: data/mpd.slice.934000-934999.json  \n",
      "  inflating: data/mpd.slice.462000-462999.json  \n",
      "  inflating: data/mpd.slice.364000-364999.json  \n",
      "  inflating: data/mpd.slice.509000-509999.json  \n",
      "  inflating: data/mpd.slice.155000-155999.json  \n",
      "  inflating: data/mpd.slice.653000-653999.json  \n",
      "  inflating: data/mpd.slice.408000-408999.json  \n",
      "  inflating: data/mpd.slice.10000-10999.json  \n",
      "  inflating: data/mpd.slice.752000-752999.json  \n",
      "  inflating: data/mpd.slice.981000-981999.json  \n",
      "  inflating: data/mpd.slice.639000-639999.json  \n",
      "  inflating: data/mpd.slice.835000-835999.json  \n",
      "  inflating: data/mpd.slice.563000-563999.json  \n",
      "  inflating: data/mpd.slice.265000-265999.json  \n",
      "  inflating: data/mpd.slice.34000-34999.json  \n",
      "  inflating: data/mpd.slice.256000-256999.json  \n",
      "  inflating: data/mpd.slice.806000-806999.json  \n",
      "  inflating: data/mpd.slice.550000-550999.json  \n",
      "  inflating: data/mpd.slice.289000-289999.json  \n",
      "  inflating: data/mpd.slice.761000-761999.json  \n",
      "  inflating: data/mpd.slice.388000-388999.json  \n",
      "  inflating: data/mpd.slice.660000-660999.json  \n",
      "  inflating: data/mpd.slice.166000-166999.json  \n",
      "  inflating: data/mpd.slice.357000-357999.json  \n",
      "  inflating: data/mpd.slice.907000-907999.json  \n",
      "  inflating: data/mpd.slice.451000-451999.json  \n",
      "  inflating: data/mpd.slice.508000-508999.json  \n",
      "  inflating: data/mpd.slice.652000-652999.json  \n",
      "  inflating: data/mpd.slice.154000-154999.json  \n",
      "  inflating: data/mpd.slice.739000-739999.json  \n",
      "  inflating: data/mpd.slice.881000-881999.json  \n",
      "  inflating: data/mpd.slice.365000-365999.json  \n",
      "  inflating: data/mpd.slice.935000-935999.json  \n",
      "  inflating: data/mpd.slice.463000-463999.json  \n",
      "  inflating: data/mpd.slice.638000-638999.json  \n",
      "  inflating: data/mpd.slice.980000-980999.json  \n",
      "  inflating: data/mpd.slice.264000-264999.json  \n",
      "  inflating: data/mpd.slice.834000-834999.json  \n",
      "  inflating: data/mpd.slice.562000-562999.json  \n",
      "  inflating: data/mpd.slice.66000-66999.json  \n",
      "  inflating: data/mpd.slice.409000-409999.json  \n",
      "  inflating: data/mpd.slice.753000-753999.json  \n",
      "  inflating: data/mpd.slice.760000-760999.json  \n",
      "  inflating: data/mpd.slice.288000-288999.json  \n",
      "  inflating: data/mpd.slice.42000-42999.json  \n",
      "  inflating: data/mpd.slice.807000-807999.json  \n",
      "  inflating: data/mpd.slice.551000-551999.json  \n",
      "  inflating: data/mpd.slice.257000-257999.json  \n",
      "  inflating: data/mpd.slice.58000-58999.json  \n",
      "  inflating: data/mpd.slice.906000-906999.json  \n",
      "  inflating: data/mpd.slice.450000-450999.json  \n",
      "  inflating: data/mpd.slice.356000-356999.json  \n",
      "  inflating: data/mpd.slice.97000-97999.json  \n",
      "  inflating: data/mpd.slice.167000-167999.json  \n",
      "  inflating: data/mpd.slice.661000-661999.json  \n",
      "  inflating: data/mpd.slice.389000-389999.json  \n",
      "  inflating: data/mpd.slice.88000-88999.json  \n",
      "  inflating: data/mpd.slice.750000-750999.json  \n",
      "  inflating: data/mpd.slice.561000-561999.json  \n",
      "  inflating: data/mpd.slice.837000-837999.json  \n",
      "  inflating: data/mpd.slice.47000-47999.json  \n",
      "  inflating: data/mpd.slice.267000-267999.json  \n",
      "  inflating: data/mpd.slice.983000-983999.json  \n",
      "  inflating: data/mpd.slice.460000-460999.json  \n",
      "  inflating: data/mpd.slice.936000-936999.json  \n",
      "  inflating: data/mpd.slice.188000-188999.json  \n",
      "  inflating: data/mpd.slice.366000-366999.json  \n",
      "  inflating: data/mpd.slice.882000-882999.json  \n",
      "  inflating: data/mpd.slice.92000-92999.json  \n",
      "  inflating: data/mpd.slice.157000-157999.json  \n",
      "  inflating: data/mpd.slice.651000-651999.json  \n",
      "  inflating: data/mpd.slice.662000-662999.json  \n",
      "  inflating: data/mpd.slice.79000-79999.json  \n",
      "  inflating: data/mpd.slice.164000-164999.json  \n",
      "  inflating: data/mpd.slice.538000-538999.json  \n",
      "  inflating: data/mpd.slice.355000-355999.json  \n",
      "  inflating: data/mpd.slice.453000-453999.json  \n",
      "  inflating: data/mpd.slice.905000-905999.json  \n",
      "  inflating: data/mpd.slice.709000-709999.json  \n",
      "  inflating: data/mpd.slice.254000-254999.json  \n",
      "  inflating: data/mpd.slice.552000-552999.json  \n",
      "  inflating: data/mpd.slice.804000-804999.json  \n",
      "  inflating: data/mpd.slice.608000-608999.json  \n",
      "  inflating: data/mpd.slice.763000-763999.json  \n",
      "  inflating: data/mpd.slice.63000-63999.json  \n",
      "  inflating: data/mpd.slice.439000-439999.json  \n",
      "  inflating: data/mpd.slice.266000-266999.json  \n",
      "  inflating: data/mpd.slice.560000-560999.json  \n",
      "  inflating: data/mpd.slice.836000-836999.json  \n",
      "  inflating: data/mpd.slice.31000-31999.json  \n",
      "  inflating: data/mpd.slice.982000-982999.json  \n",
      "  inflating: data/mpd.slice.751000-751999.json  \n",
      "  inflating: data/mpd.slice.650000-650999.json  \n",
      "  inflating: data/mpd.slice.156000-156999.json  \n",
      "  inflating: data/mpd.slice.0-999.json  \n",
      "  inflating: data/mpd.slice.367000-367999.json  \n",
      "  inflating: data/mpd.slice.189000-189999.json  \n",
      "  inflating: data/mpd.slice.461000-461999.json  \n",
      "  inflating: data/mpd.slice.937000-937999.json  \n",
      "  inflating: data/mpd.slice.883000-883999.json  \n",
      "  inflating: data/mpd.slice.452000-452999.json  \n",
      "  inflating: data/mpd.slice.904000-904999.json  \n",
      "  inflating: data/mpd.slice.354000-354999.json  \n",
      "  inflating: data/mpd.slice.708000-708999.json  \n",
      "  inflating: data/mpd.slice.165000-165999.json  \n",
      "  inflating: data/mpd.slice.663000-663999.json  \n",
      "  inflating: data/mpd.slice.539000-539999.json  \n",
      "  inflating: data/mpd.slice.762000-762999.json  \n",
      "  inflating: data/mpd.slice.15000-15999.json  \n",
      "  inflating: data/mpd.slice.438000-438999.json  \n",
      "  inflating: data/mpd.slice.553000-553999.json  \n",
      "  inflating: data/mpd.slice.805000-805999.json  \n",
      "  inflating: data/mpd.slice.255000-255999.json  \n",
      "  inflating: data/mpd.slice.609000-609999.json  \n",
      "  inflating: data/mpd.slice.731000-731999.json  \n",
      "  inflating: data/mpd.slice.889000-889999.json  \n",
      "  inflating: data/mpd.slice.685000-685999.json  \n",
      "  inflating: data/mpd.slice.183000-183999.json  \n",
      "  inflating: data/mpd.slice.206000-206999.json  \n",
      "  inflating: data/mpd.slice.856000-856999.json  \n",
      "  inflating: data/mpd.slice.500000-500999.json  \n",
      "  inflating: data/mpd.slice.307000-307999.json  \n",
      "  inflating: data/mpd.slice.957000-957999.json  \n",
      "  inflating: data/mpd.slice.401000-401999.json  \n",
      "  inflating: data/mpd.slice.630000-630999.json  \n",
      "  inflating: data/mpd.slice.136000-136999.json  \n",
      "  inflating: data/mpd.slice.988000-988999.json  \n",
      "  inflating: data/mpd.slice.21000-21999.json  \n",
      "  inflating: data/mpd.slice.784000-784999.json  \n",
      "  inflating: data/mpd.slice.105000-105999.json  \n",
      "  inflating: data/mpd.slice.603000-603999.json  \n",
      "  inflating: data/mpd.slice.559000-559999.json  \n",
      "  inflating: data/mpd.slice.964000-964999.json  \n",
      "  inflating: data/mpd.slice.432000-432999.json  \n",
      "  inflating: data/mpd.slice.334000-334999.json  \n",
      "  inflating: data/mpd.slice.586000-586999.json  \n",
      "  inflating: data/mpd.slice.768000-768999.json  \n",
      "  inflating: data/mpd.slice.280000-280999.json  \n",
      "  inflating: data/mpd.slice.865000-865999.json  \n",
      "  inflating: data/mpd.slice.533000-533999.json  \n",
      "  inflating: data/mpd.slice.235000-235999.json  \n",
      "  inflating: data/mpd.slice.487000-487999.json  \n",
      "  inflating: data/mpd.slice.669000-669999.json  \n",
      "  inflating: data/mpd.slice.381000-381999.json  \n",
      "  inflating: data/mpd.slice.702000-702999.json  \n",
      "  inflating: data/mpd.slice.458000-458999.json  \n",
      "  inflating: data/mpd.slice.857000-857999.json  \n",
      "  inflating: data/mpd.slice.501000-501999.json  \n",
      "  inflating: data/mpd.slice.207000-207999.json  \n",
      "  inflating: data/mpd.slice.82000-82999.json  \n",
      "  inflating: data/mpd.slice.888000-888999.json  \n",
      "  inflating: data/mpd.slice.730000-730999.json  \n",
      "  inflating: data/mpd.slice.182000-182999.json  \n",
      "  inflating: data/mpd.slice.684000-684999.json  \n",
      "  inflating: data/mpd.slice.989000-989999.json  \n",
      "  inflating: data/mpd.slice.137000-137999.json  \n",
      "  inflating: data/mpd.slice.631000-631999.json  \n",
      "  inflating: data/mpd.slice.57000-57999.json  \n",
      "  inflating: data/mpd.slice.785000-785999.json  \n",
      "  inflating: data/mpd.slice.956000-956999.json  \n",
      "  inflating: data/mpd.slice.400000-400999.json  \n",
      "  inflating: data/mpd.slice.306000-306999.json  \n",
      "  inflating: data/mpd.slice.98000-98999.json  \n",
      "  inflating: data/mpd.slice.335000-335999.json  \n",
      "  inflating: data/mpd.slice.965000-965999.json  \n",
      "  inflating: data/mpd.slice.433000-433999.json  \n",
      "  inflating: data/mpd.slice.73000-73999.json  \n",
      "  inflating: data/mpd.slice.281000-281999.json  \n",
      "  inflating: data/mpd.slice.769000-769999.json  \n",
      "  inflating: data/mpd.slice.587000-587999.json  \n",
      "  inflating: data/mpd.slice.602000-602999.json  \n",
      "  inflating: data/mpd.slice.104000-104999.json  \n",
      "  inflating: data/mpd.slice.558000-558999.json  \n",
      "  inflating: data/mpd.slice.703000-703999.json  \n",
      "  inflating: data/mpd.slice.459000-459999.json  \n",
      "  inflating: data/mpd.slice.234000-234999.json  \n",
      "  inflating: data/mpd.slice.864000-864999.json  \n",
      "  inflating: data/mpd.slice.532000-532999.json  \n",
      "  inflating: data/mpd.slice.380000-380999.json  \n",
      "  inflating: data/mpd.slice.668000-668999.json  \n",
      "  inflating: data/mpd.slice.69000-69999.json  \n",
      "  inflating: data/mpd.slice.486000-486999.json  \n",
      "  inflating: data/mpd.slice.759000-759999.json  \n",
      "  inflating: data/mpd.slice.305000-305999.json  \n",
      "  inflating: data/mpd.slice.403000-403999.json  \n",
      "  inflating: data/mpd.slice.955000-955999.json  \n",
      "  inflating: data/mpd.slice.76000-76999.json  \n",
      "  inflating: data/mpd.slice.786000-786999.json  \n",
      "  inflating: data/mpd.slice.568000-568999.json  \n",
      "  inflating: data/mpd.slice.632000-632999.json  \n",
      "  inflating: data/mpd.slice.134000-134999.json  \n",
      "  inflating: data/mpd.slice.687000-687999.json  \n",
      "  inflating: data/mpd.slice.181000-181999.json  \n",
      "  inflating: data/mpd.slice.469000-469999.json  \n",
      "  inflating: data/mpd.slice.733000-733999.json  \n",
      "  inflating: data/mpd.slice.658000-658999.json  \n",
      "  inflating: data/mpd.slice.204000-204999.json  \n",
      "  inflating: data/mpd.slice.502000-502999.json  \n",
      "  inflating: data/mpd.slice.854000-854999.json  \n",
      "  inflating: data/mpd.slice.485000-485999.json  \n",
      "  inflating: data/mpd.slice.383000-383999.json  \n",
      "  inflating: data/mpd.slice.87000-87999.json  \n",
      "  inflating: data/mpd.slice.531000-531999.json  \n",
      "  inflating: data/mpd.slice.867000-867999.json  \n",
      "  inflating: data/mpd.slice.237000-237999.json  \n",
      "  inflating: data/mpd.slice.48000-48999.json  \n",
      "  inflating: data/mpd.slice.700000-700999.json  \n",
      "  inflating: data/mpd.slice.107000-107999.json  \n",
      "  inflating: data/mpd.slice.601000-601999.json  \n",
      "  inflating: data/mpd.slice.52000-52999.json  \n",
      "  inflating: data/mpd.slice.584000-584999.json  \n",
      "  inflating: data/mpd.slice.282000-282999.json  \n",
      "  inflating: data/mpd.slice.430000-430999.json  \n",
      "  inflating: data/mpd.slice.966000-966999.json  \n",
      "  inflating: data/mpd.slice.336000-336999.json  \n",
      "  inflating: data/mpd.slice.569000-569999.json  \n",
      "  inflating: data/mpd.slice.787000-787999.json  \n",
      "  inflating: data/mpd.slice.135000-135999.json  \n",
      "  inflating: data/mpd.slice.633000-633999.json  \n",
      "  inflating: data/mpd.slice.758000-758999.json  \n",
      "  inflating: data/mpd.slice.402000-402999.json  \n",
      "  inflating: data/mpd.slice.954000-954999.json  \n",
      "  inflating: data/mpd.slice.304000-304999.json  \n",
      "  inflating: data/mpd.slice.659000-659999.json  \n",
      "  inflating: data/mpd.slice.503000-503999.json  \n",
      "  inflating: data/mpd.slice.855000-855999.json  \n",
      "  inflating: data/mpd.slice.205000-205999.json  \n",
      "  inflating: data/mpd.slice.468000-468999.json  \n",
      "  inflating: data/mpd.slice.180000-180999.json  \n",
      "  inflating: data/mpd.slice.686000-686999.json  \n",
      "  inflating: data/mpd.slice.732000-732999.json  \n",
      "  inflating: data/mpd.slice.701000-701999.json  \n",
      "  inflating: data/mpd.slice.382000-382999.json  \n",
      "  inflating: data/mpd.slice.484000-484999.json  \n",
      "  inflating: data/mpd.slice.236000-236999.json  \n",
      "  inflating: data/mpd.slice.530000-530999.json  \n",
      "  inflating: data/mpd.slice.866000-866999.json  \n",
      "  inflating: data/mpd.slice.283000-283999.json  \n",
      "  inflating: data/mpd.slice.585000-585999.json  \n",
      "  inflating: data/mpd.slice.337000-337999.json  \n",
      "  inflating: data/mpd.slice.431000-431999.json  \n",
      "  inflating: data/mpd.slice.967000-967999.json  \n",
      "  inflating: data/mpd.slice.600000-600999.json  \n",
      "  inflating: data/mpd.slice.24000-24999.json  \n",
      "  inflating: data/mpd.slice.106000-106999.json  \n",
      "  inflating: data/mpd.slice.941000-941999.json  \n",
      "  inflating: data/mpd.slice.417000-417999.json  \n",
      "  inflating: data/mpd.slice.311000-311999.json  \n",
      "  inflating: data/mpd.slice.5000-5999.json  \n",
      "  inflating: data/mpd.slice.792000-792999.json  \n",
      "  inflating: data/mpd.slice.120000-120999.json  \n",
      "  inflating: data/mpd.slice.626000-626999.json  \n",
      "  inflating: data/mpd.slice.195000-195999.json  \n",
      "  inflating: data/mpd.slice.14000-14999.json  \n",
      "  inflating: data/mpd.slice.693000-693999.json  \n",
      "  inflating: data/mpd.slice.727000-727999.json  \n",
      "  inflating: data/mpd.slice.840000-840999.json  \n",
      "  inflating: data/mpd.slice.516000-516999.json  \n",
      "  inflating: data/mpd.slice.210000-210999.json  \n",
      "  inflating: data/mpd.slice.30000-30999.json  \n",
      "  inflating: data/mpd.slice.397000-397999.json  \n",
      "  inflating: data/mpd.slice.491000-491999.json  \n",
      "  inflating: data/mpd.slice.179000-179999.json  \n",
      "  inflating: data/mpd.slice.223000-223999.json  \n",
      "  inflating: data/mpd.slice.873000-873999.json  \n",
      "  inflating: data/mpd.slice.525000-525999.json  \n",
      "  inflating: data/mpd.slice.348000-348999.json  \n",
      "  inflating: data/mpd.slice.1000-1999.json  \n",
      "  inflating: data/mpd.slice.918000-918999.json  \n",
      "  inflating: data/mpd.slice.714000-714999.json  \n",
      "  inflating: data/mpd.slice.249000-249999.json  \n",
      "  inflating: data/mpd.slice.819000-819999.json  \n",
      "  inflating: data/mpd.slice.615000-615999.json  \n",
      "  inflating: data/mpd.slice.113000-113999.json  \n",
      "  inflating: data/mpd.slice.296000-296999.json  \n",
      "  inflating: data/mpd.slice.590000-590999.json  \n",
      "  inflating: data/mpd.slice.322000-322999.json  \n",
      "  inflating: data/mpd.slice.972000-972999.json  \n",
      "  inflating: data/mpd.slice.424000-424999.json  \n",
      "  inflating: data/mpd.slice.793000-793999.json  \n",
      "  inflating: data/mpd.slice.78000-78999.json  \n",
      "  inflating: data/mpd.slice.627000-627999.json  \n",
      "  inflating: data/mpd.slice.121000-121999.json  \n",
      "  inflating: data/mpd.slice.310000-310999.json  \n",
      "  inflating: data/mpd.slice.940000-940999.json  \n",
      "  inflating: data/mpd.slice.416000-416999.json  \n",
      "  inflating: data/mpd.slice.211000-211999.json  \n",
      "  inflating: data/mpd.slice.841000-841999.json  \n",
      "  inflating: data/mpd.slice.517000-517999.json  \n",
      "  inflating: data/mpd.slice.692000-692999.json  \n",
      "  inflating: data/mpd.slice.62000-62999.json  \n",
      "  inflating: data/mpd.slice.194000-194999.json  \n",
      "  inflating: data/mpd.slice.726000-726999.json  \n",
      "  inflating: data/mpd.slice.919000-919999.json  \n",
      "  inflating: data/mpd.slice.89000-89999.json  \n",
      "  inflating: data/mpd.slice.349000-349999.json  \n",
      "  inflating: data/mpd.slice.715000-715999.json  \n",
      "  inflating: data/mpd.slice.178000-178999.json  \n",
      "  inflating: data/mpd.slice.490000-490999.json  \n",
      "  inflating: data/mpd.slice.46000-46999.json  \n",
      "  inflating: data/mpd.slice.396000-396999.json  \n",
      "  inflating: data/mpd.slice.872000-872999.json  \n",
      "  inflating: data/mpd.slice.524000-524999.json  \n",
      "  inflating: data/mpd.slice.222000-222999.json  \n",
      "  inflating: data/mpd.slice.591000-591999.json  \n",
      "  inflating: data/mpd.slice.297000-297999.json  \n",
      "  inflating: data/mpd.slice.973000-973999.json  \n",
      "  inflating: data/mpd.slice.425000-425999.json  \n",
      "  inflating: data/mpd.slice.323000-323999.json  \n",
      "  inflating: data/mpd.slice.818000-818999.json  \n",
      "  inflating: data/mpd.slice.93000-93999.json  \n",
      "  inflating: data/mpd.slice.248000-248999.json  \n",
      "  inflating: data/mpd.slice.112000-112999.json  \n",
      "  inflating: data/mpd.slice.614000-614999.json  \n",
      "  inflating: data/mpd.slice.725000-725999.json  \n",
      "  inflating: data/mpd.slice.929000-929999.json  \n",
      "  inflating: data/mpd.slice.197000-197999.json  \n",
      "  inflating: data/mpd.slice.379000-379999.json  \n",
      "  inflating: data/mpd.slice.691000-691999.json  \n",
      "  inflating: data/mpd.slice.514000-514999.json  \n",
      "  inflating: data/mpd.slice.842000-842999.json  \n",
      "  inflating: data/mpd.slice.212000-212999.json  \n",
      "  inflating: data/mpd.slice.43000-43999.json  \n",
      "  inflating: data/mpd.slice.148000-148999.json  \n",
      "  inflating: data/mpd.slice.415000-415999.json  \n",
      "  inflating: data/mpd.slice.943000-943999.json  \n",
      "  inflating: data/mpd.slice.59000-59999.json  \n",
      "  inflating: data/mpd.slice.313000-313999.json  \n",
      "  inflating: data/mpd.slice.96000-96999.json  \n",
      "  inflating: data/mpd.slice.122000-122999.json  \n",
      "  inflating: data/mpd.slice.624000-624999.json  \n",
      "  inflating: data/mpd.slice.828000-828999.json  \n",
      "  inflating: data/mpd.slice.278000-278999.json  \n",
      "  inflating: data/mpd.slice.790000-790999.json  \n",
      "  inflating: data/mpd.slice.617000-617999.json  \n",
      "  inflating: data/mpd.slice.111000-111999.json  \n",
      "  inflating: data/mpd.slice.320000-320999.json  \n",
      "  inflating: data/mpd.slice.426000-426999.json  \n",
      "  inflating: data/mpd.slice.970000-970999.json  \n",
      "  inflating: data/mpd.slice.294000-294999.json  \n",
      "  inflating: data/mpd.slice.592000-592999.json  \n",
      "  inflating: data/mpd.slice.221000-221999.json  \n",
      "  inflating: data/mpd.slice.527000-527999.json  \n",
      "  inflating: data/mpd.slice.871000-871999.json  \n",
      "  inflating: data/mpd.slice.395000-395999.json  \n",
      "  inflating: data/mpd.slice.493000-493999.json  \n",
      "  inflating: data/mpd.slice.716000-716999.json  \n",
      "  inflating: data/mpd.slice.67000-67999.json  \n",
      "  inflating: data/mpd.slice.213000-213999.json  \n",
      "  inflating: data/mpd.slice.35000-35999.json  \n",
      "  inflating: data/mpd.slice.515000-515999.json  \n",
      "  inflating: data/mpd.slice.843000-843999.json  \n",
      "  inflating: data/mpd.slice.149000-149999.json  \n",
      "  inflating: data/mpd.slice.724000-724999.json  \n",
      "  inflating: data/mpd.slice.4000-4999.json  \n",
      "  inflating: data/mpd.slice.690000-690999.json  \n",
      "  inflating: data/mpd.slice.378000-378999.json  \n",
      "  inflating: data/mpd.slice.196000-196999.json  \n",
      "  inflating: data/mpd.slice.928000-928999.json  \n",
      "  inflating: data/mpd.slice.625000-625999.json  \n",
      "  inflating: data/mpd.slice.123000-123999.json  \n",
      "  inflating: data/mpd.slice.791000-791999.json  \n",
      "  inflating: data/mpd.slice.279000-279999.json  \n",
      "  inflating: data/mpd.slice.829000-829999.json  \n",
      "  inflating: data/mpd.slice.312000-312999.json  \n",
      "  inflating: data/mpd.slice.414000-414999.json  \n",
      "  inflating: data/mpd.slice.942000-942999.json  \n",
      "  inflating: data/mpd.slice.427000-427999.json  \n",
      "  inflating: data/mpd.slice.971000-971999.json  \n",
      "  inflating: data/mpd.slice.321000-321999.json  \n",
      "  inflating: data/mpd.slice.593000-593999.json  \n",
      "  inflating: data/mpd.slice.295000-295999.json  \n",
      "  inflating: data/mpd.slice.110000-110999.json  \n",
      "  inflating: data/mpd.slice.616000-616999.json  \n",
      "  inflating: data/mpd.slice.11000-11999.json  \n",
      "  inflating: data/mpd.slice.717000-717999.json  \n",
      "  inflating: data/mpd.slice.526000-526999.json  \n",
      "  inflating: data/mpd.slice.870000-870999.json  \n",
      "  inflating: data/mpd.slice.220000-220999.json  \n",
      "  inflating: data/mpd.slice.492000-492999.json  \n",
      "  inflating: data/mpd.slice.394000-394999.json  \n",
      "  inflating: data/mpd.slice.744000-744999.json  \n",
      "  inflating: data/mpd.slice.318000-318999.json  \n",
      "  inflating: data/mpd.slice.948000-948999.json  \n",
      "  inflating: data/mpd.slice.273000-273999.json  \n",
      "  inflating: data/mpd.slice.823000-823999.json  \n",
      "  inflating: data/mpd.slice.575000-575999.json  \n",
      "  inflating: data/mpd.slice.129000-129999.json  \n",
      "  inflating: data/mpd.slice.997000-997999.json  \n",
      "  inflating: data/mpd.slice.372000-372999.json  \n",
      "  inflating: data/mpd.slice.922000-922999.json  \n",
      "  inflating: data/mpd.slice.474000-474999.json  \n",
      "  inflating: data/mpd.slice.896000-896999.json  \n",
      "  inflating: data/mpd.slice.645000-645999.json  \n",
      "  inflating: data/mpd.slice.143000-143999.json  \n",
      "  inflating: data/mpd.slice.219000-219999.json  \n",
      "  inflating: data/mpd.slice.25000-25999.json  \n",
      "  inflating: data/mpd.slice.849000-849999.json  \n",
      "  inflating: data/mpd.slice.170000-170999.json  \n",
      "  inflating: data/mpd.slice.498000-498999.json  \n",
      "  inflating: data/mpd.slice.676000-676999.json  \n",
      "  inflating: data/mpd.slice.911000-911999.json  \n",
      "  inflating: data/mpd.slice.447000-447999.json  \n",
      "  inflating: data/mpd.slice.341000-341999.json  \n",
      "  inflating: data/mpd.slice.810000-810999.json  \n",
      "  inflating: data/mpd.slice.546000-546999.json  \n",
      "  inflating: data/mpd.slice.240000-240999.json  \n",
      "  inflating: data/mpd.slice.599000-599999.json  \n",
      "  inflating: data/mpd.slice.777000-777999.json  \n",
      "  inflating: data/mpd.slice.822000-822999.json  \n",
      "  inflating: data/mpd.slice.574000-574999.json  \n",
      "  inflating: data/mpd.slice.272000-272999.json  \n",
      "  inflating: data/mpd.slice.996000-996999.json  \n",
      "  inflating: data/mpd.slice.128000-128999.json  \n",
      "  inflating: data/mpd.slice.86000-86999.json  \n",
      "  inflating: data/mpd.slice.745000-745999.json  \n",
      "  inflating: data/mpd.slice.949000-949999.json  \n",
      "  inflating: data/mpd.slice.319000-319999.json  \n",
      "  inflating: data/mpd.slice.49000-49999.json  \n",
      "  inflating: data/mpd.slice.142000-142999.json  \n",
      "  inflating: data/mpd.slice.644000-644999.json  \n",
      "  inflating: data/mpd.slice.53000-53999.json  \n",
      "  inflating: data/mpd.slice.848000-848999.json  \n",
      "  inflating: data/mpd.slice.218000-218999.json  \n",
      "  inflating: data/mpd.slice.923000-923999.json  \n",
      "  inflating: data/mpd.slice.475000-475999.json  \n",
      "  inflating: data/mpd.slice.373000-373999.json  \n",
      "  inflating: data/mpd.slice.897000-897999.json  \n",
      "  inflating: data/mpd.slice.340000-340999.json  \n",
      "  inflating: data/mpd.slice.910000-910999.json  \n",
      "  inflating: data/mpd.slice.446000-446999.json  \n",
      "  inflating: data/mpd.slice.77000-77999.json  \n",
      "  inflating: data/mpd.slice.677000-677999.json  \n",
      "  inflating: data/mpd.slice.499000-499999.json  \n",
      "  inflating: data/mpd.slice.171000-171999.json  \n",
      "  inflating: data/mpd.slice.776000-776999.json  \n",
      "  inflating: data/mpd.slice.598000-598999.json  \n",
      "  inflating: data/mpd.slice.241000-241999.json  \n",
      "  inflating: data/mpd.slice.811000-811999.json  \n",
      "  inflating: data/mpd.slice.547000-547999.json  \n",
      "  inflating: data/mpd.slice.894000-894999.json  \n",
      "  inflating: data/mpd.slice.698000-698999.json  \n",
      "  inflating: data/mpd.slice.370000-370999.json  \n",
      "  inflating: data/mpd.slice.476000-476999.json  \n",
      "  inflating: data/mpd.slice.920000-920999.json  \n",
      "  inflating: data/mpd.slice.72000-72999.json  \n",
      "  inflating: data/mpd.slice.647000-647999.json  \n",
      "  inflating: data/mpd.slice.141000-141999.json  \n",
      "  inflating: data/mpd.slice.746000-746999.json  \n",
      "  inflating: data/mpd.slice.995000-995999.json  \n",
      "  inflating: data/mpd.slice.799000-799999.json  \n",
      "  inflating: data/mpd.slice.271000-271999.json  \n",
      "  inflating: data/mpd.slice.68000-68999.json  \n",
      "  inflating: data/mpd.slice.577000-577999.json  \n",
      "  inflating: data/mpd.slice.821000-821999.json  \n",
      "  inflating: data/mpd.slice.118000-118999.json  \n",
      "  inflating: data/mpd.slice.83000-83999.json  \n",
      "  inflating: data/mpd.slice.544000-544999.json  \n",
      "  inflating: data/mpd.slice.812000-812999.json  \n",
      "  inflating: data/mpd.slice.242000-242999.json  \n",
      "  inflating: data/mpd.slice.979000-979999.json  \n",
      "  inflating: data/mpd.slice.329000-329999.json  \n",
      "  inflating: data/mpd.slice.775000-775999.json  \n",
      "  inflating: data/mpd.slice.878000-878999.json  \n",
      "  inflating: data/mpd.slice.228000-228999.json  \n",
      "  inflating: data/mpd.slice.172000-172999.json  \n",
      "  inflating: data/mpd.slice.56000-56999.json  \n",
      "  inflating: data/mpd.slice.674000-674999.json  \n",
      "  inflating: data/mpd.slice.445000-445999.json  \n",
      "  inflating: data/mpd.slice.913000-913999.json  \n",
      "  inflating: data/mpd.slice.99000-99999.json  \n",
      "  inflating: data/mpd.slice.343000-343999.json  \n",
      "  inflating: data/mpd.slice.140000-140999.json  \n",
      "  inflating: data/mpd.slice.646000-646999.json  \n",
      "  inflating: data/mpd.slice.895000-895999.json  \n",
      "  inflating: data/mpd.slice.477000-477999.json  \n",
      "  inflating: data/mpd.slice.921000-921999.json  \n",
      "  inflating: data/mpd.slice.371000-371999.json  \n",
      "  inflating: data/mpd.slice.699000-699999.json  \n",
      "  inflating: data/mpd.slice.994000-994999.json  \n",
      "  inflating: data/mpd.slice.576000-576999.json  \n",
      "  inflating: data/mpd.slice.820000-820999.json  \n",
      "  inflating: data/mpd.slice.270000-270999.json  \n",
      "  inflating: data/mpd.slice.798000-798999.json  \n",
      "  inflating: data/mpd.slice.747000-747999.json  \n",
      "  inflating: data/mpd.slice.328000-328999.json  \n",
      "  inflating: data/mpd.slice.978000-978999.json  \n",
      "  inflating: data/mpd.slice.774000-774999.json  \n",
      "  inflating: data/mpd.slice.119000-119999.json  \n",
      "  inflating: data/mpd.slice.243000-243999.json  \n",
      "  inflating: data/mpd.slice.545000-545999.json  \n",
      "  inflating: data/mpd.slice.813000-813999.json  \n",
      "  inflating: data/mpd.slice.342000-342999.json  \n",
      "  inflating: data/mpd.slice.444000-444999.json  \n",
      "  inflating: data/mpd.slice.912000-912999.json  \n",
      "  inflating: data/mpd.slice.229000-229999.json  \n",
      "  inflating: data/mpd.slice.879000-879999.json  \n",
      "  inflating: data/mpd.slice.675000-675999.json  \n",
      "  inflating: data/mpd.slice.173000-173999.json  \n",
      "  inflating: data/mpd.slice.20000-20999.json  \n",
      "  inflating: data/mpd.slice.666000-666999.json  \n",
      "  inflating: data/mpd.slice.160000-160999.json  \n",
      "  inflating: data/mpd.slice.488000-488999.json  \n",
      "  inflating: data/mpd.slice.351000-351999.json  \n",
      "  inflating: data/mpd.slice.457000-457999.json  \n",
      "  inflating: data/mpd.slice.901000-901999.json  \n",
      "  inflating: data/mpd.slice.18000-18999.json  \n",
      "  inflating: data/mpd.slice.250000-250999.json  \n",
      "  inflating: data/mpd.slice.556000-556999.json  \n",
      "  inflating: data/mpd.slice.800000-800999.json  \n",
      "  inflating: data/mpd.slice.767000-767999.json  \n",
      "  inflating: data/mpd.slice.589000-589999.json  \n",
      "  inflating: data/mpd.slice.958000-958999.json  \n",
      "  inflating: data/mpd.slice.308000-308999.json  \n",
      "  inflating: data/mpd.slice.754000-754999.json  \n",
      "  inflating: data/mpd.slice.139000-139999.json  \n",
      "  inflating: data/mpd.slice.987000-987999.json  \n",
      "  inflating: data/mpd.slice.565000-565999.json  \n",
      "  inflating: data/mpd.slice.833000-833999.json  \n",
      "  inflating: data/mpd.slice.263000-263999.json  \n",
      "  inflating: data/mpd.slice.886000-886999.json  \n",
      "  inflating: data/mpd.slice.464000-464999.json  \n",
      "  inflating: data/mpd.slice.932000-932999.json  \n",
      "  inflating: data/mpd.slice.362000-362999.json  \n",
      "  inflating: data/mpd.slice.26000-26999.json  \n",
      "  inflating: data/mpd.slice.859000-859999.json  \n",
      "  inflating: data/mpd.slice.209000-209999.json  \n",
      "  inflating: data/mpd.slice.153000-153999.json  \n",
      "  inflating: data/mpd.slice.655000-655999.json  \n",
      "  inflating: data/mpd.slice.74000-74999.json  \n",
      "  inflating: data/mpd.slice.456000-456999.json  \n",
      "  inflating: data/mpd.slice.900000-900999.json  \n",
      "  inflating: data/mpd.slice.350000-350999.json  \n",
      "  inflating: data/mpd.slice.489000-489999.json  \n",
      "  inflating: data/mpd.slice.161000-161999.json  \n",
      "  inflating: data/mpd.slice.667000-667999.json  \n",
      "  inflating: data/mpd.slice.588000-588999.json  \n",
      "  inflating: data/mpd.slice.766000-766999.json  \n",
      "  inflating: data/mpd.slice.557000-557999.json  \n",
      "  inflating: data/mpd.slice.801000-801999.json  \n",
      "  inflating: data/mpd.slice.251000-251999.json  \n",
      "  inflating: data/mpd.slice.85000-85999.json  \n",
      "  inflating: data/mpd.slice.986000-986999.json  \n",
      "  inflating: data/mpd.slice.138000-138999.json  \n",
      "  inflating: data/mpd.slice.262000-262999.json  \n",
      "  inflating: data/mpd.slice.564000-564999.json  \n",
      "  inflating: data/mpd.slice.832000-832999.json  \n",
      "  inflating: data/mpd.slice.309000-309999.json  \n",
      "  inflating: data/mpd.slice.959000-959999.json  \n",
      "  inflating: data/mpd.slice.755000-755999.json  \n",
      "  inflating: data/mpd.slice.208000-208999.json  \n",
      "  inflating: data/mpd.slice.50000-50999.json  \n",
      "  inflating: data/mpd.slice.858000-858999.json  \n",
      "  inflating: data/mpd.slice.654000-654999.json  \n",
      "  inflating: data/mpd.slice.152000-152999.json  \n",
      "  inflating: data/mpd.slice.887000-887999.json  \n",
      "  inflating: data/mpd.slice.363000-363999.json  \n",
      "  inflating: data/mpd.slice.465000-465999.json  \n",
      "  inflating: data/mpd.slice.933000-933999.json  \n",
      "  inflating: data/mpd.slice.80000-80999.json  \n",
      "  inflating: data/mpd.slice.252000-252999.json  \n",
      "  inflating: data/mpd.slice.802000-802999.json  \n",
      "  inflating: data/mpd.slice.554000-554999.json  \n",
      "  inflating: data/mpd.slice.108000-108999.json  \n",
      "  inflating: data/mpd.slice.765000-765999.json  \n",
      "  inflating: data/mpd.slice.339000-339999.json  \n",
      "  inflating: data/mpd.slice.969000-969999.json  \n",
      "  inflating: data/mpd.slice.664000-664999.json  \n",
      "  inflating: data/mpd.slice.162000-162999.json  \n",
      "  inflating: data/mpd.slice.55000-55999.json  \n",
      "  inflating: data/mpd.slice.238000-238999.json  \n",
      "  inflating: data/mpd.slice.868000-868999.json  \n",
      "  inflating: data/mpd.slice.353000-353999.json  \n",
      "  inflating: data/mpd.slice.903000-903999.json  \n",
      "  inflating: data/mpd.slice.455000-455999.json  \n",
      "  inflating: data/mpd.slice.930000-930999.json  \n",
      "  inflating: data/mpd.slice.466000-466999.json  \n",
      "  inflating: data/mpd.slice.688000-688999.json  \n",
      "  inflating: data/mpd.slice.360000-360999.json  \n",
      "  inflating: data/mpd.slice.71000-71999.json  \n",
      "  inflating: data/mpd.slice.884000-884999.json  \n",
      "  inflating: data/mpd.slice.151000-151999.json  \n",
      "  inflating: data/mpd.slice.657000-657999.json  \n",
      "  inflating: data/mpd.slice.756000-756999.json  \n",
      "  inflating: data/mpd.slice.831000-831999.json  \n",
      "  inflating: data/mpd.slice.567000-567999.json  \n",
      "  inflating: data/mpd.slice.789000-789999.json  \n",
      "  inflating: data/mpd.slice.261000-261999.json  \n",
      "  inflating: data/mpd.slice.985000-985999.json  \n",
      "  inflating: data/mpd.slice.39000-39999.json  \n",
      "  inflating: data/mpd.slice.764000-764999.json  \n",
      "  inflating: data/mpd.slice.968000-968999.json  \n",
      "  inflating: data/mpd.slice.338000-338999.json  \n",
      "  inflating: data/mpd.slice.803000-803999.json  \n",
      "  inflating: data/mpd.slice.555000-555999.json  \n",
      "  inflating: data/mpd.slice.253000-253999.json  \n",
      "  inflating: data/mpd.slice.109000-109999.json  \n",
      "  inflating: data/mpd.slice.902000-902999.json  \n",
      "  inflating: data/mpd.slice.454000-454999.json  \n",
      "  inflating: data/mpd.slice.352000-352999.json  \n",
      "  inflating: data/mpd.slice.163000-163999.json  \n",
      "  inflating: data/mpd.slice.23000-23999.json  \n",
      "  inflating: data/mpd.slice.665000-665999.json  \n",
      "  inflating: data/mpd.slice.869000-869999.json  \n",
      "  inflating: data/mpd.slice.239000-239999.json  \n",
      "  inflating: data/mpd.slice.656000-656999.json  \n",
      "  inflating: data/mpd.slice.150000-150999.json  \n",
      "  inflating: data/mpd.slice.361000-361999.json  \n",
      "  inflating: data/mpd.slice.689000-689999.json  \n",
      "  inflating: data/mpd.slice.931000-931999.json  \n",
      "  inflating: data/mpd.slice.467000-467999.json  \n",
      "  inflating: data/mpd.slice.885000-885999.json  \n",
      "  inflating: data/mpd.slice.260000-260999.json  \n",
      "  inflating: data/mpd.slice.788000-788999.json  \n",
      "  inflating: data/mpd.slice.830000-830999.json  \n",
      "  inflating: data/mpd.slice.566000-566999.json  \n",
      "  inflating: data/mpd.slice.984000-984999.json  \n",
      "  inflating: data/mpd.slice.757000-757999.json  \n",
      "  inflating: data/mpd.slice.535000-535999.json  \n",
      "  inflating: data/mpd.slice.863000-863999.json  \n",
      "  inflating: data/mpd.slice.233000-233999.json  \n",
      "  inflating: data/mpd.slice.481000-481999.json  \n",
      "  inflating: data/mpd.slice.169000-169999.json  \n",
      "  inflating: data/mpd.slice.33000-33999.json  \n",
      "  inflating: data/mpd.slice.387000-387999.json  \n",
      "  inflating: data/mpd.slice.704000-704999.json  \n",
      "  inflating: data/mpd.slice.908000-908999.json  \n",
      "  inflating: data/mpd.slice.358000-358999.json  \n",
      "  inflating: data/mpd.slice.103000-103999.json  \n",
      "  inflating: data/mpd.slice.605000-605999.json  \n",
      "  inflating: data/mpd.slice.809000-809999.json  \n",
      "  inflating: data/mpd.slice.259000-259999.json  \n",
      "  inflating: data/mpd.slice.434000-434999.json  \n",
      "  inflating: data/mpd.slice.962000-962999.json  \n",
      "  inflating: data/mpd.slice.332000-332999.json  \n",
      "  inflating: data/mpd.slice.580000-580999.json  \n",
      "  inflating: data/mpd.slice.29000-29999.json  \n",
      "  inflating: data/mpd.slice.286000-286999.json  \n",
      "  inflating: data/mpd.slice.301000-301999.json  \n",
      "  inflating: data/mpd.slice.407000-407999.json  \n",
      "  inflating: data/mpd.slice.951000-951999.json  \n",
      "  inflating: data/mpd.slice.636000-636999.json  \n",
      "  inflating: data/mpd.slice.130000-130999.json  \n",
      "  inflating: data/mpd.slice.782000-782999.json  \n",
      "  inflating: data/mpd.slice.737000-737999.json  \n",
      "  inflating: data/mpd.slice.683000-683999.json  \n",
      "  inflating: data/mpd.slice.17000-17999.json  \n",
      "  inflating: data/mpd.slice.185000-185999.json  \n",
      "  inflating: data/mpd.slice.200000-200999.json  \n",
      "  inflating: data/mpd.slice.506000-506999.json  \n",
      "  inflating: data/mpd.slice.850000-850999.json  \n",
      "  inflating: data/mpd.slice.705000-705999.json  \n",
      "  inflating: data/mpd.slice.359000-359999.json  \n",
      "  inflating: data/mpd.slice.909000-909999.json  \n",
      "  inflating: data/mpd.slice.232000-232999.json  \n",
      "  inflating: data/mpd.slice.534000-534999.json  \n",
      "  inflating: data/mpd.slice.862000-862999.json  \n",
      "  inflating: data/mpd.slice.386000-386999.json  \n",
      "  inflating: data/mpd.slice.45000-45999.json  \n",
      "  inflating: data/mpd.slice.168000-168999.json  \n",
      "  inflating: data/mpd.slice.480000-480999.json  \n",
      "  inflating: data/mpd.slice.333000-333999.json  \n",
      "  inflating: data/mpd.slice.435000-435999.json  \n",
      "  inflating: data/mpd.slice.963000-963999.json  \n",
      "  inflating: data/mpd.slice.287000-287999.json  \n",
      "  inflating: data/mpd.slice.581000-581999.json  \n",
      "  inflating: data/mpd.slice.604000-604999.json  \n",
      "  inflating: data/mpd.slice.102000-102999.json  \n",
      "  inflating: data/mpd.slice.258000-258999.json  \n",
      "  inflating: data/mpd.slice.808000-808999.json  \n",
      "  inflating: data/mpd.slice.90000-90999.json  \n",
      "  inflating: data/mpd.slice.131000-131999.json  \n",
      "  inflating: data/mpd.slice.637000-637999.json  \n",
      "  inflating: data/mpd.slice.783000-783999.json  \n",
      "  inflating: data/mpd.slice.406000-406999.json  \n",
      "  inflating: data/mpd.slice.950000-950999.json  \n",
      "  inflating: data/mpd.slice.300000-300999.json  \n",
      "  inflating: data/mpd.slice.507000-507999.json  \n",
      "  inflating: data/mpd.slice.851000-851999.json  \n",
      "  inflating: data/mpd.slice.201000-201999.json  \n",
      "  inflating: data/mpd.slice.736000-736999.json  \n",
      "  inflating: data/mpd.slice.61000-61999.json  \n",
      "  inflating: data/mpd.slice.184000-184999.json  \n",
      "  inflating: data/mpd.slice.682000-682999.json  \n",
      "  inflating: data/mpd.slice.101000-101999.json  \n",
      "  inflating: data/mpd.slice.607000-607999.json  \n",
      "  inflating: data/mpd.slice.582000-582999.json  \n",
      "  inflating: data/mpd.slice.284000-284999.json  \n",
      "  inflating: data/mpd.slice.960000-960999.json  \n",
      "  inflating: data/mpd.slice.436000-436999.json  \n",
      "  inflating: data/mpd.slice.330000-330999.json  \n",
      "  inflating: data/mpd.slice.483000-483999.json  \n",
      "  inflating: data/mpd.slice.385000-385999.json  \n",
      "  inflating: data/mpd.slice.861000-861999.json  \n",
      "  inflating: data/mpd.slice.537000-537999.json  \n",
      "  inflating: data/mpd.slice.231000-231999.json  \n",
      "  inflating: data/mpd.slice.64000-64999.json  \n",
      "  inflating: data/mpd.slice.706000-706999.json  \n",
      "  inflating: data/mpd.slice.369000-369999.json  \n",
      "  inflating: data/mpd.slice.681000-681999.json  \n",
      "  inflating: data/mpd.slice.939000-939999.json  \n",
      "  inflating: data/mpd.slice.187000-187999.json  \n",
      "  inflating: data/mpd.slice.735000-735999.json  \n",
      "  inflating: data/mpd.slice.158000-158999.json  \n",
      "  inflating: data/mpd.slice.202000-202999.json  \n",
      "  inflating: data/mpd.slice.40000-40999.json  \n",
      "  inflating: data/mpd.slice.852000-852999.json  \n",
      "  inflating: data/mpd.slice.504000-504999.json  \n",
      "  inflating: data/mpd.slice.303000-303999.json  \n",
      "  inflating: data/mpd.slice.953000-953999.json  \n",
      "  inflating: data/mpd.slice.405000-405999.json  \n",
      "  inflating: data/mpd.slice.268000-268999.json  \n",
      "  inflating: data/mpd.slice.780000-780999.json  \n",
      "  inflating: data/mpd.slice.838000-838999.json  \n",
      "  inflating: data/mpd.slice.634000-634999.json  \n",
      "  inflating: data/mpd.slice.95000-95999.json  \n",
      "  inflating: data/mpd.slice.132000-132999.json  \n",
      "  inflating: data/mpd.slice.285000-285999.json  \n",
      "  inflating: data/mpd.slice.583000-583999.json  \n",
      "  inflating: data/mpd.slice.331000-331999.json  \n",
      "  inflating: data/mpd.slice.961000-961999.json  \n",
      "  inflating: data/mpd.slice.437000-437999.json  \n",
      "  inflating: data/mpd.slice.606000-606999.json  \n",
      "  inflating: data/mpd.slice.100000-100999.json  \n",
      "  inflating: data/mpd.slice.707000-707999.json  \n",
      "  inflating: data/mpd.slice.12000-12999.json  \n",
      "  inflating: data/mpd.slice.384000-384999.json  \n",
      "  inflating: data/mpd.slice.482000-482999.json  \n",
      "  inflating: data/mpd.slice.230000-230999.json  \n",
      "  inflating: data/mpd.slice.860000-860999.json  \n",
      "  inflating: data/mpd.slice.536000-536999.json  \n",
      "  inflating: data/mpd.slice.159000-159999.json  \n",
      "  inflating: data/mpd.slice.853000-853999.json  \n",
      "  inflating: data/mpd.slice.505000-505999.json  \n",
      "  inflating: data/mpd.slice.36000-36999.json  \n",
      "  inflating: data/mpd.slice.203000-203999.json  \n",
      "  inflating: data/mpd.slice.186000-186999.json  \n",
      "  inflating: data/mpd.slice.938000-938999.json  \n",
      "  inflating: data/mpd.slice.680000-680999.json  \n",
      "  inflating: data/mpd.slice.368000-368999.json  \n",
      "  inflating: data/mpd.slice.734000-734999.json  \n",
      "  inflating: data/mpd.slice.839000-839999.json  \n",
      "  inflating: data/mpd.slice.781000-781999.json  \n",
      "  inflating: data/mpd.slice.269000-269999.json  \n",
      "  inflating: data/mpd.slice.133000-133999.json  \n",
      "  inflating: data/mpd.slice.635000-635999.json  \n",
      "  inflating: data/mpd.slice.952000-952999.json  \n",
      "  inflating: data/mpd.slice.404000-404999.json  \n",
      "  inflating: data/mpd.slice.302000-302999.json  \n",
      "  inflating: src/show.py             \n",
      "  inflating: src/deeper_stats.py     \n",
      "  inflating: src/check.py            \n",
      "  inflating: src/print.py            \n",
      "  inflating: src/stats.py            \n",
      "  inflating: src/descriptions.py     \n"
     ]
    }
   ],
   "source": [
    "# !gsutil cp gs://{SOURCE_BUCKET}/spotify_million_playlist_dataset.zip .\n",
    "!unzip -n spotify_million_playlist_dataset.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This step can take up to 30 minutes\n",
    "\n",
    "Iteration occurs over 1000 json files if you are using the full dataset\n",
    "\n",
    "This should give you a `playlists` bq data set with 1,076,000 rows (playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [36:47<00:00,  2.21s/it] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "data_files = os.listdir('data')\n",
    "\n",
    "def load_data(filename: str):\n",
    "    with open(f'data/{filename}') as f:\n",
    "        json_dict = json.load(f)\n",
    "        df = pd.DataFrame(json_dict['playlists'])\n",
    "        df['tracks'] = df['tracks'].map(str)\n",
    "        #write to bq\n",
    "        return df\n",
    "        \n",
    "#make sure there is not already existing data in the playlists table\n",
    "#loops over json files - converts to pandas then upload/appends\n",
    "\n",
    "### add this if you want to limit to smaller number of playlists - this scales significantly later!\n",
    "n_playliststs_limit = None #add if you want to use in for loop: while counter <= n_playliststs_limit:\n",
    "total_files = len(data_files)\n",
    "count = 0\n",
    "batch_size = 15\n",
    "\n",
    "for filename in tqdm(data_files):\n",
    "    if count == 0 or (count-1) % batch_size == 0:\n",
    "        append_df = load_data(filename)\n",
    "        count += 1\n",
    "    if count % batch_size == 0 or count == total_files:\n",
    "        df = load_data(filename) \n",
    "        append_df = pd.concat([df, append_df])\n",
    "        count += 1\n",
    "        append_df.to_gbq(\n",
    "                destination_table=f'{BQ_DATASET}.playlists', \n",
    "                project_id=PROJECT_ID, # TODO: param\n",
    "                location='US', \n",
    "                progress_bar=False, \n",
    "                reauth=True, \n",
    "                if_exists='append'\n",
    "            ) \n",
    "    else:\n",
    "        df = load_data(filename) \n",
    "        append_df = pd.concat([df, append_df])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is loaded but the playlists are nested as one large string that needs to be parsed - we will use json compatible functionality with BigQuery to address\n",
    "\n",
    "![](img/tracks-string.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import bigquery and run parameterized queries to shape the data\n",
    "\n",
    "This query formats the json strings to be read as Bigquery structs, to be manipulated in subsequent queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.7 ms, sys: 7.1 ms, total: 70.8 ms\n",
      "Wall time: 38.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f0eace3ef90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "json_extract_query = f\"\"\"create or replace table `{PROJECT_ID}.{BQ_DATASET}.playlists_nested` as (\n",
    "with json_parsed as (SELECT * except(tracks), JSON_EXTRACT_ARRAY(tracks) as json_data FROM `{PROJECT_ID}.{BQ_DATASET}.playlists` )\n",
    "\n",
    "select json_parsed.* except(json_data),\n",
    "ARRAY(SELECT AS STRUCT\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.pos\") as pos, \n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.artist_name\") as artist_name,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.track_uri\") as track_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.artist_uri\") as artist_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.track_name\") as track_name,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.album_uri\") as album_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.duration_ms\") as duration_ms,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.album_name\") as album_name\n",
    "from json_parsed.json_data\n",
    ") as tracks,\n",
    "from json_parsed) \"\"\"\n",
    "\n",
    "bigquery_client.query(json_extract_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `playlists_nested` has parsed the string data to a struct with arrays that will allow us to process the data much more easily\n",
    "\n",
    "![](img/playlists-nested.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next we get the unique track features to put in a BQ table\n",
    "\n",
    "This table will then be used to call the Spotify API and enrich with additional data about each track and artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 ms, sys: 1.43 ms, total: 16.8 ms\n",
      "Wall time: 18.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f0ea72f4890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_tracks_sql = f\"\"\"create or replace table `{PROJECT_ID}.{BQ_DATASET}.tracks_unique` as (\n",
    "SELECT distinct \n",
    "    track.track_uri,\n",
    "    track.album_uri,\n",
    "    track.artist_uri, \n",
    "FROM `{PROJECT_ID}.{BQ_DATASET}.playlists_nested`, UNNEST(tracks) as track)\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(unique_tracks_sql).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core dataset loading complete\n",
    "\n",
    "We now have our unique id tables we will use for grabbing additional audio and artist features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVKyuWRezBGF"
   },
   "source": [
    "___________\n",
    "# Spotify API Feature Extraction\n",
    "\n",
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgGWdClhze9D",
    "tags": []
   },
   "source": [
    "* Spotify Mlllion Playlist Dataset Challenge [Homepage](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n",
    "* [Spotify Web API docs](https://developer.spotify.com/documentation/web-api/reference/#/)\n",
    "\n",
    "**Community Examples**\n",
    "* [Extracting song lists](https://github.com/tojhe/recsys-spotify/blob/master/processing/songlist_extraction.py)\n",
    "* [construct audio features with Spotify API](https://github.com/tojhe/recsys-spotify/blob/master/processing/audio_features_construction.py)\n",
    "* [Using Spotify API](https://towardsdatascience.com/extracting-song-data-from-the-spotify-api-using-python-b1e79388d50)\n",
    "\n",
    "#### After reading through these, create a new Spotify App and get the customer id, secret\n",
    "![](img/spotify-dev-console.png)\n",
    "\n",
    "This example uses a local json credentials and if you are concerned over visibility to apikeys, please see [GCP Secret Manager](https://cloud.google.com/secret-manager)\n",
    "\n",
    "Below is an example if you were to add the json file to secret manager (keys: `secret`, `id`)\n",
    "\n",
    "```python\n",
    "from google.cloud import secretmanager\n",
    "\n",
    "###Note you copy/paste this from secret manager in console\n",
    "SECRET_VERSION = 'projects/934903580331/secrets/spotify-creds1/versions/1'\n",
    "\n",
    "sm_client = secretmanager.SecretManagerServiceClient()\n",
    "\n",
    "name = sm_client.secret_path(PROJECT_ID, SECRET_ID)\n",
    "\n",
    "response = client.access_secret_version(request={\"name\": SECRET_VERSION})   \n",
    "\n",
    "payload = json.loads(response.payload.data.decode(\"UTF-8\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RRSdCB_HSBSl",
    "outputId": "b272ec83-d189-4a22-da3e-5ef650c574b7",
    "tags": []
   },
   "source": [
    "### Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U spotipy google-cloud-storage google-cloud-aiplatform gcsfs --user -q\n",
    "# ! pip3 install --user kfp google-cloud-pipeline-components --upgrade -q\n",
    "# !pip3 install --user -q google-cloud-secret-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irhbKrY3fcG8",
    "outputId": "2008a7ca-303d-4943-e56b-a57040c9abd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.19\n",
      "google_cloud_pipeline_components version: 1.0.40\n",
      "aiplatform SDK version: 1.23.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCbr2tLuzTJK"
   },
   "source": [
    "### Constants - setup to your config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wwktfnCyzWO",
    "outputId": "6afe4a17-ebc2-40dc-d23a-1f447f394046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: v1-spotify-feature-enrich\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'wortz-project-352116' #update\n",
    "LOCATION = 'us-central1' \n",
    "\n",
    "BUCKET_NAME = 'matching-engine-wortz'\n",
    "\n",
    "VERSION = 1\n",
    "PIPELINE_VERSION = f'v{VERSION}' # pipeline code\n",
    "PIPELINE_TAG = f'{PIPELINE_VERSION}-spotify-feature-enrich'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Bucket if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l $LOCATION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GqhJlsodR-xX"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "# GCP\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuJk9A5I9ZfF"
   },
   "source": [
    "### Clients & credentials\n",
    "\n",
    "Setup Vertex AI client for pipelines\n",
    "\n",
    "Spotify shoulld be stored in a json file with a your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCbHe1G_gICe",
    "outputId": "c3f7d046-4997-4b59-9bcc-44df8feba2ed"
   },
   "outputs": [],
   "source": [
    "# # Setup clients\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spotify credentials\n",
    "# This file has id and secret stored as attributes\n",
    "\n",
    "\n",
    "###########################################\n",
    "### CAUTION THIS APPROACH WILL HAVE THE CREDENTIALS APPEAR IN THE CONSOLE - \n",
    "### USE SECRET MANAGER APPROACH IN EACH COMPONENT AS NEEDED (PROVIDED ABOVE)\n",
    "###########################################\n",
    "\n",
    "\n",
    "creds = open('spotify-creds.json')\n",
    "spotify_creds = json.load(creds)\n",
    "creds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbeNm6_whXMG"
   },
   "source": [
    "# Create Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m3D974DjTbE"
   },
   "source": [
    "### Audio Features\n",
    "\n",
    "[Link to artist API and related features we will pull](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec', 'google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4',\n",
    "                         'tqdm'\n",
    "                        ])\n",
    "\n",
    "def call_spotify_api_audio(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    client_id: str,\n",
    "    batch_size: int,\n",
    "    batches_to_store: int,\n",
    "    target_table: str,\n",
    "    client_secret: str,\n",
    "    unique_table: str,\n",
    "    sleep_param: float,\n",
    ") -> NamedTuple('Outputs', [('done_message', str),]):\n",
    "    print(f'pip install complete')\n",
    "    import os\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import time\n",
    "    from google.cloud import storage\n",
    "    import gcsfs\n",
    "    import numpy as np\n",
    "    from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "    from absl import logging\n",
    "    from google.cloud import bigquery\n",
    "    import pandas_gbq\n",
    "    from multiprocessing import Process\n",
    "    from tqdm import tqdm\n",
    "    from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "    from google.cloud.exceptions import NotFound\n",
    "\n",
    "\n",
    "\n",
    "    import multiprocessing\n",
    "\n",
    "    # print(f'package import complete')\n",
    "\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    logging.info(f'package import complete')\n",
    "\n",
    "    \n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "    )\n",
    "    \n",
    "    def spot_audio_features(uri, client_id, client_secret):\n",
    "\n",
    "        # Authenticate\n",
    "        client_credentials_manager = SpotifyClientCredentials(\n",
    "            client_id=client_id, \n",
    "            client_secret=client_secret\n",
    "        )\n",
    "        sp = spotipy.Spotify(\n",
    "            client_credentials_manager = client_credentials_manager, \n",
    "            requests_timeout=10, \n",
    "            retries=10 )\n",
    "        ############################################################################\n",
    "        # Create Track Audio Features DF\n",
    "        ############################################################################\n",
    "        \n",
    "        uri_stripped = [u.replace('spotify:track:', '') for u in uri] #fix the quotes \n",
    "        #getting track popularity\n",
    "        tracks = sp.tracks(uri_stripped)\n",
    "        #Audio features\n",
    "        time.sleep(sleep_param)\n",
    "    \n",
    "        a_feats = sp.audio_features(uri)\n",
    "        features = pd.json_normalize(a_feats)#.to_dict('list')\n",
    "        \n",
    "        features['track_pop'] = pd.json_normalize(tracks['tracks'])['popularity']\n",
    "        \n",
    "        features['track_uri'] = uri\n",
    "        return features\n",
    "\n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location='US'\n",
    "    )\n",
    "    \n",
    "    #check if target table exists and if so return a list to not duplicate records\n",
    "    try:\n",
    "        bq_client.get_table(target_table)  # Make an API request.\n",
    "        logging.info(\"Table {} already exists.\".format(target_table))\n",
    "        target_table_incomplete_query = f\"select distinct track_uri from `{target_table}`\"\n",
    "        loaded_tracks_df = bq_client.query(target_table_incomplete_query).result().to_dataframe()\n",
    "        loaded_tracks = loaded_tracks_df.track_uri.to_list()\n",
    "        \n",
    "    except NotFound:\n",
    "        logging.info(\"Table {} is not found.\".format(target_table))\n",
    "    \n",
    "    query = f\"select distinct track_uri from `{unique_table}`\" \n",
    "\n",
    "\n",
    "    #refactor\n",
    "    schema = [{'name':'danceability', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'energy', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'key', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'loudness', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'mode', 'type': 'INTEGER', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'speechiness', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'acousticness', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'instrumentalness', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'liveness', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'valence', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'tempo', 'type': 'FLOAT', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'type', 'type': 'STRING', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'id', 'type': 'STRING', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'uri', 'type': 'STRING', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'track_href', 'type': 'STRING', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'analysis_url', 'type': 'STRING', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'duration_ms', 'type': 'INTEGER', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'time_signature', 'type': 'INTEGER', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'track_pop', 'type': 'INTEGER', \"mode\": \"NULLABLE\"},\n",
    "        {'name':'track_uri', 'type': 'STRING', \"mode\": \"REQUIRED\"},\n",
    "    ]\n",
    "    \n",
    "    tracks = bq_client.query(query).result().to_dataframe()\n",
    "    track_list = tracks.track_uri.to_list()\n",
    "    logging.info(f'finished downloading tracks')\n",
    "    \n",
    "    \n",
    "    ### This section is used when there are tracks already loaded into BQ and you want to resume loading the data\n",
    "    try:\n",
    "        track_list = list(set(track_list) - set(loaded_tracks)) #sets the new track list to remove already loaded data in BQ\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    from tqdm import tqdm\n",
    "    def process_track_list(track_list):\n",
    "            uri_list_length = len(track_list)-1 #starting count at zero\n",
    "            inner_batch_count = 0 #avoiding calling the api on 0th iteration\n",
    "            uri_batch = []\n",
    "            for i, uri in enumerate(tqdm(track_list)):\n",
    "                uri_batch.append(uri)\n",
    "                if (len(uri_batch) == batch_size or uri_list_length == i) and i > 0: #grab a batch of 50 songs\n",
    "                    # logging.info(f\"appending final record for nth song at: {inner_batch_count} \\n i: {i} \\n uri_batch length: {len(uri_batch)}\")\n",
    "                    ### Try catch block for function\n",
    "                    try:\n",
    "                        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "                        time.sleep(sleep_param)\n",
    "                        uri_batch = []\n",
    "                    except ReadTimeout:\n",
    "                        logging.info(\"'Spotify timed out... trying again...'\")\n",
    "                        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "                        uri_batch = []\n",
    "                        time.sleep(sleep_param)\n",
    "                    except HTTPError as err: #JW ADDED\n",
    "                        logging.info(f\"HTTP Error: {err}\")\n",
    "                    except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "                        logging.info(f\"Spotify error: {spotify_error}\")\n",
    "                    # Accumulate batches on the machine before writing to BQ\n",
    "                    # if inner_batch_count <= batches_to_store or uri_list_length == i:\n",
    "                    if inner_batch_count == 0:\n",
    "                        appended_data = audio_featureDF\n",
    "                        # logging.info(f\"creating new appended data at IBC: {inner_batch_count} \\n i: {i}\")\n",
    "                        inner_batch_count += 1\n",
    "                    elif uri_list_length == i or inner_batch_count == batches_to_store: #send the batches to bq\n",
    "                        appended_data = pd.concat([audio_featureDF, appended_data])\n",
    "                        inner_batch_count = 0\n",
    "                        appended_data.to_gbq(\n",
    "                            destination_table=target_table, \n",
    "                            project_id=f'{project}', \n",
    "                            location='US', \n",
    "                            table_schema=schema,\n",
    "                            progress_bar=False, \n",
    "                            reauth=False, \n",
    "                            if_exists='append'\n",
    "                            )\n",
    "                        logging.info(f'{i+1} of {uri_list_length} complete!')\n",
    "                    else:\n",
    "                        appended_data = pd.concat([audio_featureDF, appended_data])\n",
    "                        inner_batch_count += 1\n",
    "\n",
    "            logging.info(f'audio features appended')\n",
    "    \n",
    "    #multiprocessing portion - we will loop based on the modulus of the track_uri list\n",
    "    #chunk the list \n",
    "    \n",
    "    # Yield successive n-sized\n",
    "    # chunks from l.\n",
    "    def divide_chunks(l, n):\n",
    "        # looping till length l\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "            \n",
    "    n_cores = multiprocessing.cpu_count() \n",
    "    chunked_tracks = list(divide_chunks(track_list, int(len(track_list)/n_cores))) #produces a list of lists chunked evenly by groups of n_cores\n",
    "    \n",
    "    logging.info(f\"\"\"total tracks downloaded: {len(track_list)}\\n\n",
    "                    length of chunked_tracks: {len(chunked_tracks)}\\n \n",
    "                    and inner dims: {[len(x) for x in chunked_tracks]}\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "    procs = []\n",
    "    \n",
    "    def create_job(target, *args):\n",
    "        p = multiprocessing.Process(target=target, args=args)\n",
    "        p.start()\n",
    "        return p\n",
    "\n",
    "    # starting process with arguments\n",
    "    for track_chunk in chunked_tracks:\n",
    "        proc = create_job(process_track_list, track_chunk)\n",
    "        time.sleep(np.pi)\n",
    "        procs.append(proc)\n",
    "\n",
    "    # complete the processes\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "        \n",
    "    # process_track_list(track_list) #single thread\n",
    "            \n",
    "     \n",
    "    logging.info(f'audio features appended')\n",
    "    return (\n",
    "          f'DONE',\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hppPSwkh1x2",
    "tags": []
   },
   "source": [
    "### Artists \n",
    "\n",
    "[Link to artist API and related features we will pull](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-an-artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "JYbgsLrtxPHl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Artist tracks api call\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',' google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs', 'tqdm',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4',\n",
    "                        'google-cloud-secret-manager'])\n",
    "\n",
    "def call_spotify_api_artist(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    unique_table: str,\n",
    "    batch_size: int,\n",
    "    batches_to_store: int,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: float,\n",
    "    target_table: str,\n",
    ") -> NamedTuple('Outputs', [('done_message', str),]):\n",
    "    print(f'pip install complete')\n",
    "    import os\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import time\n",
    "    from google.cloud import storage\n",
    "    import gcsfs\n",
    "    import numpy as np\n",
    "    from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "    from absl import logging\n",
    "    from google.cloud import bigquery\n",
    "    import pandas_gbq\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    from google.cloud.exceptions import NotFound\n",
    "    \n",
    "    from multiprocessing import Process\n",
    "    import multiprocessing\n",
    "\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    logging.info(f'package import complete')\n",
    "\n",
    "    storage_client = storage.Client(\n",
    "        project=project\n",
    "    )\n",
    "    \n",
    "    logging.info(f'spotipy auth complete')\n",
    "    \n",
    "    def spot_artist_features(uri, client_id, client_secret):\n",
    "\n",
    "        # Authenticate\n",
    "        client_credentials_manager = SpotifyClientCredentials(\n",
    "            client_id=client_id, \n",
    "            client_secret=client_secret\n",
    "        )\n",
    "        sp = spotipy.Spotify(\n",
    "            client_credentials_manager = client_credentials_manager, \n",
    "            requests_timeout=2, \n",
    "            retries=1 )\n",
    "\n",
    "        ############################################################################\n",
    "        # Create Track Audio Features DF\n",
    "        ############################################################################ \n",
    "\n",
    "        # uri = [u.replace('spotify:artist:', '') for u in uri] #fix the quotes \n",
    "\n",
    "        artists = sp.artists(uri)\n",
    "        features = pd.json_normalize(artists['artists'])\n",
    "        smaller_features = features[['genres', 'popularity', 'name', 'followers.total']]\n",
    "        smaller_features.columns = ['genres_list',  'artist_pop', 'name',  'followers']\n",
    "        smaller_features['artist_uri'] = uri\n",
    "        smaller_features['genres'] = smaller_features['genres_list'].map(lambda x: f\"{x}\")\n",
    "        return smaller_features[['genres', 'artist_pop', 'artist_uri', 'followers']]\n",
    "        \n",
    "\n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location='US'\n",
    "    )\n",
    "\n",
    "    #check if target table exists and if so return a list to not duplicate records\n",
    "    try:\n",
    "        bq_client.get_table(target_table)  # Make an API request.\n",
    "        logging.info(\"Table {} already exists.\".format(target_table))\n",
    "        target_table_incomplete_query = f\"select distinct artist_uri from `{target_table}`\"\n",
    "        loaded_tracks_df = bq_client.query(target_table_incomplete_query).result().to_dataframe()\n",
    "        loaded_tracks = loaded_tracks_df.artist_uri.to_list()\n",
    "        \n",
    "    except NotFound:\n",
    "        logging.info(\"Table {} is not found.\".format(target_table))\n",
    "        \n",
    "        \n",
    "    query = f\"select distinct artist_uri from `{unique_table}`\"\n",
    "    \n",
    "\n",
    "    schema = [{'name': 'artist_pop', 'type': 'INTEGER'},\n",
    "            {'name':'genres', 'type': 'STRING'},\n",
    "            {'name':'followers', 'type': 'INTEGER'},\n",
    "            {'name':'artist_uri', 'type': 'STRING'}\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    tracks = bq_client.query(query).result().to_dataframe()\n",
    "    track_list = tracks.artist_uri.to_list()\n",
    "    logging.info(f'finished downloading tracks')\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    def process_track_list(track_list):\n",
    "            uri_list_length = len(track_list)-1 #starting count at zero\n",
    "            inner_batch_count = 0 #avoiding calling the api on 0th iteration\n",
    "            uri_batch = []\n",
    "            for i, uri in enumerate(tqdm(track_list)):\n",
    "                uri_batch.append(uri)\n",
    "                if (len(uri_batch) == batch_size or uri_list_length == i) and i > 0: #grab a batch of 50 songs\n",
    "                    ### Try catch block for function\n",
    "                    try:\n",
    "                        audio_featureDF = spot_artist_features(uri_batch, client_id, client_secret)\n",
    "                        time.sleep(sleep_param)\n",
    "                        uri_batch = []\n",
    "                    except ReadTimeout:\n",
    "                        logging.info(\"'Spotify timed out... trying again...'\")\n",
    "                        audio_featureDF = spot_artist_features(uri_batch, client_id, client_secret)\n",
    "                        uri_batch = []\n",
    "                        time.sleep(sleep_param)\n",
    "                    except HTTPError as err: #JW ADDED\n",
    "                        logging.info(f\"HTTP Error: {err}\")\n",
    "                    except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "                        logging.info(f\"Spotify error: {spotify_error}\")\n",
    "                    # Accumulate batches on the machine before writing to BQ\n",
    "                    # if inner_batch_count <= batches_to_store or uri_list_length == i:\n",
    "                    if inner_batch_count == 0:\n",
    "                        appended_data = audio_featureDF\n",
    "                        # logging.info(f\"creating new appended data at IBC: {inner_batch_count} \\n i: {i}\")\n",
    "                        inner_batch_count += 1\n",
    "                    elif uri_list_length == i or inner_batch_count == batches_to_store: #send the batches to bq\n",
    "                        appended_data = pd.concat([audio_featureDF, appended_data])\n",
    "                        inner_batch_count = 0\n",
    "                        appended_data.to_gbq(\n",
    "                            destination_table=target_table, \n",
    "                            project_id=f'{project}', \n",
    "                            location='US', \n",
    "                            table_schema=schema,\n",
    "                            progress_bar=False, \n",
    "                            reauth=False, \n",
    "                            if_exists='append'\n",
    "                            )\n",
    "                        logging.info(f'{i+1} of {uri_list_length} complete!')\n",
    "                    else:\n",
    "                        appended_data = pd.concat([audio_featureDF, appended_data])\n",
    "                        inner_batch_count += 1\n",
    "\n",
    "            logging.info(f'audio features appended')\n",
    "    \n",
    "    #multiprocessing portion - we will loop based on the modulus of the track_uri list\n",
    "    #chunk the list \n",
    "    \n",
    "    # Yield successive n-sized\n",
    "    # chunks from l.\n",
    "    def divide_chunks(l, n):\n",
    "        # looping till length l\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "            \n",
    "    n_cores = multiprocessing.cpu_count() \n",
    "    chunked_tracks = list(divide_chunks(track_list, int(len(track_list)/n_cores))) #produces a list of lists chunked evenly by groups of n_cores\n",
    "    \n",
    "    logging.info(f\"\"\"total tracks downloaded: {len(track_list)}\\n\n",
    "                    length of chunked_tracks: {len(chunked_tracks)}\\n \n",
    "                    and inner dims: {[len(x) for x in chunked_tracks]}\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "    procs = []\n",
    "    \n",
    "    def create_job(target, *args):\n",
    "        p = multiprocessing.Process(target=target, args=args)\n",
    "        p.start()\n",
    "        return p\n",
    "\n",
    "    # starting process with arguments\n",
    "    for track_chunk in chunked_tracks:\n",
    "        proc = create_job(process_track_list, track_chunk)\n",
    "        time.sleep(np.pi)\n",
    "        procs.append(proc)\n",
    "\n",
    "    # complete the processes\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "        \n",
    "    # process_track_list(track_list)\n",
    "            \n",
    "     \n",
    "    logging.info(f'artist features appended')\n",
    "    return (\n",
    "          f'DONE',\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma5qzpGkuYhD"
   },
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Buwtyt7rugt4"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'spotify-feature-enrichment-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    unique_table: str,\n",
    "    target_table_audio: str,\n",
    "    target_table_artist: str,\n",
    "    batch_size: int,\n",
    "    batches_to_store: int,\n",
    "    sleep_param: float,\n",
    "    spotify_id: str = spotify_creds['id'],\n",
    "    spotify_secret: str = spotify_creds['secret'],\n",
    "    ):\n",
    "\n",
    "\n",
    "    # call_spotify_api_artist_op = call_spotify_api_artist(\n",
    "    #     project=project,\n",
    "    #     location=location,\n",
    "    #     client_id=spotify_id,\n",
    "    #     client_secret=spotify_secret,\n",
    "    #     batch_size=batch_size,\n",
    "    #     sleep_param=sleep_param,\n",
    "    #     unique_table=unique_table,\n",
    "    #     target_table=target_table_artist,\n",
    "    #     batches_to_store=batches_to_store,\n",
    "    # ).set_display_name(\"Get Artist Features From Spotify API\")\n",
    "\n",
    "    call_spotify_api_audio_op = call_spotify_api_audio(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret,\n",
    "        batch_size=batch_size,\n",
    "        sleep_param=sleep_param,\n",
    "        unique_table=unique_table,\n",
    "        target_table=target_table_audio,\n",
    "        batches_to_store=batches_to_store,\n",
    "    ).set_display_name(\"Get Track Audio Features From Spotify API\")#.after(call_spotify_api_artist_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the pipeline to json\n",
    "This can be stored on gcs as well for broader orchastration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoBsfT1IyIXd",
    "outputId": "50a65461-1c7c-44c0-9362-5524aaac21c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the pipeline parameters\n",
    "\n",
    "Use a dictionary with the afforementioned types defined by your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "evUgOHllykr5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'wortz-project-352116',\n",
       " 'location': 'us-central1',\n",
       " 'unique_table': 'wortz-project-352116.spotify_e2e_test.tracks_unique',\n",
       " 'target_table_audio': 'wortz-project-352116.spotify_e2e_test.audio_features',\n",
       " 'target_table_artist': 'wortz-project-352116.spotify_e2e_test.artist_features',\n",
       " 'batch_size': 50,\n",
       " 'batches_to_store': 400,\n",
       " 'sleep_param': 0.5}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCS_BUCKET = 'matching-engine-content'\n",
    "\n",
    "ideal_batch_size = 20_000\n",
    "bts = ideal_batch_size / 50\n",
    "\n",
    "PIPELINE_PARAMETERS = dict(\n",
    "    project = PROJECT_ID,\n",
    "    location = 'us-central1',\n",
    "    unique_table = f'{PROJECT_ID}.{BQ_DATASET}.tracks_unique', \n",
    "    target_table_audio = f'{PROJECT_ID}.{BQ_DATASET}.audio_features',\n",
    "    target_table_artist = f'{PROJECT_ID}.{BQ_DATASET}.artist_features',\n",
    "    batch_size = 50,\n",
    "    batches_to_store = int(bts),\n",
    "    sleep_param = .5,\n",
    ")\n",
    "\n",
    "PIPELINE_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/679926387543/locations/us-central1/pipelineJobs/spotify-feature-enrichment-v1-spotify-feature-enrich-20230322215942\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/679926387543/locations/us-central1/pipelineJobs/spotify-feature-enrichment-v1-spotify-feature-enrich-20230322215942')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/spotify-feature-enrichment-v1-spotify-feature-enrich-20230322215942?project=679926387543\n"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(display_name = f'spotify-feature-enrichment-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "                             template_path = 'custom_container_pipeline_spec.json',\n",
    "                             pipeline_root = f'gs://{BUCKET_NAME}/{VERSION}',\n",
    "                             parameter_values = PIPELINE_PARAMETERS,\n",
    "                             project = PROJECT_ID,\n",
    "                             location = LOCATION,\n",
    "                              enable_caching=True)\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The pipeline should look like this, it can take some time to run depending on your parameters\n",
    "\n",
    "#### It may take a couple of runs with different Spotify application creds for the audio tracks. This module can resume from where data was already loaded to BQ\n",
    "\n",
    "![](img/feature-enrich-pipeline.png)\n",
    "\n",
    "#### [The next notebook](00a-bq-data-prep.ipynb) will finish feature prep now that all the data is loaded in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract-spotify-features-pipeline-parallel-for.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
