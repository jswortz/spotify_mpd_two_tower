{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2823e5a0-3fe5-45f9-8ade-5be0e6f6275b",
   "metadata": {},
   "source": [
    "### Utility notebook to run tensorboard profiler\n",
    "This helps profile data pipeline performance and allows for optimizations to be made with `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1b7758-4ed1-48ec-b0ed-992dc6843df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:58:05.428116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 13:58:05.562482: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-17 13:58:06.289886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-17 13:58:06.289998: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-17 13:58:06.290008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U tensorboard_plugin_profile --user\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5d34ec-0df5-4d9c-b8e2-a8a4038292fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "\n",
    "# path = 'gs://jt-tfrs-central/profile-perf-v3-jtv11/run-20230104-001534/logs/train'\n",
    "# path = 'gs://jt-tfrs-output-v2/full-perf-2tower-tfrs-jtv10/run-20221230-160518/tb-logs/train' # dir for 50 epoch job\n",
    "\n",
    "# path = 'gs://jt-tfrs-central/low-profiler-v1-jtv11/run-20230104-004931/logs/' # baseline: batch=4096 | step_time=511.9 ms | kernel_launch=264.8 ms\n",
    "# path = 'gs://jt-tfrs-central/low-profiler-v1-jtv11/run-20230104-031645/logs/' # v2: batch=8192 | step_time=806.5 ms | kernel_launch=535.2 ms\n",
    "\n",
    "\n",
    "# vectorized mapping function & repeat(epochs)\n",
    "# path = 'gs://jt-tfrs-central/input-profiler-v1-jtv11/run-20230104-065622/logs/' # v1 | step_time=324.6 ms | kernel_launch=87.5 ms\n",
    "# path = 'gs://jt-tfrs-central/input-profiler-v1-jtv11/run-20230104-072445/logs/' # batch_size = 1024 step_time=253 ms | kernel_launch=32 ms\n",
    "# path = 'gs://jt-tfrs-central/input-profiler-v1-jtv11/run-20230104-072609/logs/' # batch_size = 2048 step_time=276 ms | kernel_launch=52.5 ms\n",
    "\n",
    "# # jit\n",
    "# path = 'gs://jt-tfrs-central/jit-profiler-v1-jtv11/run-20230104-074830/logs/' # set_jit=True & batch=1024 | step_time=258 ms | kernel_launch=33 ms\n",
    "# path = 'gs://jt-tfrs-central/jit-profiler-v1-jtv11/run-20230104-080251/logs/' # set_jit=True & batch=2048 | step_time=XXXX ms | kernel_launch=XXX ms\n",
    "\n",
    "# path = 'gs://jt-tfrs-central/block-profiler-v1-jtv11/run-20230104-085726/logs/' # 64 & batch=256 | step_time=249 | kernel_launch=29\n",
    "\n",
    "# path = 'gs://jt-tfrs-central/test-repo-v1-jtv12/run-20230109-205419/logs'\n",
    "\n",
    "path = 'gs://jt-tfrs-central-v3/tfrs-pipe-e2e-v2/run-20230411-131340/logs' # \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd31a5c-748a-4a67-83c9-4ba10596e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0609eb8-c25b-470a-b246-f226e1760ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21068), started 0:14:48 ago. (Use '!kill 21068' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bb80f5a8b2abdfdf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bb80f5a8b2abdfdf\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=$path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ccc8f-fb31-46df-ad79-88c9786c32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard==2.10.1\n",
    "# tensorboard-data-server==0.6.1\n",
    "# tensorboard-plugin-profile==2.11.1\n",
    "# tensorboard-plugin-wit==1.8.1\n",
    "# tensorflow==2.10.1\n",
    "# tensorflow-cloud==0.1.16\n",
    "# tensorflow-datasets==4.6.0\n",
    "# tensorflow-estimator==2.10.0\n",
    "# tensorflow-hub==0.12.0\n",
    "# tensorflow-io==0.27.0\n",
    "# tensorflow-io-gcs-filesystem==0.27.0\n",
    "# tensorflow-metadata==1.8.0\n",
    "# tensorflow-probability==0.18.0\n",
    "# tensorflow-recommenders==0.7.2\n",
    "# tensorflow-serving-api==2.8.3\n",
    "# tensorflow-transform==1.8.0"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
