{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcccb56a-9f1b-4306-a7f0-acdb6fd30a03",
   "metadata": {},
   "source": [
    "# Implementing Recommendation Engines with Matching Engine\n",
    "\n",
    "![](img/arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6ae7c-76c0-4590-863a-e8dc99761bff",
   "metadata": {},
   "source": [
    "#### VPC Network peering\n",
    "Matching engine is a high performance vector matching service that requires a seperate VPC to ensure performance. \n",
    "\n",
    "Below are the one-time instructions to set up a peering network. \n",
    "\n",
    "# **Once created, be sure to your notebook instance running this particular notebook is in the subnetwork... https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup **\n",
    "\n",
    "![](img/subnetwork2.png) \n",
    "Then select the network from advanced options\n",
    "![](img/subnetwork.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcd1ed2-a152-4c29-8b94-574f916ce854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ID = \"hybrid-vertex\" \n",
    "# NETWORK_NAME = \"ucaip-haystack-vpc-network\"  \n",
    "# PEERING_RANGE_NAME = \"ucaip-haystack-range\"\n",
    "\n",
    "# # Create a VPC network\n",
    "# ! gcloud compute networks create {NETWORK_NAME} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}\n",
    "\n",
    "# # Add necessary firewall rules\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-icmp --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow icmp\n",
    "\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-internal --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9\n",
    "\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-rdp --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow tcp:3389\n",
    "\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-ssh --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow tcp:22\n",
    "\n",
    "# # Reserve IP range\n",
    "# ! gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={NETWORK_NAME} --purpose=VPC_PEERING --project={PROJECT_ID} --description=\"peering range for uCAIP Haystack.\"\n",
    "\n",
    "# Set up peering with service networking\n",
    "# ! gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network=${NETWORK_NAME} --ranges=${PEERING_RANGE_NAME} --project=${PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04fca0-01f8-48e4-9113-207ffe6c2862",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy Playlist Query Model to a Vertex endpoint\n",
    "This will be the endpoint that a user will query with thier last n songs played "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a86c63a-aa13-48e9-927b-add97646eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "DIMENSIONS = 128 # must match output dimensions - embedding dim in two tower code\n",
    "DISPLAY_NAME = \"spotify_song_candidates_v1\"\n",
    "MODEL_PATH = 'gs://two-tower-models' #TODO change to your model directory\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from google.cloud import aiplatform_v1beta1 #needed for matching engine calls\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "EMBEDDINGS_INITIAL_URI = f'{MODEL_PATH}/candidates'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eff4f4-4159-47e6-80fd-73020ba8b85f",
   "metadata": {},
   "source": [
    "### Create a matching engine index\n",
    "\n",
    "The matching engine loads an index from a file of embeddings created from the last notebook. \n",
    "\n",
    "Many of the optimization options for matching engine are found in the ah tree settings and testing is recommended depending on each use case\n",
    "\n",
    "Recall we saved our two tower models and query embeddings (newline json) in a candidate folder like so:\n",
    "\n",
    "![](img/saved-models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bfb90-a929-413a-a9d7-fb90f39a6c9b",
   "metadata": {},
   "source": [
    "## Set the Nearest Neighbor Options\n",
    "\n",
    "See here for tips on [tuning the index](https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#tuning_the_index)\n",
    "\n",
    "From the paper - here's the rough idea\n",
    "\n",
    "1. (Initialization Step) Select a dictionary C(m) bysampling from {x(m) 1 , . . . x (m) n }. \n",
    "2. (Partition Assignment Step) For each datapoint xi , update x˜i by using the value of c ∈ C (m) that minimizes the anisotropic loss of ˜xi.\n",
    "3. (Codebook Update Step) Optimize the loss function over all codewords in all dictionaries while keeping every dictionaries partitions constant.\n",
    "4. Repeat Step 2 and Step 3 until convergence to a fixed point or maximum number of iteration is reached.\n",
    "\n",
    "\n",
    "### Relating the algorithm to the parameters:\n",
    "\n",
    "* `leafNodeEmbeddingCount` -> Number of embeddings on each leaf node. The default value is 1000 if not set.\n",
    "* `leafNodesToSearchPercent` -> The default percentage of leaf nodes that any query may be searched. Must be in range 1-100, inclusive. The default value is 10 (means 10%) if not set.\n",
    "* `approximateNeighborsCount` -> The default number of neighbors to find through approximate search before exact reordering is performed. Exact reordering is a procedure where results returned by an approximate search algorithm are reordered via a more expensive distance computation.\n",
    "* `distanceMeasureType` -> DOT_PRODUCT_DISTANCE is default - COSINE, L1 and L2^2 is available\n",
    "\n",
    "Other best practices from our PM team:\n",
    "```\n",
    "Start from leafNodesToSearchPercent=5 and approximateNeighborsCount=10 * k\n",
    "\n",
    "use default values for others.\n",
    "\n",
    "measure performance and recall and change those 2 parameters accordingly.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfca632-93e5-4c8f-be12-ae5d0769f961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/934903580331/locations/us-central1/indexes/7391796771212492800/operations/2183856935755841536\n"
     ]
    }
   ],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=50,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=7,\n",
    "    description=\"Songs embeddings from the Spotify million playlist dataset\",\n",
    "    labels={\"label_name\": \"label_value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55bfda-bf10-46b0-8abb-905e9c00544f",
   "metadata": {},
   "source": [
    "## This takes 20-30 minutes - here's some reading on what it is doing\n",
    "#### Note on the advantages of the algorithm\n",
    "\n",
    "[link](https://arxiv.org/pdf/1908.10396.pdf)\n",
    "\n",
    "```However, it is easy to see that not all pairs of (x, q) are equally important. The approximation error on the pairs which have a high inner product is far more important since they are likely to be among the top ranked pairs and can greatly affect the search result, while for the pairs whose inner product is low the approximation error matters much less. In other words, for a given datapoint x, we should quantize it with a bigger focus on its error with those queries which have high inner product with x. See Figure 1 for the illustration.```\n",
    "\n",
    "\n",
    "![](img/algo.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74eebbb-029a-44df-a069-217820d43217",
   "metadata": {},
   "source": [
    "### Create a matching engine endpoint\n",
    "\n",
    "Below we set the variable names for the endpoint along with other key values for resource creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed83a746-e3e6-491c-9c4b-19da2b8292dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT: us-central1-aiplatform.googleapis.com\n",
      "PROJECT_ID: hybrid-vertex\n",
      "REGION: us-central1\n",
      "Updated property [core/project].\n",
      "Updated property [ai_platform/region].\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT = \"{}-aiplatform.googleapis.com\".format(LOCATION)\n",
    "NETWORK_NAME = \"ucaip-haystack-vpc-network\"  # @param {type:\"string\"}\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, LOCATION)\n",
    "\n",
    "print(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "print(\"PROJECT_ID: {}\".format(PROJECT_ID))\n",
    "print(\"REGION: {}\".format(LOCATION))\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gcloud config set ai_platform/region {LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ba54ca-0856-4fa4-bb18-64056259d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_client = aiplatform_v1beta1.IndexEndpointServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")\n",
    "\n",
    "\n",
    "VPC_NETWORK_NAME = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, NETWORK_NAME) #FQN for VPC network name\n",
    "\n",
    "index_client = {\n",
    "    \"display_name\": \"index_endpoint_for_demo\",\n",
    "    \"network\": VPC_NETWORK_NAME,\n",
    "}\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT, index_endpoint=index_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a0b7-970b-401c-a453-6bac4c1d0428",
   "metadata": {},
   "source": [
    "## Other quick notes on ME while we wait for deployment\n",
    "\n",
    "[link](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "Instead of comparing vectors one by one, you could use the approximate nearest neighbor (ANN) approach to improve search times. Many ANN algorithms use vector quantization (VQ), in which you split the vector space into multiple groups, define \"codewords\" to represent each group, and search only for those codewords. This VQ technique dramatically enhances query speeds and is the essential part of many ANN algorithms, just like indexing is the essential part of relational databases and full-text search engines.\n",
    "\n",
    "![](img/vectorQuant.gif)\n",
    "\n",
    "\n",
    "As you may be able to conclude from the diagram above, as the number of groups in the space increases the speed of the search decreases and the accuracy increases.  Managing this trade-off — getting higher accuracy at shorter latency — has been a key challenge with ANN algorithms. \n",
    "\n",
    "Last year, Google Research announced ScaNN, a new solution that provides state-of-the-art results for this challenge. With ScaNN, they introduced a new VQ algorithm called anisotropic vector quantization:\n",
    "\n",
    "![](img/Loss_Types.max-1000x1000.png)\n",
    "\n",
    "Anisotropic vector quantization uses a new loss function to train a model for VQ for an optimal grouping to capture farther data points (i.e. higher inner product) in a single group. With this idea, the new algorithm gives you higher accuracy at lower latency, as you can see in the benchmark result below (the violet line): \n",
    "\n",
    "![](img/speedvsaccuracy.max-1600x1600.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa8cf18-3014-4c5b-be82-2797b2059051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/indexEndpoints/259220861364469760'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = r.result().name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa66e7ba-5ced-4671-988f-3b86dc473f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/indexEndpoints/259220861364469760'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49abb5-14a1-4f46-969a-4495e98c175e",
   "metadata": {},
   "source": [
    "### Deploy the index to the endpoint and create and endpoint object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3b041a-8a4d-4775-b217-b9d56f149010",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"deployed_spotify_v1\"\n",
    "\n",
    "deploy_ann_index = {\n",
    "    \"id\": DEPLOYED_INDEX_ID,\n",
    "    \"display_name\": DEPLOYED_INDEX_ID,\n",
    "    \"index\": tree_ah_index.resource_name,\n",
    "}\n",
    "\n",
    "s = index_endpoint_client.deploy_index(\n",
    "    index_endpoint=INDEX_ENDPOINT_NAME, deployed_index=deploy_ann_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85275bd9-776c-4223-b069-f97863a6967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n",
      "Poll the operation to deploy index...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deployed_index {\n",
       "  id: \"deployed_spotify_v1\"\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poll the operation until it's done successfullly.\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    if s.done():\n",
    "        break\n",
    "    print(\"Poll the operation to deploy index...\")\n",
    "    time.sleep(60)\n",
    "s.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f5b3bf-2dad-440c-930f-94ed1c518097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f1a934194d0> \n",
       "resource name: projects/934903580331/locations/us-central1/indexEndpoints/259220861364469760"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally create the endpoint object\n",
    "ME_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(INDEX_ENDPOINT_NAME)\n",
    "ME_index_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c47946-81bd-48c4-a9dc-90852ad8def2",
   "metadata": {},
   "source": [
    "### You should now see matching engine resources in your GCP console:\n",
    "\n",
    "![](img/me-resources2.png)\n",
    "\n",
    "![](img/me-indexes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540ccaa-f7e3-43e9-a17f-f2a9f85b7873",
   "metadata": {},
   "source": [
    "### Now instantiate the matching engine endpoint for queries\n",
    "We will use this later to send query results that return in a vector format from the query / playlist endpoint\n",
    "\n",
    "Deploying that endpoint is the next task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1765c3c5-4741-414c-943a-46770651ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/8649686451899858944/operations/179755101575970816\n",
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/8649686451899858944@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/8649686451899858944@1')\n"
     ]
    }
   ],
   "source": [
    "## Deploy the query endpoint\n",
    "QUERY_MODEL = \"gs://two-tower-models/query_model\"\n",
    "\n",
    "model_gcp = aiplatform.Model.upload(\n",
    "        display_name=\"Spotify Playlist Query Model\",\n",
    "        artifact_uri=QUERY_MODEL,\n",
    "        serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest',\n",
    "        description=\"Top of the query tower, meant to return an embedding for each playlist instance\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b9a18-d154-4fde-b2d9-6aa264829623",
   "metadata": {},
   "source": [
    "#### Deploy the uploaded model to an API endpoint\n",
    "\n",
    "At this point you should be able to see the model in the Vertex Model Registry:\n",
    "\n",
    "![](img/model-registry.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "627304a6-b514-4316-8ab4-c5e581c0f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/1185154787486728192/operations/968729461295939584\n",
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/1185154787486728192\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/1185154787486728192')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=\"Spotify Playist Model Endpoint\",\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "276786e1-e917-4acb-b580-661e85d7d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = model_gcp.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=\"Spotify Playlist Query Model\",\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=2,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9787e4f-4323-43b5-8424-c39e06b945bd",
   "metadata": {},
   "source": [
    "This part takes a few minutes - but when done you should see a deployed model:\n",
    "    \n",
    "![](img/deployed_endpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6eac6-5fb9-41f3-9b72-d3958cfe9473",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Putting it together: Combine the query endpoint with the matching engine endpoint for state-of the art recommendations\n",
    "\n",
    "You can grab a quick example from training or build yourself by utilizing the returned example structure. Skip is to get to a psuedo-random example. The data is the same from training - you can also construct your own test instances using the format provided\n",
    "\n",
    "\n",
    "```python\n",
    "for tensor_dict in train_dataset.unbatch().skip(12905).take(1):\n",
    "    td_keys = tensor_dict.keys()\n",
    "    list_dict = {}\n",
    "    for k in td_keys:\n",
    "        list_dict.update({k: tensor_dict[k].numpy()})\n",
    "    print(list_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b4179-390d-45da-bc9e-5d4a74d97c8c",
   "metadata": {},
   "source": [
    "## Get some test instances and run through the endpoint and matching engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34c07cd6-ef2e-4956-bc53-494c1eb876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {'album_name_can': 'We Just Havent Met Yet', \n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "                 'artist_followers_can': 4339757.0, \n",
    "                 'artist_genres_can': \"'hawaiian hip hop', 'rap'\", \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_can': 'Russ', \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'artist_pop_pl': [82., 80., 90., 87., 65.], \n",
    "                 'artist_uri_can': 'spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS', \n",
    "                 'artists_followers_pl': [ 4339757.,  5611842., 15046756., 30713126.,   603837.], \n",
    "                 'collaborative': 'false', \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_can': 237322.0, \n",
    "                 'duration_ms_songs_pl': [237506., 217200., 219080., 226400., 121739.], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_can': 'We Just Havent Met Yet', \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_can': 57.0, \n",
    "                 'track_pop_pl': [79., 58., 83., 71., 57.], \n",
    "                 'track_uri_can': 'spotify:track:0VzDv4wiuZsLsNOmfaUy2W', \n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09b3e9aa-1dc8-44cd-ba75-d2837c00bc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.0840319172, 0.186792836, 0.0950887352, 0.00264413841, 0.147926927, -0.0700385496, -0.102679625, -0.154979482, 0.148580015, -0.101469621, -0.091818966, 0.00616804603, 0.00408178242, -0.00168958679, 0.0360991098, 0.0825722665, 0.0213036463, 0.0813929439, -0.0449486524, 0.0399172455, 0.0706564263, -0.0271026175, 0.0144804297, -0.0893997326, -0.077369, 0.0540666, 0.0316286944, 0.0147486292, 0.071288988, 0.142902657, -0.0227023549, 0.0330891721, -0.0288588032, 0.130149409, -0.0312393289, 0.0212887935, 0.090886116, -0.114642344, 0.0448945798, 0.105831, 0.149386242, -0.0897929147, 0.103703573, -0.167980403, 0.0869361386, 0.13272588, -0.0506982207, -0.000560096931, -0.0707496703, 0.0320968144, -0.15122813, 0.0746913552, -0.0434209928, 0.0682459846, 0.0147757465, -0.154896766, -0.0927062, 0.0450625271, 0.0736268386, -0.0314874575, 0.0678062886, 0.0491155, 0.0494973101, -0.0348398499, 0.104099423, 0.0259010959, 0.0120011466, 0.057427872, -0.0411665812, -0.00769883487, -0.0234132186, 0.0838077962, -0.159660742, -0.0308106858, -0.0657879636, -0.0269315913, 0.127054721, 0.0476329252, 0.115483306, -0.0894537792, 0.0510609858, -0.0664841607, -0.210096359, -0.125929862, 0.166807011, 0.00261366274, 0.0146677028, 0.0860265642, -0.00133709575, 0.0423214, -0.0457259975, 0.000343360734, -0.143682092, -0.0569027103, 0.0392312221, 0.0270302761, 0.112147726, -0.145860344, 0.0909501761, -0.00856461562, 0.0755435079, 0.0893884376, 0.0104973521, -0.0072737122, 0.173819363, 0.000224040603, -0.119734883, 0.062109, 0.00798525196, 0.118795767, 0.0578572564, 0.00154815335, 0.0266130213, -0.040291246, 0.00568214525, -0.165928736, -0.0714046061, 0.0947447196, 0.0485963114, -0.035462603, -0.0453558639, -0.0714826137, 0.0222144891, -0.0294852722, 0.168130577, -0.0776932612, -0.213013947, 0.217071757]], deployed_model_id='1391950934438838272', model_version_id='1', model_resource_name='projects/934903580331/locations/us-central1/models/8649686451899858944', explanations=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment.predict([TEST_INSTANCE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d7f22-3455-4054-adf2-d4b41f6241c4",
   "metadata": {},
   "source": [
    "# Get our predictions for the next song recommendation - now let's feed the embedding to find the closest neighbors\n",
    "(higher distance score better - this is inner product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09056695-8641-4e5d-bd22-e99bc8b51a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_emb = deployment.predict([TEST_INSTANCE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c74f2b06-ab7a-4026-b116-26d54dcd6090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id=\"b'spotify:track:3M66kXDQHwSK68EB8bzwNX'\", distance=17.088489532470703),\n",
       "  MatchNeighbor(id=\"b'spotify:track:38HFzYat2gnWcjqtgntSBW'\", distance=11.790796279907227),\n",
       "  MatchNeighbor(id=\"b'spotify:track:0XhYgAQ8RIPT96grdcokho'\", distance=9.291814804077148),\n",
       "  MatchNeighbor(id=\"b'spotify:track:0ZdXsa7FAfSme3dZGxLYcx'\", distance=8.279316902160645),\n",
       "  MatchNeighbor(id=\"b'spotify:track:18EALdmGjJFvaPCmmVyOlT'\", distance=7.732163429260254),\n",
       "  MatchNeighbor(id=\"b'spotify:track:7J1fTxccRfKJO4umBdqKaN'\", distance=7.713829040527344),\n",
       "  MatchNeighbor(id=\"b'spotify:track:5t4xvd7Tji3PnSokrdpJBr'\", distance=7.037336349487305),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1D27lPKHCbMTFAqGRunLs3'\", distance=6.975942611694336),\n",
       "  MatchNeighbor(id=\"b'spotify:track:2QfprS7sN2u4W9gpe67YMH'\", distance=6.927917957305908),\n",
       "  MatchNeighbor(id=\"b'spotify:track:4K6z75yOLLMvfRaXmA8eCT'\", distance=6.81923770904541)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ME_index_endpoint.match(deployed_index_id='deployed_spotify_v1',\n",
    "                       queries=playlist_emb.predictions,\n",
    "                       num_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74a515-56a5-4fe6-bf43-8434d2743b5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### All set - you now have a working recommendation system!\n",
    "See the next notebook if you want to explore the system and make recommendations for yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60734373-6401-41b3-a54f-3438cbbbca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Cleanup\n",
    "# from google.cloud import aiplatform_v1beta1 #needed for matching engine calls\n",
    "\n",
    "# REGION = 'us-central1'\n",
    "# ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# index_client = aiplatform_v1beta1.IndexServiceClient(\n",
    "#     client_options=dict(api_endpoint=ENDPOINT)\n",
    "# )\n",
    "\n",
    "# index_client.delete_index(name='deployed_spotify_v1')\n",
    "# index_client.delete_index(name=INDEX_BRUTE_FORCE_RESOURCE_NAME)\n",
    "# index_endpoint_client.delete_index_endpoint(name=INDEX_ENDPOINT_NAME)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
