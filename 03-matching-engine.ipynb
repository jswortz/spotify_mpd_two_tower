{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcccb56a-9f1b-4306-a7f0-acdb6fd30a03",
   "metadata": {},
   "source": [
    "# Implementing Recommendation Engines with Matching Engine\n",
    "\n",
    "![](img/arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6ae7c-76c0-4590-863a-e8dc99761bff",
   "metadata": {},
   "source": [
    "#### VPC Network peering\n",
    "Matching engine is a high performance vector matching service that requires a seperate VPC to ensure performance. \n",
    "\n",
    "Below are the one-time instructions to set up a peering network. \n",
    "\n",
    "# **Once created, be sure to your notebook instance running this particular notebook is in the subnetwork... https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup **\n",
    "\n",
    "![](img/subnetwork2.png) \n",
    "Then select the network from advanced options\n",
    "![](img/subnetwork.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcd1ed2-a152-4c29-8b94-574f916ce854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ID = \"hybrid-vertex\" \n",
    "# NETWORK_NAME = \"ucaip-haystack-vpc-network\"  \n",
    "# PEERING_RANGE_NAME = \"ucaip-haystack-range\"\n",
    "\n",
    "# # Create a VPC network\n",
    "# ! gcloud compute networks create {NETWORK_NAME} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}\n",
    "\n",
    "# # Add necessary firewall rules\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-icmp --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow icmp\n",
    "\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-internal --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9\n",
    "\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-rdp --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow tcp:3389\n",
    "\n",
    "# ! gcloud compute firewall-rules create {NETWORK_NAME}-allow-ssh --network {NETWORK_NAME} --priority 65534 --project {PROJECT_ID} --allow tcp:22\n",
    "\n",
    "# # Reserve IP range\n",
    "# ! gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={NETWORK_NAME} --purpose=VPC_PEERING --project={PROJECT_ID} --description=\"peering range for uCAIP Haystack.\"\n",
    "\n",
    "# Set up peering with service networking\n",
    "# ! gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network=${NETWORK_NAME} --ranges=${PEERING_RANGE_NAME} --project=${PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04fca0-01f8-48e4-9113-207ffe6c2862",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy Playlist Query Model to a Vertex endpoint\n",
    "This will be the endpoint that a user will query with thier last n songs played "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a86c63a-aa13-48e9-927b-add97646eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "DIMENSIONS = 128 # must match output dimensions - embedding dim in two tower code\n",
    "DISPLAY_NAME = \"spotify_merlin_candidates_v1\"\n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "OUTPUT_PATH = os.path.join(BUCKET, \"merlin-processed\")\n",
    "MODEL_PATH = os.path.join(OUTPUT_PATH, 'query_model_merlin')\n",
    "\n",
    "import sys\n",
    "from google.cloud import aiplatform_v1beta1 #needed for matching engine calls\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "EMBEDDINGS_INITIAL_URI = os.path.join(OUTPUT_PATH, 'embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eff4f4-4159-47e6-80fd-73020ba8b85f",
   "metadata": {},
   "source": [
    "### Create a matching engine index\n",
    "\n",
    "The matching engine loads an index from a file of embeddings created from the last notebook. \n",
    "\n",
    "Many of the optimization options for matching engine are found in the ah tree settings and testing is recommended depending on each use case\n",
    "\n",
    "Recall we saved our two tower models and query embeddings (newline json) in a candidate folder like so:\n",
    "\n",
    "![](img/saved-models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bfb90-a929-413a-a9d7-fb90f39a6c9b",
   "metadata": {},
   "source": [
    "## Set the Nearest Neighbor Options\n",
    "\n",
    "See here for tips on [tuning the index](https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#tuning_the_index)\n",
    "\n",
    "From the paper - here's the rough idea\n",
    "\n",
    "1. (Initialization Step) Select a dictionary C(m) bysampling from {x(m) 1 , . . . x (m) n }. \n",
    "2. (Partition Assignment Step) For each datapoint xi , update x˜i by using the value of c ∈ C (m) that minimizes the anisotropic loss of ˜xi.\n",
    "3. (Codebook Update Step) Optimize the loss function over all codewords in all dictionaries while keeping every dictionaries partitions constant.\n",
    "4. Repeat Step 2 and Step 3 until convergence to a fixed point or maximum number of iteration is reached.\n",
    "\n",
    "\n",
    "### Relating the algorithm to the parameters:\n",
    "\n",
    "* `leafNodeEmbeddingCount` -> Number of embeddings on each leaf node. The default value is 1000 if not set.\n",
    "* `leafNodesToSearchPercent` -> The default percentage of leaf nodes that any query may be searched. Must be in range 1-100, inclusive. The default value is 10 (means 10%) if not set.\n",
    "* `approximateNeighborsCount` -> The default number of neighbors to find through approximate search before exact reordering is performed. Exact reordering is a procedure where results returned by an approximate search algorithm are reordered via a more expensive distance computation.\n",
    "* `distanceMeasureType` -> DOT_PRODUCT_DISTANCE is default - COSINE, L1 and L2^2 is available\n",
    "\n",
    "Other best practices from our PM team:\n",
    "```\n",
    "Start from leafNodesToSearchPercent=5 and approximateNeighborsCount=10 * k\n",
    "\n",
    "use default values for others.\n",
    "\n",
    "measure performance and recall and change those 2 parameters accordingly.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2d4791-c727-403f-bf8f-16f2b5553193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://spotify-beam-v3/merlin-processed/query_model_merlin/\n",
      "gs://spotify-beam-v3/merlin-processed/tb_logs/\n",
      "gs://spotify-beam-v3/merlin-processed/train/\n",
      "gs://spotify-beam-v3/merlin-processed/valid/\n",
      "gs://spotify-beam-v3/merlin-processed/workflow/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://spotify-beam-v3/merlin-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dfca632-93e5-4c8f-be12-ae5d0769f961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/934903580331/locations/us-central1/indexes/8994233813626257408/operations/6826350170481885184\n"
     ]
    },
    {
     "ename": "FailedPrecondition",
     "evalue": "400 There are invalid records under files [gs://spotify-beam-v3/merlin-processed/embeddings/candidate_embeddings.json]. Please check the details in the metadata of operation: projects/934903580331/locations/us-central1/indexes/8994233813626257408/operations/6826350170481885184.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5060/749633694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mleaf_nodes_to_search_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Songs embeddings from the Spotify million playlist dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"label_value\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index.py\u001b[0m in \u001b[0;36mcreate_tree_ah_index\u001b[0;34m(cls, display_name, contents_delta_uri, dimensions, approximate_neighbors_count, leaf_node_embedding_count, leaf_nodes_to_search_percent, distance_measure_type, description, labels, project, location, credentials, request_metadata, sync)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mrequest_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         )\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, display_name, contents_delta_uri, config, description, labels, project, location, credentials, request_metadata, sync)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_create_with_lro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_lro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcreated_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_lro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_create_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 There are invalid records under files [gs://spotify-beam-v3/merlin-processed/embeddings/candidate_embeddings.json]. Please check the details in the metadata of operation: projects/934903580331/locations/us-central1/indexes/8994233813626257408/operations/6826350170481885184."
     ]
    }
   ],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=50,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=7,\n",
    "    description=\"Songs embeddings from the Spotify million playlist dataset\",\n",
    "    labels={\"label_name\": \"label_value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55bfda-bf10-46b0-8abb-905e9c00544f",
   "metadata": {},
   "source": [
    "## This takes 20-30 minutes - here's some reading on what it is doing\n",
    "#### Note on the advantages of the algorithm\n",
    "\n",
    "[link](https://arxiv.org/pdf/1908.10396.pdf)\n",
    "\n",
    "```However, it is easy to see that not all pairs of (x, q) are equally important. The approximation error on the pairs which have a high inner product is far more important since they are likely to be among the top ranked pairs and can greatly affect the search result, while for the pairs whose inner product is low the approximation error matters much less. In other words, for a given datapoint x, we should quantize it with a bigger focus on its error with those queries which have high inner product with x. See Figure 1 for the illustration.```\n",
    "\n",
    "\n",
    "![](img/algo.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74eebbb-029a-44df-a069-217820d43217",
   "metadata": {},
   "source": [
    "### Create a matching engine endpoint\n",
    "\n",
    "Below we set the variable names for the endpoint along with other key values for resource creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83a746-e3e6-491c-9c4b-19da2b8292dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"{}-aiplatform.googleapis.com\".format(LOCATION)\n",
    "NETWORK_NAME = \"ucaip-haystack-vpc-network\"  # @param {type:\"string\"}\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, LOCATION)\n",
    "\n",
    "print(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "print(\"PROJECT_ID: {}\".format(PROJECT_ID))\n",
    "print(\"REGION: {}\".format(LOCATION))\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gcloud config set ai_platform/region {LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f7bf2-97e8-41f4-87e5-152dd5bb2dc6",
   "metadata": {},
   "source": [
    "### **If you start getting errors about consumers, ensure this notebook is running in the VPC network created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba54ca-0856-4fa4-bb18-64056259d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_client = aiplatform_v1beta1.IndexEndpointServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")\n",
    "\n",
    "\n",
    "VPC_NETWORK_NAME = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, NETWORK_NAME) #FQN for VPC network name\n",
    "\n",
    "index_client = {\n",
    "    \"display_name\": \"index_endpoint_for_demo_merlin\",\n",
    "    \"network\": VPC_NETWORK_NAME,\n",
    "}\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT, index_endpoint=index_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a0b7-970b-401c-a453-6bac4c1d0428",
   "metadata": {},
   "source": [
    "## Other quick notes on ME while we wait for deployment\n",
    "\n",
    "[link](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "Instead of comparing vectors one by one, you could use the approximate nearest neighbor (ANN) approach to improve search times. Many ANN algorithms use vector quantization (VQ), in which you split the vector space into multiple groups, define \"codewords\" to represent each group, and search only for those codewords. This VQ technique dramatically enhances query speeds and is the essential part of many ANN algorithms, just like indexing is the essential part of relational databases and full-text search engines.\n",
    "\n",
    "![](img/vectorQuant.gif)\n",
    "\n",
    "\n",
    "As you may be able to conclude from the diagram above, as the number of groups in the space increases the speed of the search decreases and the accuracy increases.  Managing this trade-off — getting higher accuracy at shorter latency — has been a key challenge with ANN algorithms. \n",
    "\n",
    "Last year, Google Research announced ScaNN, a new solution that provides state-of-the-art results for this challenge. With ScaNN, they introduced a new VQ algorithm called anisotropic vector quantization:\n",
    "\n",
    "![](img/Loss_Types.max-1000x1000.png)\n",
    "\n",
    "Anisotropic vector quantization uses a new loss function to train a model for VQ for an optimal grouping to capture farther data points (i.e. higher inner product) in a single group. With this idea, the new algorithm gives you higher accuracy at lower latency, as you can see in the benchmark result below (the violet line): \n",
    "\n",
    "![](img/speedvsaccuracy.max-1600x1600.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8cf18-3014-4c5b-be82-2797b2059051",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPOINT_NAME = r.result().name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66e7ba-5ced-4671-988f-3b86dc473f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49abb5-14a1-4f46-969a-4495e98c175e",
   "metadata": {},
   "source": [
    "### Deploy the index to the endpoint and create and endpoint object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b041a-8a4d-4775-b217-b9d56f149010",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"deployed_merlin_spotify_v1\"\n",
    "\n",
    "deploy_ann_index = {\n",
    "    \"id\": DEPLOYED_INDEX_ID,\n",
    "    \"display_name\": DEPLOYED_INDEX_ID,\n",
    "    \"index\": tree_ah_index.resource_name,\n",
    "}\n",
    "\n",
    "s = index_endpoint_client.deploy_index(\n",
    "    index_endpoint=INDEX_ENDPOINT_NAME, deployed_index=deploy_ann_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85275bd9-776c-4223-b069-f97863a6967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll the operation until it's done successfullly.\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    if s.done():\n",
    "        break\n",
    "    print(\"Poll the operation to deploy index...\")\n",
    "    time.sleep(60)\n",
    "s.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5b3bf-2dad-440c-930f-94ed1c518097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally create the endpoint object\n",
    "ME_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(INDEX_ENDPOINT_NAME)\n",
    "ME_index_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c47946-81bd-48c4-a9dc-90852ad8def2",
   "metadata": {},
   "source": [
    "### You should now see matching engine resources in your GCP console:\n",
    "\n",
    "![](img/me-resources2.png)\n",
    "\n",
    "![](img/me-indexes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540ccaa-f7e3-43e9-a17f-f2a9f85b7873",
   "metadata": {},
   "source": [
    "## Note the endpoint has already been created in the `02-build-custom-query-predictor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276786e1-e917-4acb-b580-661e85d7d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO UPDATE WITH DEPLOYED MODEL\n",
    "# deployment = model_gcp.deploy(\n",
    "#     endpoint=endpoint,\n",
    "#     deployed_model_display_name=\"Spotify Playlist Query Model\",\n",
    "#     machine_type=\"n1-standard-4\",\n",
    "#     min_replica_count=1,\n",
    "#     max_replica_count=2,\n",
    "#     accelerator_type=None,\n",
    "#     accelerator_count=0,\n",
    "#     sync=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6eac6-5fb9-41f3-9b72-d3958cfe9473",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Putting it together: Combine the query endpoint with the matching engine endpoint for state-of the art recommendations\n",
    "\n",
    "You can grab a quick example from training or build yourself by utilizing the returned example structure. Skip is to get to a psuedo-random example. The data is the same from training - you can also construct your own test instances using the format provided\n",
    "\n",
    "\n",
    "```python\n",
    "for tensor_dict in train_dataset.unbatch().skip(12905).take(1):\n",
    "    td_keys = tensor_dict.keys()\n",
    "    list_dict = {}\n",
    "    for k in td_keys:\n",
    "        list_dict.update({k: tensor_dict[k].numpy()})\n",
    "    print(list_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b4179-390d-45da-bc9e-5d4a74d97c8c",
   "metadata": {},
   "source": [
    "## Get some test instances and run through the endpoint and matching engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c07cd6-ef2e-4956-bc53-494c1eb876d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {'album_name_can': 'We Just Havent Met Yet', \n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "                 'artist_followers_can': 4339757.0, \n",
    "                 'artist_genres_can': \"'hawaiian hip hop', 'rap'\", \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_can': 'Russ', \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'artist_pop_pl': [82., 80., 90., 87., 65.], \n",
    "                 'artist_uri_can': 'spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS', \n",
    "                 'artists_followers_pl': [ 4339757.,  5611842., 15046756., 30713126.,   603837.], \n",
    "                 'collaborative': 'false', \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_can': 237322.0, \n",
    "                 'duration_ms_songs_pl': [237506., 217200., 219080., 226400., 121739.], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_can': 'We Just Havent Met Yet', \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_can': 57.0, \n",
    "                 'track_pop_pl': [79., 58., 83., 71., 57.], \n",
    "                 'track_uri_can': 'spotify:track:0VzDv4wiuZsLsNOmfaUy2W', \n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706f910-1d1f-48a9-a7e6-6419f3acd9fe",
   "metadata": {},
   "source": [
    "#### Before we submit the prediction to test, we have to call the workflow\n",
    "Ideally this could be implemented with a custom prediction routine so the data is pre-processed ahead of time.\n",
    "\n",
    "More info on how to implement a pre-processer custom model: https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319554dc-8664-46f3-b669-1a8d7e47cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtabular as nvt\n",
    "import dask.dataframe as dd\n",
    "\n",
    "workflow = nvt.Workflow.load(os.path.join(BUCKET, \"merlin-processed/workflow/2t-spotify-workflow\"))\n",
    "ddf = dd.DataFrame.from_dict(TEST_INSTANCE)\n",
    "TRANSORMED_TEST_INSTANCE = workflow.transform(TEST_INSTANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3e9aa-1dc8-44cd-ba75-d2837c00bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.predict([TEST_INSTANCE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d7f22-3455-4054-adf2-d4b41f6241c4",
   "metadata": {},
   "source": [
    "# Get our predictions for the next song recommendation - now let's feed the embedding to find the closest neighbors\n",
    "(higher distance score better - this is inner product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09056695-8641-4e5d-bd22-e99bc8b51a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_emb = deployment.predict([TEST_INSTANCE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f2b06-ab7a-4026-b116-26d54dcd6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_index_endpoint.match(deployed_index_id='deployed_spotify_v1',\n",
    "                       queries=playlist_emb.predictions,\n",
    "                       num_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74a515-56a5-4fe6-bf43-8434d2743b5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### All set - you now have a working recommendation system!\n",
    "See the next notebook if you want to explore the system and make recommendations for yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60734373-6401-41b3-a54f-3438cbbbca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Cleanup\n",
    "# from google.cloud import aiplatform_v1beta1 #needed for matching engine calls\n",
    "\n",
    "# REGION = 'us-central1'\n",
    "# ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# index_client = aiplatform_v1beta1.IndexServiceClient(\n",
    "#     client_options=dict(api_endpoint=ENDPOINT)\n",
    "# )\n",
    "\n",
    "# index_client.delete_index(name='deployed_spotify_v1')\n",
    "# index_client.delete_index(name=INDEX_BRUTE_FORCE_RESOURCE_NAME)\n",
    "# index_endpoint_client.delete_index_endpoint(name=INDEX_ENDPOINT_NAME)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
