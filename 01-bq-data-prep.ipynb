{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0636aec-1d0f-4d15-adb2-2824738853b6",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "* clean up notebook\n",
    "* parameterize\n",
    "* offer large and small options for producing dataset (create optionals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd5f47-677c-4ab6-a28c-111c53359eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars to parameterize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0eb21",
   "metadata": {},
   "source": [
    "#### Step 0: Dependencies\n",
    "\n",
    "Run this one time when starting, then restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbb59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas pandas-gbq==0.12.0 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da0ab1",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "## In this notebook we will load the songs from the zip file, and perform transformations to prepare the data for two-tower training\n",
    "Steps\n",
    "1. Extract from the zip file\n",
    "2. Upload to BQ\n",
    "3. Enrich features for the playlist songs\n",
    "4. Cross-join songs with features (expected rows = n_songs x n_playlists)\n",
    "5. Remove after-the-fact (later position songs) from the newly generated samples\n",
    "6. Create a clean train table, and flatten structs or use arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04cd08",
   "metadata": {},
   "source": [
    "#### Unzip the file and upload to BQ\n",
    "Source of data if you want to download zip: gs://spotify-million-playlist-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d08efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your variables for your project, region, and dataset name\n",
    "SOURCE_BUCKET = 'spotify-million-playlist-dataset'\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "REGION = 'us-central1'\n",
    "bq_dataset = 'mdp_eda_test'\n",
    "\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bigquery_client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c0e0b6-0bd4-42bd-bd42-b722c0d871d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset hybrid-vertex.mdp_eda_test2\n"
     ]
    }
   ],
   "source": [
    "# # Create a bigquery dataset (one time operation)\n",
    "# # Construct a full Dataset object to send to the API.\n",
    "# dataset = bigquery.Dataset(f\"`{PROJECT_ID}.{bq_dataset}`\")\n",
    "\n",
    "# # TODO(developer): Specify the geographic location where the dataset should reside.\n",
    "# dataset.location = \"US\"\n",
    "\n",
    "# # Send the dataset to the API for creation, with an explicit timeout.\n",
    "# # Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# # exists within the project.\n",
    "# dataset = bigquery_client.create_dataset(bq_dataset, timeout=30)  # Make an API request.\n",
    "# print(\"Created dataset {}.{}\".format(bigquery_client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409cabe2-16c1-4131-b298-82c7078b53ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next create unique artist and song tables\n",
    "These tables contain features obtained via the public Spotify API. Features such as track and artist popularity are in this data. For more detail on loading json data to Bigquery, [see here](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json)\n",
    "\n",
    "![](img/unique-songs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a2839d-276b-47f1-b73d-4a1e860ca8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2262292 rows.\n"
     ]
    }
   ],
   "source": [
    "table_id = f\"{PROJECT_ID}.{bq_dataset}.unique_track_features\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"track_pop\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"tracks_playlist_titles\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"track_uri\", \"STRING\"),\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")\n",
    "uri = f\"gs://{SOURCE_BUCKET}/unique_track_features.gzip\"\n",
    "\n",
    "load_job = bigquery_client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    location=\"US\",  # Must match the destination dataset location.\n",
    "    job_config=job_config,\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = bigquery_client.get_table(table_id)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866e7b6-0b6c-4d1e-9d7f-73c99c3a3a0b",
   "metadata": {},
   "source": [
    "### Unique artists\n",
    "\n",
    "![](img/unique-artists.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb911024-e624-43be-818c-8dc8ea129f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 295860 rows.\n"
     ]
    }
   ],
   "source": [
    "table_id = f\"{PROJECT_ID}.{bq_dataset}.unique_artist_features\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"artist_genres\", \"STRING\", \"REPEATED\"),\n",
    "        bigquery.SchemaField(\"artist_pop\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"artist_followers\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"artist_uri\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"artist_name\", \"STRING\"),\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")\n",
    "uri = f\"gs://{SOURCE_BUCKET}/unique_artist_features.gzip\"\n",
    "\n",
    "load_job = bigquery_client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    location=\"US\",  # Must match the destination dataset location.\n",
    "    job_config=job_config,\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = bigquery_client.get_table(table_id)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550756a-7a9e-4ce7-ada5-6f109ac09839",
   "metadata": {},
   "source": [
    "##### The data is now in BQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bc92a-b54b-4600-8bf9-a289e098a6b9",
   "metadata": {},
   "source": [
    "## The tables are set for feature enrichment\n",
    "We will visit these tables later, now let's load the Million Playlist dataset locally and push bq using `pandas-gbq` (see requirements installation at the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd3725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://{SOURCE_BUCKET}spotify_million_playlist_dataset.zip .\n",
    "# !unzip spotify_million_playlist_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420750c4",
   "metadata": {},
   "source": [
    "#### This step can take up to 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "data_files = os.listdir('data')\n",
    "\n",
    "#make sure there is not already existing data in the playlists table\n",
    "#loops over json files - converts to pandas then upload/appends\n",
    "for filename in data_files:\n",
    "    with open(f'data/{filename}') as f:\n",
    "        json_dict = json.load(f)\n",
    "        df = pd.DataFrame(json_dict['playlists'])\n",
    "        df.to_gbq(\n",
    "        destination_table=f'{bq_dataset}.playlists', \n",
    "        project_id=PROJECT_ID, # TODO: param\n",
    "        location=REGION, \n",
    "        progress_bar=False, \n",
    "        reauth=True, \n",
    "        if_exists='append'\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a96366-cab1-408f-af19-4539ba1a890e",
   "metadata": {},
   "source": [
    "Now the data is loaded but the playlists are nested as one large string that needs to be parsed - we will use json compatible functionality with BigQuery to address\n",
    "\n",
    "![](img/tracks-string.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b113f",
   "metadata": {},
   "source": [
    "### Import bigquery and run parameterized queries to shape the data\n",
    "\n",
    "This query formats the json strings to be read as Bigquery structs, to be manipulated in subsequent queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "json_extract_query = f\"\"\"create or replace table `{PROJECT_ID}.{bq_dataset}.playlists_nested` as (\n",
    "with json_parsed as (SELECT * except(tracks), JSON_EXTRACT_ARRAY(tracks) as json_data FROM `{PROJECT_ID}.{bq_dataset}.playlists` )\n",
    "\n",
    "select json_parsed.* except(json_data),\n",
    "ARRAY(SELECT AS STRUCT\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.pos\") as pos, \n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.artist_name\") as artist_name,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.track_uri\") as track_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.artist_uri\") as artist_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.track_name\") as track_name,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.album_uri\") as album_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.duration_ms\") as duration_ms,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.album_name\") as album_name\n",
    "from json_parsed.json_data\n",
    ") as tracks,\n",
    "from json_parsed) \"\"\"\n",
    "\n",
    "bigquery_client.query(json_extract_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f27fb-b56d-4759-ab10-e28c0d2c186f",
   "metadata": {},
   "source": [
    "Now `playlists_nested` has parsed the string data to a struct with arrays that will allow us to process the data much more easily\n",
    "\n",
    "![](img/playlists-nested.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543e5fe-d7d4-447c-9430-5ffa1575cb7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next we get the unique track features to put in a BQ table\n",
    "\n",
    "This table will then be used to call the Spotify API and enrich with additional data about each track and artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9761d5-3554-4a92-a05a-b167dec4f5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 757 µs, total: 13.4 ms\n",
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fa5568438d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_tracks_sql = f\"\"\"create or replace table `{PROJECT_ID}.{bq_dataset}.tracks_unique` as (\n",
    "SELECT distinct \n",
    "    track.track_uri,\n",
    "    track.album_uri,\n",
    "    track.artist_uri, \n",
    "FROM `{PROJECT_ID}.{bq_dataset}.playlists_nested`, UNNEST(tracks) as track)\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(unique_tracks_sql).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e57e9-e8bf-4733-90fd-26b80c4f2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO - MOVE THE STUFF ABOVE ON EXTRA FEATURES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2890a40",
   "metadata": {},
   "source": [
    "## Now enrich the playlist songs with the new features\n",
    "\n",
    "`unique_track_features` - created from file above\n",
    "\n",
    "+\n",
    "\n",
    "`unique_artist_features` - created from file above\n",
    "\n",
    "These are additional tables where features were added in the beginning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3066d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 ms, sys: 221 µs, total: 31.3 ms\n",
      "Wall time: 48.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f47581f7430>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "enrich_query = f\"\"\"CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.enriched_data` AS (\n",
    "    SELECT\n",
    "    a.* except(tracks),\n",
    "      ARRAY(\n",
    "    SELECT\n",
    "      AS STRUCT CAST(track.pos AS int64) AS pos_can,\n",
    "      case when track.artist_name = '' then 'NONE' else track.artist_name end AS artist_name_can,\n",
    "      case when track.track_uri = '' then 'NONE' else track.track_uri  end AS track_uri_can,\n",
    "      case when track.album_uri = '' then 'NONE' else track.album_uri  end AS album_uri_can,\n",
    "      case when track.artist_uri = '' then 'NONE' else track.artist_uri  end AS artist_uri_can,\n",
    "      CAST(track.duration_ms AS float64) / 1.0 AS duration_ms_can,\n",
    "      case when track.album_name = '' then 'NONE' else track.album_name end AS album_name_can,\n",
    "      CAST(IFNULL(tf.track_pop, 0.0) as float64) / 1.0 AS track_pop_can,\n",
    "      CAST(IFNULL(af.artist_pop, 0.0) as float64) / 1.0  AS artist_pop_can,\n",
    "      case when af.artist_genres[OFFSET(0)] = '' then ['NONE'] else af.artist_genres end AS artist_genres_can,\n",
    "      CAST(IFNULL(af.artist_followers, 0.0) as float64) / 1.0 AS artist_followers_can\n",
    "    FROM\n",
    "      UNNEST(tracks) as track\n",
    "    INNER JOIN\n",
    "      `{PROJECT_ID}.{bq_dataset}.unique_track_features` AS tf --track features\n",
    "    ON\n",
    "      (track.track_uri = tf.track_uri)\n",
    "    INNER JOIN\n",
    "      `{PROJECT_ID}.{bq_dataset}.unique_artists_features` AS af --artist features\n",
    "      ON\n",
    "      (track.artist_uri = af.artist_uri)\n",
    "      ) AS tracks\n",
    "  FROM \n",
    "  `{PROJECT_ID}.{bq_dataset}.playlists_nested` as a)\"\"\"\n",
    "\n",
    "bigquery_client.query(enrich_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933a3b9",
   "metadata": {},
   "source": [
    "## Cross join + get rid of after-the-fact `pos` data in playlist\n",
    "\n",
    "cross_join_songxplaylist_struct_query\n",
    "\n",
    "`hybrid-vertex.spotify_train_3.ordered_position_training`\n",
    "\n",
    "We create a data structure that creates unique song-playlist combos (every possible via cross-join). There is also a portion of pulling the last song in the playlist as the \"seed track\"\n",
    "________\n",
    "### Note on the approach\n",
    "\n",
    "Semantic matching requires pairs, triplets (tuples generally) of co-occurrences between pairs. This is a very broad definition, and with this newer approach many new use cases are being explored. A simple example are finding pairs of user queries and purchases. The training example pair are: (the features we know from the user query, the features we know on the product they ultimately purchased).\n",
    "\n",
    "There are other approaches where triples are considered, and there are advanced techniques on negative sampling, finding “bad” examples of query, product pairs, which we will not cover here.\n",
    "\n",
    "Note there are other sampling techniques we highlight below (different artist/album)\n",
    "\n",
    "The chosen task was predicting the next song on a playlist, given the playlist existing order. The approach taken was to create pairs for all children songs and their parent playlists. We did leveraging BigQuery’s `UNNEST` and `CROSS JOIN`. \n",
    "\n",
    "We also had rich features for playlists, albums and songs in another table that was later used to enrich post `CROSS JOIN`. This was done to optimize the computation since the cross-joining is expensive and it was subsequently much quicker to enrich after this step.\n",
    "\n",
    "Now that we completed this step, we had all combinations of child song, playlist pairs. The song was the candidate label but the playlist still contained the candidate label and all songs after. Additional criteria was added to remove the candidate song and all songs that occur after the candidate in the playlist. For the sake of performance we also only considered the last 5 played songs. Other sampling configurations are available in the example notebook as well (only predicting when there are album and artist switches).\n",
    "\n",
    "What this results in is a training dataset that has all possible child song candidates joined with the full playlist data, and the playlist data is properly censored as to only contain songs up to before the candidate song.\n",
    "\n",
    "![](img/semantic-pair.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e136cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71.8 ms, sys: 15.7 ms, total: 87.5 ms\n",
      "Wall time: 8min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fc8861f7b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cross_join_query = f\"\"\"\n",
    "  CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` AS (\n",
    "  WITH\n",
    "    -- get every combination of song and its parent playlist\n",
    "    unnest_cross AS(\n",
    "    SELECT\n",
    "      b.*,\n",
    "      CONCAT(b.pid,\"-\",track.pos_can) AS pid_pos_id,\n",
    "      CAST(track.pos_can AS int64) AS pos_can,\n",
    "      IFNULL(track.artist_name_can, \"NONE\") as artist_name_can ,\n",
    "      track.track_uri_can ,\n",
    "      track.album_uri_can,\n",
    "      IFNULL(track.track_name_can, \"NONE\") as track_name_can ,\n",
    "      track.artist_uri_can ,\n",
    "      CAST(track.duration_ms_can AS float64) AS duration_ms_can,\n",
    "      track.album_name_can ,\n",
    "      track.track_pop_can ,\n",
    "      track.artist_pop_can,\n",
    "      track.artist_genres_can ,\n",
    "      track.artist_followers_can \n",
    "    FROM (\n",
    "      SELECT\n",
    "        * EXCEPT(duration_ms)\n",
    "      FROM\n",
    "        `{PROJECT_ID}.{bq_dataset}.enriched_data`) AS b\n",
    "    CROSS JOIN\n",
    "      UNNEST(tracks) AS track)\n",
    "  SELECT\n",
    "    a.* EXCEPT(tracks,\n",
    "      num_tracks,\n",
    "      num_artists,\n",
    "      num_albums,\n",
    "      num_followers,\n",
    "      num_edits),\n",
    "    ARRAY(\n",
    "    SELECT\n",
    "      AS STRUCT CAST(track.pos_can AS int64) AS pos_pl,\n",
    "      track.artist_name_can AS artist_name_pl,\n",
    "      track.track_uri_can AS track_uri_pl,\n",
    "      track.track_name_can AS track_name_pl,\n",
    "      track.album_uri_can AS album_uri_pl,\n",
    "      track.artist_uri_can AS artist_uri_pl,\n",
    "      CAST(track.duration_ms_can AS float64) AS duration_ms_pl,\n",
    "      track.album_name_can AS album_name_pl,\n",
    "      track.track_pop_can AS track_pop_pl,\n",
    "      track.artist_pop_can AS artist_pop_pl,\n",
    "      track.artist_genres_can AS artist_genres_pl,\n",
    "      track.artist_followers_can AS artist_followers_pl,\n",
    "    FROM\n",
    "      UNNEST(tracks) AS track\n",
    "    WHERE\n",
    "      CAST(track.pos_can AS int64) < a.pos_can ORDER BY CAST(track.pos_can AS int64)) AS seed_playlist_tracks,\n",
    "    ----- seed track part\n",
    "    trx.pos_can AS pos_seed_track,\n",
    "    trx.artist_name_can AS artist_name_seed_track,\n",
    "    trx.artist_uri_can AS artist_uri_seed_track,\n",
    "    trx.track_name_can AS track_name_seed_track,\n",
    "    trx.track_uri_can AS track_uri_seed_track,\n",
    "    trx.album_name_can AS album_name_seed_track,\n",
    "    trx.album_uri_can AS album_uri_seed_track,\n",
    "    trx.duration_ms_can AS duration_seed_track,\n",
    "    trx.track_pop_can AS track_pop_seed_track,\n",
    "    trx.artist_pop_can AS artist_pop_seed_track,\n",
    "    trx.artist_genres_can as artist_genres_seed_track,\n",
    "    trx.artist_followers_can as artist_followers_seed_track\n",
    "  FROM\n",
    "    unnest_cross AS a -- with statement\n",
    "    ,\n",
    "    UNNEST(a.tracks) AS trx\n",
    "  WHERE\n",
    "    CAST(trx.pos_can AS int64) = a.pos_can-1);\n",
    "    \"\"\"\n",
    "\n",
    "bigquery_client.query(cross_join_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a1393",
   "metadata": {},
   "source": [
    "## Update the playlist metadata with the new samples created above\n",
    "\n",
    "Trainv3-clean-track-features\n",
    "\n",
    "Get new metadata for the tracks now that there are updated track counts, durations, etc...\n",
    "\n",
    "`hybrid-vertex.spotify_train_3.train`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7985b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 ms, sys: 1.54 ms, total: 36.8 ms\n",
      "Wall time: 2min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fc885937950>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_new_metadata_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train` as (\n",
    "WITH\n",
    "  playlist_features_clean AS (\n",
    "  SELECT\n",
    "    pid_pos_id,\n",
    "    SUM(trx.duration_ms_pl) / 1.0 AS duration_ms_seed_pl,\n",
    "    COUNT(1) / 1.0 AS n_songs_pl,\n",
    "    COUNT(DISTINCT trx.artist_name_pl) / 1.0 AS num_artists_pl,\n",
    "    COUNT(DISTINCT trx.album_uri_pl) /1.0 AS num_albums_pl,\n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.ordered_position_training`,\n",
    "    UNNEST(seed_playlist_tracks) AS trx\n",
    "  GROUP BY\n",
    "    pid_pos_id)\n",
    "    \n",
    "SELECT\n",
    "  a.* except(artist_genres_can, artist_genres_seed_track, track_pop_can, artist_pop_can, artist_followers_can,\n",
    "            track_pop_seed_track, artist_pop_seed_track),\n",
    "  b.* except(pid_pos_id),\n",
    "  IFNULL(a.artist_genres_can[OFFSET(0)], \"NONE\") as artist_genres_can,\n",
    "  IFNULL(a.artist_genres_seed_track[OFFSET(0)], \"NONE\") as artist_genres_seed_track,\n",
    "  IFNULL(a.track_pop_can, 0.0) / 1.0 as  track_pop_can, \n",
    "  IFNULL(a.artist_pop_can, 0.0) / 1.0 as artist_pop_can,\n",
    "  IFNULL(a.artist_followers_can, 0.0) / 1.0 as artist_followers_can,\n",
    "  IFNULL(a.track_pop_seed_track, 0.0) / 1.0 as track_pop_seed_track,\n",
    "  IFNULL(a.artist_pop_seed_track, 0.0) / 1.0 as artist_pop_seed_track,\n",
    "  \n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` a\n",
    "INNER JOIN\n",
    "  playlist_features_clean b\n",
    "ON\n",
    "  a.pid_pos_id = b.pid_pos_id )\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_new_metadata_query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19113617-7da4-4c9d-a18e-a54b414abe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 ms, sys: 0 ns, total: 14.1 ms\n",
      "Wall time: 12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fc88d7e7d10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "### Get candidates\n",
    "\n",
    "get_unique_candidates = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.candidates` as (\n",
    "SELECT DISTINCT\n",
    "  track_name_can,\n",
    "  artist_name_can,\n",
    "  album_name_can,\n",
    "  track_uri_can,\n",
    "  album_uri_can,\n",
    "  artist_uri_can,\n",
    "  track_pop_can,\n",
    "  artist_genres_can,\n",
    "  artist_followers_can,\n",
    "  duration_ms_can,\n",
    "  artist_pop_can\n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.train`\n",
    "  )\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_unique_candidates).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4517477d",
   "metadata": {},
   "source": [
    "## For TFRecords\n",
    "Get rid of structs by creating new table with arrays from playlist_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcaf70-5e96-435e-a888-ae832dc297aa",
   "metadata": {},
   "source": [
    "# Only selecting last 5 songs\n",
    "\n",
    "song_history is settable but it will impact `MAX_PLAYLIST_LENGTH` in `src/two_tower.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fa435-e2d7-48c4-a2b2-5a673d58b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_HISTORY=5 # length of playlist tracks to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c31ae6-1126-4970-bf30-cbe40065d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 ms, sys: 375 µs, total: 14.5 ms\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fc88583b7d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_flatten_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_last_5` as (\n",
    "SELECT a.* except(seed_playlist_tracks, description),\n",
    "    IFNULL(a.description, \"\") as description_pl,\n",
    "    ARRAY(select t.pos_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as pos_pl,\n",
    "    ARRAY(select t.artist_name_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_name_pl,\n",
    "    ARRAY(select t.track_uri_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as track_uri_pl,\n",
    "    ARRAY(select t.track_name_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as track_name_pl,\n",
    "    ARRAY(select t.duration_ms_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as duration_ms_songs_pl,\n",
    "    ARRAY(select t.album_name_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as album_name_pl,\n",
    "    ARRAY(select cast(t.artist_pop_pl as FLOAT64) from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_pop_pl,\n",
    "    ARRAY(select t.artist_followers_pl from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as artists_followers_pl,\n",
    "    ARRAY(select case when t.track_pop_pl is null then 0. else t.track_pop_pl end from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as track_pop_pl,\n",
    "    ARRAY(select t.artist_genres_pl[OFFSET(0)] from UNNEST(seed_playlist_tracks) t where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_genres_pl\n",
    "    from `{PROJECT_ID}.{bq_dataset}.train` a\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(train_flatten_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b5571-175c-44ac-b8bf-1df0ce8c5160",
   "metadata": {},
   "source": [
    "## Important for validation strategy\n",
    "Different playlist ids were selected for validation to prevent cross-contamination with the sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a08d4f1-ea60-46b5-b520-1d61ec0e38ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 ms, sys: 3.57 ms, total: 13.9 ms\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fc8857e8d10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.01\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_valid_last_5` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_last_5` where MOD(pid, 100) = 0\n",
    "    AND ARRAY_LENGTH(pos_pl) = {TRACK_HISTORY})\"\"\" #complete examples only\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5db82a0-253c-4f84-bab3-d087888ab30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 0 ns, total: 13.5 ms\n",
      "Wall time: 17.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fc88621cc10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.01\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_last_5` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_last_5` where MOD(pid, 100) != 0\n",
    "    AND ARRAY_LENGTH(pos_pl) = {TRACK_HISTORY})\"\"\" #complete examples only\"\"\"\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bc3ad-35a2-4e14-b946-5faf7e14dca1",
   "metadata": {},
   "source": [
    "## Done - you can move on to the [next notebook](01-tfrecord-beam-pipeline.ipynb) unless you want to do the optional sampling strategy. \n",
    "\n",
    "Your data should look like this:\n",
    "    \n",
    "![](img/train-dataset-metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28115ae6-bbc4-4f0d-b18c-e7f8e0151bd0",
   "metadata": {},
   "source": [
    "___________\n",
    "\n",
    "# Optional different artist sampling strategy\n",
    "\n",
    "In this section, you could create another dataset that only considers the cases when artist switch. This avoids training on cases where an album may be played in it's end to end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533dd54-0f8c-44cf-9f2a-66057b4a4626",
   "metadata": {},
   "source": [
    "### TODO \n",
    "* clean-up section (Create options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd5a1f7-58be-4143-9382-13364cf5ffa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.1 ms, sys: 7.18 ms, total: 59.3 ms\n",
      "Wall time: 3min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fdb52da8850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_new_metadata_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_dif_artist` as (\n",
    "WITH\n",
    "  playlist_features_clean AS (\n",
    "  SELECT\n",
    "    pid_pos_id,\n",
    "    SUM(trx.duration_ms_pl) / 1.0 AS duration_ms_seed_pl,\n",
    "    COUNT(1) / 1.0 AS n_songs_pl,\n",
    "    COUNT(DISTINCT trx.artist_name_pl) / 1.0 AS num_artists_pl,\n",
    "    COUNT(DISTINCT trx.album_uri_pl) /1.0 AS num_albums_pl,\n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.ordered_position_training`,\n",
    "    UNNEST(seed_playlist_tracks) AS trx\n",
    "  GROUP BY\n",
    "    pid_pos_id)\n",
    "    \n",
    "SELECT\n",
    "  a.* except(artist_genres_can, artist_geexcpectedres_seed_track, track_pop_can, artist_pop_can, artist_followers_can,\n",
    "            track_pop_seed_track, artist_pop_seed_track),\n",
    "  b.* except(pid_pos_id),\n",
    "  IFNULL(a.artist_genres_can[OFFSET(0)], \"NONE\") as artist_genres_can,\n",
    "  IFNULL(a.artist_genres_seed_track[OFFSET(0)], \"NONE\") as artist_genres_seed_track,\n",
    "  IFNULL(a.track_pop_can, 0.0) / 1.0 as  track_pop_can, \n",
    "  IFNULL(a.artist_pop_can, 0.0) / 1.0 as artist_pop_can,\n",
    "  IFNULL(a.artist_followers_can, 0.0) / 1.0 as artist_followers_can,\n",
    "  IFNULL(a.track_pop_seed_track, 0.0) / 1.0 as track_pop_seed_track,\n",
    "  IFNULL(a.artist_pop_seed_track, 0.0) / 1.0 as artist_pop_seed_track,\n",
    "  \n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` a\n",
    "INNER JOIN\n",
    "  playlist_features_clean b\n",
    "ON\n",
    "  a.pid_pos_id = b.pid_pos_id \n",
    "  WHERE album_uri_can != album_uri_seed_track and artist_uri_seed_track != artist_uri_can)\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_new_metadata_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f6a3a-085e-42c7-8a66-888ef7b56e63",
   "metadata": {},
   "source": [
    "## For TFRecords\n",
    "Get rid of structs by creating new table with arrays from playlist_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a78803c-9fd2-481b-bc20-a63a82df4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 ms, sys: 0 ns, total: 39 ms\n",
      "Wall time: 32.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f81200ea410>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_flatten_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_dif_artist` as (\n",
    "SELECT a.* except(seed_playlist_tracks, description),\n",
    "    IFNULL(a.description, \"\") as description_pl,\n",
    "    ARRAY(select t.pos_pl from UNNEST(seed_playlist_tracks) t) as pos_pl,\n",
    "    ARRAY(select t.artist_name_pl from UNNEST(seed_playlist_tracks) t) as artist_name_pl,\n",
    "    ARRAY(select t.track_uri_pl from UNNEST(seed_playlist_tracks) t) as track_uri_pl,\n",
    "    ARRAY(select t.track_name_pl from UNNEST(seed_playlist_tracks) t) as track_name_pl,\n",
    "    ARRAY(select t.duration_ms_pl from UNNEST(seed_playlist_tracks) t) as duration_ms_songs_pl,\n",
    "    ARRAY(select t.album_name_pl from UNNEST(seed_playlist_tracks) t) as album_name_pl,\n",
    "    ARRAY(select cast(t.artist_pop_pl as FLOAT64) from UNNEST(seed_playlist_tracks) t) as artist_pop_pl,\n",
    "    ARRAY(select t.artist_followers_pl from UNNEST(seed_playlist_tracks) t) as artists_followers_pl,\n",
    "    ARRAY(select case when t.track_pop_pl is null then 0. else t.track_pop_pl end from UNNEST(seed_playlist_tracks) t) as track_pop_pl,\n",
    "    ARRAY(select t.artist_genres_pl[OFFSET(0)] from UNNEST(seed_playlist_tracks) t) as artist_genres_pl\n",
    "    from `{PROJECT_ID}.{bq_dataset}.train_dif_artist` a\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(train_flatten_query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fb5eee9-6de1-4eec-96cc-699c03f6c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 ms, sys: 285 µs, total: 17.5 ms\n",
      "Wall time: 16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f8120095410>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "VALIDATION_P = 0.1\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_dif_artist_valid` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_dif_artist` where MOD(pid, 100) = 0)\"\"\"\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8252d2-b169-49fb-a2c8-5886fad0da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.1 ms, sys: 741 µs, total: 26.9 ms\n",
      "Wall time: 38.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f812007c590>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.1\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_dif_artist_train` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_dif_artist` where MOD(pid, 100) != 0)\"\"\"\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b4c0c-9368-49c8-9b33-2fdac81cd579",
   "metadata": {},
   "source": [
    "### Fin\n",
    "You are all set - go on to [`01-tfrecord-beam-pipeline.ipynb`](01-tfrecord-beam-pipeline.ipynb)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
