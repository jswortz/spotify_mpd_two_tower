{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0636aec-1d0f-4d15-adb2-2824738853b6",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "* clean up notebook\n",
    "* parameterize\n",
    "* offer large and small options for producing dataset (create optionals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd5f47-677c-4ab6-a28c-111c53359eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars to parameterize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0eb21",
   "metadata": {},
   "source": [
    "#### Step 0: Dependencies\n",
    "\n",
    "Run this one time when starting, then restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbb59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas pandas-gbq==0.12.0 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da0ab1",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "## In this notebook we will load the songs from the zip file, and perform transformations to prepare the data for two-tower training\n",
    "Steps\n",
    "1. Extract from the zip file\n",
    "2. Upload to BQ\n",
    "3. Enrich features for the playlist songs\n",
    "4. Cross-join songs with features (expected rows = n_songs x n_playlists)\n",
    "5. Remove after-the-fact (later position songs) from the newly generated samples\n",
    "6. Create a clean train table, and flatten structs or use arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04cd08",
   "metadata": {},
   "source": [
    "#### Unzip the file and upload to BQ\n",
    "Source of data if you want to download zip: gs://spotify-million-playlist-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d08efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your variables for your project, region, and dataset name\n",
    "SOURCE_BUCKET = 'spotify-million-playlist-dataset'\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "REGION = 'us-central1'\n",
    "bq_dataset = 'spotify_e2e_test'\n",
    "\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bigquery_client = bigquery.Client(project=PROJECT_ID, location='US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c0e0b6-0bd4-42bd-bd42-b722c0d871d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a bigquery dataset (one time operation)\n",
    "# # Construct a full Dataset object to send to the API.\n",
    "# dataset = bigquery.Dataset(f\"`{PROJECT_ID}.{bq_dataset}`\")\n",
    "\n",
    "# # TODO(developer): Specify the geographic location where the dataset should reside.\n",
    "# dataset.location = \"US\"\n",
    "\n",
    "# # Send the dataset to the API for creation, with an explicit timeout.\n",
    "# # Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# # exists within the project.\n",
    "# dataset = bigquery_client.create_dataset(bq_dataset, timeout=30)  # Make an API request.\n",
    "# print(\"Created dataset {}.{}\".format(bigquery_client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409cabe2-16c1-4131-b298-82c7078b53ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next create unique artist and song tables\n",
    "These tables contain features obtained via the public Spotify API. Features such as track and artist popularity are in this data. For more detail on loading json data to Bigquery, [see here](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json)\n",
    "\n",
    "![](img/unique-songs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a2839d-276b-47f1-b73d-4a1e860ca8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4524584 rows.\n"
     ]
    }
   ],
   "source": [
    "table_id = f\"{PROJECT_ID}.{bq_dataset}.unique_track_features\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"track_pop\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"tracks_playlist_titles\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"track_uri\", \"STRING\"),\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")\n",
    "uri = f\"gs://{SOURCE_BUCKET}/unique_track_features.gzip\"\n",
    "\n",
    "load_job = bigquery_client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    location=REGION,  # Must match the destination dataset location.\n",
    "    job_config=job_config,\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = bigquery_client.get_table(table_id)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866e7b6-0b6c-4d1e-9d7f-73c99c3a3a0b",
   "metadata": {},
   "source": [
    "### Unique artists\n",
    "\n",
    "![](img/unique-artists.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb911024-e624-43be-818c-8dc8ea129f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 295860 rows.\n"
     ]
    }
   ],
   "source": [
    "table_id = f\"{PROJECT_ID}.{bq_dataset}.unique_artist_features\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"artist_genres\", \"STRING\", \"REPEATED\"),\n",
    "        bigquery.SchemaField(\"artist_pop\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"artist_followers\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"artist_uri\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"artist_name\", \"STRING\"),\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")\n",
    "uri = f\"gs://{SOURCE_BUCKET}/unique_artist_features.gzip\"\n",
    "\n",
    "load_job = bigquery_client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_id,\n",
    "    location=\"US\",  # Must match the destination dataset location.\n",
    "    job_config=job_config,\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = bigquery_client.get_table(table_id)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550756a-7a9e-4ce7-ada5-6f109ac09839",
   "metadata": {},
   "source": [
    "##### The data is now in BQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bc92a-b54b-4600-8bf9-a289e098a6b9",
   "metadata": {},
   "source": [
    "## The tables are set for feature enrichment\n",
    "We will visit these tables later, now let's load the Million Playlist dataset locally and push bq using `pandas-gbq` (see requirements installation at the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd3725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://{SOURCE_BUCKET}spotify_million_playlist_dataset.zip .\n",
    "# !unzip spotify_million_playlist_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420750c4",
   "metadata": {},
   "source": [
    "#### This step can take up to 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "data_files = os.listdir('data')\n",
    "\n",
    "#make sure there is not already existing data in the playlists table\n",
    "#loops over json files - converts to pandas then upload/appends\n",
    "for filename in data_files:\n",
    "    with open(f'data/{filename}') as f:\n",
    "        json_dict = json.load(f)\n",
    "        df = pd.DataFrame(json_dict['playlists'])\n",
    "        df.to_gbq(\n",
    "        destination_table=f'{bq_dataset}.playlists', \n",
    "        project_id=PROJECT_ID, # TODO: param\n",
    "        location=REGION, \n",
    "        progress_bar=False, \n",
    "        reauth=True, \n",
    "        if_exists='append'\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a96366-cab1-408f-af19-4539ba1a890e",
   "metadata": {},
   "source": [
    "Now the data is loaded but the playlists are nested as one large string that needs to be parsed - we will use json compatible functionality with BigQuery to address\n",
    "\n",
    "![](img/tracks-string.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b113f",
   "metadata": {},
   "source": [
    "### Import bigquery and run parameterized queries to shape the data\n",
    "\n",
    "This query formats the json strings to be read as Bigquery structs, to be manipulated in subsequent queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "json_extract_query = f\"\"\"create or replace table `{PROJECT_ID}.{bq_dataset}.playlists_nested` as (\n",
    "with json_parsed as (SELECT * except(tracks), JSON_EXTRACT_ARRAY(tracks) as json_data FROM `{PROJECT_ID}.{bq_dataset}.playlists` )\n",
    "\n",
    "select json_parsed.* except(json_data),\n",
    "ARRAY(SELECT AS STRUCT\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.pos\") as pos, \n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.artist_name\") as artist_name,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.track_uri\") as track_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.artist_uri\") as artist_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.track_name\") as track_name,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.album_uri\") as album_uri,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.duration_ms\") as duration_ms,\n",
    "JSON_EXTRACT_SCALAR(json_data, \"$.album_name\") as album_name\n",
    "from json_parsed.json_data\n",
    ") as tracks,\n",
    "from json_parsed) \"\"\"\n",
    "\n",
    "bigquery_client.query(json_extract_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f27fb-b56d-4759-ab10-e28c0d2c186f",
   "metadata": {},
   "source": [
    "Now `playlists_nested` has parsed the string data to a struct with arrays that will allow us to process the data much more easily\n",
    "\n",
    "![](img/playlists-nested.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543e5fe-d7d4-447c-9430-5ffa1575cb7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Next we get the unique track features to put in a BQ table\n",
    "\n",
    "This table will then be used to call the Spotify API and enrich with additional data about each track and artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9761d5-3554-4a92-a05a-b167dec4f5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 757 µs, total: 13.4 ms\n",
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fa5568438d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_tracks_sql = f\"\"\"create or replace table `{PROJECT_ID}.{bq_dataset}.tracks_unique` as (\n",
    "SELECT distinct \n",
    "    track.track_uri,\n",
    "    track.album_uri,\n",
    "    track.artist_uri, \n",
    "FROM `{PROJECT_ID}.{bq_dataset}.playlists_nested`, UNNEST(tracks) as track)\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(unique_tracks_sql).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e57e9-e8bf-4733-90fd-26b80c4f2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO - MOVE THE STUFF ABOVE ON EXTRA FEATURES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2890a40",
   "metadata": {},
   "source": [
    "## Now enrich the playlist songs with the new features\n",
    "\n",
    "`audio_features` - created from prior notebook via Spotify API\n",
    "\n",
    "+\n",
    "\n",
    "`artist_features` - created from prior notebook via Spotify API\n",
    "\n",
    "These are additional tables where features were added in the beginning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3066d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 ms, sys: 0 ns, total: 22.1 ms\n",
      "Wall time: 33.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84e9bfa910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "enrich_query = f\"\"\"CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.enriched_data` AS (\n",
    "  WITH tf as (SELECT distinct * from `{PROJECT_ID}.{bq_dataset}.audio_features`),\n",
    "       af as (SELECT distinct * from `{PROJECT_ID}.{bq_dataset}.artist_features`) \n",
    "  \n",
    "    SELECT\n",
    "    a.* except(tracks),\n",
    "      ARRAY(\n",
    "    SELECT\n",
    "      AS STRUCT CAST(track.pos AS int64) AS pos_can,\n",
    "      case when track.artist_name = '' then 'NONE' else track.artist_name end AS artist_name_can,\n",
    "      case when track.track_uri = '' then 'NONE' else track.track_uri  end AS track_uri_can,\n",
    "      case when track.album_uri = '' then 'NONE' else track.album_uri  end AS album_uri_can,\n",
    "      case when track.artist_uri = '' then 'NONE' else track.artist_uri  end AS artist_uri_can,\n",
    "      case when track.track_name = '' then 'NONE' else track.track_name end AS track_name_can,\n",
    "      CAST(track.duration_ms AS float64) / 1.0 AS duration_ms_can,\n",
    "      case when track.album_name = '' then 'NONE' else track.album_name end AS album_name_can,\n",
    "      CAST(IFNULL(tf.track_pop, 0.0) as float64) / 1.0 AS track_pop_can,\n",
    "      CAST(IFNULL(af.artist_pop, 0.0) as float64) / 1.0  AS artist_pop_can,\n",
    "      case when \n",
    "        ARRAY(SELECT * FROM UNNEST(SPLIT(SUBSTR(genres, 2 , LENGTH(genres) - 2))))[OFFSET(0)] = '' \n",
    "      then \n",
    "        ['NONE'] else ARRAY(SELECT * FROM UNNEST(SPLIT(SUBSTR(genres, 2 , LENGTH(genres) - 2)))) end AS artist_genres_can,\n",
    "      CAST(IFNULL(af.followers, 0.0) as float64) / 1.0 AS artist_followers_can\n",
    "    FROM\n",
    "      UNNEST(tracks) as track\n",
    "    INNER JOIN\n",
    "     tf --track features\n",
    "    ON\n",
    "      (track.track_uri = tf.track_uri)\n",
    "    INNER JOIN\n",
    "      af\n",
    "      ON\n",
    "      (track.artist_uri = af.artist_uri)\n",
    "      ) AS tracks\n",
    "  FROM \n",
    "  `{PROJECT_ID}.{bq_dataset}.playlists_nested` as a)\"\"\"\n",
    "\n",
    "bigquery_client.query(enrich_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933a3b9",
   "metadata": {},
   "source": [
    "## Cross join + get rid of after-the-fact `pos` data in playlist\n",
    "\n",
    "cross_join_songxplaylist_struct_query\n",
    "\n",
    "`hybrid-vertex.spotify_train_3.ordered_position_training`\n",
    "\n",
    "We create a data structure that creates unique song-playlist combos (every possible via cross-join). There is also a portion of pulling the last song in the playlist as the \"seed track\"\n",
    "________\n",
    "### Note on the approach\n",
    "\n",
    "Semantic matching requires pairs, triplets (tuples generally) of co-occurrences between pairs. This is a very broad definition, and with this newer approach many new use cases are being explored. A simple example are finding pairs of user queries and purchases. The training example pair are: (the features we know from the user query, the features we know on the product they ultimately purchased).\n",
    "\n",
    "There are other approaches where triples are considered, and there are advanced techniques on negative sampling, finding “bad” examples of query, product pairs, which we will not cover here.\n",
    "\n",
    "Note there are other sampling techniques we highlight below (different artist/album)\n",
    "\n",
    "The chosen task was predicting the next song on a playlist, given the playlist existing order. The approach taken was to create pairs for all children songs and their parent playlists. We did leveraging BigQuery’s `UNNEST` and `CROSS JOIN`. \n",
    "\n",
    "We also had rich features for playlists, albums and songs in another table that was later used to enrich post `CROSS JOIN`. This was done to optimize the computation since the cross-joining is expensive and it was subsequently much quicker to enrich after this step.\n",
    "\n",
    "Now that we completed this step, we had all combinations of child song, playlist pairs. The song was the candidate label but the playlist still contained the candidate label and all songs after. Additional criteria was added to remove the candidate song and all songs that occur after the candidate in the playlist. For the sake of performance we also only considered the last 5 played songs. Other sampling configurations are available in the example notebook as well (only predicting when there are album and artist switches).\n",
    "\n",
    "What this results in is a training dataset that has all possible child song candidates joined with the full playlist data, and the playlist data is properly censored as to only contain songs up to before the candidate song.\n",
    "\n",
    "![](img/semantic-pair.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0e136cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 ms, sys: 94 µs, total: 37.8 ms\n",
      "Wall time: 1min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84ea103f10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cross_join_query = f\"\"\"\n",
    "  CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` AS (\n",
    "  WITH\n",
    "    -- get every combination of song and its parent playlist\n",
    "    unnest_cross AS(\n",
    "    SELECT\n",
    "      b.*,\n",
    "      CONCAT(b.pid,\"-\",track.pos_can) AS pid_pos_id,\n",
    "      CAST(track.pos_can AS int64) AS pos_can,\n",
    "      IFNULL(track.artist_name_can, \"NONE\") as artist_name_can ,\n",
    "      track.track_uri_can ,\n",
    "      track.album_uri_can,\n",
    "      IFNULL(track.track_name_can, \"NONE\") as track_name_can ,\n",
    "      track.artist_uri_can ,\n",
    "      CAST(track.duration_ms_can AS float64) AS duration_ms_can,\n",
    "      track.album_name_can ,\n",
    "      track.track_pop_can ,\n",
    "      track.artist_pop_can,\n",
    "      ARRAY_TO_STRING(track.artist_genres_can, ',', 'MISSING') as artist_genres_can ,\n",
    "      track.artist_followers_can \n",
    "    FROM (\n",
    "      SELECT\n",
    "        * EXCEPT(duration_ms)\n",
    "      FROM\n",
    "        `{PROJECT_ID}.{bq_dataset}.enriched_data`) AS b\n",
    "    CROSS JOIN\n",
    "      UNNEST(tracks) AS track)\n",
    "  SELECT\n",
    "    a.* EXCEPT(tracks,\n",
    "      num_tracks,\n",
    "      num_artists,\n",
    "      num_albums,\n",
    "      num_followers,\n",
    "      num_edits),\n",
    "    ARRAY(\n",
    "    SELECT\n",
    "      AS STRUCT CAST(track.pos_can AS int64) AS pos_pl,\n",
    "      track.artist_name_can AS artist_name_pl,\n",
    "      track.track_uri_can AS track_uri_pl,\n",
    "      track.track_name_can AS track_name_pl,\n",
    "      track.album_uri_can AS album_uri_pl,\n",
    "      track.artist_uri_can AS artist_uri_pl,\n",
    "      CAST(track.duration_ms_can AS float64) AS duration_ms_pl,\n",
    "      track.album_name_can AS album_name_pl,\n",
    "      track.track_pop_can AS track_pop_pl,\n",
    "      track.artist_pop_can AS artist_pop_pl,\n",
    "      ARRAY_TO_STRING(track.artist_genres_can, ',', 'MISSING') AS artist_genres_pl,\n",
    "      track.artist_followers_can AS artist_followers_pl,\n",
    "    FROM\n",
    "      UNNEST(tracks) AS track\n",
    "    WHERE\n",
    "      CAST(track.pos_can AS int64) < a.pos_can ORDER BY CAST(track.pos_can AS int64)) AS seed_playlist_tracks\n",
    "  FROM\n",
    "    unnest_cross AS a -- with statement\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "bigquery_client.query(cross_join_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a1393",
   "metadata": {},
   "source": [
    "## Update the playlist metadata with the new samples created above\n",
    "\n",
    "Add audio features from the tracks\n",
    "\n",
    "Get new metadata for the tracks now that there are updated track counts, durations, etc...\n",
    "\n",
    "`hybrid-vertex.spotify_train_3.train` will be produced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7985b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.8 ms, sys: 607 µs, total: 39.4 ms\n",
      "Wall time: 1min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84ea1c6850>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_new_metadata_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train` as (\n",
    "WITH\n",
    "  playlist_features_clean AS (\n",
    "  SELECT\n",
    "    pid_pos_id,\n",
    "    SUM(trx.duration_ms_pl) / 1.0 AS duration_ms_seed_pl,\n",
    "    COUNT(1) / 1.0 AS n_songs_pl,\n",
    "    COUNT(DISTINCT trx.artist_name_pl) / 1.0 AS num_artists_pl,\n",
    "    COUNT(DISTINCT trx.album_uri_pl) /1.0 AS num_albums_pl,\n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.ordered_position_training`,\n",
    "    UNNEST(seed_playlist_tracks) AS trx\n",
    "  GROUP BY\n",
    "    pid_pos_id)\n",
    "    \n",
    "SELECT\n",
    "  a.* except(artist_genres_can, track_pop_can, artist_pop_can, artist_followers_can),\n",
    "  b.* except(pid_pos_id),\n",
    "  a.artist_genres_can,\n",
    "  IFNULL(a.track_pop_can, 0.0) / 1.0 as  track_pop_can, \n",
    "  IFNULL(a.artist_pop_can, 0.0) / 1.0 as artist_pop_can,\n",
    "  IFNULL(a.artist_followers_can, 0.0) / 1.0 as artist_followers_can,\n",
    "\n",
    "  \n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` a\n",
    "INNER JOIN\n",
    "  playlist_features_clean b\n",
    "ON\n",
    "  a.pid_pos_id = b.pid_pos_id )\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_new_metadata_query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "19113617-7da4-4c9d-a18e-a54b414abe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.2 ms, sys: 161 µs, total: 52.4 ms\n",
      "Wall time: 15.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84e9904710>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "### Get candidates\n",
    "\n",
    "get_unique_candidates = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.candidates` as (\n",
    "WITH\n",
    "af as (SELECT DISTINCT * FROM `{PROJECT_ID}.{bq_dataset}.audio_features`)\n",
    "\n",
    "SELECT DISTINCT\n",
    "    track_uri_can,\n",
    "    track_name_can,\n",
    "    artist_uri_can,\n",
    "    artist_name_can,\n",
    "    album_uri_can,\n",
    "    album_name_can,\n",
    "    duration_ms_can,\n",
    "    track_pop_can,\n",
    "    artist_pop_can,\n",
    "    artist_genres_can,\n",
    "    artist_followers_can,\n",
    "    \n",
    "    IFNULL(af.danceability, 0.) as track_danceability_can,\n",
    "    IFNULL(af.energy, 0.) as track_energy_can,\n",
    "    IFNULL(af.key, 0.) as track_key_can,\n",
    "    IFNULL(af.loudness, 0.) as track_loudness_can,\n",
    "    IFNULL(af.mode, 0) as track_mode_can,\n",
    "    IFNULL(af.speechiness, 0.) as track_speechiness_can,\n",
    "    IFNULL(af.acousticness, 0.) as track_acousticness_can,\n",
    "    IFNULL(af.instrumentalness, 0.) as track_instrumentalness_can,\n",
    "    IFNULL(af.liveness, 0.) as track_liveness_can,\n",
    "    IFNULL(af.valence, 0.) as track_valence_can,\n",
    "    IFNULL(af.tempo, 0.) as track_tempo_can,\n",
    "    IFNULL(af.time_signature, 0) as time_signature_can,\n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.train` a\n",
    "   inner join af on af.track_uri = a.track_uri_can\n",
    "  )\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_unique_candidates).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4517477d",
   "metadata": {},
   "source": [
    "## For TFRecords\n",
    "Get rid of structs by creating new table with arrays from playlist_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcaf70-5e96-435e-a888-ae832dc297aa",
   "metadata": {},
   "source": [
    "# Only selecting last 5 songs\n",
    "\n",
    "song_history is settable but it will impact `MAX_PLAYLIST_LENGTH` in `src/two_tower.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f8fa435-e2d7-48c4-a2b2-5a673d58b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_HISTORY=5 # length of playlist tracks to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "83c31ae6-1126-4970-bf30-cbe40065d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 ms, sys: 5.91 ms, total: 28.1 ms\n",
      "Wall time: 48.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84e9900690>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_flatten_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_a` as (\n",
    "WITH audio as (SELECT DISTINCT * FROM `{PROJECT_ID}.{bq_dataset}.audio_features`)\n",
    "SELECT \n",
    "    pid,\n",
    "    IFNULL(a.name, \"\") as pl_name_src,\n",
    "    collaborative as pl_collaborative_src,\n",
    "    duration_ms_seed_pl as pl_duration_ms_new,\n",
    "    n_songs_pl as num_pl_songs_new, \n",
    "    num_artists_pl as num_pl_artists_new,\n",
    "    num_albums_pl as num_pl_albums_new,\n",
    "    track_uri_can,\n",
    "    track_name_can,\n",
    "    artist_uri_can,\n",
    "    artist_name_can,\n",
    "    album_uri_can,\n",
    "    album_name_can,\n",
    "    duration_ms_can,\n",
    "    track_pop_can,\n",
    "    artist_pop_can,\n",
    "    artist_genres_can,\n",
    "    artist_followers_can,\n",
    "    IFNULL(audio.danceability, 0.0) as track_danceability_can,\n",
    "    IFNULL(audio.energy, 0.0) as track_energy_can,\n",
    "    IFNULL(audio.key, 0.0) as track_key_can,\n",
    "    IFNULL(audio.loudness, 0.0) as track_loudness_can,\n",
    "    IFNULL(audio.mode, 0) as track_mode_can,\n",
    "    IFNULL(audio.acousticness, 0.0) as track_acousticness_can,\n",
    "    IFNULL(audio.instrumentalness, 0.0) as track_instrumentalness_can,\n",
    "    IFNULL(audio.liveness, 0.0) as track_liveness_can,\n",
    "    IFNULL(audio.speechiness, 0.0) as track_speechiness_can,\n",
    "    IFNULL(audio.valence, 0.0) as track_valence_can,\n",
    "    IFNULL(audio.tempo, 0.0) as track_tempo_can,\n",
    "    IFNULL(audio.time_signature, 0) as track_time_signature_can,\n",
    "    \n",
    "    ARRAY(select t.artist_name_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_name_pl, \n",
    "    ARRAY(select t.artist_uri_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_uri_pl, \n",
    "    ARRAY(select t.track_uri_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as track_uri_pl,\n",
    "    ARRAY(select t.track_name_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as track_name_pl,\n",
    "    ARRAY(select t.duration_ms_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as duration_ms_songs_pl, \n",
    "    ARRAY(select t.album_name_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as album_name_pl,\n",
    "    ARRAY(select t.album_uri_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as album_uri_pl,\n",
    "    ARRAY(select cast(t.artist_pop_pl as FLOAT64) from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_pop_pl,\n",
    "    ARRAY(select t.artist_followers_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artists_followers_pl,\n",
    "    ARRAY(select t.track_pop_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as track_pop_pl, \n",
    "    ARRAY(select t.artist_genres_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_genres_pl\n",
    "    \n",
    "    from `{PROJECT_ID}.{bq_dataset}.train` a\n",
    "    INNER JOIN \n",
    "    audio on audio.track_uri = a.track_uri_can\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(train_flatten_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4d75b-48aa-42d9-abfd-7c8620d85a5e",
   "metadata": {},
   "source": [
    "#### Append the audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2b96beea-92fa-4c74-9a10-913185d54f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 ms, sys: 44.7 ms, total: 360 ms\n",
      "Wall time: 22min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84e993d610>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_flatten_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_b` as (\n",
    "WITH audio as (SELECT DISTINCT * FROM `{PROJECT_ID}.{bq_dataset}.audio_features`)\n",
    "SELECT \n",
    "    a.*,\n",
    "    ARRAY(select IFNULL(audio.danceability, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_danceability_pl,\n",
    "    ARRAY(select IFNULL(audio.energy, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_energy_pl,\n",
    "    ARRAY(select IFNULL(audio.key, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_key_pl,\n",
    "    ARRAY(select IFNULL(audio.loudness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_loudness_pl,\n",
    "    ARRAY(select IFNULL(audio.mode, 0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_mode_pl,\n",
    "    ARRAY(select IFNULL(audio.acousticness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_acousticness_pl,\n",
    "    ARRAY(select IFNULL(audio.instrumentalness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_instrumentalness_pl,\n",
    "    ARRAY(select IFNULL(audio.liveness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_liveness_pl,\n",
    "    ARRAY(select IFNULL(audio.valence, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_valence_pl,\n",
    "    ARRAY(select IFNULL(audio.tempo, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_tempo_pl,\n",
    "    ARRAY(select IFNULL(audio.time_signature, 0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_time_signature_pl,\n",
    "    ARRAY(select IFNULL(audio.speechiness, 0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_speechiness_pl\n",
    "    from `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_a` a\n",
    "    WHERE\n",
    "     ARRAY_LENGTH(a.track_uri_pl) = {TRACK_HISTORY}) --limiting here for performance\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(train_flatten_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b5571-175c-44ac-b8bf-1df0ce8c5160",
   "metadata": {},
   "source": [
    "## Important for validation strategy\n",
    "Different playlist ids were selected for validation to prevent cross-contamination with the sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0a08d4f1-ea60-46b5-b520-1d61ec0e38ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.9 ms, sys: 3.37 ms, total: 59.2 ms\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84e993d590>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.01\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_valid_last_{TRACK_HISTORY}` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_b` where MOD(pid, 100) = 0\n",
    "    AND ARRAY_LENGTH(track_uri_pl) = {TRACK_HISTORY})\"\"\" #complete examples only\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c5db82a0-253c-4f84-bab3-d087888ab30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 ms, sys: 590 µs, total: 16.7 ms\n",
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f84e959bfd0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.01\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_last_{TRACK_HISTORY}` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_b` where MOD(pid, 100) != 0\n",
    "    AND ARRAY_LENGTH(track_uri_pl) = {TRACK_HISTORY})\"\"\" #complete examples only\"\"\"\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bc3ad-35a2-4e14-b946-5faf7e14dca1",
   "metadata": {},
   "source": [
    "## Done - you can move on to the [next notebook](02-tfrecord-beam-pipeline.ipynb) \n",
    "\n",
    "Your data should look like this:\n",
    "    \n",
    "![](img/train-dataset-metadata.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa410e4-2d40-435b-a5d2-068c5c440b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
