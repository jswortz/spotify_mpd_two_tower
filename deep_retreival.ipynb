{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5383b2-071e-45b8-af2c-2421eb4f923a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Two - Tower Retreival Model\n",
    "\n",
    "### Key resources:\n",
    "* Many pages [here](https://www.tensorflow.org/recommenders/examples/deep_recommenders) include great techniques to build custom TFRS Models\n",
    "\n",
    "### Goals:\n",
    "* Show how to model off of most data types \n",
    "  * (String, Existing Embeddings (vectors), \n",
    "  * Floats (Normalized), \n",
    "  * Categorical with vocab, \n",
    "  * High Dim Categorical (Embed)\n",
    "* Leverage class templates to create custom 2 Tower Models quick/easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52e5f-a13b-46a7-849a-dc188b455a86",
   "metadata": {},
   "source": [
    "## SPOTIFY Create the tensorflow.io interface for the event and product table in Bigquery\n",
    "Best practices from Google are in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3122eb-564b-46f9-9a50-851d19301521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "DROPOUT = False\n",
    "DROPOUT_RATE = 0.2\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_TOKENS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "ARCH = [128, 64]\n",
    "NUM_EPOCHS = 1\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "DROP_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']\n",
    "N_RECORDS_PER_TFRECORD_FILE = 300 * 50 #100ish mb  \n",
    "TF_RECORDS_DIR = 'gs://spotify-tfrecords'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c50a06-d69d-4d64-b254-26fb2a249fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick counts on training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1473-4a2d-4778-9f01-e2b76672a9f5",
   "metadata": {},
   "source": [
    "#### Quick counts on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa56927-6722-43f9-88ac-ab638487164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1189.20query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.12rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery TOTAL_PLAYLISTS\n",
    "select count(1) from jtotten-project.spotify_mpd.playlists_track_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418e5d8d-5410-4bca-a168-002d27ed95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_PLAYLISTS = TOTAL_PLAYLISTS.values[0][0]\n",
    "TOTAL_PLAYLISTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ee0aa-1c6d-47f0-a3a8-236c7a072ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Same with playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031039fa-decd-4396-a9ad-89f300a01f25",
   "metadata": {},
   "source": [
    "#### Quick counts (this time playlists) on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56750aa-be5c-4f4f-8b5b-4b8277e2a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1512.55query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.21rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery TOTAL_TRACKS\n",
    "select count(1) from jtotten-project.spotify_mpd.track_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccacb43d-c04c-4935-9e1f-06d51983e02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261490"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_TRACKS = TOTAL_TRACKS.values[0][0]\n",
    "TOTAL_TRACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4710f67-de96-401b-8a0c-abb05dd62c40",
   "metadata": {},
   "source": [
    "### Set the tf.io pipelines function from bigquery\n",
    "\n",
    "[Great blog post here on it](https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db86c9f-5454-4629-80ba-c0273fca117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import datetime\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.train import BytesList, Feature, FeatureList, Int64List\n",
    "from tensorflow.train import SequenceExample, FeatureLists\n",
    "\n",
    "\n",
    "\n",
    "def bq_to_tfdata(client, row_restriction, table_id, col_names, col_types, dataset, batch_size=BATCH_SIZE):\n",
    "    TABLE_ID = table_id\n",
    "    COL_NAMES = col_names\n",
    "    COL_TYPES = col_types\n",
    "    DATASET = dataset\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, TABLE_ID, DATASET,\n",
    "        COL_NAMES, COL_TYPES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45e8d-3113-4528-9d71-8afdfd922d4f",
   "metadata": {},
   "source": [
    "## Get the song metadata\n",
    "\n",
    "To get a pipeline working we need the metadata for the table along with the table information. The following functions are helpers that give us the metadata into the proper types for `tf`\n",
    "\n",
    "\n",
    "For each table id, programatically get\n",
    "* Column names\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcf9098-fd4c-4d00-9e84-8658a620b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 833.36query/s]                          \n",
      "Downloading: 100%|██████████| 2/2 [00:00<00:00,  3.34rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery schema\n",
    "SELECT * FROM jtotten-project.spotify_mpd.INFORMATION_SCHEMA.TABLES\n",
    "where table_name in ('track_audio', 'playlists_track_string');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402d9cd0-a837-418a-aa7d-8ba8350c6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>base_table_catalog</th>\n",
       "      <th>base_table_schema</th>\n",
       "      <th>base_table_name</th>\n",
       "      <th>snapshot_time_ms</th>\n",
       "      <th>ddl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>track_audio</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-06 17:46:25.801000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>playlists_track_string</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-22 22:50:46.601000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.play...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     table_catalog table_schema              table_name  table_type  \\\n",
       "0  jtotten-project  spotify_mpd             track_audio  BASE TABLE   \n",
       "1  jtotten-project  spotify_mpd  playlists_track_string  BASE TABLE   \n",
       "\n",
       "  is_insertable_into is_typed                    creation_time  \\\n",
       "0                YES       NO 2022-04-06 17:46:25.801000+00:00   \n",
       "1                YES       NO 2022-04-22 22:50:46.601000+00:00   \n",
       "\n",
       "  base_table_catalog base_table_schema base_table_name snapshot_time_ms  \\\n",
       "0               None              None            None              NaT   \n",
       "1               None              None            None              NaT   \n",
       "\n",
       "                                                 ddl  \n",
       "0  CREATE TABLE `jtotten-project.spotify_mpd.trac...  \n",
       "1  CREATE TABLE `jtotten-project.spotify_mpd.play...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema # we will get the fields out of the ddl field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e820-d1d7-48f9-902d-ad63be9b74fb",
   "metadata": {},
   "source": [
    "## Helper functions to pull metadata from ddl statements\n",
    "\n",
    "From the DDL we are going to get the types for use in a  to create a `BigQueryReadSession` from `tensorflow_io.bigquery` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e90599-b0e7-41e6-a6e7-99d6668ead55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string type representation to tf data types\n",
    "\n",
    "def conv_dtype_to_tf(dtype_str):\n",
    "    if dtype_str == 'FLOAT64':\n",
    "        return dtypes.float64\n",
    "    elif dtype_str == 'INT64':\n",
    "        return dtypes.int64\n",
    "    else: \n",
    "        return dtypes.string\n",
    "        \n",
    "def get_metadata_from_ddl(ddl, drop_field=None):\n",
    "    fields = []\n",
    "    types = []\n",
    "    ddl = ddl.values[0]\n",
    "    for line in ddl.splitlines():\n",
    "        if line[:1] == ' ': #only pull indented lines for the fields\n",
    "            # drop the comma\n",
    "            line = line.replace(',','')\n",
    "            space_delim = line.split(' ')\n",
    "            if space_delim[2] in drop_field:\n",
    "                pass\n",
    "            else:\n",
    "                fields.append(space_delim[2])\n",
    "                types.append(conv_dtype_to_tf(space_delim[3]))\n",
    "    return fields, types\n",
    "\n",
    "\n",
    "track_audio_fields, track_audio_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'track_audio'], DROP_FIELDS)\n",
    "playlist_fields, playlist_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'playlists_track_string'], DROP_FIELDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd06cfb-66c6-4a18-9e5d-22352317da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : <dtype: 'string'>\n",
      "collaborative : <dtype: 'string'>\n",
      "modified_at : <dtype: 'int64'>\n",
      "num_tracks : <dtype: 'int64'>\n",
      "num_albums : <dtype: 'int64'>\n",
      "num_followers : <dtype: 'int64'>\n",
      "tracks : <dtype: 'string'>\n",
      "num_edits : <dtype: 'int64'>\n",
      "duration_ms : <dtype: 'int64'>\n",
      "num_artists : <dtype: 'int64'>\n",
      "description : <dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(playlist_fields, playlist_types):\n",
    "    print(a +\" : \" + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4667a86-574c-4484-a331-8c9c7ae6fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_name : <dtype: 'string'>\n",
      "track_name : <dtype: 'string'>\n",
      "album_name : <dtype: 'string'>\n",
      "name : <dtype: 'string'>\n",
      "danceability : <dtype: 'float64'>\n",
      "energy : <dtype: 'float64'>\n",
      "key : <dtype: 'float64'>\n",
      "loudness : <dtype: 'float64'>\n",
      "mode : <dtype: 'float64'>\n",
      "speechiness : <dtype: 'float64'>\n",
      "acousticness : <dtype: 'float64'>\n",
      "instrumentalness : <dtype: 'float64'>\n",
      "liveness : <dtype: 'float64'>\n",
      "valence : <dtype: 'float64'>\n",
      "tempo : <dtype: 'float64'>\n",
      "type : <dtype: 'string'>\n",
      "id : <dtype: 'string'>\n",
      "uri : <dtype: 'string'>\n",
      "track_href : <dtype: 'string'>\n",
      "analysis_url : <dtype: 'string'>\n",
      "time_signature : <dtype: 'float64'>\n",
      "artist_pop : <dtype: 'int64'>\n",
      "track_pop : <dtype: 'string'>\n",
      "genres : <dtype: 'string'>\n",
      "duration_ms : <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(track_audio_fields, track_audio_types):\n",
    "    print(a +\" : \" + str(b))\n",
    "    \n",
    "DROP_TRACK_AUDIO_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94ebf1-0080-4cd5-be46-c72af9d3a0e5",
   "metadata": {},
   "source": [
    "### Now the helper functions are set. Below tf.data pipelines are created from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "311dd38e-94c3-4bef-b4b0-e051ba529530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:16:52.308487: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-04-24 22:16:52.308832: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-04-24 22:16:53.697631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.698602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.709765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.710734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.711519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.712275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.714234: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 22:16:53.897901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.898799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.899545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.900225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.900851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.901569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.837329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.838199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.838926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.839652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.840334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.841011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13793 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-24 22:16:54.841640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.842416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13793 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "track_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'track_audio'\n",
    "                                    , col_names=track_audio_fields, col_types=track_audio_types, dataset='spotify_mpd', batch_size=1) #we will change to BATCH_SIZE after we test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49e5cd5-7f73-419d-9c09-8495e09decab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:16:55.470721: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:55.470773: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:55.471304: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:55.471344: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('acousticness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.827])>), ('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Promesa De Vida'], dtype=object)>), ('analysis_url', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'https://api.spotify.com/v1/audio-analysis/0yqtUGhNzOUnp79yai2Nbw'],\n",
      "      dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'X-JIREH'], dtype=object)>), ('artist_pop', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([-1])>), ('danceability', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.523])>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([328202])>), ('energy', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.2])>), ('genres', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'unknown'], dtype=object)>), ('id', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0yqtUGhNzOUnp79yai2Nbw'], dtype=object)>), ('instrumentalness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('key', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('liveness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.133])>), ('loudness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([-10.837])>), ('mode', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'CHRISTIAN'], dtype=object)>), ('speechiness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.0305])>), ('tempo', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([124.006])>), ('time_signature', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([4.])>), ('track_href', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'https://api.spotify.com/v1/tracks/0yqtUGhNzOUnp79yai2Nbw'],\n",
      "      dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Jes\\xc3\\xbas Un Milagro Har\\xc3\\xa1 En Ti'], dtype=object)>), ('track_pop', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>), ('type', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'audio_features'], dtype=object)>), ('uri', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:0yqtUGhNzOUnp79yai2Nbw'], dtype=object)>), ('valence', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.192])>)])\n"
     ]
    }
   ],
   "source": [
    "### Validate we are getting records\n",
    "\n",
    "for line in track_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc539f35-02a5-4010-b07d-02a77f66f4ce",
   "metadata": {},
   "source": [
    "### For the song audio data, we are set and will use this pipeline in training - there's no need to pre-process as there are no nested elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3c14a9-a269-4bc5-a198-5270ac0faa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_types[-1] = dtypes.string #try manually setting the dtype for the tracks nested column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb806df-3f54-4785-a063-9a416e487ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:16:56.025225: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:56.025272: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:56.025791: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:56.025832: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([5461333])>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1508976000])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'disney favs'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([14])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([24])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([12])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([28])>), ('tracks', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'[{\\'pos\\': 0, \\'artist_name\\': \\'Peggy Lee (performer), Oliver Wallace (comductor), Walt Disney Studio Orchestra\\', \\'track_uri\\': \\'spotify:track:7gszEHRkBhgWxz4ehSe0lr\\', \\'artist_uri\\': \\'spotify:artist:3MHlIt9IAlysdZJz2xvkj6\\', \\'track_name\\': \"The Siamese Cat Song / What\\'s Going On Down There\", \\'album_uri\\': \\'spotify:album:2bDCjSVK1wjEaPT5YpgtyR\\', \\'duration_ms\\': 157126, \\'album_name\\': \\'Lady and the Tramp (1955 Film Score)\\'}, {\\'pos\\': 1, \\'artist_name\\': \\'Peggy Lee (performer), Oliver Wallace (comductor), Walt Disney Studio Orchestra\\', \\'track_uri\\': \\'spotify:track:1LBcs9JY4DedNGwQ61Jztv\\', \\'artist_uri\\': \\'spotify:artist:3MHlIt9IAlysdZJz2xvkj6\\', \\'track_name\\': \"What A Dog / He\\'s A Tramp\", \\'album_uri\\': \\'spotify:album:2bDCjSVK1wjEaPT5YpgtyR\\', \\'duration_ms\\': 145684, \\'album_name\\': \\'Lady and the Tramp (1955 Film Score)\\'}, {\\'pos\\': 2, \\'artist_name\\': \\'Angela Lansbury\\', \\'track_uri\\': \\'spotify:track:6btdYzQ8eZFBrOlUKVHuz0\\', \\'artist_uri\\': \\'spotify:artist:0LtVJXnPR8msCJiE2DjHxy\\', \\'track_name\\': \\'Be Our Guest - From \"Beauty and the Beast\"/Soundtrack\\', \\'album_uri\\': \\'spotify:album:3O5p9VNddbwvqWTdYKEqV5\\', \\'duration_ms\\': 224733, \\'album_name\\': \\'Beauty and the Beast\\'}, {\\'pos\\': 3, \\'artist_name\\': \\'Lea Salonga\\', \\'track_uri\\': \\'spotify:track:5VIfacsWytkcgr7aTt8Tql\\', \\'artist_uri\\': \\'spotify:artist:1GlMjIezcLwV3OFlX0uXOv\\', \\'track_name\\': \\'A Whole New World\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 160800, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 4, \\'artist_name\\': \\'Lillias White\\', \\'track_uri\\': \\'spotify:track:1HSJMLtNeDryJN76Tu5Ahf\\', \\'artist_uri\\': \\'spotify:artist:5TKKPpY9zr2qrz3JM3Vawq\\', \\'track_name\\': \"I Won\\'t Say (I\\'m in Love)\", \\'album_uri\\': \\'spotify:album:79xGkf1594kBEtCIaL6yKj\\', \\'duration_ms\\': 140333, \\'album_name\\': \\'Hercules Original Soundtrack\\'}, {\\'pos\\': 5, \\'artist_name\\': \\'Donny Osmond\\', \\'track_uri\\': \\'spotify:track:28UMEtwyUUy5u0UWOVHwiI\\', \\'artist_uri\\': \\'spotify:artist:5ZEAzHE2TzAwUcOj6jMIgf\\', \\'track_name\\': \\'I\\\\\\'ll Make a Man Out of You - From \"Mulan\"/Soundtrack\\', \\'album_uri\\': \\'spotify:album:3Ohs7Jo6GM6mydUOL0m5aC\\', \\'duration_ms\\': 201680, \\'album_name\\': \\'Mulan\\'}, {\\'pos\\': 6, \\'artist_name\\': \\'Samuel E. Wright\\', \\'track_uri\\': \\'spotify:track:4HGIPyqDxSf863tPOwXiLJ\\', \\'artist_uri\\': \\'spotify:artist:6Id8rcDNyBXPcgKQVfQ8rX\\', \\'track_name\\': \\'Kiss the Girl - From \"The Little Mermaid\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:4aAwvCRNJIqiUGVEjieWv6\\', \\'duration_ms\\': 163400, \\'album_name\\': \\'Little Mermaid\\'}, {\\'pos\\': 7, \\'artist_name\\': \\'Nathan Lane\\', \\'track_uri\\': \\'spotify:track:5k3U0OGYBccHdKJJu3HrUN\\', \\'artist_uri\\': \\'spotify:artist:0P0do9GwiSgweSF6Ui3mrv\\', \\'track_name\\': \\'Hakuna Matata\\', \\'album_uri\\': \\'spotify:album:3YA5DdB3wSz4pdfEXoMyRd\\', \\'duration_ms\\': 213600, \\'album_name\\': \\'The Lion King\\'}, {\\'pos\\': 8, \\'artist_name\\': \\'Bruce Adler\\', \\'track_uri\\': \\'spotify:track:0CKmN3Wwk8W4zjU0pqq2cv\\', \\'artist_uri\\': \\'spotify:artist:66oKiXdIQP7MwN0gPUY0FD\\', \\'track_name\\': \\'Arabian Nights\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 79293, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 9, \\'artist_name\\': \\'Lea Salonga\\', \\'track_uri\\': \\'spotify:track:2AILbz83cBnrAMAG06rZts\\', \\'artist_uri\\': \\'spotify:artist:1GlMjIezcLwV3OFlX0uXOv\\', \\'track_name\\': \\'Reflection - From \"Mulan\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:3Ohs7Jo6GM6mydUOL0m5aC\\', \\'duration_ms\\': 146760, \\'album_name\\': \\'Mulan\\'}, {\\'pos\\': 10, \\'artist_name\\': \\'Brad Kane\\', \\'track_uri\\': \\'spotify:track:4wN8Ov3kPZdkJ8XcYxYUGz\\', \\'artist_uri\\': \\'spotify:artist:3dAzSJ9lQnJSq5Z0OgDBep\\', \\'track_name\\': \\'One Jump Ahead\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 142440, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 11, \\'artist_name\\': \\'Jonathan Freeman\\', \\'track_uri\\': \\'spotify:track:5BEItY9of9nR4zj51JO0jU\\', \\'artist_uri\\': \\'spotify:artist:2970T0VJFpIWMA2aZi6Lpi\\', \\'track_name\\': \\'Prince Ali (Reprise)\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 67653, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 12, \\'artist_name\\': \\'Alan Menken\\', \\'track_uri\\': \\'spotify:track:30J2aUXkTp9vsGWH3tegca\\', \\'artist_uri\\': \\'spotify:artist:5sy77gt4bfsLcSQ8GIe4ZZ\\', \\'track_name\\': \\'To Be Free\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 99253, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 13, \\'artist_name\\': \\'Anika Noni Rose\\', \\'track_uri\\': \\'spotify:track:2dlxN435ZY9ruxGYND2Hq0\\', \\'artist_uri\\': \\'spotify:artist:4fqk0Vw0VrIY8O2eWtmQO2\\', \\'track_name\\': \\'Almost There\\', \\'album_uri\\': \\'spotify:album:6zgvBxOmfWxrQi4Jxxki0P\\', \\'duration_ms\\': 144426, \\'album_name\\': \\'The Princess and the Frog\\'}, {\\'pos\\': 14, \\'artist_name\\': \\'Riverfront Studio Singers\\', \\'track_uri\\': \\'spotify:track:59oPOJ9bYDhWAKNW3gaSPS\\', \\'artist_uri\\': \\'spotify:artist:1NvMcK0prF4jGBppmI3m0c\\', \\'track_name\\': \\'Prince Ali (From \"Aladdin\")\\', \\'album_uri\\': \\'spotify:album:4jbNxHbNTSlgnPj9rpwKt2\\', \\'duration_ms\\': 170024, \\'album_name\\': \\'Kids Movie Songs Vol.3\\'}, {\\'pos\\': 15, \\'artist_name\\': \\'Mandy Moore\\', \\'track_uri\\': \\'spotify:track:6klpXs2uAjagnZMFkt4qkl\\', \\'artist_uri\\': \\'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu\\', \\'track_name\\': \\'I See the Light - From \"Tangled\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:1l0aFrH24oPrQSqGtfeFyE\\', \\'duration_ms\\': 224240, \\'album_name\\': \\'Tangled\\'}, {\\'pos\\': 16, \\'artist_name\\': \\'Mandy Moore\\', \\'track_uri\\': \\'spotify:track:0TCt7OFRdD8PQ6vTRQxNgQ\\', \\'artist_uri\\': \\'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu\\', \\'track_name\\': \\'I\\\\\\'ve Got a Dream - From \"Tangled\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:1l0aFrH24oPrQSqGtfeFyE\\', \\'duration_ms\\': 191413, \\'album_name\\': \\'Tangled\\'}, {\\'pos\\': 17, \\'artist_name\\': \\'Cheryl Freeman\\', \\'track_uri\\': \\'spotify:track:0I8mZRtlFGOqZayJbEAdxL\\', \\'artist_uri\\': \\'spotify:artist:3E0MPcbZSjfJ1HsnJKXkqd\\', \\'track_name\\': \\'The Gospel Truth I / Main Titles - Hercules\\', \\'album_uri\\': \\'spotify:album:7z46fPkl9344yv05HT1Uoq\\', \\'duration_ms\\': 145639, \\'album_name\\': \\'Hercules\\'}, {\\'pos\\': 18, \\'artist_name\\': \\'Dick Van Dyke\\', \\'track_uri\\': \\'spotify:track:2hKYhft1VITPST4iiAHLGC\\', \\'artist_uri\\': \\'spotify:artist:6XIT5sGHOtxVgqtSnMCYZ6\\', \\'track_name\\': \\'Chim Chim Cher-ee\\', \\'album_uri\\': \\'spotify:album:3PlbEOxE8rE8xf7mDWdpgb\\', \\'duration_ms\\': 166080, \\'album_name\\': \\'The Sherman Brothers Songbook\\'}, {\\'pos\\': 19, \\'artist_name\\': \\'Ilene Woods\\', \\'track_uri\\': \\'spotify:track:3uVkugZz6yCTw5Z8sDI19F\\', \\'artist_uri\\': \\'spotify:artist:4DovRSplr3yJIeE3r0RtHj\\', \\'track_name\\': \\'A Dream Is A Wish Your Heart Makes - Soundtrack\\', \\'album_uri\\': \\'spotify:album:6KSC0FkAhdErc0azFDze0i\\', \\'duration_ms\\': 276306, \\'album_name\\': \"Disney\\'s Greatest Volume 2\"}, {\\'pos\\': 20, \\'artist_name\\': \\'Verna Felton\\', \\'track_uri\\': \\'spotify:track:0rzqBHKWkrZZ7R0e2y3abc\\', \\'artist_uri\\': \\'spotify:artist:7aU90hxXexP47nEeMee6xM\\', \\'track_name\\': \\'Where Did I Put That Thing / Bibbidi-Bobbidi-Boo (The Magic Song)\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 287933, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 21, \\'artist_name\\': \\'Mack David\\', \\'track_uri\\': \\'spotify:track:3uOsIy3rfPEIRawz1xPO5H\\', \\'artist_uri\\': \\'spotify:artist:4tMrFa88Ah85DwbtjQjohF\\', \\'track_name\\': \\'A Visitor / Caught In A Trap / Lucifer Medley\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 130866, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 22, \\'artist_name\\': \\'Paul J. Smith\\', \\'track_uri\\': \\'spotify:track:195dIFnht6bpaGslMHxxx7\\', \\'artist_uri\\': \\'spotify:artist:3g6RWqrG0tt6oXPMLP2WE5\\', \\'track_name\\': \"Locked in the Tower / Gus and Jaq to the Rescue / Slipper Fittings / Cinderella\\'s Slipper / Finale\", \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 461586, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 23, \\'artist_name\\': \\'Rhoda Williams\\', \\'track_uri\\': \\'spotify:track:04fAHzTVDZp4Vkb7o54tkt\\', \\'artist_uri\\': \\'spotify:artist:7C3YSHR8TLh6b73PbQojuk\\', \\'track_name\\': \\'The Music Lesson / Oh, Sing Sweet Nightingale / Bad Boy Lucifer / A Message From His Majesty\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 126733, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 24, \\'artist_name\\': \\'Mice Chorus\\', \\'track_uri\\': \\'spotify:track:7CtiVQKP9pkr9i7p6wk4gl\\', \\'artist_uri\\': \\'spotify:artist:3gcnVAcMBdtYbril7EqBz6\\', \\'track_name\\': \\'Little Dressmaker / The Work Song / Scavenger Hunt / A Dream Is a Wish Your Heart Makes / The Dress / My Beads / Escape to the Garden\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 564400, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 25, \\'artist_name\\': \\'Samuel E. Wright\\', \\'track_uri\\': \\'spotify:track:6oYkwjI1TKP9D0Y9II1GT7\\', \\'artist_uri\\': \\'spotify:artist:6Id8rcDNyBXPcgKQVfQ8rX\\', \\'track_name\\': \\'Under the Sea - From \"The Little Mermaid\"/ Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:4aAwvCRNJIqiUGVEjieWv6\\', \\'duration_ms\\': 195146, \\'album_name\\': \\'Little Mermaid\\'}, {\\'pos\\': 26, \\'artist_name\\': \\'Leon-Wooley\\', \\'track_uri\\': \\'spotify:track:0II9l1sI3Mo9XKaszKfizl\\', \\'artist_uri\\': \\'spotify:artist:6KwUkoMqmP6cPhsnkKruLr\\', \\'track_name\\': \"When We\\'re Human (feat. Terence Blanchard)\", \\'album_uri\\': \\'spotify:album:6zgvBxOmfWxrQi4Jxxki0P\\', \\'duration_ms\\': 142093, \\'album_name\\': \\'The Princess and the Frog\\'}, {\\'pos\\': 27, \\'artist_name\\': \\'Pat Carroll\\', \\'track_uri\\': \\'spotify:track:7zsw78LtXUD7JfEwH64HK2\\', \\'artist_uri\\': \\'spotify:artist:0Yy9u86cq66Se2pB9fYaiW\\', \\'track_name\\': \\'Poor Unfortunate Souls - From \"The Little Mermaid\" / Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:4aAwvCRNJIqiUGVEjieWv6\\', \\'duration_ms\\': 291693, \\'album_name\\': \\'Little Mermaid\\'}]'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "## Validate playlist data\n",
    "playlist_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'playlists_track_string'\n",
    "                                    , col_names=playlist_fields\n",
    "                                       , col_types=playlist_types\n",
    "                                       , dataset='spotify_mpd', batch_size=1)\n",
    "for line in playlist_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b3a5-a553-405d-b2f5-d37af35fdc8a",
   "metadata": {},
   "source": [
    "## In pulling one record it looks like it's properly parsing a tf record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae928c-beeb-4704-8b18-cd31bcb16d24",
   "metadata": {},
   "source": [
    "# do some data wranglging on the text data\n",
    "# tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "for _ in playlist_train_pipeline.map(lambda x: tf.io.parse_sequence_example(tf.io.serialize_tensor(x['tracks'][0]), sequence_features=feature_description, context_features=context_features, name='tracks')).take(1):\n",
    "    tensor = _\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132c7a5-5f76-429b-a1aa-47663f20080b",
   "metadata": {},
   "source": [
    "Since the data is stored in a text dictionary we will eagerly execute, grab the values and do a string `eval`\n",
    "`eval(\"{'pos': 0, 'artist_name': 'King Crimson', 'track_uri': 'spotify:track:173gp7NIXqk0MEo8K7Av4a', 'artist_uri': 'spotify:artist:7M1FPw29m5FbicYzS2xdpi', 'track_name': '21st Century Schizoid Man', 'album_uri': 'spotify:album:0ga8Q4tTXaFf9q3LvT8hrC', 'duration_ms': 657517, 'album_name': 'Radical Action To Unseat the Hold of Monkey Mind (Live)'}\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4abb83-f280-4108-998a-e19689841f8f",
   "metadata": {},
   "source": [
    "## This funcion parses the playlist data and breaks down the nested fields to be conformant with `SequenceExample`\n",
    "The 'flat' features come along as `context_features` in `SequenceExample`\n",
    "There is one more helper function to parse the example and write it to the destination `gs://` path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82765dec-1d18-49b5-9a9f-81cbfff56a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_tensor_from_tracks(tensor):\n",
    "    key_list = ['pos', 'artist_name', 'track_uri', 'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name']\n",
    "    y = {}\n",
    "    \n",
    "    \n",
    "    tracks = tensor[\"tracks\"][0]\n",
    "    tracks = tracks.numpy()\n",
    "\n",
    "    tracks = eval(tracks)\n",
    "\n",
    "    for _ in key_list:\n",
    "        y[_] = []\n",
    "\n",
    "    for track in tracks:\n",
    "        y['pos'].append(track['pos'])\n",
    "        y['artist_name'].append(track['artist_name'].encode('utf8'))\n",
    "        y['artist_uri'].append(track['artist_uri'].encode('utf8'))\n",
    "        y['track_name'].append(track['track_name'].encode('utf8'))\n",
    "        y['album_uri'].append(track['album_uri'].encode('utf8'))\n",
    "        y['duration_ms'].append(track['duration_ms'])\n",
    "        y['album_name'].append(track['album_name'].encode('utf8'))\n",
    "        y['track_uri'].append(track['track_uri'].encode('utf8'))\n",
    "        \n",
    "\n",
    "\n",
    "    # set list types\n",
    "    pos = Int64List(value=y['pos'])\n",
    "    artist_name = BytesList(value=y['artist_name'])\n",
    "    artist_uri = BytesList(value=y['artist_uri'])\n",
    "    track_name = BytesList(value=y['track_name'])\n",
    "    album_uri = BytesList(value=y['album_uri'])\n",
    "    duration_ms = Int64List(value=y['duration_ms'])\n",
    "    album_name = BytesList(value=y['album_name'])\n",
    "    track_uri = BytesList(value=y['track_uri'])\n",
    "\n",
    "    \n",
    "    sample_dict = {\n",
    "    \"name\" : Feature(bytes_list=BytesList(value=tensor['name'].numpy())),\n",
    "    \"collaborative\" : Feature(bytes_list=BytesList(value=tensor['collaborative'].numpy())),\n",
    "    \"modified_at\" : Feature(int64_list=Int64List(value=tensor['modified_at'].numpy())),\n",
    "    \"num_tracks\" : Feature(int64_list=Int64List(value=tensor['num_tracks'].numpy())),\n",
    "    \"num_albums\" : Feature(int64_list=Int64List(value=tensor['num_albums'].numpy())),\n",
    "    \"num_followers\" : Feature(int64_list=Int64List(value=tensor['num_followers'].numpy())),\n",
    "    \"num_edits\" : Feature(int64_list=Int64List(value=tensor['num_edits'].numpy())),\n",
    "    \"duration_ms\" : Feature(int64_list=Int64List(value=tensor['duration_ms'].numpy())),\n",
    "    \"num_artists\" : Feature(int64_list=Int64List(value=tensor['num_artists'].numpy())),\n",
    "    \"description\" : Feature(bytes_list=BytesList(value=tensor['description'].numpy()))\n",
    "    }\n",
    "\n",
    "    # combine feature list\n",
    "\n",
    "    pos = FeatureList(feature=[Feature(int64_list=pos)]) \n",
    "    artist_name = FeatureList(feature=[Feature(bytes_list=artist_name)])\n",
    "    artist_uri = FeatureList(feature=[Feature(bytes_list=artist_uri)])\n",
    "    track_name = FeatureList(feature=[Feature(bytes_list=track_name)])\n",
    "    album_uri = FeatureList(feature=[Feature(bytes_list=album_uri)])\n",
    "    duration_ms = FeatureList(feature=[Feature(int64_list=duration_ms)])\n",
    "    album_name = FeatureList(feature=[Feature(bytes_list=album_name)])\n",
    "    track_uri = FeatureList(feature=[Feature(bytes_list=track_uri)])\n",
    "            \n",
    "\n",
    "    #create the sequence\n",
    "    seq = SequenceExample(context=tf.train.Features(feature=sample_dict),\n",
    "                          feature_lists=FeatureLists(feature_list={\n",
    "                               \"pos\": pos,\n",
    "                               \"artist_name\": artist_name,\n",
    "                               \"track_name\": track_name,\n",
    "                               \"album_uri\": album_uri,\n",
    "                               \"duration_ms\": duration_ms,\n",
    "                               \"album_name\": album_name,\n",
    "                               \"track_uri\": track_uri,\n",
    "                              \"artist_uri\": artist_uri\n",
    "    }))\n",
    "    \n",
    "    return seq\n",
    "\n",
    "\n",
    "def write_a_tfrec(lns, n_records_per_file, file_counter, subfolder):\n",
    "    #next write to a tfrecord\n",
    "    with tf.io.TFRecordWriter(\n",
    "        TF_RECORDS_DIR + \"/\" + subfolder +\"/file_%.2i-%i.tfrec\" % (n_records_per_file, file_counter)\n",
    "    ) as writer:\n",
    "        for example in lns:\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2eb503-d2b4-424b-8f48-7b3187b5fc4a",
   "metadata": {},
   "source": [
    "## Now iterate over the pipeline\n",
    "Creating files with batches of `N_RECORDS_PER_TFRECORD_FILE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e2a4fc6-cdb7-4e81-abe0-d4df4d890b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for folder expected: 2022-04-25:00:24:17.700008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1032000 [00:00<?, ?it/s]2022-04-25 00:24:17.716901: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-25 00:24:17.716946: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-25 00:24:17.717319: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-25 00:24:17.717364: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "  4%|▎         | 37894/1032000 [01:47<47:07, 351.59it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23333/291852945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_train_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOTAL_PLAYLISTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msequence_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tensor_from_tracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#should come out based on batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mN_RECORDS_PER_TFRECORD_FILE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTOTAL_PLAYLISTS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#write-a-file and reset the batch (+1 to avoid modulus reset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_functions_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[0;31m# Only count the statistics the first time, before initialization took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23333/782605567.py\u001b[0m in \u001b[0;36mget_tensor_from_tracks\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tracks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miterable_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_iterable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "from tqdm import tqdm\n",
    "# using datetime module\n",
    "\n",
    "# ct stores current time\n",
    "ct = str(datetime.datetime.now()).replace(\" \",\":\")\n",
    "print(f\"Timestamp for folder expected: {ct}\")\n",
    "records = []\n",
    "file_count = 0\n",
    "\n",
    "for i, line in enumerate(tqdm(playlist_train_pipeline, total=TOTAL_PLAYLISTS)):\n",
    "    sequence_example = get_tensor_from_tracks(line) #should come out based on batch size\n",
    "    if (i % N_RECORDS_PER_TFRECORD_FILE == 0 or i == TOTAL_PLAYLISTS-1) and i is not 0: #write-a-file and reset the batch (+1 to avoid modulus reset)\n",
    "        records.append(sequence_example)\n",
    "        write_a_tfrec(records, n_records_per_file=N_RECORDS_PER_TFRECORD_FILE, subfolder=ct, file_counter = file_count)\n",
    "        file_count+=1\n",
    "        records = []\n",
    "    else:\n",
    "        records.append(sequence_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45888388-76c6-49f4-b9d6-47383a6b0614",
   "metadata": {},
   "source": [
    "### Parse records ensure this worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0f562-3ab4-415b-acf0-50a823f3625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move the files around\n",
    "\n",
    "!gsutil cp gs://spotify-tfrecords/$ct/* gs://spotify-tfrecords\n",
    "!gsutil rm gs://spotify-tfrecords/$ct/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4324549-7f6b-4627-a9d1-952894a9318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sequence_features = {'pos': tf.io.RaggedFeature(tf.int64), \n",
    "                     'artist_name':  tf.io.RaggedFeature(tf.string), \n",
    "                     'track_uri':  tf.io.RaggedFeature(tf.string), \n",
    "                     'artist_uri': tf.io.RaggedFeature(tf.string), \n",
    "                     'track_name': tf.io.RaggedFeature(tf.string), \n",
    "                     'album_uri': tf.io.RaggedFeature(tf.string),\n",
    "                     'duration_ms': tf.io.RaggedFeature(tf.int64), \n",
    "                     'album_name': tf.io.RaggedFeature(tf.string)\n",
    "                    }\n",
    "context_features = {\"name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"collaborative\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"modified_at\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_tracks\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_albums\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_followers\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_edits\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"duration_ms\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_artists\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"description\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1))\n",
    "                   }\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_sequence_example(example, sequence_features=sequence_features, context_features=context_features)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe5f20-b928-4649-b2f3-3baf47f90732",
   "metadata": {},
   "source": [
    "### parse tfrecord dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4b80ea9-0186-4ddb-add7-c144c89366bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "files = []\n",
    "for blob in client.list_blobs('spotify-tfrecords'):\n",
    "    files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4d24c61-c98a-4b6a-ae6d-16c8e2a8c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'collaborative': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'description': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>, 'duration_ms': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([3597747])>, 'modified_at': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1413244800])>, 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'music'], dtype=object)>, 'num_albums': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([13])>, 'num_artists': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>, 'num_edits': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([12])>, 'num_followers': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, 'num_tracks': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([16])>}, {'album_name': <tf.RaggedTensor [[b'Always Never The Same', b'Fuse', b'BRINGING BACK THE SUNSHINE', b\"Where It's At\", b'Dustin Lynch', b\"Here's To The Good Times\", b'Sadnecessary', b'BRINGING BACK THE SUNSHINE', b'BRINGING BACK THE SUNSHINE', b\"I Don't Dance\", b'Sundown Heaven Town', b'A.M.', b'Neon', b'Old Boots, New Dirt', b'Anything Goes', b'Anything Goes']]>, 'album_uri': <tf.RaggedTensor [[b'spotify:album:2Kudx2lMsMx3svYdb2xe2F', b'spotify:album:5rESCws46ubPJlqOeb30Rv', b'spotify:album:0daIqjuhsQqXoeII3pBSeT', b'spotify:album:4ZSQEnZOGWEW3XQOAzt477', b'spotify:album:3lmCslpaoa1acoJ4koOnCY', b'spotify:album:5MH765pytbQasmDxXArTah', b'spotify:album:5D20ZzsNB377xbshIFP9Nb', b'spotify:album:0daIqjuhsQqXoeII3pBSeT', b'spotify:album:0daIqjuhsQqXoeII3pBSeT', b'spotify:album:1Ug5qpIXouUHY5hpFj6575', b'spotify:album:39ZUc3Efz2TH8RbPeDTMOB', b'spotify:album:3cyLH6iUGPjEsZIUFnJfd3', b'spotify:album:4yYep1aU3lXRaONTWu2X23', b'spotify:album:2RIu1R2av2tWEu2MloUE6u', b'spotify:album:5NG7WZaCZZ12M5LJm0JcVc', b'spotify:album:5NG7WZaCZZ12M5LJm0JcVc']]>, 'artist_name': <tf.RaggedTensor [[b'George Strait', b'Keith Urban', b'Blake Shelton', b'Dustin Lynch', b'Dustin Lynch', b'Florida Georgia Line', b'Milky Chance', b'Blake Shelton', b'Blake Shelton', b'Lee Brice', b'Tim McGraw', b'Chris Young', b'Chris Young', b'Jason Aldean', b'Florida Georgia Line', b'Florida Georgia Line']]>, 'artist_uri': <tf.RaggedTensor [[b'spotify:artist:5vngPClqofybhPERIqQMYd', b'spotify:artist:0u2FHSq3ln94y5Q57xazwf', b'spotify:artist:1UTPBmNbXNTittyMJrNkvw', b'spotify:artist:1dID9zgn0OV0Y8ud7Mh2tS', b'spotify:artist:1dID9zgn0OV0Y8ud7Mh2tS', b'spotify:artist:3b8QkneNDz4JHKKKlLgYZg', b'spotify:artist:1hzfo8twXdOegF3xireCYs', b'spotify:artist:1UTPBmNbXNTittyMJrNkvw', b'spotify:artist:1UTPBmNbXNTittyMJrNkvw', b'spotify:artist:5Zq7R5qmi58ByYyBQTlNuk', b'spotify:artist:6roFdX1y5BYSbp60OTJWMd', b'spotify:artist:4BYxqVkZyFjtik7crYLg5Q', b'spotify:artist:4BYxqVkZyFjtik7crYLg5Q', b'spotify:artist:3FfvYsEGaIb52QPXhg4DcH', b'spotify:artist:3b8QkneNDz4JHKKKlLgYZg', b'spotify:artist:3b8QkneNDz4JHKKKlLgYZg']]>, 'duration_ms': <tf.RaggedTensor [[219600, 236906, 221401, 204186, 218933, 226160, 313684, 225640, 207880, 207346, 235386, 217413, 220173, 203093, 218866, 221080]]>, 'pos': <tf.RaggedTensor [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]>, 'track_name': <tf.RaggedTensor [[b'Write This Down', b'Somewhere In My Car', b'Neon Light', b\"Where It's At\", b'Waiting', b'Tell Me How You Like It', b'Stolen Dance', b\"Buzzin' (feat. RaeLynn)\", b\"Just Gettin' Started\", b'Drinking class', b'Shotgun Rider', b'Lonely Eyes', b'Tomorrow', b\"Sweet Little Somethin'\", b'Anything Goes', b\"Bumpin' The Night\"]]>, 'track_uri': <tf.RaggedTensor [[b'spotify:track:1TanmIWbaUj5NVwJ3k4XPd', b'spotify:track:50nzorQ9gi2md8UpFi8aJT', b'spotify:track:289hx4t6fH2BBe8p6cnXo1', b'spotify:track:4whYDpJ5XVQpmvecbEHP5Q', b'spotify:track:2I0Tnc5117Vkdk78M7vrrf', b'spotify:track:37z5awcsf6MNdobyY2GiLt', b'spotify:track:6vECYJHxYmm3Ydt3fF01pE', b'spotify:track:1j9JbLULlyeUltlcowiEhI', b'spotify:track:5Sxfm0RR2y5QHHSk23TORA', b'spotify:track:5Kb5utdaR6qXYZ9WpgoKWm', b'spotify:track:3LbvNFkqDTrE1liGMmZBDL', b'spotify:track:2j79NtwxoWDmkiH4MGwdLq', b'spotify:track:1qjl8UJtWTHrk4SFpwftSN', b'spotify:track:5Q93FHMA17gHIZeeQAvgaJ', b'spotify:track:46ZfPS5VpSQVU5gb82hg3K', b'spotify:track:5ygp81TQpolYKghQjdYZpD']]>})\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset('gs://spotify-tfrecords/2022-04-25:00:24:17.700008/file_15000-0.tfrec')\n",
    "\n",
    "tf_record_pipeline = raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "for _ in tf_record_pipeline.take(1):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0b41d-9959-4601-9094-57cf01890fbb",
   "metadata": {},
   "source": [
    "# Model Draft Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc57822a-235f-4459-a43c-34762964b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class PlaylistsModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, adapt_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        #start with lookups on low cardnality categorical items\n",
    "        colab_vocab = tf.constant(['true','false'], name='colab_vocab', dtype='string')\n",
    "        \n",
    "        self.colab = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=colab_vocab, mask_token=None, name=\"colab_lookup\", output_mode='count')\n",
    "        ], name=\"colab\")\n",
    "        \n",
    "        #create text vectorizors to be fed to an embedding layer\n",
    "        self.artist_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"artist_tv\", ngrams=2)\n",
    "        \n",
    "        self.album_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.description_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.query_embedding = tf.keras.Sequential([\n",
    "            self.album_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"album_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"album_embedding_model\")\n",
    "        \n",
    "        self.artist_embedding = tf.keras.Sequential([\n",
    "            self.artist_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"artist_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"artist_embedding\")\n",
    "        \n",
    "        ###############\n",
    "        ### adapt stuff\n",
    "        ###############\n",
    "        \n",
    "        self.artist_vectorizor.adapt(adapt_data.map(lambda x: x['artist_name']))\n",
    "        self.album_vectorizor.adapt(adapt_data.map(lambda x: x['album_name'])) \n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"dense_layers_query\")\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\", kernel_initializer=initializer))\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, kernel_initializer=initializer))\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, 1, epsilon=1e-12, name=\"normalize_dense\")))\n",
    "\n",
    "\n",
    "    def call(self, data):    \n",
    "        all_embs = tf.concat(\n",
    "                [\n",
    "                    self.album_embedding(data['album_name']),\n",
    "                    self.artist_embedding(data['artist_name']),\n",
    "                    self.colab(data['collaborative']),\n",
    "                    self.description_embedding(data['description'])\n",
    "                ], axis=1)\n",
    "        return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821506a-054e-4ad2-8530-bde59fb5e5d6",
   "metadata": {},
   "source": [
    "## Use the example output to think of how you process your features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83a334-4008-44a8-84f6-f2ef827200db",
   "metadata": {},
   "source": [
    "```\n",
    "OrderedDict([('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm'], dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Carrot Green'], dtype=object)>), ('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'358500'], dtype=object)>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1505692800])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'FeSTa'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([82])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([66])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([48])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([85])>), ('pos', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'45'], dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm - Carrot Green Remix'], dtype=object)>)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a663c63-58be-43bf-a573-e986cce3e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8b37b159-34ce-4ef0-88ab-e9cc1ae7d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0].keys()#originally got the values from this\n",
    "feature_description = {'pos': tf.io.RaggedFeature(tf.int64), \n",
    "                     'artist_name':  tf.io.RaggedFeature(tf.string), \n",
    "                     'track_uri':  tf.io.RaggedFeature(tf.string), \n",
    "                     'artist_uri': tf.io.RaggedFeature(tf.string), \n",
    "                     'track_name': tf.io.RaggedFeature(tf.string), \n",
    "                     'album_uri': tf.io.RaggedFeature(tf.string),\n",
    "                     'duration_ms': tf.io.RaggedFeature(tf.int64), \n",
    "                     'album_name': tf.io.RaggedFeature(tf.string)\n",
    "                    }\n",
    "context_features = {\"name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"collaborative\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"modified_at\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_tracks\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_albums\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_followers\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_edits\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"duration_ms\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_artists\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"description\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1))\n",
    "                   }"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
