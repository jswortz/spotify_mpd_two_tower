{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5383b2-071e-45b8-af2c-2421eb4f923a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Two - Tower Retreival Model\n",
    "\n",
    "### Key resources:\n",
    "* Many pages [here](https://www.tensorflow.org/recommenders/examples/deep_recommenders) include great techniques to build custom TFRS Models\n",
    "\n",
    "### Goals:\n",
    "* Show how to model off of most data types \n",
    "  * (String, Existing Embeddings (vectors), \n",
    "  * Floats (Normalized), \n",
    "  * Categorical with vocab, \n",
    "  * High Dim Categorical (Embed)\n",
    "* Leverage class templates to create custom 2 Tower Models quick/easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52e5f-a13b-46a7-849a-dc188b455a86",
   "metadata": {},
   "source": [
    "## SPOTIFY Create the tensorflow.io interface for the event and product table in Bigquery\n",
    "Best practices from Google are in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3122eb-564b-46f9-9a50-851d19301521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "DROPOUT = False\n",
    "DROPOUT_RATE = 0.2\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_TOKENS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "ARCH = [128, 64]\n",
    "NUM_EPOCHS = 1\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "DROP_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']\n",
    "N_RECORDS_PER_TFRECORD_FILE = 300 * 50 #100ish mb  \n",
    "TF_RECORDS_DIR = 'gs://spotify-tfrecords'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c50a06-d69d-4d64-b254-26fb2a249fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick counts on training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1473-4a2d-4778-9f01-e2b76672a9f5",
   "metadata": {},
   "source": [
    "#### Quick counts on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa56927-6722-43f9-88ac-ab638487164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1189.20query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.12rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery TOTAL_PLAYLISTS\n",
    "select count(1) from jtotten-project.spotify_mpd.playlists_track_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418e5d8d-5410-4bca-a168-002d27ed95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_PLAYLISTS = TOTAL_PLAYLISTS.values[0][0]\n",
    "TOTAL_PLAYLISTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ee0aa-1c6d-47f0-a3a8-236c7a072ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Same with playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031039fa-decd-4396-a9ad-89f300a01f25",
   "metadata": {},
   "source": [
    "#### Quick counts (this time playlists) on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56750aa-be5c-4f4f-8b5b-4b8277e2a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1512.55query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.21rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery TOTAL_TRACKS\n",
    "select count(1) from jtotten-project.spotify_mpd.track_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccacb43d-c04c-4935-9e1f-06d51983e02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261490"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_TRACKS = TOTAL_TRACKS.values[0][0]\n",
    "TOTAL_TRACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4710f67-de96-401b-8a0c-abb05dd62c40",
   "metadata": {},
   "source": [
    "### Set the tf.io pipelines function from bigquery\n",
    "\n",
    "[Great blog post here on it](https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db86c9f-5454-4629-80ba-c0273fca117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import datetime\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.train import BytesList, Feature, FeatureList, Int64List\n",
    "from tensorflow.train import SequenceExample, FeatureLists\n",
    "\n",
    "\n",
    "\n",
    "def bq_to_tfdata(client, row_restriction, table_id, col_names, col_types, dataset, batch_size=BATCH_SIZE):\n",
    "    TABLE_ID = table_id\n",
    "    COL_NAMES = col_names\n",
    "    COL_TYPES = col_types\n",
    "    DATASET = dataset\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, TABLE_ID, DATASET,\n",
    "        COL_NAMES, COL_TYPES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45e8d-3113-4528-9d71-8afdfd922d4f",
   "metadata": {},
   "source": [
    "## Get the song metadata\n",
    "\n",
    "To get a pipeline working we need the metadata for the table along with the table information. The following functions are helpers that give us the metadata into the proper types for `tf`\n",
    "\n",
    "\n",
    "For each table id, programatically get\n",
    "* Column names\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcf9098-fd4c-4d00-9e84-8658a620b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 833.36query/s]                          \n",
      "Downloading: 100%|██████████| 2/2 [00:00<00:00,  3.34rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery schema\n",
    "SELECT * FROM jtotten-project.spotify_mpd.INFORMATION_SCHEMA.TABLES\n",
    "where table_name in ('track_audio', 'playlists_track_string');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402d9cd0-a837-418a-aa7d-8ba8350c6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>base_table_catalog</th>\n",
       "      <th>base_table_schema</th>\n",
       "      <th>base_table_name</th>\n",
       "      <th>snapshot_time_ms</th>\n",
       "      <th>ddl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>track_audio</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-06 17:46:25.801000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>playlists_track_string</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-22 22:50:46.601000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.play...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     table_catalog table_schema              table_name  table_type  \\\n",
       "0  jtotten-project  spotify_mpd             track_audio  BASE TABLE   \n",
       "1  jtotten-project  spotify_mpd  playlists_track_string  BASE TABLE   \n",
       "\n",
       "  is_insertable_into is_typed                    creation_time  \\\n",
       "0                YES       NO 2022-04-06 17:46:25.801000+00:00   \n",
       "1                YES       NO 2022-04-22 22:50:46.601000+00:00   \n",
       "\n",
       "  base_table_catalog base_table_schema base_table_name snapshot_time_ms  \\\n",
       "0               None              None            None              NaT   \n",
       "1               None              None            None              NaT   \n",
       "\n",
       "                                                 ddl  \n",
       "0  CREATE TABLE `jtotten-project.spotify_mpd.trac...  \n",
       "1  CREATE TABLE `jtotten-project.spotify_mpd.play...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema # we will get the fields out of the ddl field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e820-d1d7-48f9-902d-ad63be9b74fb",
   "metadata": {},
   "source": [
    "## Helper functions to pull metadata from ddl statements\n",
    "\n",
    "From the DDL we are going to get the types for use in a  to create a `BigQueryReadSession` from `tensorflow_io.bigquery` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e90599-b0e7-41e6-a6e7-99d6668ead55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string type representation to tf data types\n",
    "\n",
    "def conv_dtype_to_tf(dtype_str):\n",
    "    if dtype_str == 'FLOAT64':\n",
    "        return dtypes.float64\n",
    "    elif dtype_str == 'INT64':\n",
    "        return dtypes.int64\n",
    "    else: \n",
    "        return dtypes.string\n",
    "        \n",
    "def get_metadata_from_ddl(ddl, drop_field=None):\n",
    "    fields = []\n",
    "    types = []\n",
    "    ddl = ddl.values[0]\n",
    "    for line in ddl.splitlines():\n",
    "        if line[:1] == ' ': #only pull indented lines for the fields\n",
    "            # drop the comma\n",
    "            line = line.replace(',','')\n",
    "            space_delim = line.split(' ')\n",
    "            if space_delim[2] in drop_field:\n",
    "                pass\n",
    "            else:\n",
    "                fields.append(space_delim[2])\n",
    "                types.append(conv_dtype_to_tf(space_delim[3]))\n",
    "    return fields, types\n",
    "\n",
    "\n",
    "track_audio_fields, track_audio_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'track_audio'], DROP_FIELDS)\n",
    "playlist_fields, playlist_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'playlists_track_string'], DROP_FIELDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd06cfb-66c6-4a18-9e5d-22352317da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : <dtype: 'string'>\n",
      "collaborative : <dtype: 'string'>\n",
      "modified_at : <dtype: 'int64'>\n",
      "num_tracks : <dtype: 'int64'>\n",
      "num_albums : <dtype: 'int64'>\n",
      "num_followers : <dtype: 'int64'>\n",
      "tracks : <dtype: 'string'>\n",
      "num_edits : <dtype: 'int64'>\n",
      "duration_ms : <dtype: 'int64'>\n",
      "num_artists : <dtype: 'int64'>\n",
      "description : <dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(playlist_fields, playlist_types):\n",
    "    print(a +\" : \" + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4667a86-574c-4484-a331-8c9c7ae6fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_name : <dtype: 'string'>\n",
      "track_name : <dtype: 'string'>\n",
      "album_name : <dtype: 'string'>\n",
      "name : <dtype: 'string'>\n",
      "danceability : <dtype: 'float64'>\n",
      "energy : <dtype: 'float64'>\n",
      "key : <dtype: 'float64'>\n",
      "loudness : <dtype: 'float64'>\n",
      "mode : <dtype: 'float64'>\n",
      "speechiness : <dtype: 'float64'>\n",
      "acousticness : <dtype: 'float64'>\n",
      "instrumentalness : <dtype: 'float64'>\n",
      "liveness : <dtype: 'float64'>\n",
      "valence : <dtype: 'float64'>\n",
      "tempo : <dtype: 'float64'>\n",
      "type : <dtype: 'string'>\n",
      "id : <dtype: 'string'>\n",
      "uri : <dtype: 'string'>\n",
      "track_href : <dtype: 'string'>\n",
      "analysis_url : <dtype: 'string'>\n",
      "time_signature : <dtype: 'float64'>\n",
      "artist_pop : <dtype: 'int64'>\n",
      "track_pop : <dtype: 'string'>\n",
      "genres : <dtype: 'string'>\n",
      "duration_ms : <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(track_audio_fields, track_audio_types):\n",
    "    print(a +\" : \" + str(b))\n",
    "    \n",
    "DROP_TRACK_AUDIO_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94ebf1-0080-4cd5-be46-c72af9d3a0e5",
   "metadata": {},
   "source": [
    "### Now the helper functions are set. Below tf.data pipelines are created from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "311dd38e-94c3-4bef-b4b0-e051ba529530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:16:52.308487: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-04-24 22:16:52.308832: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-04-24 22:16:53.697631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.698602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.709765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.710734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.711519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.712275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.714234: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 22:16:53.897901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.898799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.899545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.900225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.900851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:53.901569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.837329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.838199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.838926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.839652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.840334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.841011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13793 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-24 22:16:54.841640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:16:54.842416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13793 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "track_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'track_audio'\n",
    "                                    , col_names=track_audio_fields, col_types=track_audio_types, dataset='spotify_mpd', batch_size=1) #we will change to BATCH_SIZE after we test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49e5cd5-7f73-419d-9c09-8495e09decab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:16:55.470721: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:55.470773: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:55.471304: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:55.471344: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('acousticness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.827])>), ('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Promesa De Vida'], dtype=object)>), ('analysis_url', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'https://api.spotify.com/v1/audio-analysis/0yqtUGhNzOUnp79yai2Nbw'],\n",
      "      dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'X-JIREH'], dtype=object)>), ('artist_pop', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([-1])>), ('danceability', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.523])>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([328202])>), ('energy', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.2])>), ('genres', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'unknown'], dtype=object)>), ('id', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0yqtUGhNzOUnp79yai2Nbw'], dtype=object)>), ('instrumentalness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('key', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('liveness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.133])>), ('loudness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([-10.837])>), ('mode', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'CHRISTIAN'], dtype=object)>), ('speechiness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.0305])>), ('tempo', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([124.006])>), ('time_signature', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([4.])>), ('track_href', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'https://api.spotify.com/v1/tracks/0yqtUGhNzOUnp79yai2Nbw'],\n",
      "      dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Jes\\xc3\\xbas Un Milagro Har\\xc3\\xa1 En Ti'], dtype=object)>), ('track_pop', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>), ('type', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'audio_features'], dtype=object)>), ('uri', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:0yqtUGhNzOUnp79yai2Nbw'], dtype=object)>), ('valence', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.192])>)])\n"
     ]
    }
   ],
   "source": [
    "### Validate we are getting records\n",
    "\n",
    "for line in track_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc539f35-02a5-4010-b07d-02a77f66f4ce",
   "metadata": {},
   "source": [
    "### For the song audio data, we are set and will use this pipeline in training - there's no need to pre-process as there are no nested elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3c14a9-a269-4bc5-a198-5270ac0faa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_types[-1] = dtypes.string #try manually setting the dtype for the tracks nested column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb806df-3f54-4785-a063-9a416e487ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:16:56.025225: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:56.025272: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:56.025791: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:16:56.025832: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([5461333])>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1508976000])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'disney favs'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([14])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([24])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([12])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([28])>), ('tracks', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'[{\\'pos\\': 0, \\'artist_name\\': \\'Peggy Lee (performer), Oliver Wallace (comductor), Walt Disney Studio Orchestra\\', \\'track_uri\\': \\'spotify:track:7gszEHRkBhgWxz4ehSe0lr\\', \\'artist_uri\\': \\'spotify:artist:3MHlIt9IAlysdZJz2xvkj6\\', \\'track_name\\': \"The Siamese Cat Song / What\\'s Going On Down There\", \\'album_uri\\': \\'spotify:album:2bDCjSVK1wjEaPT5YpgtyR\\', \\'duration_ms\\': 157126, \\'album_name\\': \\'Lady and the Tramp (1955 Film Score)\\'}, {\\'pos\\': 1, \\'artist_name\\': \\'Peggy Lee (performer), Oliver Wallace (comductor), Walt Disney Studio Orchestra\\', \\'track_uri\\': \\'spotify:track:1LBcs9JY4DedNGwQ61Jztv\\', \\'artist_uri\\': \\'spotify:artist:3MHlIt9IAlysdZJz2xvkj6\\', \\'track_name\\': \"What A Dog / He\\'s A Tramp\", \\'album_uri\\': \\'spotify:album:2bDCjSVK1wjEaPT5YpgtyR\\', \\'duration_ms\\': 145684, \\'album_name\\': \\'Lady and the Tramp (1955 Film Score)\\'}, {\\'pos\\': 2, \\'artist_name\\': \\'Angela Lansbury\\', \\'track_uri\\': \\'spotify:track:6btdYzQ8eZFBrOlUKVHuz0\\', \\'artist_uri\\': \\'spotify:artist:0LtVJXnPR8msCJiE2DjHxy\\', \\'track_name\\': \\'Be Our Guest - From \"Beauty and the Beast\"/Soundtrack\\', \\'album_uri\\': \\'spotify:album:3O5p9VNddbwvqWTdYKEqV5\\', \\'duration_ms\\': 224733, \\'album_name\\': \\'Beauty and the Beast\\'}, {\\'pos\\': 3, \\'artist_name\\': \\'Lea Salonga\\', \\'track_uri\\': \\'spotify:track:5VIfacsWytkcgr7aTt8Tql\\', \\'artist_uri\\': \\'spotify:artist:1GlMjIezcLwV3OFlX0uXOv\\', \\'track_name\\': \\'A Whole New World\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 160800, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 4, \\'artist_name\\': \\'Lillias White\\', \\'track_uri\\': \\'spotify:track:1HSJMLtNeDryJN76Tu5Ahf\\', \\'artist_uri\\': \\'spotify:artist:5TKKPpY9zr2qrz3JM3Vawq\\', \\'track_name\\': \"I Won\\'t Say (I\\'m in Love)\", \\'album_uri\\': \\'spotify:album:79xGkf1594kBEtCIaL6yKj\\', \\'duration_ms\\': 140333, \\'album_name\\': \\'Hercules Original Soundtrack\\'}, {\\'pos\\': 5, \\'artist_name\\': \\'Donny Osmond\\', \\'track_uri\\': \\'spotify:track:28UMEtwyUUy5u0UWOVHwiI\\', \\'artist_uri\\': \\'spotify:artist:5ZEAzHE2TzAwUcOj6jMIgf\\', \\'track_name\\': \\'I\\\\\\'ll Make a Man Out of You - From \"Mulan\"/Soundtrack\\', \\'album_uri\\': \\'spotify:album:3Ohs7Jo6GM6mydUOL0m5aC\\', \\'duration_ms\\': 201680, \\'album_name\\': \\'Mulan\\'}, {\\'pos\\': 6, \\'artist_name\\': \\'Samuel E. Wright\\', \\'track_uri\\': \\'spotify:track:4HGIPyqDxSf863tPOwXiLJ\\', \\'artist_uri\\': \\'spotify:artist:6Id8rcDNyBXPcgKQVfQ8rX\\', \\'track_name\\': \\'Kiss the Girl - From \"The Little Mermaid\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:4aAwvCRNJIqiUGVEjieWv6\\', \\'duration_ms\\': 163400, \\'album_name\\': \\'Little Mermaid\\'}, {\\'pos\\': 7, \\'artist_name\\': \\'Nathan Lane\\', \\'track_uri\\': \\'spotify:track:5k3U0OGYBccHdKJJu3HrUN\\', \\'artist_uri\\': \\'spotify:artist:0P0do9GwiSgweSF6Ui3mrv\\', \\'track_name\\': \\'Hakuna Matata\\', \\'album_uri\\': \\'spotify:album:3YA5DdB3wSz4pdfEXoMyRd\\', \\'duration_ms\\': 213600, \\'album_name\\': \\'The Lion King\\'}, {\\'pos\\': 8, \\'artist_name\\': \\'Bruce Adler\\', \\'track_uri\\': \\'spotify:track:0CKmN3Wwk8W4zjU0pqq2cv\\', \\'artist_uri\\': \\'spotify:artist:66oKiXdIQP7MwN0gPUY0FD\\', \\'track_name\\': \\'Arabian Nights\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 79293, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 9, \\'artist_name\\': \\'Lea Salonga\\', \\'track_uri\\': \\'spotify:track:2AILbz83cBnrAMAG06rZts\\', \\'artist_uri\\': \\'spotify:artist:1GlMjIezcLwV3OFlX0uXOv\\', \\'track_name\\': \\'Reflection - From \"Mulan\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:3Ohs7Jo6GM6mydUOL0m5aC\\', \\'duration_ms\\': 146760, \\'album_name\\': \\'Mulan\\'}, {\\'pos\\': 10, \\'artist_name\\': \\'Brad Kane\\', \\'track_uri\\': \\'spotify:track:4wN8Ov3kPZdkJ8XcYxYUGz\\', \\'artist_uri\\': \\'spotify:artist:3dAzSJ9lQnJSq5Z0OgDBep\\', \\'track_name\\': \\'One Jump Ahead\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 142440, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 11, \\'artist_name\\': \\'Jonathan Freeman\\', \\'track_uri\\': \\'spotify:track:5BEItY9of9nR4zj51JO0jU\\', \\'artist_uri\\': \\'spotify:artist:2970T0VJFpIWMA2aZi6Lpi\\', \\'track_name\\': \\'Prince Ali (Reprise)\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 67653, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 12, \\'artist_name\\': \\'Alan Menken\\', \\'track_uri\\': \\'spotify:track:30J2aUXkTp9vsGWH3tegca\\', \\'artist_uri\\': \\'spotify:artist:5sy77gt4bfsLcSQ8GIe4ZZ\\', \\'track_name\\': \\'To Be Free\\', \\'album_uri\\': \\'spotify:album:29EiOQJnxWlX5nVOWQpu3u\\', \\'duration_ms\\': 99253, \\'album_name\\': \\'Aladdin\\'}, {\\'pos\\': 13, \\'artist_name\\': \\'Anika Noni Rose\\', \\'track_uri\\': \\'spotify:track:2dlxN435ZY9ruxGYND2Hq0\\', \\'artist_uri\\': \\'spotify:artist:4fqk0Vw0VrIY8O2eWtmQO2\\', \\'track_name\\': \\'Almost There\\', \\'album_uri\\': \\'spotify:album:6zgvBxOmfWxrQi4Jxxki0P\\', \\'duration_ms\\': 144426, \\'album_name\\': \\'The Princess and the Frog\\'}, {\\'pos\\': 14, \\'artist_name\\': \\'Riverfront Studio Singers\\', \\'track_uri\\': \\'spotify:track:59oPOJ9bYDhWAKNW3gaSPS\\', \\'artist_uri\\': \\'spotify:artist:1NvMcK0prF4jGBppmI3m0c\\', \\'track_name\\': \\'Prince Ali (From \"Aladdin\")\\', \\'album_uri\\': \\'spotify:album:4jbNxHbNTSlgnPj9rpwKt2\\', \\'duration_ms\\': 170024, \\'album_name\\': \\'Kids Movie Songs Vol.3\\'}, {\\'pos\\': 15, \\'artist_name\\': \\'Mandy Moore\\', \\'track_uri\\': \\'spotify:track:6klpXs2uAjagnZMFkt4qkl\\', \\'artist_uri\\': \\'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu\\', \\'track_name\\': \\'I See the Light - From \"Tangled\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:1l0aFrH24oPrQSqGtfeFyE\\', \\'duration_ms\\': 224240, \\'album_name\\': \\'Tangled\\'}, {\\'pos\\': 16, \\'artist_name\\': \\'Mandy Moore\\', \\'track_uri\\': \\'spotify:track:0TCt7OFRdD8PQ6vTRQxNgQ\\', \\'artist_uri\\': \\'spotify:artist:2LJxr7Pt3JnP60eLxwbDOu\\', \\'track_name\\': \\'I\\\\\\'ve Got a Dream - From \"Tangled\"/Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:1l0aFrH24oPrQSqGtfeFyE\\', \\'duration_ms\\': 191413, \\'album_name\\': \\'Tangled\\'}, {\\'pos\\': 17, \\'artist_name\\': \\'Cheryl Freeman\\', \\'track_uri\\': \\'spotify:track:0I8mZRtlFGOqZayJbEAdxL\\', \\'artist_uri\\': \\'spotify:artist:3E0MPcbZSjfJ1HsnJKXkqd\\', \\'track_name\\': \\'The Gospel Truth I / Main Titles - Hercules\\', \\'album_uri\\': \\'spotify:album:7z46fPkl9344yv05HT1Uoq\\', \\'duration_ms\\': 145639, \\'album_name\\': \\'Hercules\\'}, {\\'pos\\': 18, \\'artist_name\\': \\'Dick Van Dyke\\', \\'track_uri\\': \\'spotify:track:2hKYhft1VITPST4iiAHLGC\\', \\'artist_uri\\': \\'spotify:artist:6XIT5sGHOtxVgqtSnMCYZ6\\', \\'track_name\\': \\'Chim Chim Cher-ee\\', \\'album_uri\\': \\'spotify:album:3PlbEOxE8rE8xf7mDWdpgb\\', \\'duration_ms\\': 166080, \\'album_name\\': \\'The Sherman Brothers Songbook\\'}, {\\'pos\\': 19, \\'artist_name\\': \\'Ilene Woods\\', \\'track_uri\\': \\'spotify:track:3uVkugZz6yCTw5Z8sDI19F\\', \\'artist_uri\\': \\'spotify:artist:4DovRSplr3yJIeE3r0RtHj\\', \\'track_name\\': \\'A Dream Is A Wish Your Heart Makes - Soundtrack\\', \\'album_uri\\': \\'spotify:album:6KSC0FkAhdErc0azFDze0i\\', \\'duration_ms\\': 276306, \\'album_name\\': \"Disney\\'s Greatest Volume 2\"}, {\\'pos\\': 20, \\'artist_name\\': \\'Verna Felton\\', \\'track_uri\\': \\'spotify:track:0rzqBHKWkrZZ7R0e2y3abc\\', \\'artist_uri\\': \\'spotify:artist:7aU90hxXexP47nEeMee6xM\\', \\'track_name\\': \\'Where Did I Put That Thing / Bibbidi-Bobbidi-Boo (The Magic Song)\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 287933, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 21, \\'artist_name\\': \\'Mack David\\', \\'track_uri\\': \\'spotify:track:3uOsIy3rfPEIRawz1xPO5H\\', \\'artist_uri\\': \\'spotify:artist:4tMrFa88Ah85DwbtjQjohF\\', \\'track_name\\': \\'A Visitor / Caught In A Trap / Lucifer Medley\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 130866, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 22, \\'artist_name\\': \\'Paul J. Smith\\', \\'track_uri\\': \\'spotify:track:195dIFnht6bpaGslMHxxx7\\', \\'artist_uri\\': \\'spotify:artist:3g6RWqrG0tt6oXPMLP2WE5\\', \\'track_name\\': \"Locked in the Tower / Gus and Jaq to the Rescue / Slipper Fittings / Cinderella\\'s Slipper / Finale\", \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 461586, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 23, \\'artist_name\\': \\'Rhoda Williams\\', \\'track_uri\\': \\'spotify:track:04fAHzTVDZp4Vkb7o54tkt\\', \\'artist_uri\\': \\'spotify:artist:7C3YSHR8TLh6b73PbQojuk\\', \\'track_name\\': \\'The Music Lesson / Oh, Sing Sweet Nightingale / Bad Boy Lucifer / A Message From His Majesty\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 126733, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 24, \\'artist_name\\': \\'Mice Chorus\\', \\'track_uri\\': \\'spotify:track:7CtiVQKP9pkr9i7p6wk4gl\\', \\'artist_uri\\': \\'spotify:artist:3gcnVAcMBdtYbril7EqBz6\\', \\'track_name\\': \\'Little Dressmaker / The Work Song / Scavenger Hunt / A Dream Is a Wish Your Heart Makes / The Dress / My Beads / Escape to the Garden\\', \\'album_uri\\': \\'spotify:album:39OqFVu7klRglGlY9XQUQf\\', \\'duration_ms\\': 564400, \\'album_name\\': \\'Cinderella Special Edition\\'}, {\\'pos\\': 25, \\'artist_name\\': \\'Samuel E. Wright\\', \\'track_uri\\': \\'spotify:track:6oYkwjI1TKP9D0Y9II1GT7\\', \\'artist_uri\\': \\'spotify:artist:6Id8rcDNyBXPcgKQVfQ8rX\\', \\'track_name\\': \\'Under the Sea - From \"The Little Mermaid\"/ Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:4aAwvCRNJIqiUGVEjieWv6\\', \\'duration_ms\\': 195146, \\'album_name\\': \\'Little Mermaid\\'}, {\\'pos\\': 26, \\'artist_name\\': \\'Leon-Wooley\\', \\'track_uri\\': \\'spotify:track:0II9l1sI3Mo9XKaszKfizl\\', \\'artist_uri\\': \\'spotify:artist:6KwUkoMqmP6cPhsnkKruLr\\', \\'track_name\\': \"When We\\'re Human (feat. Terence Blanchard)\", \\'album_uri\\': \\'spotify:album:6zgvBxOmfWxrQi4Jxxki0P\\', \\'duration_ms\\': 142093, \\'album_name\\': \\'The Princess and the Frog\\'}, {\\'pos\\': 27, \\'artist_name\\': \\'Pat Carroll\\', \\'track_uri\\': \\'spotify:track:7zsw78LtXUD7JfEwH64HK2\\', \\'artist_uri\\': \\'spotify:artist:0Yy9u86cq66Se2pB9fYaiW\\', \\'track_name\\': \\'Poor Unfortunate Souls - From \"The Little Mermaid\" / Soundtrack Version\\', \\'album_uri\\': \\'spotify:album:4aAwvCRNJIqiUGVEjieWv6\\', \\'duration_ms\\': 291693, \\'album_name\\': \\'Little Mermaid\\'}]'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "## Validate playlist data\n",
    "playlist_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'playlists_track_string'\n",
    "                                    , col_names=playlist_fields\n",
    "                                       , col_types=playlist_types\n",
    "                                       , dataset='spotify_mpd', batch_size=1)\n",
    "for line in playlist_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b3a5-a553-405d-b2f5-d37af35fdc8a",
   "metadata": {},
   "source": [
    "## In pulling one record it looks like it's properly parsing a tf record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae928c-beeb-4704-8b18-cd31bcb16d24",
   "metadata": {},
   "source": [
    "# do some data wranglging on the text data\n",
    "# tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "for _ in playlist_train_pipeline.map(lambda x: tf.io.parse_sequence_example(tf.io.serialize_tensor(x['tracks'][0]), sequence_features=feature_description, context_features=context_features, name='tracks')).take(1):\n",
    "    tensor = _\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132c7a5-5f76-429b-a1aa-47663f20080b",
   "metadata": {},
   "source": [
    "Since the data is stored in a text dictionary we will eagerly execute, grab the values and do a string `eval`\n",
    "`eval(\"{'pos': 0, 'artist_name': 'King Crimson', 'track_uri': 'spotify:track:173gp7NIXqk0MEo8K7Av4a', 'artist_uri': 'spotify:artist:7M1FPw29m5FbicYzS2xdpi', 'track_name': '21st Century Schizoid Man', 'album_uri': 'spotify:album:0ga8Q4tTXaFf9q3LvT8hrC', 'duration_ms': 657517, 'album_name': 'Radical Action To Unseat the Hold of Monkey Mind (Live)'}\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4abb83-f280-4108-998a-e19689841f8f",
   "metadata": {},
   "source": [
    "## This funcion parses the playlist data and breaks down the nested fields to be conformant with `SequenceExample`\n",
    "The 'flat' features come along as `context_features` in `SequenceExample`\n",
    "There is one more helper function to parse the example and write it to the destination `gs://` path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82765dec-1d18-49b5-9a9f-81cbfff56a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_tensor_from_tracks(tensor):\n",
    "    key_list = ['pos', 'artist_name', 'track_uri', 'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name']\n",
    "    y = {}\n",
    "    \n",
    "    \n",
    "    tracks = tensor[\"tracks\"][0]\n",
    "    tracks = tracks.numpy()\n",
    "\n",
    "    tracks = eval(tracks)\n",
    "\n",
    "    for _ in key_list:\n",
    "        y[_] = []\n",
    "\n",
    "    for track in tracks:\n",
    "        y['pos'].append(track['pos'])\n",
    "        y['artist_name'].append(track['artist_name'].encode('utf8'))\n",
    "        y['artist_uri'].append(track['artist_uri'].encode('utf8'))\n",
    "        y['track_name'].append(track['track_name'].encode('utf8'))\n",
    "        y['album_uri'].append(track['album_uri'].encode('utf8'))\n",
    "        y['duration_ms'].append(track['duration_ms'])\n",
    "        y['album_name'].append(track['album_name'].encode('utf8'))\n",
    "        y['track_uri'].append(track['track_uri'].encode('utf8'))\n",
    "        \n",
    "\n",
    "\n",
    "    # set list types\n",
    "    pos = Int64List(value=y['pos'])\n",
    "    artist_name = BytesList(value=y['artist_name'])\n",
    "    artist_uri = BytesList(value=y['artist_uri'])\n",
    "    track_name = BytesList(value=y['track_name'])\n",
    "    album_uri = BytesList(value=y['album_uri'])\n",
    "    duration_ms = Int64List(value=y['duration_ms'])\n",
    "    album_name = BytesList(value=y['album_name'])\n",
    "    track_uri = BytesList(value=y['track_uri'])\n",
    "\n",
    "    \n",
    "    sample_dict = {\n",
    "    \"name\" : Feature(bytes_list=BytesList(value=tensor['name'].numpy())),\n",
    "    \"collaborative\" : Feature(bytes_list=BytesList(value=tensor['collaborative'].numpy())),\n",
    "    \"modified_at\" : Feature(int64_list=Int64List(value=tensor['modified_at'].numpy())),\n",
    "    \"num_tracks\" : Feature(int64_list=Int64List(value=tensor['num_tracks'].numpy())),\n",
    "    \"num_albums\" : Feature(int64_list=Int64List(value=tensor['num_albums'].numpy())),\n",
    "    \"num_followers\" : Feature(int64_list=Int64List(value=tensor['num_followers'].numpy())),\n",
    "    \"num_edits\" : Feature(int64_list=Int64List(value=tensor['num_edits'].numpy())),\n",
    "    \"duration_ms\" : Feature(int64_list=Int64List(value=tensor['duration_ms'].numpy())),\n",
    "    \"num_artists\" : Feature(int64_list=Int64List(value=tensor['num_artists'].numpy())),\n",
    "    \"description\" : Feature(bytes_list=BytesList(value=tensor['description'].numpy()))\n",
    "    }\n",
    "\n",
    "    # combine feature list\n",
    "\n",
    "    fl = FeatureList(feature=[Feature(int64_list=pos), \n",
    "                              Feature(bytes_list=artist_name),\n",
    "                              Feature(bytes_list=artist_uri),\n",
    "                              Feature(bytes_list=track_name),\n",
    "                              Feature(bytes_list=album_uri),\n",
    "                              Feature(int64_list=duration_ms),\n",
    "                              Feature(bytes_list=album_name),\n",
    "                              Feature(bytes_list=track_uri)\n",
    "                             ])\n",
    "\n",
    "    #create the sequence\n",
    "    seq = SequenceExample(context=tf.train.Features(feature=sample_dict),\n",
    "                          feature_lists=FeatureLists(feature_list={\n",
    "        \"tracks\": fl\n",
    "    }))\n",
    "    \n",
    "    return seq\n",
    "\n",
    "\n",
    "def write_a_tfrec(lns, n_records_per_file, file_counter, subfolder):\n",
    "    #next write to a tfrecord\n",
    "    with tf.io.TFRecordWriter(\n",
    "        TF_RECORDS_DIR + \"/\" + subfolder +\"/file_%.2i-%i.tfrec\" % (n_records_per_file, file_counter)\n",
    "    ) as writer:\n",
    "        for example in lns:\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2eb503-d2b4-424b-8f48-7b3187b5fc4a",
   "metadata": {},
   "source": [
    "## Now iterate over the pipeline\n",
    "Creating files with batches of `N_RECORDS_PER_TFRECORD_FILE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b10c9e7-a0c4-4149-870b-7e8fcd15ac43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 % 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a4fc6-cdb7-4e81-abe0-d4df4d890b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for folder expected: 2022-04-24:22:43:09.421661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1032000 [00:00<?, ?it/s]2022-04-24 22:43:09.439155: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:43:09.439205: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:43:09.439649: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-24 22:43:09.439691: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "  6%|▌         | 64476/1032000 [02:46<27:39, 582.87it/s]  "
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "from tqdm import tqdm\n",
    "# using datetime module\n",
    "\n",
    "# ct stores current time\n",
    "ct = str(datetime.datetime.now()).replace(\" \",\":\")\n",
    "print(f\"Timestamp for folder expected: {ct}\")\n",
    "records = []\n",
    "file_count = 0\n",
    "\n",
    "for i, line in enumerate(tqdm(playlist_train_pipeline, total=TOTAL_PLAYLISTS)):\n",
    "    sequence_example = get_tensor_from_tracks(line) #should come out based on batch size\n",
    "    if (i % N_RECORDS_PER_TFRECORD_FILE == 0 or i == TOTAL_PLAYLISTS-1) and i is not 0: #write-a-file and reset the batch (+1 to avoid modulus reset)\n",
    "        records.append(sequence_example)\n",
    "        write_a_tfrec(records, n_records_per_file=N_RECORDS_PER_TFRECORD_FILE, subfolder=ct, file_counter = file_count)\n",
    "        file_count+=1\n",
    "        records = []\n",
    "    else:\n",
    "        records.append(sequence_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0b41d-9959-4601-9094-57cf01890fbb",
   "metadata": {},
   "source": [
    "# Model Draft Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc57822a-235f-4459-a43c-34762964b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class PlaylistsModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, adapt_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        #start with lookups on low cardnality categorical items\n",
    "        colab_vocab = tf.constant(['true','false'], name='colab_vocab', dtype='string')\n",
    "        \n",
    "        self.colab = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=colab_vocab, mask_token=None, name=\"colab_lookup\", output_mode='count')\n",
    "        ], name=\"colab\")\n",
    "        \n",
    "        #create text vectorizors to be fed to an embedding layer\n",
    "        self.artist_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"artist_tv\", ngrams=2)\n",
    "        \n",
    "        self.album_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.description_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.query_embedding = tf.keras.Sequential([\n",
    "            self.album_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"album_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"album_embedding_model\")\n",
    "        \n",
    "        self.artist_embedding = tf.keras.Sequential([\n",
    "            self.artist_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"artist_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"artist_embedding\")\n",
    "        \n",
    "        ###############\n",
    "        ### adapt stuff\n",
    "        ###############\n",
    "        \n",
    "        self.artist_vectorizor.adapt(adapt_data.map(lambda x: x['artist_name']))\n",
    "        self.album_vectorizor.adapt(adapt_data.map(lambda x: x['album_name'])) \n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"dense_layers_query\")\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\", kernel_initializer=initializer))\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, kernel_initializer=initializer))\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, 1, epsilon=1e-12, name=\"normalize_dense\")))\n",
    "\n",
    "\n",
    "    def call(self, data):    \n",
    "        all_embs = tf.concat(\n",
    "                [\n",
    "                    self.album_embedding(data['album_name']),\n",
    "                    self.artist_embedding(data['artist_name']),\n",
    "                    self.colab(data['collaborative']),\n",
    "                    self.description_embedding(data['description'])\n",
    "                ], axis=1)\n",
    "        return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821506a-054e-4ad2-8530-bde59fb5e5d6",
   "metadata": {},
   "source": [
    "## Use the example output to think of how you process your features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83a334-4008-44a8-84f6-f2ef827200db",
   "metadata": {},
   "source": [
    "```\n",
    "OrderedDict([('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm'], dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Carrot Green'], dtype=object)>), ('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'358500'], dtype=object)>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1505692800])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'FeSTa'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([82])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([66])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([48])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([85])>), ('pos', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'45'], dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm - Carrot Green Remix'], dtype=object)>)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a663c63-58be-43bf-a573-e986cce3e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8b37b159-34ce-4ef0-88ab-e9cc1ae7d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0].keys()#originally got the values from this\n",
    "feature_description = {'pos': tf.io.RaggedFeature(tf.int64), \n",
    "                     'artist_name':  tf.io.RaggedFeature(tf.string), \n",
    "                     'track_uri':  tf.io.RaggedFeature(tf.string), \n",
    "                     'artist_uri': tf.io.RaggedFeature(tf.string), \n",
    "                     'track_name': tf.io.RaggedFeature(tf.string), \n",
    "                     'album_uri': tf.io.RaggedFeature(tf.string),\n",
    "                     'duration_ms': tf.io.RaggedFeature(tf.int64), \n",
    "                     'album_name': tf.io.RaggedFeature(tf.string)\n",
    "                    }\n",
    "context_features = {\"name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"collaborative\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"modified_at\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_tracks\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_albums\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_followers\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_edits\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"duration_ms\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_artists\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"description\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1))\n",
    "                   }"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
