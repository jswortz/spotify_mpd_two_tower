{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5383b2-071e-45b8-af2c-2421eb4f923a",
   "metadata": {},
   "source": [
    "# Two - Tower Retreival Model\n",
    "\n",
    "### Key resources:\n",
    "* Many pages [here](https://www.tensorflow.org/recommenders/examples/deep_recommenders) include great techniques to build custom TFRS Models\n",
    "\n",
    "### Goals:\n",
    "* Show how to model off of most data types \n",
    "  * (String, Existing Embeddings (vectors), \n",
    "  * Floats (Normalized), \n",
    "  * Categorical with vocab, \n",
    "  * High Dim Categorical (Embed)\n",
    "* Leverage class templates to create custom 2 Tower Models quick/easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52e5f-a13b-46a7-849a-dc188b455a86",
   "metadata": {},
   "source": [
    "## SPOTIFY Create the tensorflow.io interface for the event and product table in Bigquery\n",
    "Best practices from Google are in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3122eb-564b-46f9-9a50-851d19301521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "DROPOUT = False\n",
    "DROPOUT_RATE = 0.2\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_TOKENS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "ARCH = [128, 64]\n",
    "NUM_EPOCHS = 1\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "DROP_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c50a06-d69d-4d64-b254-26fb2a249fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick counts on training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1473-4a2d-4778-9f01-e2b76672a9f5",
   "metadata": {},
   "source": [
    "#### Quick counts on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa56927-6722-43f9-88ac-ab638487164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1536.94query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.13rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66346428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  66346428"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(1) from jtotten-project.spotify_mpd.playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ee0aa-1c6d-47f0-a3a8-236c7a072ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Same with playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031039fa-decd-4396-a9ad-89f300a01f25",
   "metadata": {},
   "source": [
    "#### Quick counts (this time playlists) on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56750aa-be5c-4f4f-8b5b-4b8277e2a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1702.92query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.23rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2261490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  2261490"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(1) from jtotten-project.spotify_mpd.track_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4710f67-de96-401b-8a0c-abb05dd62c40",
   "metadata": {},
   "source": [
    "### Set the tf.io pipelines function from bigquery\n",
    "\n",
    "[Great blog post here on it](https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db86c9f-5454-4629-80ba-c0273fca117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "\n",
    "def bq_to_tfdata(client, row_restriction, table_id, col_names, col_types, dataset, batch_size=BATCH_SIZE):\n",
    "    TABLE_ID = table_id\n",
    "    COL_NAMES = col_names\n",
    "    COL_TYPES = col_types\n",
    "    DATASET = dataset\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, TABLE_ID, DATASET,\n",
    "        COL_NAMES, COL_TYPES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45e8d-3113-4528-9d71-8afdfd922d4f",
   "metadata": {},
   "source": [
    "## Get the song metadata\n",
    "\n",
    "To get a pipeline working we need the metadata for the table along with the table information. The following functions are helpers that give us the metadata into the proper types for `tf`\n",
    "\n",
    "\n",
    "For each table id, programatically get\n",
    "* Column names\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abcf9098-fd4c-4d00-9e84-8658a620b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 821.45query/s]                          \n",
      "Downloading: 100%|██████████| 2/2 [00:00<00:00,  2.22rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery schema\n",
    "SELECT * FROM jtotten-project.spotify_mpd.INFORMATION_SCHEMA.TABLES\n",
    "where table_name in ('track_audio', 'playlists_track_string');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402d9cd0-a837-418a-aa7d-8ba8350c6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>base_table_catalog</th>\n",
       "      <th>base_table_schema</th>\n",
       "      <th>base_table_name</th>\n",
       "      <th>snapshot_time_ms</th>\n",
       "      <th>ddl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>track_audio</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-06 17:46:25.801000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>playlists_track_string</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-22 22:50:46.601000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.play...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     table_catalog table_schema              table_name  table_type  \\\n",
       "0  jtotten-project  spotify_mpd             track_audio  BASE TABLE   \n",
       "1  jtotten-project  spotify_mpd  playlists_track_string  BASE TABLE   \n",
       "\n",
       "  is_insertable_into is_typed                    creation_time  \\\n",
       "0                YES       NO 2022-04-06 17:46:25.801000+00:00   \n",
       "1                YES       NO 2022-04-22 22:50:46.601000+00:00   \n",
       "\n",
       "  base_table_catalog base_table_schema base_table_name snapshot_time_ms  \\\n",
       "0               None              None            None              NaT   \n",
       "1               None              None            None              NaT   \n",
       "\n",
       "                                                 ddl  \n",
       "0  CREATE TABLE `jtotten-project.spotify_mpd.trac...  \n",
       "1  CREATE TABLE `jtotten-project.spotify_mpd.play...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema # we will get the fields out of the ddl field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e820-d1d7-48f9-902d-ad63be9b74fb",
   "metadata": {},
   "source": [
    "## Helper functions to pull metadata from ddl statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e90599-b0e7-41e6-a6e7-99d6668ead55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string type representation to tf data types\n",
    "\n",
    "def conv_dtype_to_tf(dtype_str):\n",
    "    if dtype_str == 'FLOAT64':\n",
    "        return dtypes.float64\n",
    "    elif dtype_str == 'INT64':\n",
    "        return dtypes.int64\n",
    "    else: \n",
    "        return dtypes.string\n",
    "        \n",
    "def get_metadata_from_ddl(ddl, drop_field=None):\n",
    "    fields = []\n",
    "    types = []\n",
    "    ddl = ddl.values[0]\n",
    "    for line in ddl.splitlines():\n",
    "        if line[:1] == ' ': #only pull indented lines for the fields\n",
    "            # drop the comma\n",
    "            line = line.replace(',','')\n",
    "            space_delim = line.split(' ')\n",
    "            if space_delim[2] in drop_field:\n",
    "                pass\n",
    "            else:\n",
    "                fields.append(space_delim[2])\n",
    "                types.append(conv_dtype_to_tf(space_delim[3]))\n",
    "    return fields, types\n",
    "\n",
    "\n",
    "track_audio_fields, track_audio_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'track_audio'], DROP_FIELDS)\n",
    "playlist_fields, playlist_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'playlists_track_string'], DROP_FIELDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd06cfb-66c6-4a18-9e5d-22352317da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : <dtype: 'string'>\n",
      "collaborative : <dtype: 'string'>\n",
      "modified_at : <dtype: 'int64'>\n",
      "num_tracks : <dtype: 'int64'>\n",
      "num_albums : <dtype: 'int64'>\n",
      "num_followers : <dtype: 'int64'>\n",
      "tracks : <dtype: 'string'>\n",
      "num_edits : <dtype: 'int64'>\n",
      "duration_ms : <dtype: 'int64'>\n",
      "num_artists : <dtype: 'int64'>\n",
      "description : <dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(playlist_fields, playlist_types):\n",
    "    print(a +\" : \" + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4667a86-574c-4484-a331-8c9c7ae6fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_name : <dtype: 'string'>\n",
      "track_name : <dtype: 'string'>\n",
      "album_name : <dtype: 'string'>\n",
      "name : <dtype: 'string'>\n",
      "danceability : <dtype: 'float64'>\n",
      "energy : <dtype: 'float64'>\n",
      "key : <dtype: 'float64'>\n",
      "loudness : <dtype: 'float64'>\n",
      "mode : <dtype: 'float64'>\n",
      "speechiness : <dtype: 'float64'>\n",
      "acousticness : <dtype: 'float64'>\n",
      "instrumentalness : <dtype: 'float64'>\n",
      "liveness : <dtype: 'float64'>\n",
      "valence : <dtype: 'float64'>\n",
      "tempo : <dtype: 'float64'>\n",
      "type : <dtype: 'string'>\n",
      "id : <dtype: 'string'>\n",
      "uri : <dtype: 'string'>\n",
      "track_href : <dtype: 'string'>\n",
      "analysis_url : <dtype: 'string'>\n",
      "time_signature : <dtype: 'float64'>\n",
      "artist_pop : <dtype: 'int64'>\n",
      "track_pop : <dtype: 'string'>\n",
      "genres : <dtype: 'string'>\n",
      "duration_ms : <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(track_audio_fields, track_audio_types):\n",
    "    print(a +\" : \" + str(b))\n",
    "    \n",
    "DROP_TRACK_AUDIO_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94ebf1-0080-4cd5-be46-c72af9d3a0e5",
   "metadata": {},
   "source": [
    "### Now the helper functions are set. Below tf.data pipelines are created from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311dd38e-94c3-4bef-b4b0-e051ba529530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 23:02:48.238860: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-04-22 23:02:48.239238: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-04-22 23:02:49.655749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.656571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.666423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.667274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.668018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.668670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.670301: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-22 23:02:49.843558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.844311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.844989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.845658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.846313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:49.847000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.746743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.747642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.748377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.749092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.749731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.750404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13793 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-22 23:02:50.751314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-22 23:02:50.751943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13793 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "track_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'track_audio'\n",
    "                                    , col_names=track_audio_fields, col_types=track_audio_types, dataset='spotify_mpd', batch_size=1) #we will change to BATCH_SIZE after we test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49e5cd5-7f73-419d-9c09-8495e09decab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 23:02:51.306322: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:51.306378: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:51.306777: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:51.306799: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('acousticness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.993])>), ('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Fundo Musical'], dtype=object)>), ('analysis_url', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'https://api.spotify.com/v1/audio-analysis/2V3MAaxLBbS370RqeXpc72'],\n",
      "      dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Fundo Musical Latino Star'], dtype=object)>), ('artist_pop', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>), ('danceability', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.609])>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([337525])>), ('energy', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.103])>), ('genres', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'unknown'], dtype=object)>), ('id', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2V3MAaxLBbS370RqeXpc72'], dtype=object)>), ('instrumentalness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.945])>), ('key', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('liveness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.118])>), ('loudness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([-19.045])>), ('mode', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Dinner'], dtype=object)>), ('speechiness', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.0473])>), ('tempo', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([139.933])>), ('time_signature', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([4.])>), ('track_href', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'https://api.spotify.com/v1/tracks/2V3MAaxLBbS370RqeXpc72'],\n",
      "      dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Romantic Background Music'], dtype=object)>), ('track_pop', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>), ('type', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'audio_features'], dtype=object)>), ('uri', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:2V3MAaxLBbS370RqeXpc72'], dtype=object)>), ('valence', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.495])>)])\n"
     ]
    }
   ],
   "source": [
    "### Validate we are getting records\n",
    "\n",
    "for line in track_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3c14a9-a269-4bc5-a198-5270ac0faa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_types[-1] = dtypes.string #try manually setting the dtype for the tracks nested column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fb806df-3f54-4785-a063-9a416e487ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 23:02:51.869808: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:51.869859: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:51.870199: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:51.870227: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([5106938])>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1507852800])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'A Playlist'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([17])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([18])>), ('tracks', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'[{\\'pos\\': 0, \\'artist_name\\': \\'King Crimson\\', \\'track_uri\\': \\'spotify:track:173gp7NIXqk0MEo8K7Av4a\\', \\'artist_uri\\': \\'spotify:artist:7M1FPw29m5FbicYzS2xdpi\\', \\'track_name\\': \\'21st Century Schizoid Man\\', \\'album_uri\\': \\'spotify:album:0ga8Q4tTXaFf9q3LvT8hrC\\', \\'duration_ms\\': 657517, \\'album_name\\': \\'Radical Action To Unseat the Hold of Monkey Mind (Live)\\'}, {\\'pos\\': 1, \\'artist_name\\': \\'Woodkid\\', \\'track_uri\\': \\'spotify:track:4rPCgwmCgef78nrsqwjA7G\\', \\'artist_uri\\': \\'spotify:artist:44TGR1CzjKBxSHsSEy7bi9\\', \\'track_name\\': \\'Iron\\', \\'album_uri\\': \\'spotify:album:4qbIfYXx7DOwpKfyws3GWe\\', \\'duration_ms\\': 187466, \\'album_name\\': \\'Iron\\'}, {\\'pos\\': 2, \\'artist_name\\': \\'RJD2\\', \\'track_uri\\': \\'spotify:track:4bxbSJqs4H4HcMPVhLprfJ\\', \\'artist_uri\\': \\'spotify:artist:1O3ZOjqFLEnbpZexcRjocn\\', \\'track_name\\': \\'A Beautiful Mine (Theme Music from Mad Men)\\', \\'album_uri\\': \\'spotify:album:1IB9atEU8e02Ht5slWf98p\\', \\'duration_ms\\': 329093, \\'album_name\\': \\'Magnificent City Instrumentals\\'}, {\\'pos\\': 3, \\'artist_name\\': \\'Air\\', \\'track_uri\\': \\'spotify:track:2sNGaLOMBIkyVFPsQqPQdW\\', \\'artist_uri\\': \\'spotify:artist:1P6U1dCeHxPui5pIrGmndZ\\', \\'track_name\\': \\'Alpha Beta Gaga\\', \\'album_uri\\': \\'spotify:album:0hQOqvZv1nQvPiBjzyn363\\', \\'duration_ms\\': 279773, \\'album_name\\': \\'Talkie Walkie\\'}, {\\'pos\\': 4, \\'artist_name\\': \\'Tame Impala\\', \\'track_uri\\': \\'spotify:track:2Gl1Qdx5Px5kVYe0PQoGI0\\', \\'artist_uri\\': \\'spotify:artist:5INjqkS1o8h1imAzPqGZBb\\', \\'track_name\\': \\'Be Above It\\', \\'album_uri\\': \\'spotify:album:3C2MFZ2iHotUQOSBzdSvM7\\', \\'duration_ms\\': 201960, \\'album_name\\': \\'Lonerism\\'}, {\\'pos\\': 5, \\'artist_name\\': \\'Groove Armada\\', \\'track_uri\\': \\'spotify:track:0swtEAC2p8JBiMMryK8Jdh\\', \\'artist_uri\\': \\'spotify:artist:67tgMwUfnmqzYsNAtnP6YJ\\', \\'track_name\\': \\'At the River\\', \\'album_uri\\': \\'spotify:album:0Mdp2G3uLOoCKbJezjA1Nu\\', \\'duration_ms\\': 393360, \\'album_name\\': \\'Vertigo\\'}, {\\'pos\\': 6, \\'artist_name\\': \\'Air\\', \\'track_uri\\': \\'spotify:track:5fddI3jipxueajScJYReMT\\', \\'artist_uri\\': \\'spotify:artist:1P6U1dCeHxPui5pIrGmndZ\\', \\'track_name\\': \\'Talisman\\', \\'album_uri\\': \\'spotify:album:206GTDefY2qRMQxYXmfb0a\\', \\'duration_ms\\': 256706, \\'album_name\\': \\'Moon Safari\\'}, {\\'pos\\': 7, \\'artist_name\\': \\'Woodkid\\', \\'track_uri\\': \\'spotify:track:2YhapA5E1qTZ1Ykw9Y86ql\\', \\'artist_uri\\': \\'spotify:artist:44TGR1CzjKBxSHsSEy7bi9\\', \\'track_name\\': \\'Run Boy Run\\', \\'album_uri\\': \\'spotify:album:46rGAcYt8T7iNyePUob4YO\\', \\'duration_ms\\': 213266, \\'album_name\\': \\'The Golden Age\\'}, {\\'pos\\': 8, \\'artist_name\\': \\'Tame Impala\\', \\'track_uri\\': \\'spotify:track:7qU7vhCPKhkDiJYGoboISc\\', \\'artist_uri\\': \\'spotify:artist:5INjqkS1o8h1imAzPqGZBb\\', \\'track_name\\': \\'Apocalypse Dreams\\', \\'album_uri\\': \\'spotify:album:3C2MFZ2iHotUQOSBzdSvM7\\', \\'duration_ms\\': 356946, \\'album_name\\': \\'Lonerism\\'}, {\\'pos\\': 9, \\'artist_name\\': \\'RJD2\\', \\'track_uri\\': \\'spotify:track:09aNhXGvfo8wAhUxcsDFlZ\\', \\'artist_uri\\': \\'spotify:artist:1O3ZOjqFLEnbpZexcRjocn\\', \\'track_name\\': \\'1976\\', \\'album_uri\\': \\'spotify:album:0jbra7wbupwZLAYxjxNiJv\\', \\'duration_ms\\': 147280, \\'album_name\\': \\'Since We Last Spoke: Deluxe\\'}, {\\'pos\\': 10, \\'artist_name\\': \\'Beck\\', \\'track_uri\\': \\'spotify:track:1ELY3KTgI83N1k0xXqabMe\\', \\'artist_uri\\': \\'spotify:artist:3vbKDsSS70ZX9D2OcvbZmS\\', \\'track_name\\': \\'Sexx Laws\\', \\'album_uri\\': \\'spotify:album:5Mk8LGoWoPg0igqQXprzfR\\', \\'duration_ms\\': 219240, \\'album_name\\': \\'Midnite Vultures\\'}, {\\'pos\\': 11, \\'artist_name\\': \\'Tame Impala\\', \\'track_uri\\': \\'spotify:track:6vTtMyCg96xwpoIBws9K0Q\\', \\'artist_uri\\': \\'spotify:artist:5INjqkS1o8h1imAzPqGZBb\\', \\'track_name\\': \\'Feels Like We Only Go Backwards\\', \\'album_uri\\': \\'spotify:album:76vY9yohh4kVwSKkyKbyEQ\\', \\'duration_ms\\': 192960, \\'album_name\\': \\'Lonerism\\'}, {\\'pos\\': 12, \\'artist_name\\': \\'Beck\\', \\'track_uri\\': \\'spotify:track:7mQertZHtd37UQ2uJs0Uct\\', \\'artist_uri\\': \\'spotify:artist:3vbKDsSS70ZX9D2OcvbZmS\\', \\'track_name\\': \"Where It\\'s At\", \\'album_uri\\': \\'spotify:album:3VCaLNEZTCVRwB8fIpmuM7\\', \\'duration_ms\\': 329573, \\'album_name\\': \\'Odelay\\'}, {\\'pos\\': 13, \\'artist_name\\': \\'Groove Armada\\', \\'track_uri\\': \\'spotify:track:5mf8jY9FsGCAuWwJMmKIzF\\', \\'artist_uri\\': \\'spotify:artist:67tgMwUfnmqzYsNAtnP6YJ\\', \\'track_name\\': \\'Edge Hill\\', \\'album_uri\\': \\'spotify:album:1bS1J4OVGrpu6e2U2pHge6\\', \\'duration_ms\\': 420573, \\'album_name\\': \\'Goodbye Country (Hello Nightclub)\\'}, {\\'pos\\': 14, \\'artist_name\\': \\'Death In Vegas\\', \\'track_uri\\': \\'spotify:track:015SmK4Fvjv13dVwtGoMC0\\', \\'artist_uri\\': \\'spotify:artist:5aj3LEYRbuaabjjHkj5oE1\\', \\'track_name\\': \\'Dirge\\', \\'album_uri\\': \\'spotify:album:4qUKzyXuy3GSzQD5RTJLdq\\', \\'duration_ms\\': 343866, \\'album_name\\': \\'The Contino Sessions\\'}, {\\'pos\\': 15, \\'artist_name\\': \\'Beck\\', \\'track_uri\\': \\'spotify:track:2sDFknh1dm8xiCnE3885k2\\', \\'artist_uri\\': \\'spotify:artist:3vbKDsSS70ZX9D2OcvbZmS\\', \\'track_name\\': \\'Gamma Ray\\', \\'album_uri\\': \\'spotify:album:7iHm2lTks5aIvb3z2CCpfo\\', \\'duration_ms\\': 176920, \\'album_name\\': \\'Modern Guilt\\'}, {\\'pos\\': 16, \\'artist_name\\': \\'Bonobo\\', \\'track_uri\\': \\'spotify:track:5jdEBt26wjmM7EP8V7jwjP\\', \\'artist_uri\\': \\'spotify:artist:0cmWgDlu9CwTgxPhf403hb\\', \\'track_name\\': \\'Kiara\\', \\'album_uri\\': \\'spotify:album:1VlLLqC0tugMgQEUU4K6mq\\', \\'duration_ms\\': 230306, \\'album_name\\': \\'Black Sands\\'}, {\\'pos\\': 17, \\'artist_name\\': \\'Todd Rundgren\\', \\'track_uri\\': \\'spotify:track:3grM7XFXsz6NdtIqogedeN\\', \\'artist_uri\\': \\'spotify:artist:0Lpr5wXzWLtDWm1SjNbpPb\\', \\'track_name\\': \\'International Feel\\', \\'album_uri\\': \\'spotify:album:1RSC0dy1oOIS3RO8tomZOV\\', \\'duration_ms\\': 170133, \\'album_name\\': \\'A Wizard / A True Star\\'}]'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "## Validate playlist data\n",
    "playlist_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'playlists_track_string'\n",
    "                                    , col_names=playlist_fields\n",
    "                                       , col_types=playlist_types\n",
    "                                       , dataset='spotify_mpd', batch_size=1)\n",
    "for line in playlist_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b3a5-a553-405d-b2f5-d37af35fdc8a",
   "metadata": {},
   "source": [
    "## In pulling one record it looks like it's properly parsing a tf record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "363c49b8-f4cf-418b-9f7a-0d81345b5186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 23:02:57.453053: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:57.453098: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:57.453614: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-22 23:02:57.453655: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b\"[{'pos': 0, 'artist_name': 'K CAMP', 'track_uri': 'spotify:track:7hRwwjy1cmwGkzBnJlhtnY', 'artist_uri': 'spotify:artist:5bgfj5zUoWpyeVatGDjn6H', 'track_name': '5 Minutes', 'album_uri': 'spotify:album:2GPRyHEFB2uzrB8aFyAmkP', 'duration_ms': 203080, 'album_name': '5 Minutes'}, {'pos': 1, 'artist_name': 'Post Malone', 'track_uri': 'spotify:track:5yuShbu70mtHXY0yLzCQLQ', 'artist_uri': 'spotify:artist:246dkjvS1zLTtiykXe5h60', 'track_name': 'Go Flex', 'album_uri': 'spotify:album:5s0rmjP8XOPhP6HhqOhuyC', 'duration_ms': 179613, 'album_name': 'Stoney'}, {'pos': 2, 'artist_name': 'Marc E. Bassy', 'track_uri': 'spotify:track:0LFqxv7O10lq49g4wpJ1ht', 'artist_uri': 'spotify:artist:3tQx1LPXbsYjE9VwN1Peaa', 'track_name': 'Relapse (feat. Iamsu!)', 'album_uri': 'spotify:album:2KjK2W2EFrzLF3iTRWnKlJ', 'duration_ms': 184500, 'album_name': 'Only The Poets Mixtape (Vol. 1)'}, {'pos': 3, 'artist_name': 'Kodak Black', 'track_uri': 'spotify:track:5v7kaZNsnyByrSJOfO8gKq', 'artist_uri': 'spotify:artist:46SHBwWsqBkxI7EeeBEQG7', 'track_name': 'Skrt', 'album_uri': 'spotify:album:5pgyZ32nzg48ugJS2QVVuS', 'duration_ms': 224864, 'album_name': 'Skrt'}, {'pos': 4, 'artist_name': 'Tory Lanez', 'track_uri': 'spotify:track:2Gyc6e2cLxA5hoX1NOvYnU', 'artist_uri': 'spotify:artist:2jku7tDXc6XoB6MO2hFuqg', 'track_name': 'Say It', 'album_uri': 'spotify:album:5tBOCi2TekXZ1IbrmlBZO4', 'duration_ms': 237786, 'album_name': 'I Told You'}]\"], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#do some data wranglging on the text data\n",
    "for _ in playlist_train_pipeline.map(lambda x: x['tracks']).take(1):\n",
    "    tensor = _\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc57822a-235f-4459-a43c-34762964b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class PlaylistsModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, adapt_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        #start with lookups on low cardnality categorical items\n",
    "        colab_vocab = tf.constant(['true','false'], name='colab_vocab', dtype='string')\n",
    "        \n",
    "        self.colab = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=colab_vocab, mask_token=None, name=\"colab_lookup\", output_mode='count')\n",
    "        ], name=\"colab\")\n",
    "        \n",
    "        #create text vectorizors to be fed to an embedding layer\n",
    "        self.artist_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"artist_tv\", ngrams=2)\n",
    "        \n",
    "        self.album_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.description_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.query_embedding = tf.keras.Sequential([\n",
    "            self.album_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"album_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"album_embedding_model\")\n",
    "        \n",
    "        self.artist_embedding = tf.keras.Sequential([\n",
    "            self.artist_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"artist_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"artist_embedding\")\n",
    "        \n",
    "        ###############\n",
    "        ### adapt stuff\n",
    "        ###############\n",
    "        \n",
    "        self.artist_vectorizor.adapt(adapt_data.map(lambda x: x['artist_name']))\n",
    "        self.album_vectorizor.adapt(adapt_data.map(lambda x: x['album_name'])) \n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"dense_layers_query\")\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\", kernel_initializer=initializer))\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, kernel_initializer=initializer))\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, 1, epsilon=1e-12, name=\"normalize_dense\")))\n",
    "\n",
    "\n",
    "    def call(self, data):    \n",
    "        all_embs = tf.concat(\n",
    "                [\n",
    "                    self.album_embedding(data['album_name']),\n",
    "                    self.artist_embedding(data['artist_name']),\n",
    "                    self.colab(data['collaborative']),\n",
    "                    self.description_embedding(data['description'])\n",
    "                ], axis=1)\n",
    "        return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821506a-054e-4ad2-8530-bde59fb5e5d6",
   "metadata": {},
   "source": [
    "## Use the example output to think of how you process your features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83a334-4008-44a8-84f6-f2ef827200db",
   "metadata": {},
   "source": [
    "```\n",
    "OrderedDict([('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm'], dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Carrot Green'], dtype=object)>), ('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'358500'], dtype=object)>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1505692800])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'FeSTa'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([82])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([66])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([48])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([85])>), ('pos', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'45'], dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm - Carrot Green Remix'], dtype=object)>)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a663c63-58be-43bf-a573-e986cce3e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
