{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5383b2-071e-45b8-af2c-2421eb4f923a",
   "metadata": {},
   "source": [
    "# Two - Tower Retreival Model\n",
    "\n",
    "### Key resources:\n",
    "* Many pages [here](https://www.tensorflow.org/recommenders/examples/deep_recommenders) include great techniques to build custom TFRS Models\n",
    "\n",
    "### Goals:\n",
    "* Show how to model off of most data types \n",
    "  * (String, Existing Embeddings (vectors), \n",
    "  * Floats (Normalized), \n",
    "  * Categorical with vocab, \n",
    "  * High Dim Categorical (Embed)\n",
    "* Leverage class templates to create custom 2 Tower Models quick/easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52e5f-a13b-46a7-849a-dc188b455a86",
   "metadata": {},
   "source": [
    "## SPOTIFY Create the tensorflow.io interface for the event and product table in Bigquery\n",
    "Best practices from Google are in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3122eb-564b-46f9-9a50-851d19301521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "DROPOUT = False\n",
    "DROPOUT_RATE = 0.2\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_TOKENS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "ARCH = [128, 64]\n",
    "NUM_EPOCHS = 1\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "DROP_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c50a06-d69d-4d64-b254-26fb2a249fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick counts on training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1473-4a2d-4778-9f01-e2b76672a9f5",
   "metadata": {},
   "source": [
    "#### Quick counts on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa56927-6722-43f9-88ac-ab638487164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1065.63query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.35rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1032000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  1032000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(1) from jtotten-project.spotify_mpd.playlists_track_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ee0aa-1c6d-47f0-a3a8-236c7a072ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Same with playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031039fa-decd-4396-a9ad-89f300a01f25",
   "metadata": {},
   "source": [
    "#### Quick counts (this time playlists) on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56750aa-be5c-4f4f-8b5b-4b8277e2a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 898.91query/s] \n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.24rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2261490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  2261490"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(1) from jtotten-project.spotify_mpd.track_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4710f67-de96-401b-8a0c-abb05dd62c40",
   "metadata": {},
   "source": [
    "### Set the tf.io pipelines function from bigquery\n",
    "\n",
    "[Great blog post here on it](https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db86c9f-5454-4629-80ba-c0273fca117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "\n",
    "def bq_to_tfdata(client, row_restriction, table_id, col_names, col_types, dataset, batch_size=BATCH_SIZE):\n",
    "    TABLE_ID = table_id\n",
    "    COL_NAMES = col_names\n",
    "    COL_TYPES = col_types\n",
    "    DATASET = dataset\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, TABLE_ID, DATASET,\n",
    "        COL_NAMES, COL_TYPES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45e8d-3113-4528-9d71-8afdfd922d4f",
   "metadata": {},
   "source": [
    "## Get the song metadata\n",
    "\n",
    "To get a pipeline working we need the metadata for the table along with the table information. The following functions are helpers that give us the metadata into the proper types for `tf`\n",
    "\n",
    "\n",
    "For each table id, programatically get\n",
    "* Column names\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abcf9098-fd4c-4d00-9e84-8658a620b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 514.58query/s]                          \n",
      "Downloading: 100%|██████████| 2/2 [00:00<00:00,  2.72rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery schema\n",
    "SELECT * FROM jtotten-project.spotify_mpd.INFORMATION_SCHEMA.TABLES\n",
    "where table_name in ('track_audio', 'playlists_track_string');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402d9cd0-a837-418a-aa7d-8ba8350c6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>base_table_catalog</th>\n",
       "      <th>base_table_schema</th>\n",
       "      <th>base_table_name</th>\n",
       "      <th>snapshot_time_ms</th>\n",
       "      <th>ddl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>track_audio</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-06 17:46:25.801000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtotten-project</td>\n",
       "      <td>spotify_mpd</td>\n",
       "      <td>playlists_track_string</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-04-22 21:11:46.231000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `jtotten-project.spotify_mpd.play...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     table_catalog table_schema              table_name  table_type  \\\n",
       "0  jtotten-project  spotify_mpd             track_audio  BASE TABLE   \n",
       "1  jtotten-project  spotify_mpd  playlists_track_string  BASE TABLE   \n",
       "\n",
       "  is_insertable_into is_typed                    creation_time  \\\n",
       "0                YES       NO 2022-04-06 17:46:25.801000+00:00   \n",
       "1                YES       NO 2022-04-22 21:11:46.231000+00:00   \n",
       "\n",
       "  base_table_catalog base_table_schema base_table_name snapshot_time_ms  \\\n",
       "0               None              None            None              NaT   \n",
       "1               None              None            None              NaT   \n",
       "\n",
       "                                                 ddl  \n",
       "0  CREATE TABLE `jtotten-project.spotify_mpd.trac...  \n",
       "1  CREATE TABLE `jtotten-project.spotify_mpd.play...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema # we will get the fields out of the ddl field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e820-d1d7-48f9-902d-ad63be9b74fb",
   "metadata": {},
   "source": [
    "## Helper functions to pull metadata from ddl statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e90599-b0e7-41e6-a6e7-99d6668ead55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string type representation to tf data types\n",
    "\n",
    "def conv_dtype_to_tf(dtype_str):\n",
    "    if dtype_str == 'FLOAT64':\n",
    "        return dtypes.float64\n",
    "    elif dtype_str == 'INT64':\n",
    "        return dtypes.int64\n",
    "    else: \n",
    "        return dtypes.string\n",
    "        \n",
    "def get_metadata_from_ddl(ddl, drop_field=None):\n",
    "    fields = []\n",
    "    types = []\n",
    "    ddl = ddl.values[0]\n",
    "    for line in ddl.splitlines():\n",
    "        if line[:1] == ' ': #only pull indented lines for the fields\n",
    "            # drop the comma\n",
    "            line = line.replace(',','')\n",
    "            space_delim = line.split(' ')\n",
    "            if space_delim[2] in drop_field:\n",
    "                pass\n",
    "            else:\n",
    "                fields.append(space_delim[2])\n",
    "                types.append(conv_dtype_to_tf(space_delim[3]))\n",
    "    return fields, types\n",
    "\n",
    "\n",
    "track_audio_fields, track_audio_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'track_audio'], DROP_FIELDS)\n",
    "playlist_fields, playlist_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'playlists_track_string'], DROP_FIELDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd06cfb-66c6-4a18-9e5d-22352317da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : <dtype: 'string'>\n",
      "collaborative : <dtype: 'string'>\n",
      "modified_at : <dtype: 'int64'>\n",
      "num_tracks : <dtype: 'int64'>\n",
      "num_albums : <dtype: 'int64'>\n",
      "num_followers : <dtype: 'int64'>\n",
      "num_edits : <dtype: 'int64'>\n",
      "duration_ms : <dtype: 'int64'>\n",
      "num_artists : <dtype: 'int64'>\n",
      "description : <dtype: 'string'>\n",
      "tracks : <dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(playlist_fields, playlist_types):\n",
    "    print(a +\" : \" + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4667a86-574c-4484-a331-8c9c7ae6fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_name : <dtype: 'string'>\n",
      "track_name : <dtype: 'string'>\n",
      "album_name : <dtype: 'string'>\n",
      "name : <dtype: 'string'>\n",
      "danceability : <dtype: 'float64'>\n",
      "energy : <dtype: 'float64'>\n",
      "key : <dtype: 'float64'>\n",
      "loudness : <dtype: 'float64'>\n",
      "mode : <dtype: 'float64'>\n",
      "speechiness : <dtype: 'float64'>\n",
      "acousticness : <dtype: 'float64'>\n",
      "instrumentalness : <dtype: 'float64'>\n",
      "liveness : <dtype: 'float64'>\n",
      "valence : <dtype: 'float64'>\n",
      "tempo : <dtype: 'float64'>\n",
      "type : <dtype: 'string'>\n",
      "id : <dtype: 'string'>\n",
      "uri : <dtype: 'string'>\n",
      "track_href : <dtype: 'string'>\n",
      "analysis_url : <dtype: 'string'>\n",
      "time_signature : <dtype: 'float64'>\n",
      "artist_pop : <dtype: 'int64'>\n",
      "track_pop : <dtype: 'string'>\n",
      "genres : <dtype: 'string'>\n",
      "duration_ms : <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "# Quick check on data\n",
    "for a, b in zip(track_audio_fields, track_audio_types):\n",
    "    print(a +\" : \" + str(b))\n",
    "    \n",
    "DROP_TRACK_AUDIO_FIELDS = ['pid', 'track_uri', 'artist_uri', 'album_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94ebf1-0080-4cd5-be46-c72af9d3a0e5",
   "metadata": {},
   "source": [
    "### Now the helper functions are set. Below tf.data pipelines are created from bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311dd38e-94c3-4bef-b4b0-e051ba529530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 21:18:14.370201: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-04-22 21:18:14.370632: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-04-22 21:18:14.504737: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "track_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'track_audio'\n",
    "                                    , col_names=track_audio_fields, col_types=track_audio_types, dataset='spotify_mpd', batch_size=10) #we will change to BATCH_SIZE after we test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e5cd5-7f73-419d-9c09-8495e09decab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate we are getting records\n",
    "\n",
    "for line in track_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb806df-3f54-4785-a063-9a416e487ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate playlist data\n",
    "playlist_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'playlists_track_string'\n",
    "                                    , col_names=playlist_fields, col_types=playlist_types, dataset='spotify_mpd', batch_size=1)\n",
    "for line in playlist_train_pipeline.take(1):\n",
    "    print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57822a-235f-4459-a43c-34762964b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class PlaylistsModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, adapt_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        #start with lookups on low cardnality categorical items\n",
    "        colab_vocab = tf.constant(['true','false'], name='colab_vocab', dtype='string')\n",
    "        \n",
    "        self.colab = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=colab_vocab, mask_token=None, name=\"colab_lookup\", output_mode='count')\n",
    "        ], name=\"colab\")\n",
    "        \n",
    "        #create text vectorizors to be fed to an embedding layer\n",
    "        self.artist_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"artist_tv\", ngrams=2)\n",
    "        \n",
    "        self.album_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.description_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.query_embedding = tf.keras.Sequential([\n",
    "            self.album_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"album_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"album_embedding_model\")\n",
    "        \n",
    "        self.artist_embedding = tf.keras.Sequential([\n",
    "            self.artist_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"artist_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"artist_embedding\")\n",
    "        \n",
    "        ###############\n",
    "        ### adapt stuff\n",
    "        ###############\n",
    "        \n",
    "        self.artist_vectorizor.adapt(adapt_data.map(lambda x: x['artist_name']))\n",
    "        self.album_vectorizor.adapt(adapt_data.map(lambda x: x['album_name'])) \n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"dense_layers_query\")\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\", kernel_initializer=initializer))\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, kernel_initializer=initializer))\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, 1, epsilon=1e-12, name=\"normalize_dense\")))\n",
    "\n",
    "\n",
    "    def call(self, data):    \n",
    "        all_embs = tf.concat(\n",
    "                [\n",
    "                    self.album_embedding(data['album_name']),\n",
    "                    self.artist_embedding(data['artist_name']),\n",
    "                    self.colab(data['collaborative']),\n",
    "                    self.description_embedding(data['description'])\n",
    "                ], axis=1)\n",
    "        return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821506a-054e-4ad2-8530-bde59fb5e5d6",
   "metadata": {},
   "source": [
    "## Use the example output to think of how you process your features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83a334-4008-44a8-84f6-f2ef827200db",
   "metadata": {},
   "source": [
    "```\n",
    "OrderedDict([('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm'], dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Carrot Green'], dtype=object)>), ('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'358500'], dtype=object)>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1505692800])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'FeSTa'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([82])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([66])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([48])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([85])>), ('pos', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'45'], dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm - Carrot Green Remix'], dtype=object)>)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a663c63-58be-43bf-a573-e986cce3e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
