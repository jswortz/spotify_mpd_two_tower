{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f523ce16-b93d-4107-8905-f3e07176174c",
   "metadata": {},
   "source": [
    "# Deploy Query Model to online endpoint with Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c8ed5-f34b-44f8-9028-b8b716165b08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Steps in this notebook:\n",
    "\n",
    "* Deploy Query model to online prediction endpoint\n",
    "* Setup model monitoring for online prediction endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10943eed-f2af-4201-9e62-5f2ef91128cb",
   "metadata": {},
   "source": [
    "## Load env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8a1a95-6cd5-4d1f-94a0-d5762ebffaa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ndr-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"                  # TODO\n",
    "PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7964af95-f749-418f-a0b1-4012864aff9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"cpg-cdp\"\n",
      "PROJECT_NUM              = \"939655404703\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"genai-haystack-vpc\"\n",
      "\n",
      "VERTEX_SA                = \"939655404703-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ndr-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "APP                      = \"sp\"\n",
      "MODEL_TYPE               = \"2tower\"\n",
      "FRAMEWORK                = \"tfrs\"\n",
      "DATA_VERSION             = \"v1\"\n",
      "TRACK_HISTORY            = \"5\"\n",
      "\n",
      "BUCKET_NAME              = \"ndr-v1-cpg-cdp-bucket\"\n",
      "BUCKET_URI               = \"gs://ndr-v1-cpg-cdp-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ndr-v1-cpg-cdp-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "CANDIDATE_PREFIX         = \"candidates\"\n",
      "TRAIN_DIR_PREFIX         = \"train\"\n",
      "VALID_DIR_PREFIX         = \"valid\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/939655404703/global/networks/genai-haystack-vpc\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "BQ_TABLE_TRAIN           = \"train_flatten_last_5\"\n",
      "BQ_TABLE_VALID           = \"train_flatten_valid_last_5\"\n",
      "BQ_TABLE_CANDIDATES      = \"candidates\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"ndr-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/cpg-cdp/ndr-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n",
      "SERVING_IMAGE_URI_CPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
      "SERVING_IMAGE_URI_GPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233ca33-d18e-4bba-a016-67b2b691c83d",
   "metadata": {},
   "source": [
    "#### Edit these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0c55f4-97e4-4b22-9ed2-4b3e0149f5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CREATE_NEW_ASSETS     = True # True | False\n",
    "ENABLE_XAI_MONITORING = False # True | False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e0d3f3-3455-4cb1-88fe-cfd97382f5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME : scale-training-v1\n",
      "RUN_NAME        : run-20231116-164100\n",
      "RUN_DIR_PATH    : scale-training-v1/run-20231116-164100\n"
     ]
    }
   ],
   "source": [
    "# local-train-v1/run-20230919-150451/candidates/candidate_embeddings.json\n",
    "\n",
    "EXPERIMENT_NAME       = \"scale-training-v1\"         # local-train-v1\" \n",
    "RUN_NAME              = \"run-20231116-164100\"  # \"run-20230919-150451\"\n",
    "\n",
    "RUN_DIR_PATH = f'{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME        : {RUN_NAME}\")\n",
    "print(f\"RUN_DIR_PATH    : {RUN_DIR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6f278-8edf-4eb7-b355-d85f94bb044e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18bc2342-4c0b-43e0-ac8a-da94d007342e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 13:53:11.535263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-21 13:53:11.535427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-21 13:53:11.681360: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# google cloud SDKs\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import model_monitoring\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# this repo\n",
    "from src.two_tower_jt import test_instances as test_instances\n",
    "from util import feature_set_utils as feature_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831bb4e2-7f81-4f3a-864b-333db47961ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c9a05-7794-40d7-bff2-0ed3cf5a07d7",
   "metadata": {},
   "source": [
    "# Deploy Query Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724761b6-697b-4716-bd60-6e95f0702f3e",
   "metadata": {},
   "source": [
    "## Register Query model to Vertex Model Registry\n",
    "\n",
    "**TODO:** parametrize new vs existing assets\n",
    "\n",
    "```\n",
    "model = vertex_ai.Model.list(filter=f\"display_name=bqml_fraud_classifier\")[-1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42779994-fa65-4469-9d3e-e2edf691fe51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY_MODEL_DIR: gs://ndr-v1-cpg-cdp-bucket/scale-training-v1/run-20231116-164100/model-dir/query_model\n"
     ]
    }
   ],
   "source": [
    "QUERY_MODEL_DIR = f\"{BUCKET_URI}/{RUN_DIR_PATH}/model-dir/query_model\"\n",
    "\n",
    "print(f\"QUERY_MODEL_DIR: {QUERY_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b220ea-8c86-4349-9d1f-efa83a8cfd15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ndr-v1-cpg-cdp-bucket/scale-training-v1/run-20231116-164100/model-dir/query_model/\n",
      "gs://ndr-v1-cpg-cdp-bucket/scale-training-v1/run-20231116-164100/model-dir/query_model/saved_model.pb\n",
      "gs://ndr-v1-cpg-cdp-bucket/scale-training-v1/run-20231116-164100/model-dir/query_model/assets/\n",
      "gs://ndr-v1-cpg-cdp-bucket/scale-training-v1/run-20231116-164100/model-dir/query_model/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $QUERY_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12da6c87-988d-47a6-8b87-0644edd5a5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/939655404703/locations/us-central1/models/8534899636983300096/operations/134669764717969408\n",
      "Model created. Resource name: projects/939655404703/locations/us-central1/models/8534899636983300096@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/939655404703/locations/us-central1/models/8534899636983300096@1')\n",
      "display_name         : query_model_two-tower-query-model-nov-2023-v2\n",
      "\n",
      "uploaded_query_model : <google.cloud.aiplatform.models.Model object at 0x7f62c2847610> \n",
      "resource name: projects/939655404703/locations/us-central1/models/8534899636983300096\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_NAME = \"two-tower-query-model-nov-2023-v2\"\n",
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    uploaded_query_model = vertex_ai.Model.upload(\n",
    "        display_name=f'query_model_{DISPLAY_NAME}',\n",
    "        artifact_uri=QUERY_MODEL_DIR,\n",
    "        serving_container_image_uri=SERVING_IMAGE_URI_CPU,\n",
    "        description=\"Top of the query tower, meant to return an embedding for each playlist instance\",\n",
    "        sync=True,\n",
    "    )\n",
    "else:\n",
    "    # use existing\n",
    "    uploaded_query_model = vertex_ai.Model('projects/934903580331/locations/us-central1/models/2404541769992634368@1')\n",
    "\n",
    "print(f\"display_name         : {uploaded_query_model.display_name}\\n\")\n",
    "print(f\"uploaded_query_model : {uploaded_query_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35268707-4be6-43ed-a8de-e95e2fc4e046",
   "metadata": {},
   "source": [
    "## Deploy registered model to online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa3fc4-2889-4de4-bb95-d7fe2b9905a2",
   "metadata": {},
   "source": [
    "**Create model endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0af496a-7ebd-4cc9-ae1a-b29e205c15ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name : endpoint_two-tower-query-model-nov-2023-v2\n",
      "\n",
      "endpoint     : <google.cloud.aiplatform.models.Endpoint object at 0x7f2411906c80> \n",
      "resource name: projects/939655404703/locations/us-central1/endpoints/6476864558437761024\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE = 1.0\n",
    "BQ_PREDICTION_LOG_TABLE = f\"{PROJECT_ID}.{BQ_DATASET}.req_resp\"\n",
    "\n",
    "if CREATE_NEW_ASSETS == True:\n",
    "\n",
    "    endpoint = vertex_ai.Endpoint.create(\n",
    "        display_name=f'endpoint_{DISPLAY_NAME}',\n",
    "        project=PROJECT_ID,\n",
    "        location=LOCATION,\n",
    "        enable_request_response_logging=True,\n",
    "        request_response_logging_sampling_rate=SAMPLE_RATE,\n",
    "        request_response_logging_bq_destination_table=f\"bq://{BQ_PREDICTION_LOG_TABLE}\",\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    endpoint = vertex_ai.Endpoint('projects/939655404703/locations/us-central1/endpoints/6476864558437761024')\n",
    "\n",
    "print(f\"display_name : {endpoint.display_name}\\n\")\n",
    "print(f\"endpoint     : {endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e93ad1-b812-491b-8ed2-b2c47fd3a5b9",
   "metadata": {},
   "source": [
    "**Deploy to endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fe6b3-095c-4473-971f-3e2d71e13f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CREATE_NEW_ASSETS == False:\n",
    "    \n",
    "    deployed_query_model = uploaded_query_model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=f'deployed_qmodel_{DISPLAY_NAME}',\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        accelerator_type=None,\n",
    "        accelerator_count=0,\n",
    "        sync=True,\n",
    "        traffic_percentage=100\n",
    "    )\n",
    "\n",
    "else:\n",
    "    deployed_query_model = vertex_ai.Endpoint('projects/939655404703/locations/us-central1/endpoints/6476864558437761024')\n",
    "\n",
    "print(f\"display_name         : {deployed_query_model.display_name}\\n\")\n",
    "print(f\"deployed_query_model : {deployed_query_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea3d7a-7bae-46f0-8d3a-d45037db6410",
   "metadata": {},
   "source": [
    "#### list all model endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121573c3-a437-4856-8802-11769ecec489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_of_model_endpoints = deployed_query_model.list()\n",
    "# list_of_model_endpoints[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1658136-11f3-4140-846d-2ed779d43f93",
   "metadata": {},
   "source": [
    "#### list all models on a single endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c79c85-f933-406c-825b-cec39777af39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_of_model_endpoints = deployed_query_model.list_models()\n",
    "# list_of_model_endpoints #[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c97c86-2552-4e7f-abbe-59751353d883",
   "metadata": {},
   "source": [
    "## Centralized Model Monitoring - Create a Model Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b798df8-fa9e-4c89-96df-8cbc717264ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proto-plus module google.cloud.aiplatform.private_preview.centralized_model_monitoring.types.types has a declared manifest but Tensor is not in it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ModelMonitor\n",
      "Create ModelMonitor backing LRO: projects/939655404703/locations/us-central1/modelMonitors/3660300597145370624/operations/7898875522304704512\n",
      "ModelMonitor created. Resource name: projects/939655404703/locations/us-central1/modelMonitors/3660300597145370624\n",
      "To use this ModelMonitor in another session:\n",
      "model_monitor = aiplatform.ModelMonitor('projects/939655404703/locations/us-central1/modelMonitors/3660300597145370624')\n",
      "MODEL MONITOR 3660300597145370624 created.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.private_preview.centralized_model_monitoring import model_monitor\n",
    "\n",
    "MODEL_VERSION_ID = \"1\"\n",
    "MONITOR_DISPLAY_NAME=\"query_model_spotify_monitor\"\n",
    "\n",
    "my_model_monitor = model_monitor.ModelMonitor.create(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    display_name=MONITOR_DISPLAY_NAME,\n",
    "    model_name=uploaded_query_model.resource_name,\n",
    "    model_version_id=MODEL_VERSION_ID)\n",
    "MODEL_MONITOR_RESOURCE_NAME = my_model_monitor.name\n",
    "print(f\"MODEL MONITOR {MODEL_MONITOR_RESOURCE_NAME} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4b98f-edef-4827-8fed-fbe5d875e7b7",
   "metadata": {},
   "source": [
    "#### Define the drift detection configuration\n",
    "\n",
    "With the drift detection configuration, you define the input features and the associated thresholds for monitoring feature distribution drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0408a464-e255-461a-9be6-d0321ee9bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_names\n",
    "feature_names = ['pl_duration_ms_new'\n",
    "                  ,'num_pl_songs_new'\n",
    "                  ,'num_pl_artists_new'\n",
    "                  ,'num_pl_albums_new'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5783284c-c561-4098-bb38-13fe9a4f84ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_thresholds      : {'pl_duration_ms_new': 0.05, 'num_pl_songs_new': 0.05, 'num_pl_artists_new': 0.05, 'num_pl_albums_new': 0.05}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DRIFT_THRESHOLD_VALUE = 0.05\n",
    "ATTRIBUTION_DRIFT_THRESHOLD_VALUE = 0.05\n",
    "\n",
    "# =========================== #\n",
    "##   Feature value drift     ##\n",
    "# =========================== #\n",
    "drift_thresholds = dict()\n",
    "\n",
    "for feature in feature_names:\n",
    "    if feature in drift_thresholds:\n",
    "        print(\"feature name already in dict\")\n",
    "    else:\n",
    "        drift_thresholds[feature] = DRIFT_THRESHOLD_VALUE\n",
    "        \n",
    "print(f\"drift_thresholds      : {drift_thresholds}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "740555ea-c30f-4df9-8aea-956c3ad2c9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TIMESTAMP = pd.Timestamp.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "DEFAULT_THRESHOLD_VALUE = 0.001\n",
    "EMAIL = 'jwortz@google.com'\n",
    "JOB_DISPLAY_NAME = f\"spotify_query_model_monitoring_job_{TIMESTAMP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffc128e8-96e8-4e58-9772-69cfce2ec538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelMonitoringJob created. Resource name: projects/939655404703/locations/us-central1/modelMonitors/3660300597145370624/modelMonitoringJobs/5662854318953332736\n",
      "To use this ModelMonitoringJob in another session:\n",
      "model_monitoring_job = aiplatform.ModelMonitoringJob('projects/939655404703/locations/us-central1/modelMonitors/3660300597145370624/modelMonitoringJobs/5662854318953332736')\n",
      "Model Monitoring Job projects/939655404703/locations/us-central1/modelMonitors/3660300597145370624/modelMonitoringJobs/5662854318953332736 created.\n"
     ]
    }
   ],
   "source": [
    "model_monitoring_job=my_model_monitor.run(\n",
    "    display_name=JOB_DISPLAY_NAME,\n",
    "    objective_config=model_monitor.spec.ObjectiveSpec(\n",
    "        baseline=model_monitor.spec.MonitoringInput(\n",
    "            table_uri=f\"bq://{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_VALID}\"\n",
    "        ),\n",
    "        target=model_monitor.spec.MonitoringInput(\n",
    "            endpoints=[endpoint.resource_name]\n",
    "        ),\n",
    "        feature_distribution_skew=model_monitor.spec.SkewSpec(\n",
    "            default_threshold=DEFAULT_THRESHOLD_VALUE,\n",
    "            feature_thresholds=drift_thresholds,\n",
    "            # The data window of the serving data is \"2h\", indicating the selection of '2-hour' data windows before the current time for analysis.\n",
    "            window=\"2h\")\n",
    "    ),\n",
    "    notification_config=model_monitor.spec.NotificationSpec(\n",
    "        user_emails=[EMAIL],\n",
    "    ),\n",
    "    output_config=model_monitor.spec.OutputSpec(\n",
    "        gcs_base_dir=BUCKET_URI\n",
    "    )\n",
    ")\n",
    "\n",
    "CMM_JOB_RESOURCE_NAME = model_monitoring_job.name\n",
    "print(f\"Model Monitoring Job {CMM_JOB_RESOURCE_NAME} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f453a-48ce-4542-b944-e3ab8551c106",
   "metadata": {},
   "source": [
    "## Create Scheduled Model Monitoring Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc955056-b03e-46b0-bf88-f6222edd2e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CRON=\"0 * * * *\" # @param {type:\"string\"} Every 1 hour at :00, for example 1:00, 2:00..\n",
    "DATA_WINDOW=\"1h\"\n",
    "SCHEDULE_DISPLAY_NAME=\"query-endpoint-spotify-hourly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d59e2d37-3172-4f04-9eaf-0d965c75b647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule projects/939655404703/locations/us-central1/schedules/1465305952197541888 created.\n"
     ]
    }
   ],
   "source": [
    "model_monitoring_schedule=my_model_monitor.create_schedule(\n",
    "    display_name=SCHEDULE_DISPLAY_NAME,\n",
    "    cron=CRON,\n",
    "    objective_config=model_monitor.spec.ObjectiveSpec(\n",
    "        baseline=model_monitor.spec.MonitoringInput(\n",
    "            table_uri=f\"bq://{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_VALID}\"\n",
    "        ),\n",
    "        target=model_monitor.spec.MonitoringInput(\n",
    "            endpoints=[endpoint.resource_name]\n",
    "        ),\n",
    "        feature_distribution_skew=model_monitor.spec.SkewSpec(\n",
    "            default_threshold=DEFAULT_THRESHOLD_VALUE,\n",
    "            feature_thresholds=drift_thresholds,\n",
    "            # The data window of the serving data is \"2h\", indicating the selection of '2-hour' data windows before the current time for analysis.\n",
    "            window=\"2h\")\n",
    "    ),\n",
    "    notification_config=model_monitor.spec.NotificationSpec(\n",
    "        user_emails=[EMAIL],\n",
    "    ),\n",
    "    output_config=model_monitor.spec.OutputSpec(\n",
    "        gcs_base_dir=BUCKET_URI\n",
    "    )\n",
    ")\n",
    "\n",
    "SCHEDULE_RESOURCE_NAME = model_monitoring_schedule.name\n",
    "print(f\"Schedule {SCHEDULE_RESOURCE_NAME} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e143b-df43-4bbb-b2be-967463b3d612",
   "metadata": {},
   "source": [
    "# Test endpoint deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19318841-f6e1-42d9-9210-148bc6b98932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRACK_HISTORY == '5':\n",
    "    TEST_INSTANCE = test_instances.TEST_INSTANCE_5\n",
    "elif TRACK_HISTORY == '15':\n",
    "    TEST_INSTANCE = test_instances.TEST_INSTANCE_15\n",
    "else:\n",
    "    TEST_INSTANCE = None\n",
    "    print(\"Track History length not supported\")\n",
    "    \n",
    "# TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b8faa-960a-49a1-afc8-a88a01597890",
   "metadata": {},
   "source": [
    "### Make prediction request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113da48-48a6-4492-a529-dee96ba1d8b3",
   "metadata": {},
   "source": [
    "test single prediction request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d279b029-dd5e-428f-876a-5fa617a9fcae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5727675, -0.478426367, -1.48506081, 1.63012981, 0.207987741, -1.07165945, 0.708537221, 0.973639607, -1.31733668, 0.430333912, 0.203536034, -0.991817415, -0.336415708, -0.364583969, 0.748859465, 0.32331267, -0.832917809, -0.1681014, 1.14483774, 1.42354131, -1.06543791, -0.393461972, -0.503103, 0.265378535, -0.196776718, 1.4200505, -0.852416337, 0.825526357, -0.284980953, -0.307609379, -0.0755918175, 0.626654208, -0.809113801, 0.353907973, -0.26276, -0.425157845, 0.919185758, -0.883253396, -0.334266454, 1.21176898, -0.112918615, 1.55699313, 1.79519391, -0.370241284, 0.287336051, -1.1449461, 1.0705148, -1.44784117, -1.67035174, -0.303792179, 0.358365715, 0.329541594, -0.668701887, 1.60419786, 1.69286656, 0.637520313, -1.33965516, -0.627404153, -1.1610347, -0.188887462, -0.617347896, -0.45977819, -1.65789604, -0.817034066, 0.0378097594, 0.906091452, 0.81617105, 1.2639792, 1.71842718, 1.15019393, 0.489773244, -0.546301603, 1.07499707, 0.187670663, 0.961778045, -0.759879291, -0.197109252, -0.550823748, -0.128608525, -1.84402454, -1.94311666, -1.2685951, 1.07838976, 2.46617961, -0.391459405, -1.65680921, 0.072773926, 0.71333766, -1.15422606, 0.30595842, 0.61505568, -0.939558625, 1.37869763, 0.956505597, 0.442029148, -1.09575033, -1.17008197, -1.80906761, 0.660537183, -0.239028126, -0.821756601, 0.861768067, 0.197680816, -0.82983011, -1.29799271, -1.4874078, 0.434547335, 0.210091218, 0.194568634, -1.21892774, 0.571735322, 0.369953841, 1.43708932, 0.214307457, -1.80786812, 0.101817794, 3.26022601, 0.074109368, 0.941662431, 0.337954223, -1.3254354, 1.31393206, -0.775485277, -0.618441701, -0.451179892, -0.757006407, -0.292376548, 1.64862716]\n"
     ]
    }
   ],
   "source": [
    "response = endpoint.predict(instances=[TEST_INSTANCE])\n",
    "\n",
    "prediction = response[0]\n",
    "\n",
    "# print the prediction for the first instance\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06916856-115c-4f0f-8e0f-c52edee8ddc9",
   "metadata": {},
   "source": [
    "### Write (many) test instances to file\n",
    "\n",
    "> test endpoint monitoring with >= 1000 prediction requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b63e4dc-5796-4692-8654-366a1d3e962f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED_REQUEST_N : 50\n",
      "INTERVAL       : 25\n"
     ]
    }
   ],
   "source": [
    "PRED_REQUEST_N = 50\n",
    "INTERVAL       = PRED_REQUEST_N // 2\n",
    "SKIP_N         = INTERVAL\n",
    "\n",
    "print(f\"PRED_REQUEST_N : {PRED_REQUEST_N}\")\n",
    "print(f\"INTERVAL       : {INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e69b724-110e-47f4-a161-3ffeac3d6820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "valid_parsed = valid.map(feature_utils.parse_towers_tfrecord)\n",
    "# valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3337331-5dda-459b-a788-78ea5632dc94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "subset_val = valid_parsed.skip(SKIP_N).take(PRED_REQUEST_N)\n",
    "\n",
    "list_of_dicts = []\n",
    "\n",
    "for tensor_dict in subset_val:\n",
    "    list_dict = {}\n",
    "    td_keys = tensor_dict.keys()\n",
    "    for k in td_keys:\n",
    "        \n",
    "        value = tensor_dict[k].numpy()\n",
    "        \n",
    "        if type(value) == bytes:\n",
    "\n",
    "            list_dict.update({k: value.decode()})\n",
    "        \n",
    "        elif type(value) == numpy.ndarray:\n",
    "            \n",
    "            if type(value[0]) != bytes:\n",
    "                list_dict.update({k: value.tolist()})\n",
    "            else:\n",
    "\n",
    "                tmp_list = []\n",
    "\n",
    "                for ele in value:\n",
    "                    tmp_list.append(ele.decode())\n",
    "\n",
    "                list_dict.update({k: tmp_list})\n",
    "                \n",
    "        elif type(value) == numpy.float32:\n",
    "            list_dict.update({k: value.item()})\n",
    "                \n",
    "        else:\n",
    "            list_dict.update({k: value})\n",
    "            \n",
    "        list_of_dicts.append(list_dict)\n",
    "    \n",
    "# list_dict\n",
    "len(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af75be56-86ef-4122-9dfd-6ed60e4952b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 prediciton requests..\n",
      "50 prediciton requests..\n",
      "75 prediciton requests..\n",
      "100 prediciton requests..\n",
      "125 prediciton requests..\n",
      "150 prediciton requests..\n",
      "175 prediciton requests..\n",
      "200 prediciton requests..\n",
      "225 prediciton requests..\n",
      "250 prediciton requests..\n",
      "275 prediciton requests..\n",
      "300 prediciton requests..\n",
      "325 prediciton requests..\n",
      "350 prediciton requests..\n",
      "375 prediciton requests..\n",
      "400 prediciton requests..\n",
      "425 prediciton requests..\n",
      "450 prediciton requests..\n",
      "475 prediciton requests..\n",
      "500 prediciton requests..\n",
      "525 prediciton requests..\n",
      "550 prediciton requests..\n",
      "575 prediciton requests..\n",
      "600 prediciton requests..\n",
      "625 prediciton requests..\n",
      "650 prediciton requests..\n",
      "675 prediciton requests..\n",
      "700 prediciton requests..\n",
      "725 prediciton requests..\n",
      "750 prediciton requests..\n",
      "775 prediciton requests..\n",
      "800 prediciton requests..\n",
      "825 prediciton requests..\n",
      "850 prediciton requests..\n",
      "875 prediciton requests..\n",
      "900 prediciton requests..\n",
      "925 prediciton requests..\n",
      "950 prediciton requests..\n",
      "975 prediciton requests..\n",
      "1000 prediciton requests..\n",
      "1025 prediciton requests..\n",
      "1050 prediciton requests..\n",
      "1075 prediciton requests..\n",
      "1100 prediciton requests..\n",
      "1125 prediciton requests..\n",
      "1150 prediciton requests..\n",
      "1175 prediciton requests..\n",
      "1200 prediciton requests..\n",
      "1225 prediciton requests..\n",
      "1250 prediciton requests..\n",
      "1275 prediciton requests..\n",
      "1300 prediciton requests..\n",
      "1325 prediciton requests..\n",
      "1350 prediciton requests..\n",
      "1375 prediciton requests..\n",
      "1400 prediciton requests..\n",
      "1425 prediciton requests..\n",
      "1450 prediciton requests..\n",
      "1475 prediciton requests..\n",
      "1500 prediciton requests..\n",
      "1525 prediciton requests..\n",
      "1550 prediciton requests..\n",
      "1575 prediciton requests..\n",
      "1600 prediciton requests..\n",
      "1625 prediciton requests..\n",
      "1650 prediciton requests..\n",
      "1675 prediciton requests..\n",
      "1700 prediciton requests..\n",
      "1725 prediciton requests..\n",
      "1750 prediciton requests..\n",
      "1775 prediciton requests..\n",
      "1800 prediciton requests..\n",
      "1825 prediciton requests..\n",
      "1850 prediciton requests..\n",
      "1875 prediciton requests..\n",
      "1900 prediciton requests..\n",
      "1925 prediciton requests..\n",
      "1950 prediciton requests..\n",
      "1975 prediciton requests..\n",
      "2000 prediciton requests..\n",
      "2025 prediciton requests..\n",
      "2050 prediciton requests..\n",
      "2075 prediciton requests..\n",
      "2100 prediciton requests..\n",
      "2125 prediciton requests..\n",
      "2150 prediciton requests..\n",
      "2175 prediciton requests..\n",
      "2200 prediciton requests..\n",
      "2225 prediciton requests..\n",
      "2250 prediciton requests..\n",
      "2275 prediciton requests..\n",
      "2300 prediciton requests..\n",
      "2325 prediciton requests..\n",
      "2350 prediciton requests..\n",
      "2375 prediciton requests..\n",
      "2400 prediciton requests..\n",
      "2425 prediciton requests..\n",
      "2450 prediciton requests..\n",
      "2475 prediciton requests..\n",
      "2500 prediciton requests..\n",
      "2525 prediciton requests..\n",
      "2550 prediciton requests..\n",
      "2575 prediciton requests..\n",
      "[-0.0642908737, -0.562390268, 0.708521724, -2.96538281, -0.625948429, -0.29556185, 2.00112557, 0.184278458, 0.988007843, -0.12059591, 0.331397444, 0.712384164, -0.904397368, -0.148389056, -0.222270012, 1.14395905, 0.193404168, -0.735904515, -0.366130471, -0.263506144, 2.11705375, -0.210492745, -1.60381615, -0.557619512, 0.393995225, -0.107131079, -0.05147, 1.27135408, 0.475824863, -0.360078841, 0.695937574, -1.75949848, 0.209390759, -0.0665192, 0.195576549, 0.0699933097, -0.149457887, 0.380210936, 0.628898382, -1.09161615, -0.18470706, 0.0107769985, -1.69841909, -1.34287953, -1.7580688, -0.153499827, -0.530629277, 0.40556246, 2.21220946, 0.941983044, -0.638499498, -0.145725116, 0.797581792, 0.473945439, -0.555979133, 0.446066529, -0.853077352, -1.44557238, 0.093569465, 0.441685855, -0.0262860786, -0.0584072061, 0.618442953, 0.832591951, 1.19607556, 0.394089758, 0.0938161686, -1.50131202, -1.78426135, -0.276905477, -0.804554462, -0.0405820757, -0.443919897, -0.177272, -2.3038342, -1.1577673, -0.106173515, 1.07192254, 0.838054299, -0.368584275, 0.395161599, 1.02057111, 0.169684365, -2.04744554, -0.194932491, 2.41372681, 0.655805111, -0.999868274, 0.457070678, 0.455517977, -0.285293341, 0.253815413, -1.09837401, -0.574448287, 0.79857868, 0.694397509, 0.293612391, 0.893185735, -0.294510961, 0.340432942, 0.572906613, -1.00773585, 0.711198628, -1.17490971, -0.221902102, 0.577271, -0.692467, -0.671529889, -0.0990393, 1.86147141, -1.0560534, 0.540824413, 0.220808417, 2.19990039, 2.86771321, -0.372099, -2.2455, 0.118872479, 0.627804637, -0.474634558, 0.847263873, -0.0768913925, 2.1024456, -0.0330412, 0.183143795, -0.336133242, 0.12085747, -0.191475406]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for test in list_of_dicts:\n",
    "    response = endpoint.predict(instances=[test])\n",
    "    \n",
    "    if count > 0 and count % INTERVAL == 0:\n",
    "        print(f\"{count} prediciton requests..\")\n",
    "        \n",
    "    count += 1\n",
    "    \n",
    "prediction = response[0]\n",
    "# print the prediction for the first instance\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4fe2e2-ff4f-4135-8e02-894c406975ab",
   "metadata": {},
   "source": [
    "### Save test instances to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a59f282-7b36-4741-b3a4-7aa08441a209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "LOCAL_INSTANCE_FILE = 'test_instance_list.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "230b7816-94ba-432f-a54d-d246d5315bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filehandler = open(LOCAL_INSTANCE_FILE, 'wb')\n",
    "pkl.dump(list_of_dicts, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d65169c-a9ae-4537-b6ee-38c4cdddc568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filehandler = open(LOCAL_INSTANCE_FILE, 'rb')\n",
    "LIST_OF_INSTANCES = pkl.load(filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a54b6c2-2a68-4e7e-b4fc-5bef6903c871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIST_OF_INSTANCES[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcb203a9-8e92-431d-9a70-6ba922e11a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ndr-v1-cpg-cdp-bucket/endpoint-tests/test_instance_list.pkl\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_TEST_SUBDIR = \"endpoint-tests\"\n",
    "\n",
    "!gsutil -q cp $LOCAL_INSTANCE_FILE $BUCKET_URI/$ENDPOINT_TEST_SUBDIR/$LOCAL_INSTANCE_FILE\n",
    "\n",
    "!gsutil ls $BUCKET_URI/$ENDPOINT_TEST_SUBDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e0e55-c935-419d-ba08-12b31fd9dc24",
   "metadata": {},
   "source": [
    "## Create skewed online query traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "703c3579-dcc0-4884-9370-cadbada868f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENERATE_NEW_STATS       = True # True | False\n",
    "SKEW_FEATURES_STATS_FILE = 'skew_feat_stats.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08ee60e2-6574-4835-a197-0718574d3e92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 0\n",
      "mean_durations : 16840084.0\n",
      "std_durations : 15045907.0\n",
      "mean_num_songs : 71.39299774169922\n",
      "std_num_songs  : 61.79998779296875\n",
      "mean_num_artists : 35.209999084472656\n",
      "std_num_artists  : 29.72267723083496\n",
      "mean_num_albums : 41.86000061035156\n",
      "std_num_albums  : 36.4605598449707\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_NEW_STATS:\n",
    "    \n",
    "    valid_files = []\n",
    "    for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "        if '.tfrecords' in blob.name:\n",
    "            valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "    valid = tf.data.TFRecordDataset(valid_files)\n",
    "    valid_parsed = valid.map(feature_utils.parse_towers_tfrecord)\n",
    "    \n",
    "    PRED_REQUEST_N = 5000\n",
    "    valid_parsed = valid_parsed.take(PRED_REQUEST_N)\n",
    "    \n",
    "    # feature\n",
    "    start_time = time.time()\n",
    "\n",
    "    durations = np.concatenate(list(valid_parsed.map(lambda x: x[\"pl_duration_ms_new\"]).batch(100)))\n",
    "    mean_durations = durations.mean()\n",
    "    std_durations = durations.std()\n",
    "\n",
    "    num_songs = np.concatenate(list(valid_parsed.map(lambda x: x[\"num_pl_songs_new\"]).batch(100)))\n",
    "    mean_num_songs = num_songs.mean()\n",
    "    std_num_songs = num_songs.std()\n",
    "\n",
    "    num_artists = np.concatenate(list(valid_parsed.map(lambda x: x[\"num_pl_artists_new\"]).batch(100)))\n",
    "    mean_num_artists = num_artists.mean()\n",
    "    std_num_artists = num_artists.std()\n",
    "\n",
    "    num_albums = np.concatenate(list(valid_parsed.map(lambda x: x[\"num_pl_albums_new\"]).batch(100)))\n",
    "    mean_num_albums = num_albums.mean()\n",
    "    std_num_albums = num_albums.std()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = int((end_time - start_time) / 60)\n",
    "    print(f\"elapsed_time: {elapsed_time}\")\n",
    "    \n",
    "    SKEW_FEATURES = {\n",
    "        'pl_duration_ms_new': (mean_durations, std_durations),\n",
    "        'num_pl_songs_new': (mean_num_songs, std_num_songs),\n",
    "        'num_pl_artists_new': (mean_num_artists, std_num_artists),\n",
    "        'num_pl_albums_new': (mean_num_albums, std_num_albums),\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    \n",
    "    filehandler = open(SKEW_FEATURES_STATS_FILE, 'rb')\n",
    "    SKEW_FEATURES = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    mean_durations, std_durations = SKEW_FEATURES['pl_duration_ms_new']\n",
    "    mean_num_songs, std_num_songs = SKEW_FEATURES['num_pl_songs_new']\n",
    "    mean_num_artists, std_num_artists = SKEW_FEATURES['num_pl_artists_new']\n",
    "    mean_num_albums, std_num_albums = SKEW_FEATURES['num_pl_albums_new']\n",
    "\n",
    "print(f\"mean_durations : {mean_durations}\")\n",
    "print(f\"std_durations : {std_durations}\")\n",
    "\n",
    "print(f\"mean_num_songs : {mean_num_songs}\")\n",
    "print(f\"std_num_songs  : {std_num_songs}\")\n",
    "\n",
    "print(f\"mean_num_artists : {mean_num_artists}\")\n",
    "print(f\"std_num_artists  : {std_num_artists}\")\n",
    "\n",
    "print(f\"mean_num_albums : {mean_num_albums}\")\n",
    "print(f\"std_num_albums  : {std_num_albums}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cf6da2a-f183-4e4e-83d8-193fff2b3d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monitoring_test(endpoint, instances, skew_feat_stat, start=2, end=4):\n",
    "    \n",
    "    mean_durations, std_durations = skew_feat_stat['pl_duration_ms_new']\n",
    "    mean_num_songs, std_num_songs = skew_feat_stat['num_pl_songs_new']\n",
    "    mean_num_artists, std_num_artists = skew_feat_stat['num_pl_artists_new']\n",
    "    mean_num_albums, std_num_albums = skew_feat_stat['num_pl_albums_new']\n",
    "    print(f\"std_durations   : {round(std_durations, 0)}\")\n",
    "    print(f\"std_num_songs   : {round(std_num_songs, 0)}\")\n",
    "    print(f\"std_num_artists : {round(std_num_artists, 0)}\")\n",
    "    print(f\"std_num_albums  : {round(std_num_albums, 0)}\\n\")\n",
    "    \n",
    "    total_preds = 0\n",
    "    \n",
    "    for multiplier in range(start, end+1):\n",
    "\n",
    "        print(f\"multiplier: {multiplier}\")\n",
    "\n",
    "        pred_count = 0\n",
    "\n",
    "        for example in instances:\n",
    "            list_dict = {}\n",
    "\n",
    "            example['pl_duration_ms_new'] = round(std_durations * multiplier, 0)\n",
    "            example['num_pl_songs_new'] = round(std_num_songs * multiplier, 0)\n",
    "            example['num_pl_artists_new'] = round(std_num_artists * multiplier, 0)\n",
    "            example['num_pl_albums_new'] = round(std_num_albums * multiplier, 0)\n",
    "            # list_of_skewed_instances.append(example)\n",
    "\n",
    "            response = endpoint.predict(instances=[example])\n",
    "\n",
    "            if pred_count > 0 and pred_count % 250 == 0:\n",
    "                print(f\"pred_count: {pred_count}\")\n",
    "\n",
    "            pred_count += 1\n",
    "            total_preds += 1\n",
    "\n",
    "        print(f\"sent {pred_count} pred requests with {multiplier}X multiplier\")\n",
    "    \n",
    "    print(f\"sent {total_preds} total pred requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5326c-fc06-49cc-a7f9-546f878a4f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_durations   : 15045907.0\n",
      "std_num_songs   : 62.0\n",
      "std_num_artists : 30.0\n",
      "std_num_albums  : 36.0\n",
      "\n",
      "multiplier: 2\n",
      "pred_count: 250\n",
      "pred_count: 500\n",
      "pred_count: 750\n",
      "pred_count: 1000\n",
      "pred_count: 1250\n",
      "pred_count: 1500\n",
      "pred_count: 1750\n",
      "pred_count: 2000\n",
      "pred_count: 2250\n",
      "pred_count: 2500\n",
      "sent 2600 pred requests with 2X multiplier\n",
      "multiplier: 3\n",
      "pred_count: 250\n",
      "pred_count: 500\n",
      "pred_count: 750\n",
      "pred_count: 1000\n",
      "pred_count: 1250\n",
      "pred_count: 1500\n",
      "pred_count: 1750\n",
      "pred_count: 2000\n",
      "pred_count: 2250\n",
      "pred_count: 2500\n",
      "sent 2600 pred requests with 3X multiplier\n",
      "multiplier: 4\n",
      "pred_count: 250\n",
      "pred_count: 500\n",
      "pred_count: 750\n",
      "pred_count: 1000\n",
      "pred_count: 1250\n",
      "pred_count: 1500\n",
      "pred_count: 1750\n",
      "pred_count: 2000\n",
      "pred_count: 2250\n",
      "pred_count: 2500\n",
      "sent 2600 pred requests with 4X multiplier\n",
      "multiplier: 5\n",
      "pred_count: 250\n",
      "pred_count: 500\n",
      "pred_count: 750\n",
      "pred_count: 1000\n",
      "pred_count: 1250\n",
      "pred_count: 1500\n",
      "pred_count: 1750\n",
      "pred_count: 2000\n",
      "pred_count: 2250\n",
      "pred_count: 2500\n",
      "sent 2600 pred requests with 5X multiplier\n",
      "sent 10400 total pred requests\n",
      "Sleeping for  472  seconds\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    monitoring_test(\n",
    "        endpoint=endpoint, \n",
    "        instances=LIST_OF_INSTANCES,\n",
    "        skew_feat_stat=SKEW_FEATURES,\n",
    "        start=2, \n",
    "        end=5\n",
    "    )\n",
    "    random_sleep_time = np.random.randint(3600*0.5)\n",
    "    print(\"Sleeping for \", random_sleep_time, \" seconds\")\n",
    "    time.sleep(random_sleep_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd5a1d-4066-475b-acca-e0e32c2c07dc",
   "metadata": {},
   "source": [
    "# (Optional): Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50fc72a8-a0cf-4499-9358-b423a4c06bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# When no jobs are running, delete the schedule and all the jobs.\n",
    "my_model_monitor.delete_schedule(SCHEDULE_RESOURCE_NAME)\n",
    "my_model_monitor.delete_all_model_monitoring_jobs()\n",
    "my_model_monitor.delete()\n",
    "\n",
    "# Undeploy the model and delete the endpoint\n",
    "endpoint.undeploy_all()\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the model\n",
    "uploaded_query_model.delete()\n",
    "\n",
    "# Delete BQ logging table\n",
    "bqclient = bigquery.Client(project=PROJECT_ID)\n",
    "# Delete the dataset (including all tables)\n",
    "bqclient.delete_table(BQ_PREDICTION_LOG_TABLE, not_found_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376728a1-380e-4e44-b14e-66e20a1b9082",
   "metadata": {},
   "source": [
    "### Learn more about model monitoring\n",
    "\n",
    "**Congratulations!** You've now learned what model monitoring is, how to configure and enable it, and how to find and interpret the results. Check out the following resources to learn more about model monitoring and ML Ops.\n",
    "\n",
    "- [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv)\n",
    "- [Data Understanding, Validation, and Monitoring At Scale](https://blog.tensorflow.org/2018/09/introducing-tensorflow-data-validation.html)\n",
    "- [Vertex Product Documentation](https://cloud.google.com/vertex-ai)\n",
    "- [Vertex AI Model Monitoring Reference Docs](https://cloud.google.com/vertex-ai/docs/reference)\n",
    "- [Vertex AI Model Monitoring blog article](https://cloud.google.com/blog/topics/developers-practitioners/monitor-models-training-serving-skew-vertex-ai)\n",
    "- [Explainable AI Whitepaper](https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
