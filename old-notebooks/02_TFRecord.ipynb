{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5383b2-071e-45b8-af2c-2421eb4f923a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Two - Tower Retreival Model\n",
    "\n",
    "### Key resources:\n",
    "* Many pages [here](https://www.tensorflow.org/recommenders/examples/deep_recommenders) include great techniques to build custom TFRS Models\n",
    "\n",
    "### Goals:\n",
    "* Show how to model off of most data types \n",
    "  * (String, Existing Embeddings (vectors), \n",
    "  * Floats (Normalized), \n",
    "  * Categorical with vocab, \n",
    "  * High Dim Categorical (Embed)\n",
    "* Leverage class templates to create custom 2 Tower Models quick/easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52e5f-a13b-46a7-849a-dc188b455a86",
   "metadata": {},
   "source": [
    "## SPOTIFY Create the tensorflow.io interface for the event and product table in Bigquery\n",
    "Best practices from Google are in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312070aa-00ae-467b-8747-0fefac329474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://spotify-tfrecords-blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3122eb-564b-46f9-9a50-851d19301521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "DROPOUT = False\n",
    "DROPOUT_RATE = 0.2\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_TOKENS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "ARCH = [128, 64]\n",
    "NUM_EPOCHS = 1\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "DROP_FIELDS = ['modified_at', 'row_number', 'seed_playlist_tracks']\n",
    "N_RECORDS_PER_TFRECORD_FILE = 15000 #100ish mb  \n",
    "TF_RECORDS_DIR = 'gs://spotify-tfrecords-blog'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c50a06-d69d-4d64-b254-26fb2a249fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick counts on training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1473-4a2d-4778-9f01-e2b76672a9f5",
   "metadata": {},
   "source": [
    "#### Quick counts on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa56927-6722-43f9-88ac-ab638487164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1136.67query/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.13rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery TOTAL_PLAYLISTS\n",
    "select count(1) from hybrid-vertex.spotify_train_3.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418e5d8d-5410-4bca-a168-002d27ed95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65346428"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_PLAYLISTS = TOTAL_PLAYLISTS.values[0][0]\n",
    "TOTAL_PLAYLISTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4710f67-de96-401b-8a0c-abb05dd62c40",
   "metadata": {},
   "source": [
    "### Set the tf.io pipelines function from bigquery\n",
    "\n",
    "[Great blog post here on it](https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e985c505-1712-4d63-bc25-75df479fc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757fa0da-e390-445c-b316-6861f13e3af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-io in /home/jupyter/.local/lib/python3.7/site-packages (0.26.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-io) (0.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-io --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db86c9f-5454-4629-80ba-c0273fca117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import datetime\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.train import BytesList, Feature, FeatureList, Int64List, FloatList\n",
    "from tensorflow.train import SequenceExample, FeatureLists\n",
    "\n",
    "\n",
    "\n",
    "def bq_to_tfdata(client, row_restriction, table_id, col_names, dataset, batch_size=BATCH_SIZE):\n",
    "    TABLE_ID = table_id\n",
    "    COL_NAMES = col_names\n",
    "    DATASET = dataset\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, TABLE_ID, DATASET,\n",
    "        COL_NAMES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45e8d-3113-4528-9d71-8afdfd922d4f",
   "metadata": {},
   "source": [
    "## Get the song metadata\n",
    "\n",
    "To get a pipeline working we need the metadata for the table along with the table information. The following functions are helpers that give us the metadata into the proper types for `tf`\n",
    "\n",
    "\n",
    "For each table id, programatically get\n",
    "* Column names\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcf9098-fd4c-4d00-9e84-8658a620b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 527.65query/s]                          \n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.12rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery schema\n",
    "SELECT * FROM hybrid-vertex.spotify_train_3.INFORMATION_SCHEMA.TABLES\n",
    "where table_name in ('train');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402d9cd0-a837-418a-aa7d-8ba8350c6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_catalog</th>\n",
       "      <th>table_schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "      <th>is_insertable_into</th>\n",
       "      <th>is_typed</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>base_table_catalog</th>\n",
       "      <th>base_table_schema</th>\n",
       "      <th>base_table_name</th>\n",
       "      <th>snapshot_time_ms</th>\n",
       "      <th>ddl</th>\n",
       "      <th>default_collation_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hybrid-vertex</td>\n",
       "      <td>spotify_train_3</td>\n",
       "      <td>train</td>\n",
       "      <td>BASE TABLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-06-24 15:53:36.907000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CREATE TABLE `hybrid-vertex.spotify_train_3.tr...</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table_catalog     table_schema table_name  table_type is_insertable_into  \\\n",
       "0  hybrid-vertex  spotify_train_3      train  BASE TABLE                YES   \n",
       "\n",
       "  is_typed                    creation_time base_table_catalog  \\\n",
       "0       NO 2022-06-24 15:53:36.907000+00:00               None   \n",
       "\n",
       "  base_table_schema base_table_name snapshot_time_ms  \\\n",
       "0              None            None              NaT   \n",
       "\n",
       "                                                 ddl default_collation_name  \n",
       "0  CREATE TABLE `hybrid-vertex.spotify_train_3.tr...                   NULL  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema # we will get the fields out of the ddl field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e820-d1d7-48f9-902d-ad63be9b74fb",
   "metadata": {},
   "source": [
    "## Helper functions to pull metadata from ddl statements\n",
    "\n",
    "From the DDL we are going to get the types for use in a  to create a `BigQueryReadSession` from `tensorflow_io.bigquery` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da24c95d-f598-49b6-a60a-3e1ff3c29bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string type representation to tf data types\n",
    "\n",
    "def conv_dtype_to_tf(dtype_str):\n",
    "    if dtype_str == 'FLOAT64':\n",
    "        return dtypes.float64\n",
    "    elif dtype_str == 'INT64':\n",
    "        return dtypes.int64\n",
    "    elif dtype_str == 'ARRAY<STRING>':\n",
    "        return dtypes.int64\n",
    "    else: \n",
    "        return dtypes.string\n",
    "        \n",
    "def get_metadata_from_ddl(ddl, drop_field=None):\n",
    "    fields = []\n",
    "    types = []\n",
    "    ddl = ddl.values[0]\n",
    "    for line in ddl.splitlines():\n",
    "        if line[:1] == ' ': #only pull indented lines for the fields\n",
    "            # drop the comma\n",
    "            line = line.replace(',','')\n",
    "            space_delim = line.split(' ')\n",
    "            if space_delim[2] in drop_field:\n",
    "                pass\n",
    "            else:\n",
    "                fields.append(space_delim[2])\n",
    "                types.append(conv_dtype_to_tf(space_delim[3]))\n",
    "    return fields, types\n",
    "\n",
    "\n",
    "playlist_fields, playlist_types = get_metadata_from_ddl(schema.ddl[schema.table_name == 'train'], DROP_FIELDS) \n",
    "\n",
    "# { \"field_a_name\": {\"mode\": \"repeated\", \"output_type\": dtypes.int64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e90599-b0e7-41e6-a6e7-99d6668ead55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string type representation to tf data types\n",
    "\n",
    "def conv_dtype_to_tf(dtype_str):\n",
    "    if dtype_str == 'FLOAT64':\n",
    "        return dtypes.float64\n",
    "    elif dtype_str == 'INT64':\n",
    "        return dtypes.int64\n",
    "    elif dtype_str == 'ARRAY<INT64>':\n",
    "        return dtypes.int64\n",
    "    elif dtype_str == 'ARRAY<FLOAT64>':\n",
    "        return dtypes.float64\n",
    "    else: \n",
    "        return dtypes.string\n",
    "\n",
    "def get_metadata_from_ddl(ddl, drop_field=None):\n",
    "    field_dict = {} \n",
    "    ddl = ddl.values[0]\n",
    "    for line in ddl.splitlines():\n",
    "        if line[:1] == ' ': #only pull indented lines for the fields\n",
    "            # drop the comma\n",
    "            line = line.replace(',','')\n",
    "            space_delim = line.split(' ')\n",
    "            if space_delim[2] in drop_field:\n",
    "                pass\n",
    "            else:\n",
    "                # { \"field_a_name\": {\"mode\": \"repeated\", \"output_type\": dtypes.int64}\n",
    "                if 'ARRAY' in space_delim[3]:\n",
    "                    mode = BigQueryClient.FieldMode.REPEATED\n",
    "                else:\n",
    "                    mode = BigQueryClient.FieldMode.NULLABLE\n",
    "                field_dict.update({space_delim[2]: {\"mode\": mode, \"output_type\": conv_dtype_to_tf(space_delim[3])}})\n",
    "    return field_dict\n",
    "\n",
    "\n",
    "playlist_fields_dict = get_metadata_from_ddl(schema.ddl[schema.table_name == 'train'], DROP_FIELDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b2013c-7896-4738-a174-79d9f2fbc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_2_tf_dict = {'name': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'collaborative': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'pid': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'description': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'duration_ms_playlist': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.int64},\n",
    " 'pid_pos_id': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'pos': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'artist_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'track_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'artist_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'track_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'album_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'duration_ms_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.float64},\n",
    " 'album_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'track_pop_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.int64},\n",
    " 'artist_pop_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.float64},\n",
    " 'artist_genres_seed': {'mode': BigQueryClient.FieldMode.REPEATED,\n",
    "  'output_type': dtypes.string},\n",
    " 'artist_followers_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.float64},\n",
    " 'pos_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.int64},\n",
    " 'artist_name_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'artist_uri_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'track_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'track_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'album_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'album_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.string},\n",
    " 'duration_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.float64},\n",
    " 'duration_ms_seed_pl': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.float64},\n",
    " 'n_songs': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.int64},\n",
    " 'num_artists': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.int64},\n",
    " 'num_albums': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    "  'output_type': dtypes.int64},\n",
    "'seed_playlist_tracks': {'mode': BigQueryClient.FieldMode.REPEATED,\n",
    "  'output_type': dtypes.string}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98236269-1d9e-4fed-82d8-5add618dec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_2_tf_dict = {'track_uri': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " # 'collaborative': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'pid': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " # 'description': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'duration_ms_playlist': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.int64},\n",
    " # 'pid_pos_id': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'pos': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " # 'artist_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'track_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'artist_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'track_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'album_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'duration_ms_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.float64},\n",
    " # 'album_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'track_pop_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.int64},\n",
    " # 'artist_pop_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.float64},\n",
    " # 'artist_genres_seed': {'mode': BigQueryClient.FieldMode.REPEATED,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'artist_followers_seed': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.float64},\n",
    " # 'pos_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.int64},\n",
    " # 'artist_name_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'artist_uri_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'track_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'track_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'album_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'album_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.string},\n",
    " # 'duration_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.float64},\n",
    " # 'duration_ms_seed_pl': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.float64},\n",
    " # 'n_songs': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.int64},\n",
    " # 'num_artists': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.int64},\n",
    " # 'num_albums': {'mode': BigQueryClient.FieldMode.NULLABLE,\n",
    " #  'output_type': dtypes.int64}\n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa17d16d-a645-43af-bab2-950085f90ab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "unable to open file: libtensorflow_io.so, from paths: ['/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFNS_8StatusOrISt10unique_ptrIS1_NS_4core15RefCountDeleterEEEEvEE']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12104/1907373423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigQueryClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m bqsession = client.read_session(\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"projects/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unique_track_features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spotify_train_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/bigquery_dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m\"\"\"Creates a BigQueryClient to start BigQuery read sessions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_big_query_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     def read_session(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attrb)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/__init__.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/__init__.py\u001b[0m in \u001b[0;36m_load_library\u001b[0;34m(filename, lib)\u001b[0m\n\u001b[1;32m     69\u001b[0m     raise NotImplementedError(\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m\"unable to open file: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0;34mf\"{filename}, from paths: {filenames}\\ncaused by: {errs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: unable to open file: libtensorflow_io.so, from paths: ['/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFNS_8StatusOrISt10unique_ptrIS1_NS_4core15RefCountDeleterEEEEvEE']"
     ]
    }
   ],
   "source": [
    "client = BigQueryClient()\n",
    "batch_size = 1\n",
    "bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, 'unique_track_features', 'spotify_train_3',\n",
    "        bq_2_tf_dict,\n",
    "        requested_streams=2,)\n",
    "dataset = bqsession.parallel_read_rows()\n",
    "dataset = dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d812a6-9d55-4c4a-b687-896e2ae54caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94ebf1-0080-4cd5-be46-c72af9d3a0e5",
   "metadata": {},
   "source": [
    "### Now the helper functions are set. Below tf.data pipelines are created from bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc539f35-02a5-4010-b07d-02a77f66f4ce",
   "metadata": {},
   "source": [
    "### For the song audio data, we are set and will use this pipeline in training - there's no need to pre-process as there are no nested elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb806df-3f54-4785-a063-9a416e487ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate playlist data\n",
    "playlist_train_pipeline = bq_to_tfdata(BigQueryClient(), row_restriction=None, table_id = 'train'\n",
    "                                    , col_names=bq_2_tf_dict\n",
    "                                       , dataset='spotify_train_3', batch_size=1) #set to one to process each record and maintain shape\n",
    "# for line in playlist_train_pipeline.take(1):\n",
    "#     print(line) #should come out based on batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b3a5-a553-405d-b2f5-d37af35fdc8a",
   "metadata": {},
   "source": [
    "## In pulling one record it looks like it's properly parsing a tf record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f114af1-53f2-45c8-a6cd-17c58c9bea4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'playlist_train_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31215/2363313518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplaylist_train_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'playlist_train_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in playlist_train_pipeline.take(1):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae928c-beeb-4704-8b18-cd31bcb16d24",
   "metadata": {},
   "source": [
    "# do some data wranglging on the text data\n",
    "# tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "for _ in playlist_train_pipeline.map(lambda x: tf.io.parse_sequence_example(tf.io.serialize_tensor(x['tracks'][0]), sequence_features=feature_description, context_features=context_features, name='tracks')).take(1):\n",
    "    tensor = _\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132c7a5-5f76-429b-a1aa-47663f20080b",
   "metadata": {},
   "source": [
    "Since the data is stored in a text dictionary we will eagerly execute, grab the values and do a string `eval`\n",
    "`eval(\"{'pos': 0, 'artist_name': 'King Crimson', 'track_uri': 'spotify:track:173gp7NIXqk0MEo8K7Av4a', 'artist_uri': 'spotify:artist:7M1FPw29m5FbicYzS2xdpi', 'track_name': '21st Century Schizoid Man', 'album_uri': 'spotify:album:0ga8Q4tTXaFf9q3LvT8hrC', 'duration_ms': 657517, 'album_name': 'Radical Action To Unseat the Hold of Monkey Mind (Live)'}\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4abb83-f280-4108-998a-e19689841f8f",
   "metadata": {},
   "source": [
    "## This funcion parses the playlist data and breaks down the nested fields to be conformant with `SequenceExample`\n",
    "The 'flat' features come along as `context_features` in `SequenceExample`\n",
    "There is one more helper function to parse the example and write it to the destination `gs://` path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82765dec-1d18-49b5-9a9f-81cbfff56a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_tensor_from_tracks(tensor):\n",
    "    key_list = ['pos', 'artist_name', 'track_uri', 'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name']\n",
    "    y = {}\n",
    "    \n",
    "    \n",
    "    tracks = tensor[\"tracks\"][0]\n",
    "    tracks = tracks.numpy()\n",
    "\n",
    "    tracks = eval(tracks)\n",
    "\n",
    "    for _ in key_list:\n",
    "        y[_] = []\n",
    "\n",
    "    for track in tracks:\n",
    "        y['pos'].append(track['pos'])\n",
    "        y['artist_name'].append(track['artist_name'].encode('utf8'))\n",
    "        y['artist_uri'].append(track['artist_uri'].encode('utf8'))\n",
    "        y['track_name'].append(track['track_name'].encode('utf8'))\n",
    "        y['album_uri'].append(track['album_uri'].encode('utf8'))\n",
    "        y['duration_ms'].append(track['duration_ms'])\n",
    "        y['album_name'].append(track['album_name'].encode('utf8'))\n",
    "        y['track_uri'].append(track['track_uri'].encode('utf8'))\n",
    "        \n",
    "\n",
    "\n",
    "    # set list types\n",
    "    pos = Int64List(value=y['pos'])\n",
    "    artist_name = BytesList(value=y['artist_name'])\n",
    "    artist_uri = BytesList(value=y['artist_uri'])\n",
    "    track_name = BytesList(value=y['track_name'])\n",
    "    album_uri = BytesList(value=y['album_uri'])\n",
    "    duration_ms = Int64List(value=y['duration_ms'])\n",
    "    album_name = BytesList(value=y['album_name'])\n",
    "    track_uri = BytesList(value=y['track_uri'])\n",
    "\n",
    "\n",
    "\n",
    "    sample_dict = {\n",
    "    \"pl_name\" : Feature(bytes_list=BytesList(value=tensor['pl_name'].numpy())),\n",
    "    \"collaborative\" : Feature(bytes_list=BytesList(value=tensor['collaborative'].numpy())),\n",
    "    \"modified_at_playlist\" : Feature(int64_list=Int64List(value=tensor['modified_at_playlist'].numpy())),\n",
    "    \"num_tracks\" : Feature(int64_list=Int64List(value=tensor['num_tracks'].numpy())),\n",
    "    \"num_albums\" : Feature(int64_list=Int64List(value=tensor['num_albums'].numpy())),\n",
    "    \"num_followers\" : Feature(int64_list=Int64List(value=tensor['num_followers'].numpy())),\n",
    "    \"num_edits\" : Feature(int64_list=Int64List(value=tensor['num_edits'].numpy())),\n",
    "    \"duration_ms\" : Feature(int64_list=Int64List(value=tensor['duration_ms'].numpy())),\n",
    "    \"num_artists\" : Feature(int64_list=Int64List(value=tensor['num_artists'].numpy())),\n",
    "    \"genres\" : Feature(bytes_list=BytesList(value=tensor['genres'].numpy())),\n",
    "    #\"track_pop\" : Feature(int64_list=Int64List(value=tensor['track_pop'].numpy())),\n",
    "    \"time_signature\" : Feature(float_list=FloatList(value=tensor['time_signature'].numpy())),\n",
    "    \"uri\" : Feature(bytes_list=BytesList(value=tensor['uri'].numpy())),\n",
    "    \"tempo\" : Feature(float_list=FloatList(value=tensor['tempo'].numpy())),\n",
    "    \"valence\" : Feature(float_list=FloatList(value=tensor['valence'].numpy())),\n",
    "    \"liveness\" : Feature(float_list=FloatList(value=tensor['liveness'].numpy())),\n",
    "    \"instrumentalness\" : Feature(float_list=FloatList(value=tensor['instrumentalness'].numpy())),\n",
    "    \"acousticness\" : Feature(float_list=FloatList(value=tensor['acousticness'].numpy())),\n",
    "    \"speechiness\" : Feature(float_list=FloatList(value=tensor['speechiness'].numpy())),\n",
    "    \"mode\" : Feature(float_list=FloatList(value=tensor['mode'].numpy())),\n",
    "    \"loudness\" : Feature(float_list=FloatList(value=tensor['loudness'].numpy())),\n",
    "    \"key\" : Feature(float_list=FloatList(value=tensor['key'].numpy())),\n",
    "    \"energy\" : Feature(float_list=FloatList(value=tensor['energy'].numpy())),\n",
    "    \"danceability\" : Feature(float_list=FloatList(value=tensor['danceability'].numpy())),\n",
    "    \"speechiness\" : Feature(float_list=FloatList(value=tensor['speechiness'].numpy())),\n",
    "    \"artist_name\" : Feature(bytes_list=BytesList(value=tensor['artist_name'].numpy())),\n",
    "    \"track_name\" : Feature(bytes_list=BytesList(value=tensor['track_name'].numpy())),\n",
    "    \"album_name\" : Feature(bytes_list=BytesList(value=tensor['album_name'].numpy())),\n",
    "    \"description\" : Feature(bytes_list=BytesList(value=tensor['album_name'].numpy()))\n",
    "    }\n",
    "\n",
    "    # combine feature list\n",
    "\n",
    "    pos = FeatureList(feature=[Feature(int64_list=pos)]) \n",
    "    artist_name = FeatureList(feature=[Feature(bytes_list=artist_name)])\n",
    "    artist_uri = FeatureList(feature=[Feature(bytes_list=artist_uri)])\n",
    "    track_name = FeatureList(feature=[Feature(bytes_list=track_name)])\n",
    "    album_uri = FeatureList(feature=[Feature(bytes_list=album_uri)])\n",
    "    duration_ms = FeatureList(feature=[Feature(int64_list=duration_ms)])\n",
    "    album_name = FeatureList(feature=[Feature(bytes_list=album_name)])\n",
    "    track_uri = FeatureList(feature=[Feature(bytes_list=track_uri)])\n",
    "            \n",
    "\n",
    "    #create the sequence\n",
    "    seq = SequenceExample(context=tf.train.Features(feature=sample_dict),\n",
    "                          feature_lists=FeatureLists(feature_list={\n",
    "                               \"pos\": pos,\n",
    "                               \"artist_name\": artist_name,\n",
    "                               \"track_name\": track_name,\n",
    "                               \"album_uri\": album_uri,\n",
    "                               \"duration_ms\": duration_ms,\n",
    "                               \"album_name\": album_name,\n",
    "                               \"track_uri\": track_uri,\n",
    "                              \"artist_uri\": artist_uri\n",
    "    }))\n",
    "    \n",
    "    return seq\n",
    "\n",
    "\n",
    "def write_a_tfrec(lns, n_records_per_file, file_counter, subfolder):\n",
    "    #next write to a tfrecord\n",
    "        with tf.io.TFRecordWriter(\n",
    "            TF_RECORDS_DIR + \"/\" + subfolder +\"/file_%.2i-%i.tfrec\" % (n_records_per_file, file_counter)\n",
    "        ) as writer:\n",
    "            for example in lns:\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2eb503-d2b4-424b-8f48-7b3187b5fc4a",
   "metadata": {},
   "source": [
    "## Now iterate over the pipeline\n",
    "Creating files with batches of `N_RECORDS_PER_TFRECORD_FILE`\n",
    "\n",
    "This takes about 30 minutes on a 64 vCPUs, 57.6 GB RAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2a4fc6-cdb7-4e81-abe0-d4df4d890b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for folder expected: 2022-04-26:13:17:31.737488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68441867 [00:00<?, ?it/s]2022-04-26 13:17:31.758739: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-26 13:17:31.758789: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-26 13:17:31.759263: E tensorflow/core/framework/dataset.cc:577] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-04-26 13:17:31.759292: E tensorflow/core/framework/dataset.cc:581] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      " 11%|█         | 7592670/68441867 [9:32:46<76:30:23, 220.93it/s] \n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "from tqdm import tqdm\n",
    "# using datetime module\n",
    "\n",
    "# ct stores current time\n",
    "ct = str(datetime.datetime.now()).replace(\" \",\":\")\n",
    "print(f\"Timestamp for folder expected: {ct}\")\n",
    "records = []\n",
    "file_count = 0\n",
    "for i, line in enumerate(tqdm(playlist_train_pipeline, total=TOTAL_PLAYLISTS)):\n",
    "    sequence_example = get_tensor_from_tracks(line) #should come out based on batch size\n",
    "    if i % N_RECORDS_PER_TFRECORD_FILE == 0 and i is not 0: #write-a-file and reset the batch (+1 to avoid modulus reset)\n",
    "        records.append(sequence_example)\n",
    "        write_a_tfrec(records, n_records_per_file=N_RECORDS_PER_TFRECORD_FILE, subfolder=ct, file_counter = file_count)\n",
    "        file_count+=1\n",
    "        records = []\n",
    "    else:\n",
    "        records.append(sequence_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45888388-76c6-49f4-b9d6-47383a6b0614",
   "metadata": {},
   "source": [
    "### Parse records ensure this worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0f562-3ab4-415b-acf0-50a823f3625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #move the files around\n",
    "\n",
    "# !gsutil cp gs://spotify-tfrecords/$ct/* gs://spotify-tfrecords\n",
    "# !gsutil rm gs://spotify-tfrecords/$ct/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4324549-7f6b-4627-a9d1-952894a9318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sequence_features = {'pos': tf.io.RaggedFeature(tf.int64), \n",
    "                     'artist_name':  tf.io.RaggedFeature(tf.string), \n",
    "                     'track_uri':  tf.io.RaggedFeature(tf.string), \n",
    "                     'artist_uri': tf.io.RaggedFeature(tf.string), \n",
    "                     'track_name': tf.io.RaggedFeature(tf.string), \n",
    "                     'album_uri': tf.io.RaggedFeature(tf.string),\n",
    "                     'duration_ms': tf.io.RaggedFeature(tf.int64), \n",
    "                     'album_name': tf.io.RaggedFeature(tf.string)\n",
    "                    }\n",
    "context_features = {\"pl_name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"collaborative\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"modified_at_playlist\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"num_tracks\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"num_albums\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"num_followers\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"num_edits\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"duration_ms\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"num_artists\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1,)),\n",
    "                    \"description\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"genres\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"time_signature\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"uri\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"tempo\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"valence\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"liveness\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"instrumentalness\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"acousticness\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"speechiness\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"mode\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"loudness\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"key\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"energy\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"danceability\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"speechiness\" : tf.io.FixedLenFeature(dtype=tf.float32, shape=(1,)),\n",
    "                    \"artist_name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"track_name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,)),\n",
    "                    \"album_name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1,))    \n",
    "                   }\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_sequence_example(example, sequence_features=sequence_features, context_features=context_features)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe5f20-b928-4649-b2f3-3baf47f90732",
   "metadata": {},
   "source": [
    "### parse tfrecord dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b80ea9-0186-4ddb-add7-c144c89366bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "files = []\n",
    "for blob in client.list_blobs('spotify-tfrecords'):\n",
    "    files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d24c61-c98a-4b6a-ae6d-16c8e2a8c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 13:10:08.097630: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.097737: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.097844: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.097897: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.097975: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098082: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098113: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098134: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098251: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098291: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098376: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098430: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098491: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098518: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098572: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098624: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098648: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098712: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098740: W tensorflow/core/framework/"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n\t [[{{node ParseSingleSequenceExample/ParseSequenceExample/ParseSequenceExampleV2}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28152/1594010292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf_record_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_tfrecord_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf_record_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2843\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n\t [[{{node ParseSingleSequenceExample/ParseSequenceExample/ParseSequenceExampleV2}}]] [Op:IteratorGetNext]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098807: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098864: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098914: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098954: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.098993: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099078: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099112: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099175: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099227: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099263: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099340: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099366: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099419: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n",
      "2022-04-25 13:10:08.099482: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:480 : INVALID_ARGUMENT: Inconsistent max number of elements for feature acousticness: expected 1, but found 500\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "raw_dataset = tf.data.TFRecordDataset(\"gs://spotify-tfrecords/2022-04-25:12:34:55.692336/file_1000-0.tfrec\")\n",
    "\n",
    "tf_record_pipeline = raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "for _ in tf_record_pipeline.take(1):\n",
    "    pprint(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0b41d-9959-4601-9094-57cf01890fbb",
   "metadata": {},
   "source": [
    "# Model Draft Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57822a-235f-4459-a43c-34762964b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class PlaylistsModel(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, adapt_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        #start with lookups on low cardnality categorical items\n",
    "        colab_vocab = tf.constant(['true','false'], name='colab_vocab', dtype='string')\n",
    "        \n",
    "        self.colab = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=colab_vocab, mask_token=None, name=\"colab_lookup\", output_mode='count')\n",
    "        ], name=\"colab\")\n",
    "        \n",
    "        #create text vectorizors to be fed to an embedding layer\n",
    "        self.artist_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"artist_tv\", ngrams=2)\n",
    "        \n",
    "        self.album_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.description_vectorizor = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=MAX_TOKENS, name=\"album_tv\", ngrams=2)\n",
    "        \n",
    "        self.query_embedding = tf.keras.Sequential([\n",
    "            self.album_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"album_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"album_embedding_model\")\n",
    "        \n",
    "        self.artist_embedding = tf.keras.Sequential([\n",
    "            self.artist_vectorizor,\n",
    "            tf.keras.layers.Embedding(MAX_TOKENS+1, EMBEDDING_DIM , mask_zero=True, name=\"artist_emb\"),\n",
    "            tf.keras.layers.GlobalAveragePooling1D()\n",
    "        ], name=\"artist_embedding\")\n",
    "        \n",
    "        ###############\n",
    "        ### adapt stuff\n",
    "        ###############\n",
    "        \n",
    "        self.artist_vectorizor.adapt(adapt_data.map(lambda x: x['artist_name']))\n",
    "        self.album_vectorizor.adapt(adapt_data.map(lambda x: x['album_name'])) \n",
    "        \n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"dense_layers_query\")\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\", kernel_initializer=initializer))\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, kernel_initializer=initializer))\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, 1, epsilon=1e-12, name=\"normalize_dense\")))\n",
    "\n",
    "\n",
    "    def call(self, data):    \n",
    "        all_embs = tf.concat(\n",
    "                [\n",
    "                    self.album_embedding(data['album_name']),\n",
    "                    self.artist_embedding(data['artist_name']),\n",
    "                    self.colab(data['collaborative']),\n",
    "                    self.description_embedding(data['description'])\n",
    "                ], axis=1)\n",
    "        return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821506a-054e-4ad2-8530-bde59fb5e5d6",
   "metadata": {},
   "source": [
    "## Use the example output to think of how you process your features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83a334-4008-44a8-84f6-f2ef827200db",
   "metadata": {},
   "source": [
    "```\n",
    "OrderedDict([('album_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm'], dtype=object)>), ('artist_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Carrot Green'], dtype=object)>), ('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'358500'], dtype=object)>), ('modified_at', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1505692800])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'FeSTa'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([82])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([66])>), ('num_edits', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([48])>), ('num_followers', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>), ('num_tracks', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([85])>), ('pos', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'45'], dtype=object)>), ('track_name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Helm - Carrot Green Remix'], dtype=object)>)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a663c63-58be-43bf-a573-e986cce3e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37b159-34ce-4ef0-88ab-e9cc1ae7d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0].keys()#originally got the values from this\n",
    "feature_description = {'pos': tf.io.RaggedFeature(tf.int64), \n",
    "                     'artist_name':  tf.io.RaggedFeature(tf.string), \n",
    "                     'track_uri':  tf.io.RaggedFeature(tf.string), \n",
    "                     'artist_uri': tf.io.RaggedFeature(tf.string), \n",
    "                     'track_name': tf.io.RaggedFeature(tf.string), \n",
    "                     'album_uri': tf.io.RaggedFeature(tf.string),\n",
    "                     'duration_ms': tf.io.RaggedFeature(tf.int64), \n",
    "                     'album_name': tf.io.RaggedFeature(tf.string)\n",
    "                    }\n",
    "context_features = {\"name\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"collaborative\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "                    \"modified_at\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_tracks\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_albums\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_followers\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_edits\" :tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"duration_ms\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"num_artists\" : tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "                    \"description\" : tf.io.FixedLenFeature(dtype=tf.string, shape=(1))\n",
    "                   }"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
