{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `two_tower_src/` for the source code and model code\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n",
    "\n",
    "We will use managed Tensorboard for training. Before beginning, create a new tensorboard instance by going to Vertex -> Experiments -> Tensorboard Instances -> Create\n",
    "\n",
    "![](img/create-a-tb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "#### Restart kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "path = 'gs://jt-tfrs-output-v2' #TODO change to your model directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29085e-1037-49a2-9927-3ad20c8974e6",
   "metadata": {},
   "source": [
    "**TF debugging logs**\n",
    "\n",
    "```\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# from two_tower_src import two_tower as tt\n",
    "from two_tower_jt import two_tower as tt\n",
    "#inside this tt module the data parsing functions, candidate dataset and model classes are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtwo_tower_jt\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "├── task.py\n",
      "└── two_tower.py\n",
      "\n",
      "1 directory, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree two_tower_jt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6b7ccd-03b3-4cf7-ab25-41701d10063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "batch_size = 1024*16\n",
    "\n",
    "client = storage.Client()\n",
    "# options = tf.data.Options()\n",
    "# options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0099fb-8f49-41e2-98ae-c75540def07f",
   "metadata": {},
   "source": [
    "### train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dir = 'spotify-data-regimes'\n",
    "train_dir_prefix = 'jtv8/train_flat_last_5_v8/'\n",
    "\n",
    "train_files = []\n",
    "for blob in client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}', delimiter=\"/\"):\n",
    "    train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "# train_dataset = train_dataset.interleave(\n",
    "#     full_parse,\n",
    "#     cycle_length=tf.data.AUTOTUNE, \n",
    "#     num_parallel_calls=tf.data.AUTOTUNE,\n",
    "#     deterministic=False,\n",
    "# ).shuffle(batch_size*4, reshuffle_each_iteration=False).map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "#     batch_size \n",
    "# ).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# ).with_options(options)\n",
    "\n",
    "# train_files = [\n",
    "#     'gs://spotify-data-regimes/jtv5/train_last_5_feats_v4/-00000-of-00899.tfrecords',\n",
    "#     'gs://spotify-data-regimes/jtv5/train_last_5_feats_v4/-00001-of-00899.tfrecords',\n",
    "# ]\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_parsed = train_dataset.map(tt.parse_tfrecord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0c549c-8844-4ff0-81cc-db39e224c44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pl_titles_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'tracks_playlist_titles_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f5e263-3cd8-4672-863b-4d1077651b52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'No Complaints'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:4VXEIoFGEjhFMW7wYAvWSf'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=2884916.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'hip hop', 'pop rap', 'rap', 'southern hip hop', 'trap'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Metro Boomin'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=83.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:0iEtIxbK0KxaSlF7G42ZOp'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=261733.0>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=49.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=38.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=59.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=12398746.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'Bonfire'>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0829>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.913>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.498>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0369>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'2'>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0799>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-10.742>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'No Complaints'>,\n",
      " 'track_pl_titles_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"vybz l i t clique chilln chill rap straight fire plane set 2 angel something different showa 2014 workout 2017 hip.hop number 1 summer jamz  \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbc\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbc josh workouts nick sigh autumn vibes mason  weekend  new music  party tunes school what they want \\xf0\\x9f\\x92\\x8e\\xf0\\x9f\\x92\\x8e playlist1 ej \\xf0\\x9f\\x98\\x9b\\xf0\\x9f\\x98\\x9b get high smooth current obsessions swim living zack kick it*** \\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f traps ahhhh rapp  pre-game  \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbf romeo everyday  basic ballin yah. yaaas getting ready tu songs 1 only the best variety. breakfast club tunes : in my feels urban dope trash owen la flame baller losin control august 2017 summer songs 2017 summer ben daniel cuts  sarah litty.  good stuff  sz taylor feelings updated ;) (2017) june 2017 // dreams hypee 24/7!!!!!!!!!! music <3 kelly perfect salt lydia yellow fuego  summer jams yeeeee rap 2 damn. yes meow mix real 24/7 ratchet am new favorites beast mode hot sauce sk8 rachet new wave papi dp playlist #1 that new new  fresh finds werkout \\xf0\\x9f\\x96\\x95\\xf0\\x9f\\x8f\\xbc old school bag hoodrat let her go get ready loud. dope beats new 1 dr bar drunk william sabrina absolute bangers  mark  my type aux $$$ lets get lit sept high gang gang  af hood mikey everyday trap! drop the bass j cole bang bang newwwww personal favorites \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbd kira culture  bangerz maybe party 1 skiing wild game sick beats shred lit\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 hype up tm rap/ hip hop trap/rap  music. second idfwu vibess \\xf0\\x9f\\x8e\\xb6\\xf0\\x9f\\x8e\\xb6 woodstock kool bc 2k17  \\xf0\\x9f\\x92\\x80\\xf0\\x9f\\x92\\x80 pre game trap send it hype\\xf0\\x9f\\x94\\xa5 beach vibes songs i like calm before the storm  clout ayyyyy euphoric* lets go lit. snow vacation 2016 ky \\xe2\\x9c\\xa8\\xe2\\x9c\\xa8\\xe2\\x9c\\xa8 all music  preach main list  mike's playlist game time  kung fu kenny go pump up \\xf0\\x9f\\x92\\xa6\\xf0\\x9f\\x92\\xa6\\xf0\\x9f\\x92\\xa6 it's a vibe baked runn pump up jams unforgettable  gym playlist drivin rap/hip hop lit lit feel better benji \\xe2\\x9d\\x8c\\xe2\\x9d\\x8c spring '17 lit tunes vibezzzz chill \\xf0\\x9f\\x98\\x8e han my jams abc best bumpin' gucci attention coolin  swerve \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbd upbeat tunage  ~~~\\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbc~~~  r&b thrash recents .rap. sleep playlist correr great music tl the boys bangers only  hip hip dope tracks kick back alright litty  slow jams pop mix  infinite red supreme heaven $wag chilllll school songs currents summer seventeen fuego beast playlist  blessings beach \\xf0\\x9f\\x92\\xa6\\xf0\\x9f\\x92\\xa6 free feels good man passionfruit parker tahoe party party party  party playlist random playlist pre game!  gas ?? turn up  don't kill my vibe jacob party hits yikes  current mood nf summer solstice stuff i like pissed songz hi dat way  turn up new vibes work pull up august  basketball. ride nicks playlist party time! rap workout dank tunes manon kw trill! new  vibey drake \\xe2\\x80\\x93 what a time to be alive bo gucci  chief keef  sp done tyga now playing stephen daily ok  chill out 6 god chill 2 f**kin' problems summer \\xe2\\x98\\x80\\xef\\xb8\\x8f spring 2017 pulse dance get pumped lit list candy beep beep  lifestyle dh rap game <> issa playlist  trap trap trap rowdy ooo black people music trappin boat playlist new mix flows issa nah july17 jamz !! r&b morning current jams  simon greatest \\xe2\\x9c\\x94\\xef\\xb8\\x8f good rap savage fire\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 goosebumps werk  bass \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbb hip hop hits rap jams bailey extra lit lit lit regular old songs gp party vibes fun fun everyday songs fall/winter pc  meep 2016-2017  future hype playlist here  new jams yay bangerzzz ispy \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 pre game ;) wavy  the mix spring 17 ++ lul $bangerz$ bump!! lex get_schwifty timeless  culture pump up  not today bass!!! \\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x8f\\xbd humble \\xf0\\x9f\\x92\\xaf\\xf0\\x9f\\x92\\xaf workout  humble. hypebeast partay fun july tiff 10/10 rap & hip hop!  new bangers gr8 shower playlist my rap bb wave chance da playlist 7/17 joe waves lucas house warming  jamin kb cookout lit songs workout twerkout benny hip hop ez $ pregame playlist halloween \\xf0\\x9f\\x8e\\x83 \\xe2\\x98\\x80\\xef\\xb8\\x8f banana issues driving  birthday playlist  casual mew relax .iv. rap vibes saved songs ka new jamz maddie  crap rap and hip hop october '17! soft rap music. 1234 #turnt yikes \\xf0\\x9f\\xa4\\x91\\xf0\\x9f\\xa4\\x91\\xf0\\x9f\\xa4\\x91 logan for taylor thug classics house party lil bit of everything mainstream rc this one new year mine  zone the good good car rides smokey hits work out vibing chillen gym2 trap.mix ganggang kd float for ryan  ryan's playlist new stuff  2k 2.17 other music softball playlist gucci $$$ relatable  cash  fml jammin' boost hypeee yaaa  mitch mix #1 cake kaleo pre-game \\xf0\\x9f\\x98\\x88\\xf0\\x9f\\x98\\x88 me work out playlist ggg mine.  julian chief bangerzz ppp this. feb 17  some songs \\xf0\\x9f\\x92\\x9e\\xf0\\x9f\\x92\\x9e\\xf0\\x9f\\x92\\x9e \\xe2\\x9c\\x8c\\xf0\\x9f\\x8f\\xbb\\xef\\xb8\\x8f claudia smooth operator rappin 2017 favs 1st beast mode!! vii. chill songs rainy songs i love jumpman turnup morning vibes  good car ride  chill vibes parties luis jamzzz car rides! black beatles current favorites workout 3 groovy newbies  rap game! oh kendrick  get lit explicit. partayyyyy sweat meow loud good good rap 3 haha flame \\xf0\\x9f\\x91\\x80\\xf0\\x9f\\x91\\x80 bet greatness aux cord hard  cash chief keef sesh playlit anthems. asdfgh pt.2 cruise 2k13 driving. mix  mikes boop misc colorado real talk be happy little bit of everything airplane list 2018 summer '17 \\xf0\\x9f\\x92\\x8b\\xf0\\x9f\\x92\\x8b\\xf0\\x9f\\x92\\x8b new songs jamzzzz starboy hot fire  car\\xf0\\x9f\\x9a\\x97 get psyched vibin get hype tfb caviar. fre$h pregame playlist  jamzz rolex hip hop  prom 2k17 \\xf0\\x9f\\x91\\x85\\xf0\\x9f\\x92\\xa6 soundhound rich pa hype songs max's playlist \\xf0\\x9f\\xa4\\xb7\\xf0\\x9f\\x8f\\xbd\\xe2\\x80\\x8d\\xe2\\x99\\x80\\xef\\xb8\\x8f wedding 2017 jamz dre yuhh out first moves wrkout rap 2017 brad sober seventeen wiz megan  lion king jake bbb rip up october 17 happy purple wap childish  2015 lifting  the good ones straight up \\xe2\\xad\\x90\\xef\\xb8\\x8f a$ap new one  lit tunes trapp hard rap yams hiphop new finds * everything lit\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 new discoveries pregame!!! summer 17' rapper's delight check this out salty oh yeah taylor :)  tribe good music  rap party trappin  driving music uzi \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbd\\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbd turn boolin juice all hoops chris xox the grind that playlist atlanta favourite games traphouse pimp dd litt  jordan  crazy college quinn penis rap/chill rap songs too good shmood nate toonz 2.0 mind.  mike mark \\xe2\\x9c\\x8c\\xf0\\x9f\\x8f\\xbd kev cleaning  banger$ summer vibes. dj set #gainz rockstar  hype. june 2017.  worship songs  bopz aux car chill rap  whip whatever migos \\xe2\\x80\\x93 culture baseball rapppp lol hell rap americano all of it house warming summer heat reign  playlist3 feelin' myself stuffs the stuff ss17 '17 ice versace flex new new  new car  car vibes yasss gym 2017 kys vibe  litty :)  top 50 may 2017 \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbb\\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbb tennis  jp bpm again trap house  idk asdfghjkl partyyyyy alex's playlist bonfire halloween 2017 4am rappy working out mask off baked. newest lit af  grind time \\xe2\\x9d\\x84\\xef\\xb8\\x8f\\xe2\\x9d\\x84\\xef\\xb8\\x8f\\xe2\\x9d\\x84\\xef\\xb8\\x8f dna. d o p e  freshies rap rap  00 rap !!! new stuff my fav fv sometimes gimnasio 4/4 chill af drake dope beats  okay litty titty rhymes cam mobbin skool workout 2.0 nv summer bops jungle gavin favs <3 cool songs 4 am chilll favourite music jams.  drive jamm fire  game time iz \\xf0\\x9f\\xa4\\xb7\\xe2\\x80\\x8d\\xe2\\x99\\x80\\xef\\xb8\\x8f matt's playlist car beats other songs  motion rap*** wake  dip. gud 22 jen coffee summer feels the good stuff  hype playlist  ignorant *party* one day hb kodak aaaaaa chill  666 \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x92\\xaf \\xf0\\x9f\\xa4\\xa4\\xf0\\x9f\\xa4\\xa4 negro kk rap.  10 gains  it's a trap baddie sauce \\xc2\\xaf\\\\_(\\xe3\\x83\\x84)_/\\xc2\\xaf luv ultralight beam. rapz classical music  musik cruz ella danny sports ak \\xf0\\x9f\\x96\\x95\\xf0\\x9f\\x8f\\xbf sum17  g.o.a.t. smoove zzz trap city  road music yuhhh hip hop playlist car playlist   andrew \\xe2\\x99\\xa5\\xef\\xb8\\x8f tight kdot. \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbc\\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbc new me pull up  philip dope songs summer 2k17 aa summa  party up party party  the king <3 hype songs(: pretty good \\xf0\\x9f\\x96\\x95\\xf0\\x9f\\x8f\\xbd trap trap jacks playlist popular turnt  junior year 45 trvp rap yo carro the playlist ola traffic jams  fantasy newnew lee bball partayyyy \\xe2\\x80\\xa2\\xe2\\x80\\xa2 weekend work in progress june 17 yup body best ever rage real chill lift. 2016  mmmm #lit \\xf0\\x9f\\x92\\xb8\\xf0\\x9f\\x92\\xb8\\xf0\\x9f\\x92\\xb8 slap main playlist fire!!!!!!!!!!! jam sesh 30 birthday def get it ! jammin  dopeness work  everything  newwww my ish mines. \\xe2\\x80\\xa2\\xe2\\x80\\xa2\\xe2\\x80\\xa2 recently added these days aux  vibe back lit songs  jt$ get lit trappy low life sept 2017 favorite songs untitled banger pg joanne partay. boredom atl blk \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 rap playlist  swole people sleep pass the aux summa top songs raw current jams singles ocean my vibes dub car jams gravy a playlist turnip get it hip peter bangers oh boy. jet pipe it up \\xf0\\x9f\\x92\\x97\\xf0\\x9f\\x92\\x97\\xf0\\x9f\\x92\\x97 fall ignorant  hip hop 2017 other litty! hoco pluto workin out chill hip hop ll sway danielle logic car ride el perd\\xc3\\xb3n bm gb lk party party mixes  lets get it xo bass  the good stuff dope  emily dope! d1 dude esketit  t r a p \\xf0\\x9f\\x94\\xa5lit\\xf0\\x9f\\x94\\xa5 \\xf0\\x9f\\x8f\\xb3\\xef\\xb8\\x8f\\xe2\\x80\\x8d\\xf0\\x9f\\x8c\\x88 birthday party  summer mood  pray werk october 2017 sky yolo cage rap music  mac fire\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 hippity hoppity alter ego pump$ hippidy hop stay woke freshman  old and new  lit fam south cj music1 long car rides real friends \\xf0\\x9f\\xa6\\x84\\xf0\\x9f\\xa6\\x84\\xf0\\x9f\\xa6\\x84 leggo tuna \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbb tops  riley omw golf jams  jammy jams \\xf0\\x9f\\x92\\xaf\\xf0\\x9f\\x92\\xaf\\xf0\\x9f\\x92\\xaf focus old rap active litt ;)) ratchet  it is what it is winter 2017 liz \\xe2\\x9a\\xa1\\xef\\xb8\\x8f\\xe2\\x9a\\xa1\\xef\\xb8\\x8f newww summer 17 litty get lit  issa playlist my list lust. jesus music general never gets old softball not bad \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbf walk 50 sad  football car tunes kush saved bose 2017 playlist tunez ish \\xe2\\x9c\\xa8\\xe2\\x9c\\xa8 hip-hop/rap it's lit. oh well party 2k17 high af  plane ride  r&b mix run! summer jams  stoned college  beats 100 ovo bounce back july 2017 summa 17 joey ride out toons match boujee dylan hips august/17 daily  #function senior meh lovey \\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x8f\\xbb gold party music boys hip hop / rap hella boolin$$ trap trap trap  jay groove fiestaaa greats  pregame hype summer love work out mix slow boi halloween dance real music  jeje  1738 music  get $$$$ ( \\xcd\\xa1\\xc2\\xb0 \\xcd\\x9c\\xca\\x96 \\xcd\\xa1\\xc2\\xb0)  oh my tessa btr july 2016 summer'17 gaby bangerzzz ~ 123 interstellar no. 1 sam's playlist mob turn it up 27 deja vu part howdy ami rap ftb gang gang gang mellow solid chicago  junior mixed  rap workout  yayo right offline litty titty  \\xf0\\x9f\\x94\\x8a\\xf0\\x9f\\x94\\x8a\\xf0\\x9f\\x94\\x8a sophomore year escape spotify hip hop/rap  nashville \\xf0\\x9f\\x8d\\xbb\\xf0\\x9f\\x8d\\xbb chilling  comp gr chilling fool boat river good vibes :) goat  silk workout tunes fav rap felix gym flow yeeee ot vibes !! i love college trap rap  ye fridays rn hard max yea \\xf0\\x9f\\x92\\xaf\\xf0\\x9f\\x94\\xa5 bars drake \\xe2\\x80\\x94 more life july 17 unknown  art vince ethan car jamz summer party splash butterfly issa bop gucci gang car jams!! me  dumb lit bang sweg icy \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 cody jamss going out 17' beastmode maddie today 24 pt. 2 sofia  hehe 2pac twerkout asdf izzy em my favs:)) boogie woogie  #1 playlist paradise vball lightskin alan car playlist katie  sorry not sorry fire playlist something new maybe  dizzy  cole ok ok interlude fresh mo bangerz only bus ride dumb lit  workout \\xf0\\x9f\\x92\\xaa\\xf0\\x9f\\x8f\\xbc diablo party list nicholas sauce. 2017 god my music  the boss  main list good vibes bus get turnt motivation hippity hop simple bamf tailgate yooooo yah  revenge fall '17 nice  beats.  \\xf0\\x9f\\x92\\xa3\\xf0\\x9f\\x92\\xa3 rap \\xf0\\x9f\\x94\\xa5 mymusic new hits hype  bless up  grind yeahhh \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbc\\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbc cruisin' live hood jams new workout #sweg trip skrt  ss beer nav johnny  newnewnew best!!!!! music 2 evan ultimate playlist 2001 high vibes miami \\xe2\\x9c\\x88\\xef\\xb8\\x8f whippin barcelona fish nunu ashley litt emily's playlist  summer17 my favorites luke's playlist broccoli lorenzo rap/trap sick main. aaliyah jim ovoxo phineas and ferb my mix sexy fire emoji cha fire \\xf0\\x9f\\x94\\xa5 lake hype rap seba turn up mine emma  jack's playlist random road new hip hop new tracks summer vibes  \\xf0\\x9f\\x96\\x95\\xf0\\x9f\\x8f\\xbb jiggy \\xf0\\x9f\\x99\\x8c\\xf0\\x9f\\x8f\\xbb workout 2 \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbf this is me play me mhmm four dna lifted issa  gabby iii roadtrip basketball we$ best of rap  hyped up vibes \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbc crank this summer \\xe2\\x9d\\xa4\\xef\\xb8\\x8f summer2k17 jj new ish 21 savage partyyyy alone time musica jordan car2 no name drew bros gio bad boy slappers hot stuff hybrid victor bangers  \\xf0\\x9f\\x92\\xb8\\xf0\\x9f\\x92\\xb8 bestest dab pumped s17 lan ratch turnup  hype af  rap songs  pedro chill down kay merry litmas project x hip hop & rap the tunes clean rap top \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbe lifting fh car mix work out  saucy bangers only mm rap caviar ( \\xcd\\xa1\\xc2\\xb0 \\xcd\\x9c\\xca\\x96 \\xcd\\xa1\\xc2\\xb0) 420 bach party h y p e \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x91\\x8c balance  woo! shower playlist  sk playlist 6 slide litty $$ word road trip riding music rollin  hop israel trappin' phresh  loading... congratulations aaa xxl summer 2k17  study hall april 2017 my hits 8th grade usa zen new h2o  adrenaline go to  mood music  lil uzi june thug life the sound current faves atm \\xf0\\x9f\\x98\\x9d\\xf0\\x9f\\x98\\x9d\\xf0\\x9f\\x98\\x9d bop mood. 21  \\xf0\\x9f\\x8c\\x8a\\xf0\\x9f\\x8c\\x8a mustang a1 goat idek good mood littt ahhh dubs wavy homecoming ch blaze life bounce claire jesus :)\\xe2\\x9d\\xa4\\xef\\xb8\\x8f typical ww \\xf0\\x9f\\x94\\xa5fire\\xf0\\x9f\\x94\\xa5 07 rnr  that good stuff party$$ it drift english favss yummy friends lost 29 \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbb trash  power hour current  ooouuu gracie bangs  my workout my party raf dab. emma's playlist morgan  foreign c h i l l  all the feels pregame. you already know unforgettable bu football  ccc get swole! party. lit playlist!!! ha summer jamz highlights yes sir amped hype turnt drake  summer vibes bumps :) summer 17  \\xf0\\x9f\\x9a\\x97\\xf0\\x9f\\x9a\\x97 it's lit car bangers speed flames \\xf0\\x9f\\x92\\xa5\\xf0\\x9f\\x92\\xa5 musica variada la flame  summer2017 texas travel beer pong my top songs tomas  hype it up bmx summa '17 freedom 2016-2017 shower yay. any mood bumping party playlist  party rap bops !  miranda the goods hip hop party newer famous vegas 300 new jam hypebeast  rap 2017~ september  lit playlist 1000 nacht matteo morgan nut chaos lexi power rap\\xf0\\x9f\\x94\\xa5 low key bens playlist  777 skrrr diana \\xf0\\x9f\\x98\\x87\\xf0\\x9f\\x98\\x87\\xf0\\x9f\\x98\\x87 speaker knockerz goose andy ay bump  \\xf0\\x9f\\xa4\\x94\\xf0\\x9f\\xa4\\x94 game day  \\xe2\\x9a\\xa1\\xef\\xb8\\x8f lukas turnup! rns  kris study buddy awesome daddy locker room trap.. stuck in my head party jams passionfruit. workout!!! mmhmm the beginning  around the world dad birthday bash  n2 lmao class ~trap~ black music work playlist skrt skrt start 13.1 love songs no.2 beatz pregame  my favs hype$$$ yee straight chillin live  partyplaylist j chillin fav songs  bangas melo hotel  p1 party! beast mode  goods yesh kg hyphy savage mode its lit cod \\xf0\\x9f\\x91\\x85\\xf0\\x9f\\x91\\x85\\xf0\\x9f\\x91\\x85 \\xf0\\x9f\\x91\\x85\\xf0\\x9f\\x91\\x85 lit asf mosh darty lc queue anders newer stuff vanessa the new  best i ever had \\xf0\\x9f\\xa6\\x8b\\xf0\\x9f\\xa6\\x8b\\xf0\\x9f\\xa6\\x8b yeah play i like sticky franco up up up  lyfe lift september 2017 assorted st cools feierabend yung winter  ahora  \\xf0\\x9f\\xa4\\x99\\xf0\\x9f\\x8f\\xbe what ey ultimate party playlist top 10 caca summer run shleep maggie zach rap music bangaz more l i t  favs rn \\xe2\\x9d\\x84\\xef\\xb8\\x8f audi. good songs step bang bang  rns coolio star albert heat. playa part ii marie final riding lalalala brandon  \\xe2\\x98\\xb9\\xef\\xb8\\x8f xbox hood  gym bump mix workout mix best playlist ever hiphop/rap school . the jams jose hip to the hop sophomore court lit 2.0 #playlist noice banda pip justin  the essentials spicy jammin jams rap  premium rap/hip-hop lit jams rappppp june 2017 rockstar vibin' pandora trap house joel j a m s summer15 \\xf0\\x9f\\x92\\xaa\\xf0\\x9f\\x8f\\xbd eli 21 rap2 party hardy ty seth \\xf0\\x9f\\x92\\x96\\xf0\\x9f\\x92\\x96 litty\\xf0\\x9f\\x94\\xa5 all time favs fall 17 poo current  \\xf0\\x9f\\x94\\xa5\\xe2\\x9d\\xa4\\xef\\xb8\\x8f daily mix 1 trap nation  road trippin wo magnolia ko gg song it's all good  partying let's ride!!! stronger mint top music feel good tunes  \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbc yeet party hip-hop present  dank anything jam rap playlist ok fart thugger party mix  ridin'  party sssss dirt lax my mixtape practice new jamz  the best !! gangsta bumpin  my songs alexis yuh  1-800-273-8255 rap 2.0 \\xf0\\x9f\\x98\\x88\\xf0\\x9f\\x98\\x88\\xf0\\x9f\\x98\\x88 ooh \\xf0\\x9f\\x8c\\x88\\xf0\\x9f\\x8c\\x88 $$?? \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbb\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbb skrrrt summer jams! lel summer rap adri too turnt! silence nav  brap pump it up slappers! party mix game day woo car songs crunk ;)))))) feelin it trevor all day rap 1 lounging bella rap 2  aye  \\xe2\\x99\\xbb\\xef\\xb8\\x8f lit music  cruisin cherry rap stuff gang skrt musix turnt up my music 2 old hyped modern rap plop game music butterfly effect 1975 lit \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 summer jams!! ap u know  playlist joshua w.e lacrosse yoo workout momma ayy weights noah no. car jams  migos christian ton party time  nh get lit! classic bangers chillax fall 2k17  bangin' \\xf0\\x9f\\x8d\\xbe\\xf0\\x9f\\x8d\\xbe driving mix panda my tunes paige work flow chill (2) bruh. prince party music  timeless sam  offline playlist slaps hype rap  fall 2017 mi playlist $lit$ ~hype~ the vibes  modern. you and i finale. grindin 55 nice tape mixed fam hood rat burn kayla nov 17 arizona get it done  pub gametime ooouuu go to ra boxing june17 what i like nu tgif up beat ?!? shower music workout jams vibe$ lean hoco  !*premium*! rides chill tf out sus summer drive hyped  slow it down c3 uber driving tunes boom yuh  bass house tunes ayeee steam explicit lil pump \\xf0\\x9f\\x9a\\x97\\xf0\\x9f\\x92\\xa8 black turn tf up brooke b&w rawr xd era banter ultralight beam the drive party time ayyy football pump up the hills pl1 g.o.a.t way up music play me! the best chill jams turnt ! bomb m&m raps karaoke \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbb\\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbb\\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbb swagger who bam hit chillers 2u \\xe2\\x98\\xa0\\xef\\xb8\\x8f are & be warrior flow chillin wow bike ride michael plus melo  hotel california xvii circuits my chill hype af rj 101 #toast blvck \\xf0\\x9f\\xa4\\xb7\\xf0\\x9f\\x8f\\xbb\\xe2\\x80\\x8d\\xe2\\x99\\x82\\xef\\xb8\\x8f oui ga$$$$ new. moods now new new stuff ryan all songs etc 17 bahamas moosic  alex playlist crunk boat mix  jeep get swole smoke break hip hop. bubu ball throwback gym playlist  sum senior year bops lit playlist  hype music clean dat new new \\xf0\\x9f\\x92\\x93\\xf0\\x9f\\x92\\x93 trap music kate coon toons \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbd spring/summer 2017 new era xx fake love jonny pres wub rocks shotgun work it! reminder look at me! you know summer '17  andrew* 2k17 happy friday just good music vibez 2017  wrap roadie jam sesh  smoke fresh. summer tunes \\xe2\\x9c\\x8c\\xf0\\x9f\\x8f\\xbc favorite songs  gee krunk --- flight my top songs  vol.2 nicky p a r t y  karen sum17 jax good stuff \\xe2\\x80\\xbc\\xef\\xb8\\x8f aye issa vibe \\xe2\\x9a\\xa1\\xef\\xb8\\x8f\\xe2\\x9a\\xa1\\xef\\xb8\\x8f\\xe2\\x9a\\xa1\\xef\\xb8\\x8f freshman fye pancakes yep must listen!! spanish trap chill 2.0 \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x92\\xa6 kevin gates  lalo merp lit!! ooooo the feels yes  smoke sesh og wicked games taco  eh anna gaming  poppin get lit!! boomin breath dodgeball peak alex huh h_y_p_e new and improved gym hype hendrix soul food that good good da best rappp ingles  rnb chill music 1 \\xf0\\x9f\\x94\\xab\\xf0\\x9f\\x94\\xab \\xf0\\x9f\\x98\\xb4\\xf0\\x9f\\x98\\xb4 143 three chill lit  favesss frozen new music tunes  chill music old old 4.20 fall2017 lit music pool side camping edwin temp rr anthems emmas playlist needed me ac goodies download fire september 17 kickback paris xo tour llif3 isaac goodgood bbc hunter derek no homo bool \\xf0\\x9f\\x98\\x81\\xf0\\x9f\\x98\\x81 elizabeth 2017-2018 best songs ya drizzy trevor  transfer amnesia tru driving playlist windows down 90210 litttt pre race snowboarding shower songs jee xavier summertime dope rap heavy rotation \\xf0\\x9f\\xa4\\x91\\xf0\\x9f\\xa4\\x91 feel good  my hip hop gym  house 2 feelz l i t !  up north  starboy! cloudy prodigy  \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x8f\\xbc bank account weight room hey main playlist  bump it yaaaa party starter september hip hop 2 rap/r&b mixxx warmup p3 do not disturb mason tits jeffrey \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 swang the jams. rap/hiphop tyler autumn '17 yaaa playlist1  mixer pump up songs downloads touch the sky party anthems  cruisin  12 pat dm run it houseparty hip hop/ rap box 505 my music pump volleyball  jack tunnel vision trap   c h i l l  boat party car  young dumb & broke views out  swish lowkey  wasted whippin  pregame summer  party 2 mgk fire\\xf0\\x9f\\x94\\xa5 july '17 november vibesss gaming chill drive warm ups personal playlist fire mixtape faded le$ mhm anthem. fiesta  jz go time! new1 fade away minnesota goldie trap$$$ i'm the one prom playlist loading.... good rap  hangout supreme  hip hop rap  \\xf0\\x9f\\x8c\\xb8\\xf0\\x9f\\x8c\\xb8 hockey blurryface bp ghetto xxx bass songs a.m. johnny dakota new songs  stuff 2 party  new rap ayee finesse mix music  rotation bliss ham litness #hype cruising connor woke let's ride  cameron migos  chill 2017 \\xe2\\x9d\\x84\\xef\\xb8\\x8f\\xe2\\x9d\\x84\\xef\\xb8\\x8f favorite drive  v3 boot camp lit \\xf0\\x9f\\x94\\xa5 rap mix jams. 4th alpha car jamz  no sleep gang $$$ mix tape gym \\xf0\\x9f\\x92\\xaa\\xf0\\x9f\\x8f\\xbc pesad\\xc3\\xa3o summer 2017  vice w/o spice gameday good music gang gang trapsoul exclusive litttttt drizzy  luke bangerzzzz smooth jazz living room feel good chillin  trap/rap back to school  the jam shower  a list for me get hyped bruh overwatch daily playlist mk workout playlist car music dope playlist gainz running 2 loves camp 2017 experiment  crusin' chill jams  gym 2 gym mix wtf random playlist  rap beats boii \\xe2\\x9c\\x8c\\xf0\\x9f\\x8f\\xbb vibezzz party bus 2020 trance amazing songs honey dat good good the list top  fall17 august summer water this could be us up! \\xf0\\x9f\\x96\\xa4\\xf0\\x9f\\x96\\xa4\\xf0\\x9f\\x96\\xa4 hip hop/rap new school \\xf0\\x9f\\x92\\xb0\\xf0\\x9f\\x92\\xb0\\xf0\\x9f\\x92\\xb0 chill. listen rap hip-hop high times newschool trap music  late rap game  henry running db mad  23 party people \\xf0\\x9f\\x85\\xb1\\xef\\xb8\\x8f pre _-_-_- \\xf0\\x9f\\x8c\\x8a\\xf0\\x9f\\x8c\\x8a\\xf0\\x9f\\x8c\\x8a best rap october '17 que higher tailgate  clean workout beachin  i dont know stupid rnb yoooo  spin best of the best vibes  warm up pre game  \\xe2\\x9d\\x97\\xef\\xb8\\x8f sophie's playlist one gaming music dank beats ----- soccer thuggin  triggered cheeky ctfo d o p e oldies but goodies  champagne for bae new rap  lil charlie \\xf0\\x9f\\xa4\\xa4\\xf0\\x9f\\xa4\\xa4\\xf0\\x9f\\xa4\\xa4 hoe #1 playlist  chloe devon sauce  23 swag feels good essentials  goats school playlist brand new a little bit of everything bridget october g2 taytay groovy tunes tiffany thinking music good vibes  fun  boss #party that new new songs to sing to [] 18 summer 2017 -- \\xf0\\x9f\\x92\\x96\\xf0\\x9f\\x92\\x96\\xf0\\x9f\\x92\\x96 songs 2 summer playlist wavy. update my jam woah \\xe2\\x80\\xbc\\xef\\xb8\\x8f\\xe2\\x80\\xbc\\xef\\xb8\\x8f sounds pregame! right now rapp jammers slick  bumpin run awesome songs mixtape verano 2 0 1 7 tracks peachy that good good  new2 rhythm and poetry outside bryan everyday music goodie vaca rap music:) lit.\\xf0\\x9f\\x94\\xa5 stoney refresh workout music pl  2017 p2 esketit strawberry jams litness  cold bo$$ currently slapz 112 hot fire trap rap yass ice cold good good  \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbd\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\x8f\\xbd morning drive white girl wasted royalty explicit  pop lit lit  dumb rap it up savannah barz rapish rap. alec ayyyy ridin dirty summer playlist  13 lit af songs that i like clouds oct grwm dope music too much sauce  dead decent its lit  \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8\\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 downloaded neat ++++ sb heat lit\\xf0\\x9f\\x94\\xa5 \\xf0\\x9f\\x91\\xbd\\xf0\\x9f\\x91\\xbd\\xf0\\x9f\\x91\\xbd bumps action </3 dom vibe out pt 2 trill uh oh yas turnt :) milk same jammies new chill agosto summer chill partayyy sep jakob random songs numb go flex cardio skrrt flexin ignant high life wee poop porn peaceful \\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98 aux! transition dang layla  gym mix  hc parental advisory  main lituation damn seniors main songs isabella prty feels eric anthony pump up music ignite bop  found something cloud 9 jc  current music bubbly who knows august '17 oof cream\">,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.165>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=123.975>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:6kig1UFggPUyZBCvXD3Wod'>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.217>}\n",
      "_______________\n",
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Empires'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:4twr7zT1cX9NP5mk11FKDD'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=3343591.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'ccm', 'christian alternative rock', 'christian music', 'world worship', 'worship'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Hillsong United'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=74.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:74cb3MG0x0BOnYNW1uXYnM'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=262120.0>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=30.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=23.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=38.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=11325496.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'Something New'>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.263>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.502>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.43>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=7.48e-06>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'9'>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.148>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-9.466>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Touch The Sky'>,\n",
      " 'track_pl_titles_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"yasssss sleep quiet times roadtrip casting crowns dad praise!!!!! sam coffee  bethel music  leah (::::: beautiful day acoustic hillsong give me jesus  revival good for the soul songs i like  share lit music beloved reception songs surrender fave  work  \\xe2\\x98\\xba\\xef\\xb8\\x8f w o r s h i p sing it  taylor breathe. morning worship my jam  hillsong  kev ptl! uplift god is good. hillsong ! come as you are blessed calming  for him melodies yosemite zion contemporary  fight song playlist 7 church songs rohani first playlist pure love  wonder. //w o r s h i p// driving praise him driving  for the soul christian hits the way mommy gratitude new playlist 3 w o r s h i p. spotify dance playlist jesus. new jesus jams:) divine. take it easy praises praise!! summer 2015 ooh  christian family  summer hillsong young & free \\xe2\\x80\\x93 we are young & free \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbc charleston holy  praise:) gospel songs sunday funday 4th of july uplifting \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbe first love  warriors june disney rachael germany jams good music summer 2016 hey awesomeness alabanzas god is good 2015 inspirational bless up \\xe2\\x9d\\xa4\\xe2\\x9d\\xa4\\xe2\\x9d\\xa4 2017 faves  it is well ++ preach heart songs. jesus jams  romantics good friday courage work playlist repeats go to \\xe2\\x98\\x81\\xef\\xb8\\x8f food for the soul spring relaxation christian jams! good morning worship playlist  \\xe2\\x9a\\xa1\\xef\\xb8\\x8f //worship// working worship!!!! yo 001 wedding dinner music sweat take me back. worship. spiritual listen pray safari favesss. hands up vibing easter morning songs \\xe2\\x9c\\x9d\\xef\\xb8\\x8f jesus  \\xf0\\x9f\\x99\\x8c\\xf0\\x9f\\x8f\\xbb jesus!!!!! ***faith*** pop high school jams upbeat christian cry listen to this <3 <3 <3 jesus songs antidote the playlist calm adoracion me trust road christian  mix of everything  songs i like songs that remind me of you awake give me jesus \\xf0\\x9f\\x98\\x87\\xf0\\x9f\\x98\\x87\\xf0\\x9f\\x98\\x87 02 5k up fight songs christian. i love you alternative  god is love youth group mornings:) aesthetic new songs sing along moving on! abba hillsongs the cave finals \\xf0\\x9f\\x91\\xbc\\xf0\\x9f\\x8f\\xbc on the road again surrender  jc pause god  lyrics christian! free kk go play it forward sundays sabbath // god is good!!! 2015 favorites praise heart strings love  something new hope ~be still~ prayer time birth sleeping music soft god  reflective music yea this week chill beats christian favs camp mornings  practice other adoraci\\xc3\\xb3n. adore colorado  happy happy happy i got you. emily jesus!  church  #praise* ^ jesus ^ \\xf0\\x9f\\x92\\x8b\\xf0\\x9f\\x92\\x8b life let it out get hyped! hope:) religious my mix whistle while you work spiritual  fall jams selah morning jams worship:) jesus culture work tunes chill party engagement party random fc divine good stuff good songs  #jesus mom's music jesus time! yus january 2016 car rides  music  get psyched chilll faith christian pop love vibes soul songs saved christian favorites feels perfection \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbd peaceful worship // christian mix :) love\\xe2\\x9d\\xa4\\xef\\xb8\\x8f the best. praise the lord. hannah songsss super chill worship :) glow !!!!!!! worship mix sg worship/ hello summer playlist run jesus !!! reading playlist <3 .worship. freedom a playlist you lit playlist real. be still  contemporary christian go for it! worship songs.  missing you christian glory alabanza \\xf0\\x9f\\x99\\x8c\\xf0\\x9f\\x8f\\xbc loved joy sunday vibes random  workshop sabbath glorious amen christian worship pumped  ch possibilities shower car tunes rise and shine jesus jams hiking praise  love songs smiles fierce songs for the soul worship playlist autumn  ptl. medicine sabbath :) broken worship him  worship.  holy worship jams discovered slow songs  dinner grace. 2015 top tracks jackie 2016 :) best music run!  community office no diggity sunday morning  saturday especial baseball be  personal playlist fish purpose why not good good slow it down downloaded christian playlist .all songs faith.  one chill worship prayer  refresh worship time  bless can't get enough daily dose fall worship favorites  prayer time  pool party february 2016 day 1 pump up songs to learn 10k lit \\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5 mine emmanuel stretch greece newbies  katie breathe christian mix christian favorites  heal best songs of 2015 abby c&c sunday songs partytime  jesus music  beautiful.  devo jesus music!! lets chill work this one work day liz reborn worship singing in the shower sing bible study worship him carride weekend devotional pt2 calmness my life send it gospel music me. sunny higher november '15 good songs qt running  serene katherine lift me up jenna drive home new music roadtrip playlist bethel my favorite songs  riot road trip maddie jam  everyday songs  morning worship (: stacey study tunes #depression valentine's day i need you blessed  slow worship hsm happy day easy listening zumba summer2k15 yay!!! devotion lyrical musica cristiana believe. babyshower august \\xf0\\x9f\\x92\\x97\\xf0\\x9f\\x92\\x97\\xf0\\x9f\\x92\\x97 christian music  ccm best alternative my jams #blessed  let it go worship   jams friends. give me jesus.  jungle praise and worship  teen morning mix ya sweet dreams 18 focus ! :)  september be still chill music  / w o r s h i p / christain heart. instrumental contemporary jesus music :) discover cc pre-service essentials intimacy you and me. overflow bridal shower  lullabies praise & worship winter 2015 my favorite  soul music core best of the best :) ymca  sleepy sarah annie  worship songs  church spring break oceans  sleeping at last beautiful country music revival  reminders tailgate spring 2014 selection reception first love sun cabin hallelujah nice pick me up! monkey pool music worship time for grace smooth baby shower amen!! jesus wedding playlist feelin good worship music  oceans just chill jesus songs! jesus time  truth him.  alive quiet  now. now \\xf0\\x9f\\x87\\xae\\xf0\\x9f\\x87\\xb9 nicki  easter 2017 pancakes breathing worship! christian music!  amazing grace uplifting  liza wonder christian songs still ------ rest christian music :) r&r rainy day soundhound summer\\xf0\\x9f\\x8c\\x9e kiddos happy spirit soak the best playlist sleep \\xf0\\x9f\\x92\\xa4 christian rock new sounds mellow katie  sleep time l o v e  mom ingles the list the good good a little bit of everything graduation feel good harvest elevate on the road again  grace my music road trippin' ana ~feels~ jesus! shower songs walkin spirit. \\xf0\\x9f\\x99\\x8c\\xf0\\x9f\\x8f\\xbd \\xe2\\x9d\\xa4\\xef\\xb8\\x8f camp 2017 contemporary christian :)  alpha gospel reflection praise songs sleepy music flawless youth passion \\xe2\\x98\\x80\\xef\\xb8\\x8f all ptl joy. school \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbb me like blessings \\xf0\\x9f\\x99\\x83\\xf0\\x9f\\x99\\x83\\xf0\\x9f\\x99\\x83 the chill first this is it. wedding *jesus* new life! new beginning sfw cheese!!!!! sunday morning acoustic worship spring 2016 jesus time. yas sweet sounds my soul worship// studio  goat best mix \\xf0\\x9f\\x98\\x8d\\xf0\\x9f\\x98\\x8d jesus music comfort camp. c2 salt elevation worship  natalie phil wickham greatest hits praise him!! worship 2 p&w victory happy songs encounter acoustic worship  cruising cw lent jesus time new worship iglesia jesus :)  my songs christan this is it worship :)) favv summer '16 for the soul  lecrae mexico up beat yes jesus :) mama chill out praises  inspirations mix 2016 beats two. god prayer amanda ..jesus.. remember me moms playlist morning music breakfast touch the sky bri 2016 songs praise the lord march 2015 anxiety the best 13.1 hillsong united   meditation ignite  loop church songs((: endless love cristian faith  him dance party hillsong worship walk. the king jesus!!! thursdays let it be ireland christian songs.  jul true  bread hillsong united kamp quiet time dreams relaxing  christian contemporary study touch the sky  cameron fun times  blue skies windows down \\xf0\\x9f\\x92\\x95\\xf0\\x9f\\x92\\x95\\xf0\\x9f\\x92\\x95 china amazing grace.  grad party true love sunday  i won't give up sabrina w o r s h i p : ) praise and worship christian/worship my worship bethel music christain  chill rad hillsong/worship {heart} airplane christian worship  christian playlist  crunchy happiness good vibes cro soaking sunsets bb angel pre service power.  everything dank party \\xf0\\x9f\\x8e\\x89 meditation chillllll my favorite songs!! soul food sunday playlist sunday worship dream god. cd hillsong united \\xe2\\x80\\x93 empires jesus jamz annie yoga \\xe2\\x99\\xa5\\xef\\xb8\\x8f flexin cs jay be still. house music flow car chris tomlin fall 2015 positive mood music praise him  strength christ wild horses pineapple car vibes awakening chill vibes. holy spirit idk feel good music at stone ashley  thinking  loading... study mix contemporary christian  wordless jesus!!!! everyday ... upbeat worship light daily music sweet music jesus tunes faith... strong. church music sleeping  worship mix spring playlist upbeat praise music forward new beginnings :: worship christian workout jessica eric jesus!!!!!!  deep peace worship favorites waking up.  worship think coffeehouse my love summer 15 favorite heather pre ceremony god is good!! king \\xe2\\x9c\\x88\\xef\\xb8\\x8f all in v i b e s slow wedding jams restore zen christian :) spanglish  dub april 2016 mornings praise! current heaven chillll sleeping playlist  before ceremony quiet time  peace of mind  worship!! \\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f favorite songs daniel soul running mix {head in the clouds} relax justin bliss christian songs  mom  creative tenth avenue north daily mix 1 mymix into the wild \\xf0\\x9f\\x99\\x8c\\xf0\\x9f\\x8f\\xbc\\xf0\\x9f\\x99\\x8c\\xf0\\x9f\\x8f\\xbc him. nate worship songs workout repeat thinking christan   modern soothing car ride inspirational  christian (: healing work work work religiosa mellow music concert prep relax. worship music holy spirit  praise. music for the soul sunday mornings laura close np 3.0 glory. christian music mix #1 adoration slower too good morning {favorite songs} christian.  cheers everyday christian jams christian songs. julia october 16 praise!!! #yes classroom   praise  keep going lit kairos luv!! fre$h quiet english songs shleep favorite worship volleyball summit hh thoughtful the feels\">,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=57.0>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0271>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=90.5>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:58yhHre6kOePZPD15hZWgP'>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.217>}\n",
      "_______________\n",
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Legendary Movie Music'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:1iq7OCpF8ScxwKYZXlZodf'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=177195.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'bow pop', 'otacore', 'pop violin', 'scorecore'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Taylor Davis'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=54.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:480xKab3lUPhBBnCzlzqIu'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=267573.0>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=10.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=29.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=6515206.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'Violin '>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'3'>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.806>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.135>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.541>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.364>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'9'>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.109>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-9.695>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Now We Are Free (From \"Gladiator\")'>,\n",
      " 'track_pl_titles_can': <tf.Tensor: shape=(), dtype=string, numpy=b'violin!! classical music violin  gaming classical instrumental gaby violin soundtrack secrets throw back dnd ambient car study time epic music  sleep g.o.a.t. older soundtracks instrumentals flight riding'>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0484>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=83.498>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:3MKep4BfEwSlAHuFJrA9aV'>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.152>}\n",
      "_______________\n",
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Anchor'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:5Q2OCUO71PZcF97WUlf3ZB'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=212806.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'ccm', 'christian alternative rock', 'christian music', 'christian pop', 'worship'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Colton Dixon'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=54.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:52oVYHQ99ORZzeig2YGo4R'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=205866.0>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=52.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=41.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=65.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=16021439.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'hope'>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.761>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.444>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.385>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'0'>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.253>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-7.759>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Through All Of It'>,\n",
      " 'track_pl_titles_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"gym motivation electronic christ bang bang  my songs piano jams slow country <3 jesus songs!  suggestions church soundhound one of those days \\xf0\\x9f\\x92\\xa4\\xf0\\x9f\\x92\\xa4 general god is good  camp sleep prayer time  hillsong united   funeral listening current favorites god uplifting megs feels  cinderella give me jesus  christian playlist  more songs yes goodstuff christian hits kairos morning worship nicki driving worship music jesus!!! still working out songs i like  elisa shower casting crowns  the good stuff youth group adoration thinking cp inspired new chill love  love  love running 2 praise him  beloved road trip jesus music a1 prayer my favorites faith awesome mix jesus songs!  worship w o r s h i p worship 2 jesus  meditation glory heaven jonas brothers little bit of everything chillaxing easy listening christian music blessed  praise rad tunes 2015 p&w workout  christian songs \\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f god is love jesus time stressed out!! relaxing music joy sunday fight songs qt vibe hope sunday morning my jams! ptl church  inspiration  different jul sunday funday christian contemporary jesus jams 2016 songs bangers heal best of discover weekly will my fav for the soul natalie car trips happy thoughts inspirational rock it praise and worship. jesus songs calming  jesus :)) revival give me jesus church music bonfire road trippin' remember me feeling down goodness chill playlist jesus music !! soul food casting crowns contemporary christian up gospel  praise & worship worship  favorite songs restore crossroads awesome strong grace music quiet time slow jams wedding playlist christian pop wedding songs sotd hallelujah christine him.  redemption stuff slow down love contemporary christian  here and now shared playlist jesus jamz luv random music everything other rachael lets do this!!! uplift:) good songs ian lent selah christian mix  isaac  blessed  god is good work jesus music :)))))) worship ccm sleepin long drives summer 16 new mix positive jc mix \\xe2\\x9d\\xa4\\xef\\xb8\\x8f homework super chill upbeat worship jesus music  my music jesus! christian rock stay strong christian music  nicole worship! jesus tunes stuck in my head  boot camp * christian * gospel music caroline new music chillen \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbc favorite songs  gospel praise worship time reception praise and worship jesus jams  ivy christian brave mellow  sweet dreams jason aldean  praise him summer 2015 it is well \\xf0\\x9f\\x99\\x8f\\xf0\\x9f\\x8f\\xbb summer 2016 worship   christian jams \\xe2\\x98\\x94\\xef\\xb8\\x8f chillz contemporary run christian favs worship songs cc mhm dawn contemporary christian :)  my mix christian playlist faith  love  christian favorites inspiring spiritual cool beans jesus random running praise songs christian  christian mix happiness be still \\xf0\\x9f\\x92\\x95\\xf0\\x9f\\x92\\x95\\xf0\\x9f\\x92\\x95 come as you are anytime new favs waiting sabbath lift me up black mommy encouragement smile inspire me\">,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=57.0>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0293>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=77.813>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:1jcxDswcwde8Ffp1yvqSWY'>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.229>}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for features in train_parsed.skip(8).take(4):\n",
    "    pprint(features)\n",
    "    print(\"_______________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f446210b-db28-4a7c-bf71-c824b0abca16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"album_name_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Alex Goot & Friends, Vol. 3\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"album_name_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Be Not Nobody\"\n",
      "        value: \"Let Go\"\n",
      "        value: \"Goodbye Lullaby\"\n",
      "        value: \"The Best Damn Thing\"\n",
      "        value: \"Alex Goot & Friends, Vol. 3\"\n",
      "        value: \"Two Lanes Of Freedom\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"album_uri_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:album:0GhppB5IFroTmdP5HxQKE0\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"album_uri_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:album:7D6BFTArx2ajtkKRVXIKO2\"\n",
      "        value: \"spotify:album:7h6XeTzy0SRXDrFJeA9gO7\"\n",
      "        value: \"spotify:album:3WKHuDtWB0Ota02oXE9f9S\"\n",
      "        value: \"spotify:album:0XypvgyeJm4mNjH4QRHmYR\"\n",
      "        value: \"spotify:album:0GhppB5IFroTmdP5HxQKE0\"\n",
      "        value: \"spotify:album:1O3BsjGx9plSOJ036ZY4Fl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_followers_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 228756.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_genres_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\'post-teen pop\\', \\'viral pop\\'\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_genres_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\'lilith\\', \\'neo mellow\\', \\'piano rock\\', \\'pop rock\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'canadian pop\\', \\'candy pop\\', \\'dance pop\\', \\'pop\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'canadian pop\\', \\'candy pop\\', \\'dance pop\\', \\'pop\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'canadian pop\\', \\'candy pop\\', \\'dance pop\\', \\'pop\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'post-teen pop\\', \\'viral pop\\'\"\n",
      "        value: \"\\'contemporary country\\', \\'country\\', \\'country road\\'\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_name_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Alex Goot\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_name_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Vanessa Carlton\"\n",
      "        value: \"Avril Lavigne\"\n",
      "        value: \"Avril Lavigne\"\n",
      "        value: \"Avril Lavigne\"\n",
      "        value: \"Alex Goot\"\n",
      "        value: \"Tim McGraw\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_pop_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 57.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_pop_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 67.0\n",
      "        value: 82.0\n",
      "        value: 82.0\n",
      "        value: 82.0\n",
      "        value: 57.0\n",
      "        value: 75.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_uri_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:artist:66Fb5gJ9SX2WGlqDLUpjux\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_uri_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:artist:5ILrArfIV0tMURcHJN8Q07\"\n",
      "        value: \"spotify:artist:0p4nmQO2msCgU4IF37Wi3j\"\n",
      "        value: \"spotify:artist:0p4nmQO2msCgU4IF37Wi3j\"\n",
      "        value: \"spotify:artist:0p4nmQO2msCgU4IF37Wi3j\"\n",
      "        value: \"spotify:artist:66Fb5gJ9SX2WGlqDLUpjux\"\n",
      "        value: \"spotify:artist:6roFdX1y5BYSbp60OTJWMd\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artists_followers_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 527127.0\n",
      "        value: 8536842.0\n",
      "        value: 8536842.0\n",
      "        value: 8536842.0\n",
      "        value: 228756.0\n",
      "        value: 3924742.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"avg_art_followers_pl_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 13801767.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"avg_artist_pop_pl_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 73.8125\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"avg_track_pop_pl_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 37.72916793823242\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"duration_ms_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 185893.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"duration_ms_songs_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 238440.0\n",
      "        value: 204000.0\n",
      "        value: 225680.0\n",
      "        value: 240866.0\n",
      "        value: 185893.0\n",
      "        value: 276880.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_albums_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 43.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_artists_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 31.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_followers_src\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_songs_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 48.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pl_collaborative_src\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"false\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pl_duration_ms_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 10803409.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pl_name_src\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Twisted\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"time_signature_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"3\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_acousticness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.8270000219345093\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_acousticness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.22599999606609344\n",
      "        value: 6.790000043110922e-05\n",
      "        value: 0.03370000049471855\n",
      "        value: 0.20800000429153442\n",
      "        value: 0.8270000219345093\n",
      "        value: 0.02160000056028366\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_danceability_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.5830000042915344\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_danceability_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.3190000057220459\n",
      "        value: 0.4869999885559082\n",
      "        value: 0.4560000002384186\n",
      "        value: 0.4560000002384186\n",
      "        value: 0.5830000042915344\n",
      "        value: 0.4699999988079071\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_energy_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.45399999618530273\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_energy_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6710000038146973\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.8619999885559082\n",
      "        value: 0.7139999866485596\n",
      "        value: 0.45399999618530273\n",
      "        value: 0.7900000214576721\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_instrumentalness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_instrumentalness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_key_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"3\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_key_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"0\"\n",
      "        value: \"0\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"3\"\n",
      "        value: \"2\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_liveness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.08219999819993973\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_liveness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.16899999976158142\n",
      "        value: 0.3580000102519989\n",
      "        value: 0.1720000058412552\n",
      "        value: 0.29600000381469727\n",
      "        value: 0.08219999819993973\n",
      "        value: 0.08630000054836273\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_loudness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -8.517999649047852\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_loudness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -3.322999954223633\n",
      "        value: -4.416999816894531\n",
      "        value: -3.818000078201294\n",
      "        value: -3.9800000190734863\n",
      "        value: -8.517999649047852\n",
      "        value: -5.3520002365112305\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_mode_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_mode_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"1\"\n",
      "        value: \"1\"\n",
      "        value: \"1\"\n",
      "        value: \"0\"\n",
      "        value: \"1\"\n",
      "        value: \"1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_name_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Clarity\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_name_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Ordinary Day\"\n",
      "        value: \"Sk8er Boi\"\n",
      "        value: \"Wish You Were Here\"\n",
      "        value: \"When You\\'re Gone\"\n",
      "        value: \"Clarity\"\n",
      "        value: \"Highway Don\\'t Care\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_pop_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 32.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_pop_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 32.0\n",
      "        value: 67.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_speechiness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.03099999949336052\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_speechiness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.03290000185370445\n",
      "        value: 0.04820000007748604\n",
      "        value: 0.05000000074505806\n",
      "        value: 0.03319999948143959\n",
      "        value: 0.03099999949336052\n",
      "        value: 0.039000000804662704\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_tempo_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 125.052001953125\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_tempo_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 185.25599670410156\n",
      "        value: 149.93699645996094\n",
      "        value: 165.99099731445312\n",
      "        value: 142.07200622558594\n",
      "        value: 125.052001953125\n",
      "        value: 158.06100463867188\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_time_signature_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"4\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_uri_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:track:6KJcEmFDUHX6zt8Rhuf0AW\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_uri_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:track:0ua956J0x3UIq9xL4qtRcY\"\n",
      "        value: \"spotify:track:4omisSlTk6Dsq2iQD7MA07\"\n",
      "        value: \"spotify:track:3VcaQY2NiZuZEOKNghNhqe\"\n",
      "        value: \"spotify:track:4VdYpmlf6EDmqbAcWc2jt7\"\n",
      "        value: \"spotify:track:6KJcEmFDUHX6zt8Rhuf0AW\"\n",
      "        value: \"spotify:track:4wFUdSCer8bdQsrp1M90sa\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_valence_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6470000147819519\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_valence_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.4090000092983246\n",
      "        value: 0.48399999737739563\n",
      "        value: 0.3370000123977661\n",
      "        value: 0.1550000011920929\n",
      "        value: 0.6470000147819519\n",
      "        value: 0.4950000047683716\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_record in train_dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec28160-b821-4220-aeba-3aba45156b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.182 0.119 0.131 0.425 0.363]\n",
      " [0.287 0.245 0.189 0.326 0.213]\n",
      " [0.577 0.171 0.132 0.149 0.321]\n",
      " [0.141 0.493 0.166 0.501 0.378]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(4).skip(2).take(1):\n",
    "    print(x['track_valence_pl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e606a196-04df-416a-a75c-10c4b5ca5ea0",
   "metadata": {},
   "source": [
    "### Validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3193429-b242-4b43-86ed-d83073471e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = 'spotify-data-regimes'\n",
    "valid_dir_prefix = 'jtv8/train_flat_valid_last_5_v8/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "# valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "# valid_dataset = valid_dataset.interleave(\n",
    "#     full_parse,\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE,\n",
    "#     cycle_length=tf.data.AUTOTUNE, \n",
    "#     deterministic=False,\n",
    "# ).map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE).batch(\n",
    "#     batch_size\n",
    "# ).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# ).with_options(options)\n",
    "\n",
    "valid_dataset = tf.data.TFRecordDataset(valid_files)\n",
    "valid_parsed = valid_dataset.map(tt.parse_tfrecord)\n",
    "\n",
    "# valid_dataset = valid_dataset #.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4abe2c8b-28c2-452b-8dbb-21d0565b8706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pl_titles_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'tracks_playlist_titles_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53daf45-1bf5-4909-8fbd-449ae5372d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b'spotify:track:4EbULzyWMuFx94aoIY1MlJ'\n",
      "  b'spotify:track:5Od0M7jp6IODTPW0cygHgu'\n",
      "  b'spotify:track:5aZrmUOr1kL5U6cg0WZNyw'\n",
      "  b'spotify:track:0gHcxtyWQT0HrlGxaxP1KT'\n",
      "  b'spotify:track:6QMlELXFU07NLdqv3DGNPI']\n",
      " [b'spotify:track:0ndDhvAwW4Gsf7qbTwPcsj'\n",
      "  b'spotify:track:4ORGofTLAoyh6wi3c4HYNv'\n",
      "  b'spotify:track:5Ob2Wt2IifgoFrSFrBnRZJ'\n",
      "  b'spotify:track:045sp2JToyTaaKyXkGejPy'\n",
      "  b'spotify:track:2XkQ9Zo65x7QhRx82Qcy1o']\n",
      " [b'spotify:track:7Hz6LLOVxrojLPIHJJ1S0E'\n",
      "  b'spotify:track:2EkCnnMwdFLPZm6z5ZmQtU'\n",
      "  b'spotify:track:1z6gni0sV2IXCO61LSzgjp'\n",
      "  b'spotify:track:7u9Vpr8JN941aG2pJJDWns'\n",
      "  b'spotify:track:6RVeRpqKEPXR4drIhYiu5V']], shape=(3, 5), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(3).take(1):\n",
    "    print(x['track_uri_pl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2f2ac-e7d0-4e5c-9b7b-85ba395ecd36",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11777fbe-a77c-4c7b-94d3-30b11b3f72f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# candidate_files = ['gs://spotify-data-regimes/jtv1-candidates/candidates-00000-of-00001.tfrecords'] # TODO: parametrize\n",
    "# candidate_files = ['gs://spotify-data-regimes/jtv5/candidates/candidates-00000-of-00001.tfrecords']   # removed track_playlist_titles\n",
    "candidate_files = ['gs://spotify-data-regimes/jtv8/candidates/candidates-00000-of-00001.tfrecords']\n",
    "\n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "parsed_candidate_dataset = candidate_dataset.map(tt.parse_candidate_tfrecord_fn)\n",
    "# parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcca25d-8a96-4bc9-bfcb-b7bac0524bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in parsed_candidate_dataset.batch(2).take(1):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b366e3-6563-4815-82c1-e62827fe9f34",
   "metadata": {},
   "source": [
    "## Adapts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fa77-6401-47bc-b198-14c1891ddcac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adapt the text vectorizors - copy/paste to run one time\n",
    "\n",
    "We are accessing the `TextVectorizor` layers in the model via the layer print-outs above\n",
    "\n",
    "```python\n",
    "# adpat the text vectorizors\n",
    "model.query_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['artist_name_pl']) #artist name pl\n",
    "model.query_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['track_name_pl']) #track name pl\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['album_name_pl']) #album name pl\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['artist_genres_pl']) #artist genres pl\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['track_name_can'])) #track name can\n",
    "model.candidate_tower.layers[2].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['album_name_can'])) #album name can\n",
    "model.candidate_tower.layers[10].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['artist_genres_can'])) #artist genres can\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74964f2-e818-4703-98d0-3e56135f8f45",
   "metadata": {},
   "source": [
    "### Save the vocab dictionary for later so you will not have to adapt\n",
    "\n",
    "```python\n",
    "vocab_dict = {\n",
    "    'artist_name_pl' : model.query_tower.layers[3].layers[0].get_vocabulary(), #artist name pl\n",
    "    'track_name_pl' : model.query_tower.layers[5].layers[0].get_vocabulary(), #track name pl\n",
    "    'album_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(), #album name pl\n",
    "    'artist_genres_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(), #artist genres pl\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(), #track name can\n",
    "    'album_name_can' : model.candidate_tower.layers[2].layers[0].get_vocabulary(), #album name can\n",
    "    'artist_genres_can' : model.candidate_tower.layers[10].layers[0].get_vocabulary(), #artist genres can\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff9a86-9455-423d-bb47-7a068726b973",
   "metadata": {},
   "source": [
    "#### pickles\n",
    "\n",
    "```python\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af98774-812a-4d3b-b6f6-d0d2c6c3552d",
   "metadata": {},
   "source": [
    "### adapt `TextVectorization` layers\n",
    "\n",
    "*note: run `adapt()` for new train sets, before initializing model*\n",
    "\n",
    "1. Create standalone `TextVectorization()` layers\n",
    "2. run `adapt` method on parsed train dataset\n",
    "3. run `get_vocabulary()` method and store in dictionary (`vocab_dict`), where key is the feature name\n",
    "4. save/pickle `vocab_dict` to GCS for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "158371c4-344d-49cc-8999-a8630a9b5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=20000 #50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc06d1-1936-405b-96ba-bc996f0f7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# pl_name_src\n",
    "pl_name_src_text_layer = tf.keras.layers.TextVectorization() # max_tokens=MAX_TOKENS,ngrams=2,\n",
    "pl_name_src_text_layer.adapt(train_parsed.map(lambda x: x['pl_name_src']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd71dac-eb97-43c2-9016-884f57039fd4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 07:21:51.196080: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:51.405048: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:51.412763: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[StringSplit/StringSplitV2/_2]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_605]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27166/1913353400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pl_name_src\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpl_name_src_text_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TOKENS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpl_name_src_text_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_parsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pl_name_src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# track_name_pl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    426\u001b[0m           \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[StringSplit/StringSplitV2/_2]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 07:21:51.548160: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:51.749236: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.020817: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.020930: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.023126: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.250144: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.250906: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.397886: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.585969: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.694836: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.862954: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:53.035667: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:53.165490: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:53.167459: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    }
   ],
   "source": [
    "# MAX_TOKENS=20000 #50000\n",
    "\n",
    "# ==========================================================================================\n",
    "# PLAYLIST (query) TOWER\n",
    "# ==========================================================================================\n",
    "# pl_name_src\n",
    "# pl_name_src_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# pl_name_src_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['pl_name_src']))\n",
    "\n",
    "# # track_name_pl\n",
    "# track_name_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# track_name_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_name_pl']))\n",
    "\n",
    "# # artist_name_pl\n",
    "# artist_name_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# artist_name_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_name_pl']))\n",
    "\n",
    "# # album_name_pl\n",
    "# album_name_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# album_name_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['album_name_pl']))\n",
    "\n",
    "# # artist_genres_pl\n",
    "# artist_genres_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# artist_genres_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_genres_pl']))\n",
    "\n",
    "# # tracks_playlist_titles_pl\n",
    "# tracks_playlist_titles_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# tracks_playlist_titles_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['tracks_playlist_titles_pl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "778143ac-3fe2-4490-a518-41eaaf078936",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3a70> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3a70>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3a70> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3a70>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3dd0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3dd0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3dd0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3dd0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3c20> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3c20>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3c20> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3c20>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3cb0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3cb0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1bd06c3cb0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1bd06c3cb0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function inner.<locals>.<lambda> at 0x7f1c08274290> and will run it as-is.\n",
      "Cause: could not parse the source code of <function inner.<locals>.<lambda> at 0x7f1c08274290>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2min 15s ± 8.86 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# track_name_can\n",
    "track_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "track_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_name_can']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df82097c-6690-4d01-85b5-2833307a9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 116.89 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# artist_name_can\n",
    "artist_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "artist_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_name_can']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa1d1a-ff7c-4270-8166-a5ba0c942641",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# album_name_can\n",
    "album_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "album_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['album_name_can']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65e880-32eb-49a8-926d-a455dcfc5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# artist_genres_can\n",
    "artist_genres_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "artist_genres_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_genres_can']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e254c80-a701-4462-a856-9824b8d11ebf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ==========================================================================================\n",
    "# # CANDIDATE TOWER\n",
    "# # ==========================================================================================\n",
    "\n",
    "# # track_name_can\n",
    "# track_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# track_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_name_can']))\n",
    "\n",
    "# # artist_name_can\n",
    "# artist_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# artist_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_name_can']))\n",
    "\n",
    "# # album_name_can\n",
    "# album_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# album_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['album_name_can']))\n",
    "\n",
    "# # artist_genres_can\n",
    "# artist_genres_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# artist_genres_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_genres_can']))\n",
    "\n",
    "# # # track_pl_titles_can\n",
    "# # track_pl_titles_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# # track_pl_titles_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_pl_titles_can']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd814d96-66b1-40ef-a998-c60d1e2d07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st adapt\n",
    "# gsutil cp gs://spotify-data-regimes/jtv1/vocabs/vocab_dict.pkl .\n",
    "\n",
    "# BUCKET_DATA = 'spotify-data-regimes'\n",
    "# VOCAB_LOCAL_FILE = 'vocab_dict.pkl'\n",
    "# VOCAB_GCS_OBJ = 'jtv1/vocabs/vocab_dict.pkl'\n",
    "\n",
    "vocab_dict = {\n",
    "    'pl_name_src' : pl_name_src_text_layer.get_vocabulary(),\n",
    "    # 'track_name_pl' : track_name_pl_text_layer.get_vocabulary(),\n",
    "    # 'artist_name_pl' : artist_name_pl_text_layer.get_vocabulary(),\n",
    "    # 'album_name_pl' : album_name_pl_text_layer.get_vocabulary(),\n",
    "    # 'artist_genres_pl' : artist_genres_pl_text_layer.get_vocabulary(),\n",
    "    # 'tracks_playlist_titles_pl': tracks_playlist_titles_pl_text_layer.get_vocabulary(),\n",
    "    'track_name_can' : track_name_can_text_layer.get_vocabulary(),\n",
    "    'artist_name_can' : artist_name_can_text_layer.get_vocabulary(),\n",
    "    'album_name_can' : album_name_can_text_layer.get_vocabulary(),\n",
    "    'artist_genres_can' : artist_genres_can_text_layer.get_vocabulary(),\n",
    "    'track_pl_titles_can' : track_pl_titles_can_text_layer.get_vocabulary(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ac31d4-b174-4dbe-b9b6-1e3cbaadb4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File vocab_dict.pkl uploaded to jtv1/vocabs/vocab_dict.pkl.\n"
     ]
    }
   ],
   "source": [
    "# # write vocab to gcs\n",
    "\n",
    "# filehandler = open('vocab_dict.pkl', 'wb')\n",
    "\n",
    "# pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "# filehandler.close()\n",
    "\n",
    "# tt.upload_blob(f'{BUCKET_DATA}', f'{VOCAB_LOCAL_FILE}', f'{VOCAB_GCS_OBJ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17c7815f-f79f-4774-9be3-aeb0e9e74d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pl_name_src': ['empty'], 'track_name_pl': ['empty'], 'artist_name_pl': ['empty'], 'artist_genres_pl': ['empty'], 'tracks_playlist_titles_pl': ['empty'], 'track_name_can': ['empty'], 'artist_name_can': ['empty'], 'album_name_can': ['empty'], 'artist_genres_can': ['empty'], 'track_pl_titles_can': ['empty']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filehandler = open(f'{VOCAB_LOCAL_FILE}', 'rb')\n",
    "# vocab_dict_load = pkl.load(filehandler)\n",
    "# filehandler.close()\n",
    "# vocab_dict_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_tower_jt import two_tower as tt\n",
    "\n",
    "layer_sizes=[512,256]\n",
    "\n",
    "model = tt.TheTwoTowers(layer_sizes) \n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 num_pl_followers_src_emb_model\n",
      "3 pl_duration_ms_new_emb_model\n",
      "4 num_pl_songs_new_emb_model\n",
      "5 num_pl_artists_new_emb_model\n",
      "6 num_pl_albums_new_emb_model\n",
      "7 avg_track_pop_pl_new_emb_model\n",
      "8 avg_artist_pop_pl_new_emb_model\n",
      "9 avg_art_followers_pl_new_emb_model\n",
      "10 track_uri_pl_emb_model\n",
      "11 track_name_pl_emb_model\n",
      "12 artist_uri_pl_emb_model\n",
      "13 artist_name_pl_emb_model\n",
      "14 album_uri_pl_emb_model\n",
      "15 album_name_pl_emb_model\n",
      "16 artist_genres_pl_emb_model\n",
      "17 duration_ms_songs_pl_emb_model\n",
      "18 track_pop_pl_emb_model\n",
      "19 artist_pop_pl_emb_model\n",
      "20 artists_followers_pl_emb_model\n",
      "21 track_danceability_pl_emb_model\n",
      "22 track_energy_pl_emb_model\n",
      "23 track_key_pl_emb_model\n",
      "24 track_loudness_pl_emb_model\n",
      "25 track_mode_pl_emb_model\n",
      "26 track_speechiness_pl_emb_model\n",
      "27 track_acousticness_pl_emb_model\n",
      "28 track_instrumentalness_pl_emb_model\n",
      "29 track_liveness_pl_emb_model\n",
      "30 track_valence_pl_emb_model\n",
      "31 track_tempo_pl_emb_model\n",
      "32 time_signature_pl_emb_model\n",
      "33 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 track_time_signature_can_emb_model\n",
      "23 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e51ae0-18ba-4e66-aec5-15db2acf62e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f0e87c3b6d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.query_tower.layers[11].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed15009f-58fb-4054-ac5e-a85bac810e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 13:02:36.733498: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[None_lookup_table_find/LookupTableFindV2/_24]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_3911]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11576/1115475071.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # adpat the text vectorizors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.query_tower.layers[0].layers[0].adapt(\n\u001b[0;32m----> 3\u001b[0;31m     train_parsed.batch(1000).map(lambda x: x['pl_name_src']))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.query_tower.layers[11].layers[0].adapt(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    426\u001b[0m           \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[None_lookup_table_find/LookupTableFindV2/_24]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_3911]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 13:02:36.867952: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 13:02:36.877955: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    }
   ],
   "source": [
    "# # adpat the text vectorizors\n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_parsed.batch(1000).map(lambda x: x['pl_name_src']))\n",
    "\n",
    "# model.query_tower.layers[11].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['track_name_pl']))\n",
    "\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_name_pl']))\n",
    "\n",
    "# model.query_tower.layers[15].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['album_name_pl']))\n",
    "\n",
    "# model.query_tower.layers[16].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_genres_pl']))\n",
    "\n",
    "# # model.query_tower.layers[17].layers[0].adapt(\n",
    "# #     train_parsed.batch(40000).map(lambda x: x['tracks_playlist_titles_pl']))\n",
    "    \n",
    "# # candidate tower layers\n",
    "# model.candidate_tower.layers[1].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['track_name_can']))\n",
    "\n",
    "# model.candidate_tower.layers[3].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_name_can']))\n",
    "\n",
    "# model.candidate_tower.layers[5].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['album_name_can']))\n",
    "\n",
    "# model.candidate_tower.layers[9].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_genres_can']))\n",
    "\n",
    "# # model.candidate_tower.layers[11].layers[0].adapt(\n",
    "# #     train_parsed.batch(40000).map(lambda x: x['track_pl_titles_can']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855292d1-c069-4559-b598-e275e310826b",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aefbf5-7dea-4bbb-ac3a-6232062d29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Local Training\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "EXPERIMENT_NAME = f'spotify-singe-node-train-full-data-v7-01'\n",
    "RUN_NAME = EXPERIMENT_NAME+'run'+time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "LOG_DIR = path+\"/tb-logs/\"+EXPERIMENT_NAME\n",
    "\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "vertex_ai.init(experiment=EXPERIMENT_NAME)\n",
    "    \n",
    "\n",
    "# we are going to ecapsulate this one-shot log uploader via a custom callback:\n",
    "\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cea523d-812a-4a67-a85f-58b9577a50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Training using tensorboard callback\n",
    "\n",
    "While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:34:46.515483: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-11-09 00:34:47.244207: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3707/Unknown - 4882s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 50909.8305 - regularization_loss: 0.0000e+00 - total_loss: 50909.8305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 01:55:59.926501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 01:56:00.062321: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 01:56:00.103058: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 01:56:00.841399: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 01:56:00.841494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 01:56:00.841504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T01:56:04]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T01:56:07]\u001b[0m Total uploaded: 8 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4893s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 50899.2761 - regularization_loss: 0.0000e+00 - total_loss: 50899.2761\n",
      "Epoch 2/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 11222.0707 - regularization_loss: 0.0000e+00 - total_loss: 11222.07078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:15:09.702038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 03:15:09.836815: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 03:15:09.879861: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 03:15:10.623233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 03:15:10.623324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 03:15:10.623334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 03:15:11.524794 139639993792320 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T03:15:11]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T03:15:17]\u001b[0m Total uploaded: 16 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4749s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 11221.1035 - regularization_loss: 0.0000e+00 - total_loss: 11221.1035\n",
      "Epoch 3/70\n",
      "3303/3708 [=========================>....] - ETA: 8:33 - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 8856.4106 - regularization_loss: 0.0000e+00 - total_loss: 8856.4106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:09:16.437085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 11:09:16.573402: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 11:09:16.616563: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 11:09:17.344141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 11:09:17.344239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 11:09:17.344250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 11:09:18.241973 140144034944832 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T11:09:18]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T11:09:26]\u001b[0m Total uploaded: 40 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 28448s 8s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 8803.8781 - regularization_loss: 0.0000e+00 - total_loss: 8803.8781 - val_batch_categorical_accuracy_at_1: 0.0000e+00 - val_batch_categorical_accuracy_at_5: 0.0000e+00 - val_factorized_top_k/top_1_categorical_accuracy: 0.7862 - val_factorized_top_k/top_5_categorical_accuracy: 0.9233 - val_factorized_top_k/top_10_categorical_accuracy: 0.9382 - val_loss: 10986.7881 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10986.7881\n",
      "Epoch 4/70\n",
      "1816/3708 [=============>................] - ETA: 40:59 - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 8198.6702 - regularization_loss: 0.0000e+00 - total_loss: 8198.6702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7889.6094 - regularization_loss: 0.0000e+00 - total_loss: 7889.6094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 13:48:14.090572: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 13:48:14.232195: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 13:48:14.274022: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 13:48:15.026854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 13:48:15.026949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 13:48:15.026960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 13:48:15.938464 139918749620032 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T13:48:16]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T13:48:26]\u001b[0m Total uploaded: 56 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4734s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7889.1334 - regularization_loss: 0.0000e+00 - total_loss: 7889.1334\n",
      "Epoch 6/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7800.3888 - regularization_loss: 0.0000e+00 - total_loss: 7800.3888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 15:07:11.962236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 15:07:12.099022: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 15:07:12.142491: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 15:07:12.893604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 15:07:12.893705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 15:07:12.893715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 15:07:13.799662 140111523784512 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T15:07:14]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T15:07:24]\u001b[0m Total uploaded: 64 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4738s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7799.9284 - regularization_loss: 0.0000e+00 - total_loss: 7799.9284\n",
      "Epoch 7/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7757.1865 - regularization_loss: 0.0000e+00 - total_loss: 7757.1865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 16:26:22.889692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 16:26:23.026815: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 16:26:23.067868: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 16:26:23.808168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 16:26:23.808258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 16:26:23.808268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 16:26:24.718955 140335566804800 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T16:26:25]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T16:26:35]\u001b[0m Total uploaded: 72 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4751s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7756.7933 - regularization_loss: 0.0000e+00 - total_loss: 7756.7933\n",
      "Epoch 8/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7737.3258 - regularization_loss: 0.0000e+00 - total_loss: 7737.3258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:45:56.065276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 17:45:56.208794: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 17:45:56.251314: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 17:45:56.992739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 17:45:56.992834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 17:45:56.992844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 17:45:57.893610 140106310330176 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T17:45:58]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T17:46:08]\u001b[0m Total uploaded: 80 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4773s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7736.9064 - regularization_loss: 0.0000e+00 - total_loss: 7736.9064\n",
      "Epoch 9/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7722.9688 - regularization_loss: 0.0000e+00 - total_loss: 7722.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 19:05:47.547252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 19:05:47.686335: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 19:05:47.730003: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 19:05:48.480374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 19:05:48.480468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 19:05:48.480478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 19:05:49.379873 140251568813888 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T19:05:49]\u001b[0m Started scanning logdir.\n",
      "3608/3708 [============================>.] - ETA: 2:08 - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7716.3438 - regularization_loss: 0.0000e+00 - total_loss: 7716.3438"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 70\n",
    "RUN_NAME = f'run-{EXPERIMENT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'#be sure to think about run and experiment naming strategies so names don't collide\n",
    "\n",
    "#start the run to collect metrics - note `.log_parameters()` is available but not used\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "layer_history = model.fit(\n",
    "    train_dataset.unbatch().batch(batch_size),\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=3,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=2, #use this for development to run just a few steps\n",
    "    validation_steps = 100,\n",
    "    callbacks=[tensorboard_callback,\n",
    "               UploadTBLogsBatchEnd()], #the tensorboard will be automatically associated with the experiment and log subsequent runs with this callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params({\"layers\": str(layer_sizes), \n",
    "                      \"learning_rate\": LR,\n",
    "                        \"num_epochs\": epochs,\n",
    "                        \"batch_size\": batch_size,\n",
    "                     })\n",
    "\n",
    "#gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "vertex_ai.log_metrics(metrics_dict)\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:\n",
    "\n",
    "![](img/experiment-console.png)\n",
    "\n",
    "![](img/tensorboard.png)\n",
    "\n",
    "### Also, while this is running - check out the Tensorboard profiler in `utils`.\n",
    "\n",
    "![](img/tb-profiler.png)\n",
    "\n",
    "### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`\n",
    "\n",
    "![](img/nvtop-optimized.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ceb80-2365-4b85-8218-3f721ddebada",
   "metadata": {},
   "source": [
    "### When complete you get a decent model with around 30-40 hit rate for top 1\n",
    "\n",
    "![](img/tb-metrics.png)\n",
    "![](img/tb-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559139c-d669-43b1-8ac2-6155b10ef83e",
   "metadata": {},
   "source": [
    "### Now, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1957-1883-4527-83ee-fd5c9857f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the bucket to store the tensorflow models\n",
    "# ! gsutil mb -l us-central1 $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d57ed-540c-41f4-b7cf-d3dad716f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=path + \"/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=path + \"/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.upload_blob('two-tower-models', 'candidate_embeddings.json', 'candidates/candidate_embeddings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    "(base) jupyter@tf28-jsw-sep-a100:~/spotify_mpd_two_tower$ wc -l candidate_embeddings.json \n",
    "2249561 candidate_embeddings.json\n",
    "```\n",
    "\n",
    "### Finished\n",
    "\n",
    "Go on to the [03 notebook](03-matching-engine.ipynb)\n",
    "\n",
    "You should see results similar to the screenshot below\n",
    "![](img/embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2e2b2-74a8-4485-9db0-22146e4a5159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
