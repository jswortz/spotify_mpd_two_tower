{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c84b0f-ecdd-4df2-b239-ce7ad8388851",
   "metadata": {},
   "source": [
    "## Load env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc9bcee-090a-45b6-89b6-8d7bffc6f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ndr-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"                  # TODO\n",
    "PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0318a52-85f7-48de-a7d3-483c199df4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ndr-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "APP                      = \"sp\"\n",
      "MODEL_TYPE               = \"2tower\"\n",
      "FRAMEWORK                = \"tfrs\"\n",
      "DATA_VERSION             = \"v1\"\n",
      "TRACK_HISTORY            = \"5\"\n",
      "\n",
      "BUCKET_NAME              = \"ndr-v1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://ndr-v1-hybrid-vertex-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ndr-v1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "CANDIDATE_PREFIX         = \"candidates\"\n",
      "TRAIN_DIR_PREFIX         = \"train\"\n",
      "VALID_DIR_PREFIX         = \"valid\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "BQ_TABLE_TRAIN           = \"train_flatten_last_5\"\n",
      "BQ_TABLE_VALID           = \"train_flatten_valid_last_5\"\n",
      "BQ_TABLE_CANDIDATES      = \"candidates\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"ndr-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/ndr-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n",
      "SERVING_IMAGE_URI_CPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
      "SERVING_IMAGE_URI_GPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5856e02-89a9-4237-8ada-bdd639e4af65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://ndr-v1-hybrid-vertex-bucket/config/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/data/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/endpoint-tests/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/local-train-v1/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/local-train-v2/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/scale-training-v1/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bd23b-7d91-463e-bf10-adeb318169e3",
   "metadata": {},
   "source": [
    "## pip & package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]' --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5227d2ae-c04a-4ae7-b61a-d65233a80f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "# Run Dataflow to convert BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "* Candidate generation\n",
    "\n",
    "> `beam_candidates\\python3 main.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES`\n",
    "   \n",
    "* Training generation\n",
    "  \n",
    "> `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_training\u001b[00m\n",
      "├── README.MD\n",
      "├── __init__.py\n",
      "├── \u001b[01;34mcreate_tfrecords_training.egg-info\u001b[00m\n",
      "│   ├── PKG-INFO\n",
      "│   ├── SOURCES.txt\n",
      "│   ├── dependency_links.txt\n",
      "│   ├── requires.txt\n",
      "│   └── top_level.txt\n",
      "├── main-train.py\n",
      "├── setup.py\n",
      "└── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "    ├── __init__.py\n",
      "    ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "    │   ├── __init__.cpython-37.pyc\n",
      "    │   ├── train_pipe.cpython-37.pyc\n",
      "    │   └── train_pipe_shape.cpython-37.pyc\n",
      "    └── train_pipe_shape.py\n",
      "\n",
      "3 directories, 14 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a764cd-f14b-4f88-8314-4c1e5bf77bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower/beam_candidates\n"
     ]
    }
   ],
   "source": [
    "%cd beam_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55b2d-4533-4329-97e7-4e175db2a7bd",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0953936-a39a-4d2e-8ba1-2b57d045b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-candidates-v3data-230919-130656, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://ndr-v1-hybrid-vertex-bucket/data/v3data/job/staging/, temp_location=gs://ndr-v1-hybrid-vertex-bucket/data/v3data/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 17\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1752427e-abad-4740-8c16-38ff711c9bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faff9999-83c1-417f-86b2-49b83d0432ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3af313-e958-4e62-ac0a-8482dc8763c4",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a44dce0b-c3c7-4ad7-b243-995766ec5e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23e4e85-b611-42f1-b8e5-023ffb49919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_VALID = 250\n",
    "TOTAL_MB_VALID = 500\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_VALID) // int(TARGET_SHARD_SIZE_MB_VALID)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 2\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-230922-031920, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://ndr-v1-hybrid-vertex-bucket/data/v1/job/staging/, temp_location=gs://ndr-v1-hybrid-vertex-bucket/data/v1/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 18\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# ! python3 main-train.py $BQ_TABLE_VALID $VALID_DIR_PREFIX $TARGET_SHARD_SIZE_MB_VALID $TOTAL_MB_VALID $VERSION $BUCKET_NAME $REGION $PROJECT_ID $NETWORK $BQ_DATASET\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $VALID_DIR_PREFIX $TOTAL_MB_VALID $TARGET_SHARD_SIZE_MB_VALID $BQ_DATASET $BQ_TABLE_VALID\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c97d0-3518-45b0-a72f-10ac9f8007ff",
   "metadata": {},
   "source": [
    "### Tain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9896f5e7-975c-441c-99a2-2f19fa444910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_TRAIN = 2000\n",
    "TOTAL_MB_TRAIN = 44_000\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_TRAIN) // int(TARGET_SHARD_SIZE_MB_TRAIN)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6d635a3-cdf4-4537-abba-f7a43275ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 22\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-230922-104236, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://ndr-v1-hybrid-vertex-bucket/data/v1/job/staging/, temp_location=gs://ndr-v1-hybrid-vertex-bucket/data/v1/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 30\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $TRAIN_DIR_PREFIX $TOTAL_MB_TRAIN $TARGET_SHARD_SIZE_MB_TRAIN $BQ_DATASET $BQ_TABLE_TRAIN\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "# Test TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d190ac1-1a81-4f64-8c24-8a5405f19830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import feature_set_utils as feature_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e13d-9985-40ae-8b1a-3a9d06487bcb",
   "metadata": {},
   "source": [
    "## Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccb4df-a503-4b56-95e6-7af42dd2453e",
   "metadata": {},
   "source": [
    "### Candidate tower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36de4fc9-1a3c-44f7-bf9b-7e7e9d86bbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_genres_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_followers_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_key_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_features = feature_utils.get_candidate_features()\n",
    "candidate_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eb2d9-a81a-4c94-bd70-26eb605037ab",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{CANDIDATE_PREFIX}'):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(feature_utils.parse_candidate_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Thanatophobia'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:5GBUYg5EqeDI0CuszAvDzj'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([27438.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'indie garage rock'\"], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Worn-Tin'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([40.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:7j8ds7BnqaEKuz1a1GN0J9'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([216923.], dtype=float32)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.655], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.321], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.555], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.752], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4.0'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.117], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-9.589], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Doug'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0323], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([129.537], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:2XZ3bL3ROk605SPpy6Dn9C'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.21], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f835e-fb68-4610-92a5-3f4c9547923d",
   "metadata": {},
   "source": [
    "## Train & Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bb2d770-681b-466d-ba4a-f7e84f2fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACK_HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b519ecc-fae8-4a9e-9f89-303c7f24e107",
   "metadata": {},
   "source": [
    "### Get all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2cb3949-bc40-4aab-a99d-aed5ec680832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_genres_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_followers_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_key_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_name_src': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_collaborative_src': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_duration_ms_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_songs_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_artists_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_albums_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'album_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'album_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_genres_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_songs_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'artists_followers_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_key_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'candidate_rank': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = feature_utils.get_all_features(TRACK_HISTORY, ranker=True)\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975cd65-6d6f-412c-8154-41f6041b381a",
   "metadata": {},
   "source": [
    "### Choose feature set mappings\n",
    "\n",
    "> TODO: define mappings\n",
    "\n",
    "* `towers`\n",
    "* `rank`\n",
    "* `audio-rank`\n",
    "* `lw-audio-rank`\n",
    "\n",
    "```python\n",
    "def get_feature_mapping(key):\n",
    "    \"\"\"\n",
    "    returns chosen parse function\n",
    "    \n",
    "    example:\n",
    "        desired_mapping = get_feature_mapping(MY_CHOICE)\n",
    "    \"\"\"\n",
    "    \n",
    "    map_dict = {\n",
    "        \"towers\": feature_utils.parse_towers_tfrecord,\n",
    "        \"rank\": feature_utils.parse_rank_tfrecord,\n",
    "        \"audio-rank\": feature_utils.parse_audio_rank_tfrecord,\n",
    "        \"lw-audio-rank\": feature_utils.parse_lw_audio_rank_tfrecord,\n",
    "    }\n",
    "    return map_dict[key]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d61b0-9f70-48c4-b2ec-c682f4a7c034",
   "metadata": {},
   "source": [
    "### Valid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a500213-a3e4-46c3-a0d7-24452eaa80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_MAP = feature_utils.parse_rank_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid size: 662124\n"
     ]
    }
   ],
   "source": [
    "valid_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "print(f\"valid size: {len(list(valid))}\")\n",
    "\n",
    "valid_parsed = valid.map(FEATURE_MAP)\n",
    "# valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"B'Day\"], dtype=object)>,\n",
      " 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"B'Day Deluxe Edition\", b\"B'Day Deluxe Edition\",\n",
      "        b\"B'Day Deluxe Edition\", b\"B'Day Deluxe Edition\", b\"B'Day\"]],\n",
      "      dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:3MJHoQUI828kmB6IpjejbW'], dtype=object)>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:2WkOVbvgyo0E0G7w2ZsAi2',\n",
      "        b'spotify:album:2WkOVbvgyo0E0G7w2ZsAi2',\n",
      "        b'spotify:album:2WkOVbvgyo0E0G7w2ZsAi2',\n",
      "        b'spotify:album:0JLv6iVbeiy4Dh2eIw6FKI',\n",
      "        b'spotify:album:3MJHoQUI828kmB6IpjejbW']], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([33813884.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'dance pop', 'pop', 'r&b'\"], dtype=object)>,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'dance pop', 'pop', 'r&b'\", b\"'dance pop', 'pop', 'r&b'\",\n",
      "        b\"'dance pop', 'pop', 'r&b'\", b\"'dance pop', 'pop', 'r&b'\",\n",
      "        b\"'dance pop', 'pop', 'r&b'\"]], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Beyonc\\xc3\\xa9'], dtype=object)>,\n",
      " 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Beyonc\\xc3\\xa9', b'Beyonc\\xc3\\xa9', b'Beyonc\\xc3\\xa9',\n",
      "        b'Beyonc\\xc3\\xa9', b'Beyonc\\xc3\\xa9']], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([89.], dtype=float32)>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[89., 89., 89., 89., 89.]], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:6vWDO969PvNqNYHIOW5v0m'], dtype=object)>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
      "        b'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
      "        b'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
      "        b'spotify:artist:6vWDO969PvNqNYHIOW5v0m',\n",
      "        b'spotify:artist:6vWDO969PvNqNYHIOW5v0m']], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
      "array([[33813884., 33813884., 33813884., 33813884., 33813884.]],\n",
      "      dtype=float32)>,\n",
      " 'candidate_rank': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[5., 4., 3., 2., 1.]], dtype=float32)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([204813.], dtype=float32)>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[250146., 221786., 378920., 198506., 200533.]], dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7.], dtype=float32)>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([97.], dtype=float32)>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([21263004.], dtype=float32)>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'BEY'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.226], dtype=float32)>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.151  , 0.247  , 0.00429, 0.233  , 0.0043 ]], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.682], dtype=float32)>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.665, 0.683, 0.488, 0.484, 0.923]], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.939], dtype=float32)>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.703, 0.839, 0.73 , 0.717, 0.477]], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.000315], dtype=float32)>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[1.61e-06, 0.00e+00, 1.49e-05, 6.54e-04, 0.00e+00]], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'9.0'], dtype=object)>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'1.0', b'8.0', b'1.0', b'11.0', b'1.0']], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.346], dtype=float32)>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.232 , 0.109 , 0.0688, 0.0599, 0.123 ]], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-4.054], dtype=float32)>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[-6.822, -7.721, -3.709, -8.789, -5.154]], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'1', b'0', b'1', b'1', b'1']], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Suga Mama'], dtype=object)>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Flaws and All', b'World Wide Woman',\n",
      "        b'Get Me Bodied - Extended Mix', b'If', b'Freakum Dress']],\n",
      "      dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.], dtype=float32)>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[24., 16., 29., 18., 25.]], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.284], dtype=float32)>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.253 , 0.0585, 0.1   , 0.036 , 0.223 ]], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([93.81], dtype=float32)>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[ 98.953, 151.921,  94.867,  91.625,  96.542]], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'4', b'4', b'4', b'4', b'4']], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:3wI6IBqc7qoydP4WmGjDdu'], dtype=object)>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:6kAg2tL3QyZMttR5OolAtE',\n",
      "        b'spotify:track:2qigyAuvoKtaZZKsnynMFT',\n",
      "        b'spotify:track:4uRmZ0sheulzVmJQgIfAfq',\n",
      "        b'spotify:track:4e3p8QsYgeMf8eOUwZEIOx',\n",
      "        b'spotify:track:6bj69qAg4JOErXXbWwyKUt']], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.615], dtype=float32)>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.194, 0.674, 0.665, 0.28 , 0.378]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6031b7e-fcbb-4139-a6c6-75d8a63e6c54",
   "metadata": {},
   "source": [
    "### Train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fc764-c1ca-4346-8fcd-bd9e2939d722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{TRAIN_DIR_PREFIX}/', delimiter=\"/\"):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "train = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "print(f\"train size: {len(list(train))}\")\n",
    "\n",
    "train_parsed = train.map(FEATURE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f98d42e-4ca6-4e1f-a832-6c0a9b1c44a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'candidate_rank': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b4a2ecb-0255-4b67-afe5-13659a6921f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Anything Goes'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'The Big Revival', b'Just As I Am', b\"Here's To The Good Times\",\n",
      "        b'You Get What You Give', b'True Believers']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:5NG7WZaCZZ12M5LJm0JcVc'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:2R5PAxygJ4YeRuSwoalKam',\n",
      "        b'spotify:album:2TRJMLAU1nVzGA7Zpvkl7L',\n",
      "        b'spotify:album:5MH765pytbQasmDxXArTah',\n",
      "        b'spotify:album:0AXoQGOZDaYSaOo0qCTiCr',\n",
      "        b'spotify:album:6cowf7fdb5dgKoglTekOK8']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5135879.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"'contemporary country', 'country', 'country pop', 'country road', 'modern country rock'\"],\n",
      "      dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'contemporary country', 'country', 'country road'\",\n",
      "        b\"'contemporary country', 'country', 'country road', 'modern country rock'\",\n",
      "        b\"'contemporary country', 'country', 'country pop', 'country road', 'modern country rock'\",\n",
      "        b\"'contemporary country', 'country', 'country road', 'modern country rock'\",\n",
      "        b\"'black americana', 'contemporary country', 'country', 'country road'\"]],\n",
      "      dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Florida Georgia Line'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Kenny Chesney', b'Brantley Gilbert', b'Florida Georgia Line',\n",
      "        b'Zac Brown Band', b'Darius Rucker']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([77.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[73., 68., 77., 74., 68.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:3b8QkneNDz4JHKKKlLgYZg'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:3grHWM9bx2E9vwJCdlRv9O',\n",
      "        b'spotify:artist:5q8HGNo0BjLWaTAhRtbwxa',\n",
      "        b'spotify:artist:3b8QkneNDz4JHKKKlLgYZg',\n",
      "        b'spotify:artist:6yJCxee7QumYr820xdIsjo',\n",
      "        b'spotify:artist:7FY5V3XMwlNBPitEjXowHQ']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[4202754., 2797789., 5135879., 3462240., 2378520.]], dtype=float32)>, 'candidate_rank': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[5., 4., 3., 2., 1.]], dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([230586.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[182960., 221226., 208960., 273893., 298400.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([26.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([18.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([33.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7468959.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Road'], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0638], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.113 , 0.458 , 0.0476, 0.455 , 0.0191]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.547], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.537, 0.667, 0.457, 0.782, 0.474]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.878], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.589, 0.948, 0.381, 0.857, 0.66 ]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7.08e-06], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[5.84e-06, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'2.0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'7.0', b'0.0', b'9.0', b'10.0', b'3.0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.106], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.135 , 0.116 , 0.0366, 0.0536, 0.133 ]], dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-4.224], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[-7.174, -5.734, -7.37 , -7.494, -3.364]], dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'1', b'1', b'1', b'1', b'1']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Dirt'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'American Kids', b'Bottoms Up', b'Cruise', b'Colder Weather',\n",
      "        b'Wagon Wheel']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([57.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[68., 47., 68.,  0., 74.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0451], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0354, 0.0296, 0.0435, 0.0294, 0.0803]], dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([121.973], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[170.006, 148.   , 135.979, 148.096,  85.022]], dtype=float32)>, 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'4', b'4', b'4', b'4', b'4']], dtype=object)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:5CXnIPD6rTjszYYQm6fY2P'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:1dgWTMoHwTUnQhOQ8SR5fV',\n",
      "        b'spotify:track:7nDoBWDvf02SyD8kEQuuPO',\n",
      "        b'spotify:track:0i5el041vd6nxrGEU8QRxy',\n",
      "        b'spotify:track:1M2l9ReoabUnvl6Y8jLUe7',\n",
      "        b'spotify:track:3xdjjKMcMOFgo1eQrfbogM']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.592], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.878, 0.545, 0.199, 0.849, 0.574]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c17ea-9381-439c-aebe-665e6d9fb7ac",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
