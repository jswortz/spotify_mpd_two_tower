{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training\n",
    "\n",
    "### IMPORTANT - run this upgrade and restart the kernel before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]' --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db357fb-d242-4336-940d-071a3e548dee",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2a517-0db0-40c0-8e70-19c6a07a495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5227d2ae-c04a-4ae7-b61a-d65233a80f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# TODO - parameterize\n",
    "REGION = 'us-central1'\n",
    "NETWORK = 'ucaip-haystack-vpc-network'\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "\n",
    "\n",
    "BQ_DATASET = 'spotify_e2e_test'\n",
    "BQ_TABLE_TRAIN = 'train_flatten_last_5' # TODO\n",
    "BQ_TABLE_VALID = 'train_flatten_valid_last_5'\n",
    "BQ_TABLE_CANDIDATES = 'candidates'\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 5\n",
    "\n",
    "VERSION= \"v1-0-0\" # version tag for dataflow pipeline\n",
    "\n",
    "# gcs subfolders - destinations for processed data: f'gs://{BUCKET_NAME}/{VERSION}/{___PREFIX}'\n",
    "CANDIDATE_PREFIX = 'candidates'\n",
    "TRAIN_DIR_PREFIX = 'train'\n",
    "VALID_DIR_PREFIX = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54e67f5f-2539-407f-8f24-3be640420f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://matching-engine-content/10/\n",
      "                                 gs://matching-engine-content/11/\n",
      "                                 gs://matching-engine-content/13/\n",
      "                                 gs://matching-engine-content/5/\n",
      "                                 gs://matching-engine-content/6/\n",
      "                                 gs://matching-engine-content/7/\n",
      "                                 gs://matching-engine-content/8/\n",
      "                                 gs://matching-engine-content/v1-0-0/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "# Run Dataflow to convert BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "* Candidate generation\n",
    "\n",
    "> `beam_candidates\\python3 main.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES`\n",
    "   \n",
    "* Training generation\n",
    "  \n",
    "> `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_training\u001b[00m\n",
      "├── README.MD\n",
      "├── __init__.py\n",
      "├── main-train.py\n",
      "├── setup.py\n",
      "└── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "    ├── __init__.py\n",
      "    ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "    │   ├── __init__.cpython-37.pyc\n",
      "    │   └── train_pipe.cpython-37.pyc\n",
      "    └── train_pipe_shape.py\n",
      "\n",
      "2 directories, 8 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79a764cd-f14b-4f88-8314-4c1e5bf77bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/spotify_mpd_two_tower/beam_candidates'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower/beam_candidates\n"
     ]
    }
   ],
   "source": [
    "%cd beam_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55b2d-4533-4329-97e7-4e175db2a7bd",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0953936-a39a-4d2e-8ba1-2b57d045b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-0-0-230308-151304, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://matching-engine-content/v1-0-0/job/staging/, temp_location=gs://matching-engine-content/v1-0-0/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 18\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faff9999-83c1-417f-86b2-49b83d0432ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3af313-e958-4e62-ac0a-8482dc8763c4",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9929178-a033-46ec-b400-2c7059fe98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c23e4e85-b611-42f1-b8e5-023ffb49919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_VALID = 250\n",
    "TOTAL_MB_VALID = 500\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_VALID) // int(TARGET_SHARD_SIZE_MB_VALID)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 2\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-0-0-230308-013003, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://matching-engine-content/v1-0-0/job/staging/, temp_location=gs://matching-engine-content/v1-0-0/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 15\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# ! python3 main-train.py $BQ_TABLE_VALID $VALID_DIR_PREFIX $TARGET_SHARD_SIZE_MB_VALID $TOTAL_MB_VALID $VERSION $BUCKET_NAME $REGION $PROJECT_ID $NETWORK $BQ_DATASET\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $VALID_DIR_PREFIX $TOTAL_MB_VALID $TARGET_SHARD_SIZE_MB_VALID $BQ_DATASET $BQ_TABLE_VALID\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c97d0-3518-45b0-a72f-10ac9f8007ff",
   "metadata": {},
   "source": [
    "### Tain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9896f5e7-975c-441c-99a2-2f19fa444910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_TRAIN = 2000\n",
    "TOTAL_MB_TRAIN = 44_000\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_TRAIN) // int(TARGET_SHARD_SIZE_MB_TRAIN)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6d635a3-cdf4-4537-abba-f7a43275ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 22\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-0-0-230308-014748, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://matching-engine-content/v1-0-0/job/staging/, temp_location=gs://matching-engine-content/v1-0-0/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 30\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $TRAIN_DIR_PREFIX $TOTAL_MB_TRAIN $TARGET_SHARD_SIZE_MB_TRAIN $BQ_DATASET $BQ_TABLE_TRAIN\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "# Test output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e13d-9985-40ae-8b1a-3a9d06487bcb",
   "metadata": {},
   "source": [
    "## Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccb4df-a503-4b56-95e6-7af42dd2453e",
   "metadata": {},
   "source": [
    "### Candidate tower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66216584-d182-4eb9-9187-a67c6a3cb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = {\n",
    "    \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "    \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "    \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # new\n",
    "    # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_time_signature_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eb2d9-a81a-4c94-bd70-26eb605037ab",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{VERSION}/{CANDIDATE_PREFIX}'):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "candidate_files\n",
    "# # candidate_files = f'gs://{BUCKET_NAME}/{VERSION}/{CANDIDATE_PREFIX}/candidates-00000-of-00001.tfrecords'\n",
    "# candidate_files = f'gs://{BUCKET_NAME}/{VERSION}/candidates-00000-of-00001.tfrecords'\n",
    "#     matching-engine-content/v1-0-0/candidates\n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "def parse_candidate_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Festival Party Riddim'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:6HRMv5gpkJDvfBhpBr1OVK'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'NONE'], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Winners Table Band'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:2oy6bRhmrdW8M5IVCNpu1A'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([113554.], dtype=float32)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0542], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.455], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.965], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.959], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'11.0'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.366], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.018], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Festival Party Riddim'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0664], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([160.826], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:6rAdzenD1M3W0Jpiwzo2Km'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.887], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f835e-fb68-4610-92a5-3f4c9547923d",
   "metadata": {},
   "source": [
    "## Train & Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb2d770-681b-466d-ba4a-f7e84f2fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLAYLIST_LENGTH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b519ecc-fae8-4a9e-9f89-303c7f24e107",
   "metadata": {},
   "source": [
    "### train & valid features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49445d15-3782-42e3-9820-8494ad67ac7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feats = {\n",
    "    # ===================================================\n",
    "    # candidate track features\n",
    "    # ===================================================\n",
    "    \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "    \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "    \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_time_signature_can\": tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \n",
    "    # ===================================================\n",
    "    # summary playlist features\n",
    "    # ===================================================\n",
    "    \"pl_name_src\" : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    'pl_collaborative_src' : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    # 'num_pl_followers_src' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    'pl_duration_ms_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    'num_pl_songs_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),  # num_pl_songs_new | n_songs_pl_new\n",
    "    'num_pl_artists_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    'num_pl_albums_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    # 'avg_track_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    # 'avg_artist_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # 'avg_art_followers_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \n",
    "    # ===================================================\n",
    "    # ragged playlist features\n",
    "    # ===================================================\n",
    "    # bytes / string\n",
    "    \"track_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"album_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"album_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_genres_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    # \"tracks_playlist_titles_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \n",
    "    # Float List\n",
    "    \"duration_ms_songs_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artists_followers_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_danceability_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_energy_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_key_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_loudness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_mode_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_speechiness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_acousticness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_instrumentalness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_liveness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_valence_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_tempo_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_time_signature_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d61b0-9f70-48c4-b2ec-c682f4a7c034",
   "metadata": {},
   "source": [
    "### Valid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "valid_parsed = valid.map(parse_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b733662-a8d9-4581-9a24-fc02265569e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'I Decided.'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Big Baby DRAM', b'Coloring Book', b'To Pimp A Butterfly',\n",
      "        b'Views', b'Camp']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:0XAIjjN5qxViVS0Y5fYkar'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:0NrZHZ0y5kTO8EHliuUUca',\n",
      "        b'spotify:album:71QyofYesSsRMwFOTafnhB',\n",
      "        b'spotify:album:7ycBtnsMtyVbbwTfJwRjSP',\n",
      "        b'spotify:album:3hARKC8cinq3mZLLAEaBh9',\n",
      "        b'spotify:album:4q5E2s5u5X5HT4UMJpbMKE']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([10521744.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"'detroit hip hop', 'hip hop', 'pop', 'pop rap', 'rap', 'southern hip hop', 'trap'\"],\n",
      "      dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'alternative r&b', 'rap', 'virginia hip hop'\",\n",
      "        b\"'chicago rap', 'conscious hip hop', 'hip hop', 'pop rap', 'rap'\",\n",
      "        b\"'conscious hip hop', 'hip hop', 'rap', 'west coast rap'\",\n",
      "        b\"'canadian hip hop', 'canadian pop', 'hip hop', 'rap', 'toronto rap'\",\n",
      "        b\"'atl hip hop', 'hip hop', 'pop', 'rap'\"]], dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Big Sean'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'DRAM', b'Chance The Rapper', b'Kendrick Lamar', b'Drake',\n",
      "        b'Childish Gambino']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([80.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[64., 77., 91., 98., 82.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:0c173mlxpT3dSFRgMO8XPh'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:5M0lbkGluOPXLeFjApw8r8',\n",
      "        b'spotify:artist:1anyVhU62p31KFi8MEzkbf',\n",
      "        b'spotify:artist:2YZyLoL8N0Wb9xBt1NhZWg',\n",
      "        b'spotify:artist:3TVXtAsR1Inumwj472S9r4',\n",
      "        b'spotify:artist:73sIBHcqh3Z3NyqHKZ7FOL']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
      "array([[  835726.,  5830995., 23130752., 72567600., 10530350.]],\n",
      "      dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([222360.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[225205., 203794., 219333., 245226., 192946.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([11.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([21.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([4661506.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"Don't\"], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.106], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0627, 0.0773, 0.308 , 0.236 , 0.0742]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.78], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.796, 0.886, 0.531, 0.607, 0.508]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.575], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.476, 0.544, 0.525, 0.763, 0.766]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.00e+00, 1.89e-06, 0.00e+00, 0.00e+00, 0.00e+00]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1.0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'7.0', b'0.0', b'8.0', b'1.0', b'10.0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.129], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.057 , 0.0827, 0.347 , 0.113 , 0.0835]], dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.628], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[ -7.39 ,  -8.615, -11.076,  -5.974,  -5.674]], dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'0', b'1', b'0', b'1', b'1']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Bounce Back'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Broccoli (feat. Lil Yachty)',\n",
      "        b\"All We Got (feat. Kanye West & Chicago Children's Choir)\",\n",
      "        b'Alright', b'Controlla', b'Bonfire']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([67.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[58., 54., 78.,  0.,  0.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.139], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.131, 0.303, 0.249, 0.462, 0.238]], dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([81.502], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[122.976, 145.99 , 110.034, 131.921, 161.59 ]], dtype=float32)>, 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'5', b'4', b'4', b'4', b'4']], dtype=object)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:0SGkqnVQo9KPytSri1H6cF'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:7yyRTcZmCiyzzJlNzGC9Ol',\n",
      "        b'spotify:track:3ZLyt2ndLFBh148XRYjYYZ',\n",
      "        b'spotify:track:3iVcZ5G6tvkXZkZKlMpIUs',\n",
      "        b'spotify:track:6F609ICg9Spjrw1epsAnpa',\n",
      "        b'spotify:track:4zGvb8hxGLB2jEPRFiRRqw']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.273], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.347, 0.275, 0.558, 0.708, 0.398]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6031b7e-fcbb-4139-a6c6-75d8a63e6c54",
   "metadata": {},
   "source": [
    "### Train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f5fc764-c1ca-4346-8fcd-bd9e2939d722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{VERSION}/{TRAIN_DIR_PREFIX}/', delimiter=\"/\"):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "train = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "train_parsed = train.map(parse_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f98d42e-4ca6-4e1f-a832-6c0a9b1c44a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b4a2ecb-0255-4b67-afe5-13659a6921f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'H3'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Pluto', b'Tha Carter IV', b'Drop That #NaeNae', b'Stoner',\n",
      "        b'H3']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:2SgtoSJoJ9gKozK8PCBLpv'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:1yNIBzlvPVBALSPkUMq1ma',\n",
      "        b'spotify:album:1uuSC0RCJB3dSp8Mb6GflZ',\n",
      "        b'spotify:album:5L3nn0pw1AsAGi6QYSHXjT',\n",
      "        b'spotify:album:3mEM2ULIptDPwU07OLk1qy',\n",
      "        b'spotify:album:2SgtoSJoJ9gKozK8PCBLpv']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'chicago rap', 'vapor trap'\"], dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'atl hip hop', 'rap', 'southern hip hop', 'trap'\",\n",
      "        b\"'hip hop', 'new orleans rap', 'pop rap', 'rap', 'trap'\",\n",
      "        b'NONE',\n",
      "        b\"'atl hip hop', 'atl trap', 'gangster rap', 'hip hop', 'melodic rap', 'pop rap', 'rap', 'southern hip hop', 'trap'\",\n",
      "        b\"'chicago rap', 'vapor trap'\"]], dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Cdot Honcho'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Future', b'Lil Wayne', b'We Are Toonz', b'Young Thug',\n",
      "        b'Cdot Honcho']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([38.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[92., 88., 20., 87., 38.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:6iFfBnyywMEcptbnx4sSp6'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:1RyvyyTE3xzB2ZywiAwp0i',\n",
      "        b'spotify:artist:55Aa2cqylxrFIXC767Z865',\n",
      "        b'spotify:artist:4rN9gEi2IbnV59Tm4kid4c',\n",
      "        b'spotify:artist:50co4Is1HCEo8bhOyUWKpn',\n",
      "        b'spotify:artist:6iFfBnyywMEcptbnx4sSp6']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
      "array([[13246443., 13218158.,    18581.,  8020316.,        0.]],\n",
      "      dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([186383.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[262306., 240306., 237307., 239999., 128757.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([151.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([81.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([233.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([49452936.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Party Playlist'], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.325], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[8.84e-03, 1.77e-04, 3.16e-03, 4.21e-01, 5.27e-03]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.758], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.759, 0.597, 0.876, 0.644, 0.79 ]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.751], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.461, 0.56 , 0.675, 0.642, 0.661]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[6.83e-05, 0.00e+00, 1.16e-06, 5.14e-06, 7.70e-04]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0.0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'2.0', b'11.0', b'9.0', b'2.0', b'3.0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.157], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.111 , 0.24  , 0.0939, 0.108 , 0.0667]], dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-6.032], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[ -6.093,  -7.082,  -3.28 , -14.027,  -7.594]], dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'1', b'1', b'0', b'1', b'1']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Together (Prod.By Bilbo)'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Neva End', b'How To Love', b'Drop That #NaeNae', b'Stoner',\n",
      "        b'Zaytiggy (Prod.By Zaytoven x Polo)']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[27.,  5., 26., 46.,  0.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0682], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0418, 0.246 , 0.146 , 0.114 , 0.0548]], dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([135.02], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[145.009, 134.953, 154.001, 135.959, 148.931]], dtype=float32)>, 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'4', b'4', b'4', b'4', b'4']], dtype=object)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:11z5EBO7x7KnfIHnoE1hNh'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:7KyEgCM3EdWPYi5WHuhc1y',\n",
      "        b'spotify:track:4aX4Oycsk1fhHIee1zqsDe',\n",
      "        b'spotify:track:5raJprQNbc6DlAeRygnDFy',\n",
      "        b'spotify:track:1jROHCeEzDr6VnV8EnBnik',\n",
      "        b'spotify:track:4fvzm0E7yhZqwEsZqEAqLo']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.736], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.621, 0.549, 0.606, 0.148, 0.272]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
