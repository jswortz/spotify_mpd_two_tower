{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]' --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db357fb-d242-4336-940d-071a3e548dee",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f2a517-0db0-40c0-8e70-19c6a07a495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "# BUCKET_NAME = f\"{PROJECT_ID}-tfrs-retrieval\"\n",
    "# config = !gsutil cat gs://{BUCKET_NAME}/config/notebook_env.py\n",
    "# print(config.n)\n",
    "# exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5227d2ae-c04a-4ae7-b61a-d65233a80f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# TODO - parameterize\n",
    "REGION = 'us-central1'\n",
    "NETWORK = 'ucaip-haystack-vpc-network'\n",
    "BUCKET_NAME = 'spotify-data-regimes'\n",
    "\n",
    "BQ_DATASET = 'a_spotify_hack_v2'\n",
    "BQ_TABLE_TRAIN = 'train_flat_last_15_v6' # TODO\n",
    "BQ_TABLE_VALID = 'train_flat_valid_last_15_v6'\n",
    "BQ_TABLE_CANDIDATES = 'candidates_v9'\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 15\n",
    "\n",
    "VERSION= \"jtv15-8m\" # version tag for dataflow pipeline\n",
    "\n",
    "# gcs subfolders - destinations for processed data: f'gs://{BUCKET_NAME}/{VERSION}/{___PREFIX}'\n",
    "CANDIDATE_PREFIX = 'candidates'\n",
    "TRAIN_DIR_PREFIX = 'train'\n",
    "VALID_DIR_PREFIX = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e67f5f-2539-407f-8f24-3be640420f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://spotify-data-regimes/jtv1-candidates/\n",
      "                                 gs://spotify-data-regimes/jtv1/\n",
      "                                 gs://spotify-data-regimes/jtv10/\n",
      "                                 gs://spotify-data-regimes/jtv11/\n",
      "                                 gs://spotify-data-regimes/jtv12/\n",
      "                                 gs://spotify-data-regimes/jtv13-lite/\n",
      "                                 gs://spotify-data-regimes/jtv14-8m/\n",
      "                                 gs://spotify-data-regimes/jtv15-8m/\n",
      "                                 gs://spotify-data-regimes/jtv2/\n",
      "                                 gs://spotify-data-regimes/jtv4/\n",
      "                                 gs://spotify-data-regimes/jtv5/\n",
      "                                 gs://spotify-data-regimes/jtv8/\n",
      "                                 gs://spotify-data-regimes/jtv9demo/\n",
      "                                 gs://spotify-data-regimes/test/\n",
      "                                 gs://spotify-data-regimes/v1/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "# Run Dataflow to convert BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "* Candidate generation\n",
    "\n",
    "> `beam_candidates\\python3 main.py`\n",
    "   \n",
    "* Training generation\n",
    "  \n",
    "> `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_training\u001b[00m\n",
      "├── README.MD\n",
      "├── __init__.py\n",
      "├── main-train.py\n",
      "├── setup.py\n",
      "└── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "    ├── __init__.py\n",
      "    ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "    │   ├── __init__.cpython-37.pyc\n",
      "    │   └── train_pipe.cpython-37.pyc\n",
      "    └── train_pipe_shape.py\n",
      "\n",
      "2 directories, 8 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a764cd-f14b-4f88-8314-4c1e5bf77bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/jw-repo/spotify_mpd_two_tower'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('/home/jupyter/jw-repo/spotify_mpd_two_tower')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd beam_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3af313-e958-4e62-ac0a-8482dc8763c4",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23e4e85-b611-42f1-b8e5-023ffb49919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_VALID = 250\n",
    "TOTAL_MB_VALID = 500\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_VALID) // int(TARGET_SHARD_SIZE_MB_VALID)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 2\n",
      "2023-01-27 16:12:37.003866: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-jtv15-8m-230127-161240, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://spotify-data-regimes/jtv15-8m/job/staging/, temp_location=gs://spotify-data-regimes/jtv15-8m/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "total runtime_mins: 16\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# ! python3 main-train.py $BQ_TABLE_VALID $VALID_DIR_PREFIX $TARGET_SHARD_SIZE_MB_VALID $TOTAL_MB_VALID $VERSION $BUCKET_NAME $REGION $PROJECT_ID $NETWORK $BQ_DATASET\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $VALID_DIR_PREFIX $TOTAL_MB_VALID $TARGET_SHARD_SIZE_MB_VALID $BQ_DATASET $BQ_TABLE_VALID\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c97d0-3518-45b0-a72f-10ac9f8007ff",
   "metadata": {},
   "source": [
    "### Tain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9896f5e7-975c-441c-99a2-2f19fa444910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_TRAIN = 2000\n",
    "TOTAL_MB_TRAIN = 44_000\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_TRAIN) // int(TARGET_SHARD_SIZE_MB_TRAIN)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6d635a3-cdf4-4537-abba-f7a43275ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 22\n",
      "2023-01-27 16:33:09.276993: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-jtv15-8m-230127-163312, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://spotify-data-regimes/jtv15-8m/job/staging/, temp_location=gs://spotify-data-regimes/jtv15-8m/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "total runtime_mins: 26\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $TRAIN_DIR_PREFIX $TOTAL_MB_TRAIN $TARGET_SHARD_SIZE_MB_TRAIN $BQ_DATASET $BQ_TABLE_TRAIN\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacf47b-bd83-47e8-804b-b53471d00e5d",
   "metadata": {},
   "source": [
    "# Now export the candidates\n",
    "\n",
    "**TODO:** clean-up section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d12ea7-be9f-49cb-b7dc-663b7b81a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo/spotify_mpd_two_tower/beam_candidates\n"
     ]
    }
   ],
   "source": [
    "%cd ../beam_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350506bc-dadd-4781-84f6-5544fdfc78b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-27 17:05:42.868226: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-jtv15-8m-230127-170542, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://spotify-data-regimes/jtv15-8m/job/staging/, temp_location=gs://spotify-data-regimes/jtv15-8m/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "# Test output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e13d-9985-40ae-8b1a-3a9d06487bcb",
   "metadata": {},
   "source": [
    "## Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccb4df-a503-4b56-95e6-7af42dd2453e",
   "metadata": {},
   "source": [
    "### Candidate tower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66216584-d182-4eb9-9187-a67c6a3cb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = {\n",
    "    \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "    \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "    \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # new\n",
    "    # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"time_signature_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eb2d9-a81a-4c94-bd70-26eb605037ab",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_files = []\n",
    "# for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "#     candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "# candidate_files = f'gs://{BUCKET_NAME}/{VERSION}/{CANDIDATE_PREFIX}/candidates-00000-of-00001.tfrecords'\n",
    "candidate_files = f'gs://{BUCKET_NAME}/{VERSION}/candidates-00000-of-00001.tfrecords'\n",
    "    \n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "def parse_candidate_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"Nim's Island\"], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:3s9jAEzWINEIDxqbtqkli3'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([72135.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"'british soundtrack', 'hollywood', 'orchestral soundtrack', 'scorecore', 'soundtrack'\"],\n",
      "      dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Patrick Doyle'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([61.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:1W42coQfIlt6btgqpfJWYQ'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([242320.], dtype=float32)>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.928], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.257], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.116], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.722], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'6'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0748], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-21.454], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"Nim's Island\"], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0385], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([129.063], dtype=float32)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:6Nx4UYbpHuU4x5mozUDaQQ'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0786], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f835e-fb68-4610-92a5-3f4c9547923d",
   "metadata": {},
   "source": [
    "## Train & Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb2d770-681b-466d-ba4a-f7e84f2fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLAYLIST_LENGTH = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b519ecc-fae8-4a9e-9f89-303c7f24e107",
   "metadata": {},
   "source": [
    "### train & valid features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49445d15-3782-42e3-9820-8494ad67ac7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feats = {\n",
    "    # ===================================================\n",
    "    # candidate track features\n",
    "    # ===================================================\n",
    "    \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "    \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "    \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"time_signature_can\": tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \n",
    "    # ===================================================\n",
    "    # summary playlist features\n",
    "    # ===================================================\n",
    "    \"pl_name_src\" : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    'pl_collaborative_src' : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    # 'num_pl_followers_src' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    'pl_duration_ms_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    'num_pl_songs_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),  # num_pl_songs_new | n_songs_pl_new\n",
    "    'num_pl_artists_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    'num_pl_albums_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    # 'avg_track_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "    # 'avg_artist_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # 'avg_art_followers_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \n",
    "    # ===================================================\n",
    "    # ragged playlist features\n",
    "    # ===================================================\n",
    "    # bytes / string\n",
    "    \"track_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"album_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"album_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_genres_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    # \"tracks_playlist_titles_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \n",
    "    # Float List\n",
    "    \"duration_ms_songs_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artist_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"artists_followers_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_danceability_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_energy_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_key_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_loudness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_mode_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_speechiness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_acousticness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_instrumentalness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_liveness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"track_valence_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    \"track_tempo_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "    \"time_signature_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d61b0-9f70-48c4-b2ec-c682f4a7c034",
   "metadata": {},
   "source": [
    "### Valid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{VERSION}/{VALID_DIR_PREFIX}/', delimiter=\"/\"):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "valid_parsed = valid.map(parse_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b733662-a8d9-4581-9a24-fc02265569e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Lolly'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'9', b'In My Mind', b'Nervous System',\n",
      "        b'Nervous (The Ooh Song)', b'Fast Car', b'Wedding Bells EP',\n",
      "        b'DARKNESS AND LIGHT', b'Night & Day',\n",
      "        b'A Head Full Of Dreams Tour Edition', b'FUTURE', b'Oh My My',\n",
      "        b'GALLERY', b'Once In a While', b'By Your Side',\n",
      "        b'Double Vision']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:0Jy2FoyFXxrHi6XIa8cHzU'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'spotify:album:0JjoGwsBjce2mgHRliH0VN',\n",
      "        b'spotify:album:0YOVfyE9xg8noB5rDNLtm4',\n",
      "        b'spotify:album:22aqlgX39cWQMWazg9qwuv',\n",
      "        b'spotify:album:6jfuBG9u0Au2nWXGXTXmux',\n",
      "        b'spotify:album:5jfuIbTeaLhBZxsCVv3QyM',\n",
      "        b'spotify:album:4IzStrE9iX01yM5gUUAe74',\n",
      "        b'spotify:album:7xMjYDrgPLp1ReFGAOyS1O',\n",
      "        b'spotify:album:52bwpFP1d8uri0V5oWQLF0',\n",
      "        b'spotify:album:5IDGBfcVjwMoGPKOsfyXLN',\n",
      "        b'spotify:album:17FBoXK1NU2rvJBbzdzw0r',\n",
      "        b'spotify:album:6p01JdkB7ry8iAf4IuC1Lv',\n",
      "        b'spotify:album:2FNk380jCQyICbwtkOdEHE',\n",
      "        b'spotify:album:7nsWIOWiX7Zt0AdR5imU50',\n",
      "        b'spotify:album:6IJVWErYhvWqG41NnLSGMM',\n",
      "        b'spotify:album:2iTpTfHG5yui5JVtfRNOdK']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'detroit hip hop'\"], dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b\"'dance pop', 'downtempo', 'pop', 'post-teen pop', 'shiver pop'\",\n",
      "        b\"'alt z', 'electropop', 'indie electropop', 'indie poptimism', 'pop', 'social media pop'\",\n",
      "        b\"'alt z', 'dance pop', 'electropop', 'pop', 'post-teen pop'\",\n",
      "        b\"'irish pop', 'neo mellow', 'pop', 'pop rock', 'viral pop'\",\n",
      "        b\"'dance pop', 'edm', 'pop', 'pop dance', 'tropical house', 'uk dance'\",\n",
      "        b\"'dance pop', 'downtempo', 'pop', 'post-teen pop', 'shiver pop'\",\n",
      "        b\"'neo soul', 'pop', 'pop soul', 'r&b', 'urban contemporary'\",\n",
      "        b\"'boy band', 'dance pop', 'pop', 'post-teen pop'\",\n",
      "        b\"'permanent wave', 'pop'\",\n",
      "        b\"'atl hip hop', 'hip hop', 'pop rap', 'rap', 'southern hip hop', 'trap'\",\n",
      "        b\"'dance pop', 'piano rock', 'pop', 'pop rock'\",\n",
      "        b\"'electropop', 'indie poptimism', 'pop', 'pop dance', 'tropical house'\",\n",
      "        b\"'dance pop', 'indie pop rap', 'pop', 'pop dance', 'pop rap', 'pop rock', 'post-teen pop', 'tropical house'\",\n",
      "        b\"'dance pop', 'edm', 'pop', 'pop dance', 'tropical house', 'uk dance'\",\n",
      "        b\"'bachata', 'latin', 'latin hip hop', 'latin pop'\"]],\n",
      "      dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Maejor Ali'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'Cashmere Cat', b'Maty Noyes', b'Julia Michaels',\n",
      "        b'Gavin James', b'Jonas Blue', b'Cashmere Cat', b'John Legend',\n",
      "        b'The Vamps', b'Coldplay', b'Future', b'OneRepublic',\n",
      "        b'A R I Z O N A', b'Timeflies', b'Jonas Blue', b'Prince Royce']],\n",
      "      dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([65.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[61., 59., 80., 69., 79., 61., 81., 75., 92., 92., 86., 66., 62.,\n",
      "        79., 80.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:1l7P8zlCKFbvOtUYYoJtoV'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'spotify:artist:2LZDXcxJWgsJfKXZv9a5eG',\n",
      "        b'spotify:artist:5JSXWmQO8csVUy6hSRu8TA',\n",
      "        b'spotify:artist:0ZED1XzwlLHW4ZaG4lOT6m',\n",
      "        b'spotify:artist:25tMQOrIU4LlUo6Sv8v5SE',\n",
      "        b'spotify:artist:1HBjj22wzbscIZ9sEb5dyf',\n",
      "        b'spotify:artist:2LZDXcxJWgsJfKXZv9a5eG',\n",
      "        b'spotify:artist:5y2Xq6xcjJb2jVM54GHK3t',\n",
      "        b'spotify:artist:7gAppWoH7pcYmphCVTXkzs',\n",
      "        b'spotify:artist:4gzpq5DPGxSnKTe4SA8HAU',\n",
      "        b'spotify:artist:1RyvyyTE3xzB2ZywiAwp0i',\n",
      "        b'spotify:artist:5Pwc4xIPtQLFEnJriah9YJ',\n",
      "        b'spotify:artist:7hOGhpa8RMSuDOWntGIAJt',\n",
      "        b'spotify:artist:6dC0rIJNLSFZwqckLgXJ8p',\n",
      "        b'spotify:artist:1HBjj22wzbscIZ9sEb5dyf',\n",
      "        b'spotify:artist:3MHaV05u0io8fQbZ2XPtlC']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[  316055.,   239689.,  4325374.,   633015.,  3502041.,   316055.,\n",
      "         6131889.,  5064685., 34753940., 11270410., 13351301.,   382370.,\n",
      "          320519.,  3502041.,  6825828.]], dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([225506.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[215670., 212026., 176320., 195194., 212424., 265100., 210293.,\n",
      "        197640., 212647., 180520., 169773., 194013., 215160., 201254.,\n",
      "        221653.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([127.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([87.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([184.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([39368824.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'idk'], dtype=object)>, 'time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'time_signature_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'5', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "        b'4', b'4', b'4', b'4']], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0383], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.494  , 0.45   , 0.413  , 0.0732 , 0.453  , 0.337  , 0.591  ,\n",
      "        0.0038 , 0.00868, 0.0312 , 0.0915 , 0.13   , 0.00758, 0.0778 ,\n",
      "        0.086  ]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.661], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.42 , 0.768, 0.706, 0.432, 0.459, 0.71 , 0.495, 0.544, 0.564,\n",
      "        0.618, 0.552, 0.617, 0.786, 0.696, 0.685]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.88], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.636, 0.632, 0.427, 0.874, 0.587, 0.633, 0.762, 0.809, 0.849,\n",
      "        0.727, 0.689, 0.642, 0.687, 0.743, 0.4  ]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.00e+00, 0.00e+00, 0.00e+00, 6.14e-06, 0.00e+00, 3.72e-01,\n",
      "        0.00e+00, 0.00e+00, 4.68e-06, 0.00e+00, 0.00e+00, 1.57e-01,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'10', b'0', b'8', b'7', b'9', b'0', b'8', b'8', b'0', b'3',\n",
      "        b'10', b'8', b'0', b'6', b'0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.782], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.122 , 0.0449, 0.0609, 0.371 , 0.307 , 0.0989, 0.0763, 0.323 ,\n",
      "        0.12  , 0.196 , 0.27  , 0.0929, 0.619 , 0.0581, 0.156 ]],\n",
      "      dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-2.978], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[-7.216, -3.807, -6.864, -5.558, -6.983, -7.421, -3.842, -5.098,\n",
      "        -3.516, -7.224, -6.444, -8.624, -5.914, -3.838, -9.749]],\n",
      "      dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'1', b'0', b'1', b'1', b'1', b'0', b'1', b'1', b'0', b'0', b'0',\n",
      "        b'1', b'1', b'1', b'1']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Lolly'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'Trust Nobody (feat. Selena Gomez & Tory Lanez)', b'in my miNd',\n",
      "        b'Issues', b'Nervous (The Ooh Song) - Mark McCabe Remix',\n",
      "        b'Fast Car', b'Rice Rain', b'Love Me Now', b'All Night',\n",
      "        b'Hymn For The Weekend - Seeb Remix', b'Used to This',\n",
      "        b'Wherever I Go', b'Oceans Away', b'Once In a While',\n",
      "        b'By Your Side', b'Handcuffs']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[ 0.,  0.,  0., 55.,  1.,  0., 70.,  0., 36., 55., 76., 66., 65.,\n",
      "         0., 38.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.296], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.22  , 0.0254, 0.0879, 0.0462, 0.0785, 0.0393, 0.0862, 0.0363,\n",
      "        0.0517, 0.208 , 0.0425, 0.0334, 0.141 , 0.0331, 0.122 ]],\n",
      "      dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([152.221], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[156.104, 102.061, 113.804, 103.85 , 113.901, 145.126, 123.893,\n",
      "        145.017, 102.028, 164.992,  99.961, 105.885, 105.021, 122.978,\n",
      "         74.962]], dtype=float32)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:1x7QWWVpQdoiOGDRWuSK5l'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'spotify:track:2wDjpPW3HZdA9quPPmZAMu',\n",
      "        b'spotify:track:0F1Rc18rZcJOALxIIQPTYd',\n",
      "        b'spotify:track:6D0b04NJIKfEMg040WioJQ',\n",
      "        b'spotify:track:0L9lXMXddmoBbBUeF7A9An',\n",
      "        b'spotify:track:6OZh916QF8XNunWaP97WEZ',\n",
      "        b'spotify:track:0M6Jr7EA0Mgo334VOjHvPo',\n",
      "        b'spotify:track:6nxQdXa1uAL0rY72wPZu89',\n",
      "        b'spotify:track:4b4KcovePX8Ke2cLIQTLM0',\n",
      "        b'spotify:track:1OAiWI2oPmglaOiv9fdioU',\n",
      "        b'spotify:track:78sr3ogs4UzITcCNbXM9cM',\n",
      "        b'spotify:track:46jLy47W8rkf8rEX04gMKB',\n",
      "        b'spotify:track:6A8dnC0xkiuWN4BshmTB2I',\n",
      "        b'spotify:track:6cREm4bV7V79Yxdilx9HDo',\n",
      "        b'spotify:track:1D3ODoXHBLpdxolZRHWV1j',\n",
      "        b'spotify:track:5aGeQVoI3u3k2SArUNuIVq']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.827], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.784, 0.786, 0.42 , 0.374, 0.581, 0.506, 0.708, 0.448, 0.427,\n",
      "        0.401, 0.349, 0.221, 0.345, 0.644, 0.392]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6031b7e-fcbb-4139-a6c6-75d8a63e6c54",
   "metadata": {},
   "source": [
    "### Train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f5fc764-c1ca-4346-8fcd-bd9e2939d722",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_31232/1992728820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://storage.googleapis.com/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gs://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_tfrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filenames, compression_type, buffer_size, num_parallel_reads, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0many\u001b[0m \u001b[0margument\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_or_validate_filenames_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/readers.py\u001b[0m in \u001b[0;36m_create_or_validate_filenames_dataset\u001b[0;34m(filenames, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_normalise_fspath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1618\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         ret = conversion_func(\n\u001b[0;32m-> 1620\u001b[0;31m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1621\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0;31m# Could not coerce the conversion to use the preferred dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                          as_ref=False):\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{VERSION}/{TRAIN_DIR_PREFIX}/', delimiter=\"/\"):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "train = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "train_parsed = train.map(parse_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f98d42e-4ca6-4e1f-a832-6c0a9b1c44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b4a2ecb-0255-4b67-afe5-13659a6921f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Melody Hits Vol. 7'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'Ahla W Ahla (Summer Edition)', b'Ayech Bi Oyouni',\n",
      "        b'Sweetness of Nancy', b'Enti Mshiti',\n",
      "        b'Ahla W Ahla (Summer Edition)',\n",
      "        b'Top 25 DJ Mixes of Arabic Music',\n",
      "        b'Ahla W Ahla (Summer Edition)', b'Best Arabic Music',\n",
      "        b'Lamaallem', b'Top 25 DJ Mixes of Arabic Music',\n",
      "        b'Melody Hits, Vol. 6', b'Top 25 DJ Mixes of Arabic Music',\n",
      "        b'Ghaltana', b'Malyoun Bhebbik Malyoun', b'Ghammadt Einy']],\n",
      "      dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:4GHKFNuSbVVcdwGtZ6AlCt'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'spotify:album:5A4q1RPTVObTLih6EhG67w',\n",
      "        b'spotify:album:5pfkDggECTlWNLL9Jf4orK',\n",
      "        b'spotify:album:4ZC7cD2S99dPXUMKkQ6Sic',\n",
      "        b'spotify:album:32H47741Ke2C4lq45RLke8',\n",
      "        b'spotify:album:5A4q1RPTVObTLih6EhG67w',\n",
      "        b'spotify:album:3YO7cWbXdeytvv43gMt2ve',\n",
      "        b'spotify:album:5A4q1RPTVObTLih6EhG67w',\n",
      "        b'spotify:album:2KT65vIRfsNVOcqSfHKgej',\n",
      "        b'spotify:album:3GOfAS1UAgKIpc4YswbicJ',\n",
      "        b'spotify:album:3YO7cWbXdeytvv43gMt2ve',\n",
      "        b'spotify:album:2juaHFVSnWkyT3RT7Eqjo3',\n",
      "        b'spotify:album:3YO7cWbXdeytvv43gMt2ve',\n",
      "        b'spotify:album:3aywhQv2kHYxaNrJOpq8Kh',\n",
      "        b'spotify:album:1GcA5rrUecUzoTBC93t5z3',\n",
      "        b'spotify:album:4gg2CJrmvibTRGgHbzfj2H']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'arab pop', 'lebanese pop'\"], dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b\"'arab pop', 'belly dance', 'egyptian pop', 'persian pop', 'rif'\",\n",
      "        b\"'arab pop', 'lebanese pop', 'moroccan pop'\",\n",
      "        b\"'afghan pop', 'arab pop', 'belly dance', 'lebanese pop'\",\n",
      "        b\"'arab pop', 'dabke', 'lebanese pop'\",\n",
      "        b\"'arab pop', 'belly dance', 'egyptian pop', 'persian pop', 'rif'\",\n",
      "        b\"'classic arab pop', 'jalsat', 'khaliji'\",\n",
      "        b\"'arab pop', 'belly dance', 'egyptian pop', 'persian pop', 'rif'\",\n",
      "        b\"'arab pop', 'egyptian pop'\",\n",
      "        b\"'arab pop', 'moroccan pop', 'rif', 'shaabi'\",\n",
      "        b\"'arab pop', 'egyptian pop'\", b\"'arab pop', 'lebanese pop'\",\n",
      "        b\"'arab pop', 'belly dance', 'egyptian pop', 'persian pop', 'rif'\",\n",
      "        b\"'arab pop', 'moroccan pop', 'rif', 'shaabi'\",\n",
      "        b\"'arab pop', 'dabke', 'syrian pop'\",\n",
      "        b\"'arab pop', 'egyptian pop'\"]], dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Mohamed Eskandar'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'Amr Diab', b'Yara', b'Nancy Ajram', b'Melhem Zein',\n",
      "        b'Amr Diab', b'Rashed Al Majed', b'Amr Diab', b'Mohamed Hamaki',\n",
      "        b'Saad Lamjarred', b'Amr Mostafa', b'Mohamed Eskandar',\n",
      "        b'Amr Diab', b'Saad Lamjarred', b'Hussein el Deek',\n",
      "        b'Ramy Sabry']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([33.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[60., 46., 61., 46., 60., 47., 60., 58., 60., 32., 33., 60., 60.,\n",
      "        44., 52.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:1N3XmTZ6YmMI1oIvgP6BI3'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'spotify:artist:5abSRg0xN1NV3gLbuvX24M',\n",
      "        b'spotify:artist:46FJPTBdnCK0GMd76nil6e',\n",
      "        b'spotify:artist:0LnHdW6HMPoOlNdhG3DHjE',\n",
      "        b'spotify:artist:3pCdpK2DVRSs77L9RtxFy0',\n",
      "        b'spotify:artist:5abSRg0xN1NV3gLbuvX24M',\n",
      "        b'spotify:artist:3bAY4XYwWCUNpuXclgudSX',\n",
      "        b'spotify:artist:5abSRg0xN1NV3gLbuvX24M',\n",
      "        b'spotify:artist:6bb9VI1PpPTEmdgcgjTppX',\n",
      "        b'spotify:artist:4x2yBQF4hq8b0DEv8HVvrl',\n",
      "        b'spotify:artist:6YZXwVnjrIIz9SlBd8l2Cg',\n",
      "        b'spotify:artist:1N3XmTZ6YmMI1oIvgP6BI3',\n",
      "        b'spotify:artist:5abSRg0xN1NV3gLbuvX24M',\n",
      "        b'spotify:artist:4x2yBQF4hq8b0DEv8HVvrl',\n",
      "        b'spotify:artist:1QxkWzg3QsYJv6xMXSuVMs',\n",
      "        b'spotify:artist:5LtHZB7vU02HtNoOzNcVhc']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[4.058075e+06, 2.463890e+05, 1.550741e+06, 3.260180e+05,\n",
      "        4.058075e+06, 6.644300e+05, 4.058075e+06, 2.698446e+06,\n",
      "        5.950000e+02, 2.372310e+05, 0.000000e+00, 4.058075e+06,\n",
      "        5.950000e+02, 1.356850e+05, 9.085060e+05]], dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([231418.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[160906., 242747., 305475., 353123., 196760., 208003., 226800.,\n",
      "        189800., 237714., 187376.,  56294., 230004., 238214., 258560.,\n",
      "        291266.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([61.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([42.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([93.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([23391204.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Arabic'], dtype=object)>, 'time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'time_signature_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "        b'4', b'4', b'4', b'4']], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.155], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.0424 , 0.345  , 0.0571 , 0.106  , 0.00567, 0.227  , 0.153  ,\n",
      "        0.0422 , 0.0117 , 0.1    , 0.166  , 0.265  , 0.0343 , 0.247  ,\n",
      "        0.308  ]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.787], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.634, 0.63 , 0.604, 0.727, 0.754, 0.698, 0.723, 0.638, 0.503,\n",
      "        0.574, 0.671, 0.691, 0.702, 0.618, 0.65 ]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.926], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.765, 0.572, 0.81 , 0.708, 0.624, 0.939, 0.912, 0.67 , 0.867,\n",
      "        0.934, 0.791, 0.989, 0.906, 0.817, 0.778]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.68e-06], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[6.20e-02, 0.00e+00, 8.52e-05, 3.67e-06, 7.74e-04, 1.13e-03,\n",
      "        8.14e-05, 7.20e-06, 0.00e+00, 1.21e-02, 0.00e+00, 1.14e-05,\n",
      "        0.00e+00, 2.08e-06, 1.07e-01]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'3', b'5', b'8', b'5', b'10', b'9', b'11', b'6', b'8', b'11',\n",
      "        b'7', b'7', b'9', b'3', b'0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.329], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.0299, 0.0915, 0.187 , 0.133 , 0.0392, 0.0465, 0.0436, 0.0733,\n",
      "        0.0729, 0.349 , 0.258 , 0.14  , 0.299 , 0.109 , 0.405 ]],\n",
      "      dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.473], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[-7.746, -6.668, -3.72 , -4.188, -8.274, -4.072, -6.954, -9.166,\n",
      "        -3.543, -3.362, -7.261, -4.119, -4.219, -6.197, -7.315]],\n",
      "      dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'1', b'0', b'0', b'1', b'0', b'0', b'0', b'1', b'1', b'0', b'1',\n",
      "        b'1', b'1', b'0', b'0']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Joumhoureyet Alby'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'Ahla W Ahla (Remix)', b'Ma Baaref', b'Ya Kether',\n",
      "        b'Enti Mshiti', b'La La (Remix)', b'Mashkalne',\n",
      "        b'Rasmaha (Remix)',\n",
      "        b'\\xd9\\x83\\xd8\\xa7\\xd9\\x86 \\xd9\\x88\\xd9\\x83\\xd8\\xa7\\xd9\\x86',\n",
      "        b'Lamaallem', b'Moonaya Habeebee', b'Ouly Behebny',\n",
      "        b'Lailee Nharee (Remix DJ Aventura)', b'Ghaltana',\n",
      "        b'Malyoun Bhebbik Malyoun', b\"Gowwaya Hat'eish\"]], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([44.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[11.,  0.,  0., 42.,  4.,  0.,  3.,  0., 61.,  0.,  0.,  0.,  0.,\n",
      "         0., 17.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0917], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.0434, 0.032 , 0.0438, 0.042 , 0.108 , 0.211 , 0.0497, 0.066 ,\n",
      "        0.269 , 0.29  , 0.0946, 0.148 , 0.163 , 0.043 , 0.0459]],\n",
      "      dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([104.979], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[121.696,  95.969,  91.947, 148.06 , 139.993, 105.363,  96.378,\n",
      "        169.94 , 104.923, 109.074, 199.963, 106.036,  92.946, 142.015,\n",
      "         91.997]], dtype=float32)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:0SqYaqatc1f9qewgVYp7d1'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 15), dtype=string, numpy=\n",
      "array([[b'spotify:track:4R1MQzA4CsKvqvpAGYlF6X',\n",
      "        b'spotify:track:6S49sbvebaWWUYJCxQ9kYx',\n",
      "        b'spotify:track:3zET1ACJRJTe5r9TQIlokg',\n",
      "        b'spotify:track:4MmVIBw7hNG9Iw9arQDyKb',\n",
      "        b'spotify:track:1Qgqx6i5hi3MWyvDw0h8mw',\n",
      "        b'spotify:track:38xaVeL7qkcbhrSaquVIux',\n",
      "        b'spotify:track:5ErQtnHkr6iYxq5vObi7tq',\n",
      "        b'spotify:track:2raw6Yx50bs8olIQUMD4iE',\n",
      "        b'spotify:track:6Tr7kvkbSd4ZKNTn6oynr7',\n",
      "        b'spotify:track:179VuTIPCKJf2yOKLpmESm',\n",
      "        b'spotify:track:4YuDey5Cd2LIwX79FCmW3i',\n",
      "        b'spotify:track:0xYOOhOhRc1mwz0rz0NClc',\n",
      "        b'spotify:track:3gOi8JeC2ngkjRKPKIFM6b',\n",
      "        b'spotify:track:5qIVeShhY969SX0DeAtFTC',\n",
      "        b'spotify:track:2M3YHr5QyjcsCJJ1lEOAQs']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.631], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 15), dtype=float32, numpy=\n",
      "array([[0.842, 0.458, 0.827, 0.589, 0.65 , 0.595, 0.64 , 0.6  , 0.658,\n",
      "        0.635, 0.698, 0.632, 0.791, 0.615, 0.86 ]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
