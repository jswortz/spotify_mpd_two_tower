{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c84b0f-ecdd-4df2-b239-ce7ad8388851",
   "metadata": {},
   "source": [
    "## Load env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc9bcee-090a-45b6-89b6-8d7bffc6f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ndr-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"                  # TODO\n",
    "PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0318a52-85f7-48de-a7d3-483c199df4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ndr-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "APP                      = \"sp\"\n",
      "MODEL_TYPE               = \"2tower\"\n",
      "FRAMEWORK                = \"tfrs\"\n",
      "DATA_VERSION             = \"v1\"\n",
      "TRACK_HISTORY            = \"5\"\n",
      "\n",
      "BUCKET_NAME              = \"ndr-v1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://ndr-v1-hybrid-vertex-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ndr-v1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "CANDIDATE_PREFIX         = \"candidates\"\n",
      "TRAIN_DIR_PREFIX         = \"train\"\n",
      "VALID_DIR_PREFIX         = \"valid\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"ndr-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/ndr-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n",
      "SERVING_IMAGE_URI_CPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
      "SERVING_IMAGE_URI_GPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74520eea-2d91-4973-918c-1cfa1b90b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_TABLE_TRAIN         = 'v2_train_flatten_last_5'\n",
    "BQ_TABLE_VALID         = 'v2_train_flatten_valid_last_5'\n",
    "BQ_TABLE_CANDIDATES    = 'candidates'\n",
    "\n",
    "# =============================== #\n",
    "# included in env-setup.ipynb     #\n",
    "# =============================== #\n",
    "# TRACK_HISTORY = 5\n",
    "# VERSION = \"v2-0-0\" # version tag for dataflow pipeline\n",
    "# CANDIDATE_PREFIX = 'candidates'\n",
    "# TRAIN_DIR_PREFIX = 'train'\n",
    "# VALID_DIR_PREFIX = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5856e02-89a9-4237-8ada-bdd639e4af65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://ndr-v1-hybrid-vertex-bucket/config/\n",
      "                                 gs://ndr-v1-hybrid-vertex-bucket/data/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bd23b-7d91-463e-bf10-adeb318169e3",
   "metadata": {},
   "source": [
    "## pip & package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]' --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f2a517-0db0-40c0-8e70-19c6a07a495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP_PROJECTS = !gcloud config get-value project\n",
    "# PROJECT_ID = GCP_PROJECTS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5227d2ae-c04a-4ae7-b61a-d65233a80f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "# Run Dataflow to convert BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "* Candidate generation\n",
    "\n",
    "> `beam_candidates\\python3 main.py $PROJECT_ID $NETWORK $REGION $VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES`\n",
    "   \n",
    "* Training generation\n",
    "  \n",
    "> `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_training\u001b[00m\n",
      "├── README.MD\n",
      "├── __init__.py\n",
      "├── \u001b[01;34mcreate_tfrecords_training.egg-info\u001b[00m\n",
      "│   ├── PKG-INFO\n",
      "│   ├── SOURCES.txt\n",
      "│   ├── dependency_links.txt\n",
      "│   ├── requires.txt\n",
      "│   └── top_level.txt\n",
      "├── main-train.py\n",
      "├── setup.py\n",
      "└── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "    ├── __init__.py\n",
      "    ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "    │   ├── __init__.cpython-37.pyc\n",
      "    │   ├── train_pipe.cpython-37.pyc\n",
      "    │   └── train_pipe_shape.cpython-37.pyc\n",
      "    └── train_pipe_shape.py\n",
      "\n",
      "3 directories, 14 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a764cd-f14b-4f88-8314-4c1e5bf77bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower/beam_candidates\n"
     ]
    }
   ],
   "source": [
    "%cd beam_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55b2d-4533-4329-97e7-4e175db2a7bd",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0953936-a39a-4d2e-8ba1-2b57d045b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-candidates-v3data-230919-130656, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://ndr-v1-hybrid-vertex-bucket/data/v3data/job/staging/, temp_location=gs://ndr-v1-hybrid-vertex-bucket/data/v3data/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 17\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $CANDIDATE_PREFIX $BQ_DATASET $BQ_TABLE_CANDIDATES\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1752427e-abad-4740-8c16-38ff711c9bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower/beam_candidates\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faff9999-83c1-417f-86b2-49b83d0432ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3af313-e958-4e62-ac0a-8482dc8763c4",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9929178-a033-46ec-b400-2c7059fe98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jw-repo2/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23e4e85-b611-42f1-b8e5-023ffb49919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_VALID = 250\n",
    "TOTAL_MB_VALID = 500\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_VALID) // int(TARGET_SHARD_SIZE_MB_VALID)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 2\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v1-230919-132747, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://ndr-v1-hybrid-vertex-bucket/v1/job/staging/, temp_location=gs://ndr-v1-hybrid-vertex-bucket/v1/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mtotal runtime_mins: 15\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# ! python3 main-train.py $BQ_TABLE_VALID $VALID_DIR_PREFIX $TARGET_SHARD_SIZE_MB_VALID $TOTAL_MB_VALID $VERSION $BUCKET_NAME $REGION $PROJECT_ID $NETWORK $BQ_DATASET\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $VALID_DIR_PREFIX $TOTAL_MB_VALID $TARGET_SHARD_SIZE_MB_VALID $BQ_DATASET $BQ_TABLE_VALID\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c97d0-3518-45b0-a72f-10ac9f8007ff",
   "metadata": {},
   "source": [
    "### Tain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9896f5e7-975c-441c-99a2-2f19fa444910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SHARD_SIZE_MB_TRAIN = 2000\n",
    "TOTAL_MB_TRAIN = 44_000\n",
    "NUM_TF_RECORDS = int(TOTAL_MB_TRAIN) // int(TARGET_SHARD_SIZE_MB_TRAIN)\n",
    "NUM_TF_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d635a3-cdf4-4537-abba-f7a43275ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Expected TFRecords: 22\n",
      "GoogleCloudOptions(create_from_snapshot=None, dataflow_endpoint=https://dataflow.googleapis.com, dataflow_kms_key=None, dataflow_service_options=None, enable_artifact_caching=False, enable_hot_key_logging=False, enable_streaming_engine=False, flexrs_goal=None, gcp_oauth_scopes=['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/devstorage.full_control', 'https://www.googleapis.com/auth/userinfo.email', 'https://www.googleapis.com/auth/datastore', 'https://www.googleapis.com/auth/spanner.admin', 'https://www.googleapis.com/auth/spanner.data'], impersonate_service_account=None, job_name=spotify-bq-tfrecords-v3data-230919-032310, labels=None, no_auth=False, project=hybrid-vertex, region=us-central1, service_account_email=None, staging_location=gs://twotower-v2-hybrid-vertex-bucket/v3data/job/staging/, temp_location=gs://twotower-v2-hybrid-vertex-bucket/v3data/job/temp/, template_location=None, transform_name_mapping=None, update=False)\n",
      "/opt/conda/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:2485: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = pcoll.pipeline.options.view_as(\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yyaml (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ocker (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "! python3 main-train.py $PROJECT_ID $VPC_NETWORK_NAME $REGION $DATA_VERSION $BUCKET_NAME $TRAIN_DIR_PREFIX $TOTAL_MB_TRAIN $TARGET_SHARD_SIZE_MB_TRAIN $BQ_DATASET $BQ_TABLE_TRAIN\n",
    "\n",
    "end_time = time.time()\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"total runtime_mins: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "# Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d190ac1-1a81-4f64-8c24-8a5405f19830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import feature_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e13d-9985-40ae-8b1a-3a9d06487bcb",
   "metadata": {},
   "source": [
    "## Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccb4df-a503-4b56-95e6-7af42dd2453e",
   "metadata": {},
   "source": [
    "### Candidate tower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36de4fc9-1a3c-44f7-bf9b-7e7e9d86bbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_genres_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_followers_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_key_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_features = feature_sets.get_candidate_features()\n",
    "candidate_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eb2d9-a81a-4c94-bd70-26eb605037ab",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_files = []\n",
    "\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{CANDIDATE_PREFIX}'):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(feature_sets.parse_candidate_tfrecord_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Thanatophobia'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:5GBUYg5EqeDI0CuszAvDzj'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([27438.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'indie garage rock'\"], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Worn-Tin'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([40.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:7j8ds7BnqaEKuz1a1GN0J9'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([216923.], dtype=float32)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.655], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.321], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.555], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.752], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4.0'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.117], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-9.589], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Doug'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([14.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0323], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([129.537], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:2XZ3bL3ROk605SPpy6Dn9C'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.21], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f835e-fb68-4610-92a5-3f4c9547923d",
   "metadata": {},
   "source": [
    "## Train & Valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb2d770-681b-466d-ba4a-f7e84f2fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACK_HISTORY = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b519ecc-fae8-4a9e-9f89-303c7f24e107",
   "metadata": {},
   "source": [
    "### train & valid features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2cb3949-bc40-4aab-a99d-aed5ec680832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_uri_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'album_name_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'artist_genres_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'artist_followers_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_key_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_can': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_can': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_name_src': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_collaborative_src': FixedLenFeature(shape=(), dtype=tf.string, default_value=None),\n",
       " 'pl_duration_ms_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_songs_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_artists_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'num_pl_albums_new': FixedLenFeature(shape=(), dtype=tf.float32, default_value=None),\n",
       " 'track_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'album_uri_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'album_name_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'artist_genres_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'duration_ms_songs_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_pop_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'artist_pop_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'artists_followers_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_danceability_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_energy_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_key_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_loudness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_mode_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None),\n",
       " 'track_speechiness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_acousticness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_instrumentalness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_liveness_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_valence_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_tempo_pl': FixedLenFeature(shape=('5',), dtype=tf.float32, default_value=None),\n",
       " 'track_time_signature_pl': FixedLenFeature(shape=('5',), dtype=tf.string, default_value=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = feature_sets.get_all_features(TRACK_HISTORY)\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d61b0-9f70-48c4-b2ec-c682f4a7c034",
   "metadata": {},
   "source": [
    "### Valid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "valid_parsed = valid.map(feature_sets.parse_tfrecord)\n",
    "# valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'In Return'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Smash', b'Welcome Reality', b'Welcome Reality',\n",
      "        b'Welcome Reality', b'Welcome Reality']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:7eq7Um3f3NMlHuNQSpicsz'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:4HrD6q13Ig1GFesH8hWlA6',\n",
      "        b'spotify:album:7mLdDLzH8tMpan5Xi8tzB3',\n",
      "        b'spotify:album:02Zb13fM8k04tRwTfMUhe9',\n",
      "        b'spotify:album:02Zb13fM8k04tRwTfMUhe9',\n",
      "        b'spotify:album:02Zb13fM8k04tRwTfMUhe9']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1457832.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'chillwave', 'edm'\"], dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'dance pop', 'disco house', 'edm', 'electro house', 'filter house', 'house', 'pop dance', 'tropical house', 'vocal house'\",\n",
      "        b\"'drum and bass', 'edm', 'electro house', 'melodic dubstep'\",\n",
      "        b\"'drum and bass', 'edm', 'electro house', 'melodic dubstep'\",\n",
      "        b\"'drum and bass', 'edm', 'electro house', 'melodic dubstep'\",\n",
      "        b\"'drum and bass', 'edm', 'electro house', 'melodic dubstep'\"]],\n",
      "      dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'ODESZA'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Martin Solveig', b'NERO', b'NERO', b'NERO', b'NERO']],\n",
      "      dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([72.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[66., 58., 58., 58., 58.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:21mKp7DqtSNHhCAU2ugvUw'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:1bj5GrcLom5gZFF5t949Xl',\n",
      "        b'spotify:artist:4uRYpUQZrNrY5t8tAv3XrD',\n",
      "        b'spotify:artist:4uRYpUQZrNrY5t8tAv3XrD',\n",
      "        b'spotify:artist:4uRYpUQZrNrY5t8tAv3XrD',\n",
      "        b'spotify:artist:4uRYpUQZrNrY5t8tAv3XrD']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[1211275.,  820912.,  820912.,  820912.,  820912.]], dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([211200.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[255010., 257359., 250346., 284120., 247520.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([112.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([58.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([220.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([53584480.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Coachella 2015'], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00429], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[4.08e-03, 3.45e-03, 6.69e-03, 8.53e-05, 4.50e-05]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.644], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.489, 0.255, 0.579, 0.42 , 0.639]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.848], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.952, 0.889, 0.893, 0.849, 0.925]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0179], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[6.39e-03, 1.21e-06, 1.19e-05, 8.74e-01, 0.00e+00]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4.0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'5.0', b'9.0', b'0.0', b'8.0', b'1.0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0629], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.469, 0.177, 0.311, 0.144, 0.152]], dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-4.947], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[-3.462, -4.52 , -3.745, -4.372, -4.803]], dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'0', b'0', b'1', b'1', b'0']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'All We Need'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'The Night Out - Single Version', b'Promises', b'Crush On You',\n",
      "        b'Guilt', b'Me And You']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[31.,  0.,  0.,  0.,  0.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0519], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0702, 0.0694, 0.0381, 0.154 , 0.0616]], dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([99.991], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[144.047, 139.745, 143.935, 140.188, 127.961]], dtype=float32)>, 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'4', b'4', b'4', b'4', b'4']], dtype=object)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:7yaJYLVDJhxFCkm9WUZNth'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:3HAORquqzuV99HBZBXsHK0',\n",
      "        b'spotify:track:4A7qcJp2Sg867JST1pSPJz',\n",
      "        b'spotify:track:7JJLUJwQCMv7i9lWDvTCLN',\n",
      "        b'spotify:track:0VSdYNTKyZZZRYSHDVb4YQ',\n",
      "        b'spotify:track:6DEeUrq2VhjAj6KOhZcsu3']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.292], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.293, 0.154, 0.187, 0.659, 0.236]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6031b7e-fcbb-4139-a6c6-75d8a63e6c54",
   "metadata": {},
   "source": [
    "### Train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f5fc764-c1ca-4346-8fcd-bd9e2939d722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{TRAIN_DIR_PREFIX}/', delimiter=\"/\"):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "train = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "train_parsed = train.map(feature_sets.parse_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f98d42e-4ca6-4e1f-a832-6c0a9b1c44a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_time_signature_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(5,), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b4a2ecb-0255-4b67-afe5-13659a6921f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'My Everything'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'My Everything', b'My Everything', b'My Everything',\n",
      "        b'My Everything', b'My Everything']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:2ZnzBwKw4e2SHpGvOTWnj4'], dtype=object)>, 'album_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:album:2ZnzBwKw4e2SHpGvOTWnj4',\n",
      "        b'spotify:album:2ZnzBwKw4e2SHpGvOTWnj4',\n",
      "        b'spotify:album:2ZnzBwKw4e2SHpGvOTWnj4',\n",
      "        b'spotify:album:2ZnzBwKw4e2SHpGvOTWnj4',\n",
      "        b'spotify:album:2ZnzBwKw4e2SHpGvOTWnj4']], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([88380944.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"'dance pop', 'pop'\"], dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b\"'dance pop', 'pop'\", b\"'dance pop', 'pop'\",\n",
      "        b\"'dance pop', 'pop'\", b\"'dance pop', 'pop'\",\n",
      "        b\"'dance pop', 'pop'\"]], dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Ariana Grande'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Ariana Grande', b'Ariana Grande', b'Ariana Grande',\n",
      "        b'Ariana Grande', b'Ariana Grande']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([92.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[92., 92., 92., 92., 92.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:66CXWjxzNUsdJxJ2JdwvnR'], dtype=object)>, 'artist_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:artist:66CXWjxzNUsdJxJ2JdwvnR',\n",
      "        b'spotify:artist:66CXWjxzNUsdJxJ2JdwvnR',\n",
      "        b'spotify:artist:66CXWjxzNUsdJxJ2JdwvnR',\n",
      "        b'spotify:artist:66CXWjxzNUsdJxJ2JdwvnR',\n",
      "        b'spotify:artist:66CXWjxzNUsdJxJ2JdwvnR']], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
      "array([[88380944., 88380944., 88380944., 88380944., 88380944.]],\n",
      "      dtype=float32)>, 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([217053.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[193893., 197253., 211880., 214840., 233733.]], dtype=float32)>, 'num_pl_albums_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([24.], dtype=float32)>, 'num_pl_artists_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([22.], dtype=float32)>, 'num_pl_songs_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([37.], dtype=float32)>, 'pl_collaborative_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>, 'pl_duration_ms_new': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7215391.], dtype=float32)>, 'pl_name_src': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sup'], dtype=object)>, 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0759], dtype=float32)>, 'track_acousticness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.00756, 0.0456 , 0.0216 , 0.115  , 0.53   ]], dtype=float32)>, 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.622], dtype=float32)>, 'track_danceability_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.432, 0.654, 0.624, 0.68 , 0.634]], dtype=float32)>, 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.592], dtype=float32)>, 'track_energy_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.665, 0.618, 0.797, 0.579, 0.692]], dtype=float32)>, 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.53e-06], dtype=float32)>, 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.00e+00, 4.52e-05, 3.30e-06, 1.04e-05, 0.00e+00]], dtype=float32)>, 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'3.0'], dtype=object)>, 'track_key_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'6.0', b'1.0', b'8.0', b'8.0', b'7.0']], dtype=object)>, 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0764], dtype=float32)>, 'track_liveness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.202, 0.112, 0.153, 0.131, 0.104]], dtype=float32)>, 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-6.188], dtype=float32)>, 'track_loudness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[-5.93 , -6.999, -4.868, -5.304, -5.278]], dtype=float32)>, 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'track_mode_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'1', b'0', b'0', b'1', b'0']], dtype=object)>, 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Be My Baby'], dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'Problem', b'One Last Time', b'Why Try', b'Break Free',\n",
      "        b'Best Mistake']], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0., 0., 0., 0., 0.]], dtype=float32)>, 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0363], dtype=float32)>, 'track_speechiness_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.0463, 0.0441, 0.0322, 0.182 , 0.484 ]], dtype=float32)>, 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([145.042], dtype=float32)>, 'track_tempo_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[159.864, 143.941, 102.998, 129.943, 125.036]], dtype=float32)>, 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>, 'track_time_signature_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=array([[b'4', b'4', b'4', b'4', b'4']], dtype=object)>, 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:6djcQtHtVZHfAKlRNydlIi'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(1, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:7fYbFYt7X4FZvuJJC90EX0',\n",
      "        b'spotify:track:7bJwvubZZaoGE1AGEfu8Fi',\n",
      "        b'spotify:track:6LZkF2fayIxtA1SIMmAGoX',\n",
      "        b'spotify:track:1X2Zd5wKGbY1oKzb8dzJRy',\n",
      "        b'spotify:track:1BP617VnYByf7FzCnLEjbg']], dtype=object)>, 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.396], dtype=float32)>, 'track_valence_pl': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=array([[0.122, 0.207, 0.289, 0.61 , 0.327]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(1).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c17ea-9381-439c-aebe-665e6d9fb7ac",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
