{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "* source code for model can be found in `src/`\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.26.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-recommenders google-cloud-aiplatform --user\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "### set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f5e488-ed81-4b49-99fa-63dea67ab6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'twotower-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6fbc7e-1dba-46c8-9abf-380fc80042e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"twotower-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "DATA_VERSION             = \"v1-0-0\"\n",
      "\n",
      "BUCKET_NAME              = \"twotower-v1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://twotower-v1-hybrid-vertex-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://twotower-v1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"twotower-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/twotower-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REGION           = 'us-central1' \n",
    "BUCKET_NAME      = 'matching-engine-content'    # location to store output\n",
    "BUCKET_URI       = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "# DATA_VERSION     = \"v1-0-0\"                     # version tag for dataflow pipeline\n",
    "\n",
    "TRAIN_DIR_PREFIX = f'valid'                # subset: valid_v9 | train_v9\n",
    "VALID_DIR_PREFIX = f'valid'                # valid_v9 | train_v9\n",
    "CANDIDATE_PREFIX = f'candidates' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "os.environ[\"CLOUD_ML_PROJECT_ID\"] = PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "from src.two_tower_jt import two_tower as tt\n",
    "from src.two_tower_jt import train_utils as train_utils\n",
    "# from src.two_tower_jt import feature_sets\n",
    "\n",
    "from util import feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e214c04a-e77a-4e26-a5ea-b54285957b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34msrc/two_tower_jt\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   ├── feature_sets.cpython-37.pyc\n",
      "│   ├── test_instances.cpython-37.pyc\n",
      "│   ├── train_config.cpython-37.pyc\n",
      "│   ├── train_utils.cpython-37.pyc\n",
      "│   ├── train_utils_v1.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "├── feature_sets.py\n",
      "├── interactive_train.py\n",
      "├── requirements.txt\n",
      "├── task.py\n",
      "├── test_instances.py\n",
      "├── train_config.py\n",
      "├── train_utils.py\n",
      "└── two_tower.py\n",
      "\n",
      "1 directory, 16 files\n"
     ]
    }
   ],
   "source": [
    "!tree src/two_tower_jt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d8dc5-a796-4295-a1da-5474827ef859",
   "metadata": {},
   "source": [
    "## Create Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c26cf3b-6f23-476f-9806-27dd9697d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "\n",
    "batch_size = 1024 #*16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6827209-b916-4291-8f56-6afdb33c26ee",
   "metadata": {},
   "source": [
    "### data input pipeline \n",
    "\n",
    "> interleave --> map --> batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset element_spec={'album_name_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'album_name_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'album_uri_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'artist_genres_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'artist_name_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'artist_pop_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'artist_uri_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'artists_followers_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'duration_ms_songs_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_acousticness_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_danceability_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_energy_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_instrumentalness_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'track_key_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_liveness_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_loudness_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'track_mode_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'track_name_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_pop_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_speechiness_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_tempo_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'track_time_signature_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'track_uri_pl': TensorSpec(shape=(None, 5), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'track_valence_pl': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_VERSION}/{TRAIN_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "# train_files    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    train_utils.full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(\n",
    "    feature_sets.parse_tfrecord, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0ccf9-4602-49b8-bde7-dbb962d6cc25",
   "metadata": {},
   "source": [
    "### Create Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4983881f-099b-43d6-b296-381cf3e1d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    train_utils.full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(\n",
    "    feature_sets.parse_tfrecord, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "# valid_dataset = valid_dataset.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)\n",
    "\n",
    "# valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf15fc9-5d2d-470c-83d6-29354ff813d9",
   "metadata": {},
   "source": [
    "### Create Candidates dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b115e4b4-f616-4314-ac65-b956bbc2d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'{DATA_VERSION}/{CANDIDATE_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "candidate_dataset = tf.data.Dataset.from_tensor_slices(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.interleave(\n",
    "    train_utils.full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False\n",
    ").map(\n",
    "    feature_sets.parse_candidate_tfrecord_fn, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "parsed_candidate_dataset = parsed_candidate_dataset.cache() #400 MB on machine mem\n",
    "# parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e25957-1097-457a-aa8d-967f8cb031fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Festival Party Riddim'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:6HRMv5gpkJDvfBhpBr1OVK'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'NONE'], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Winners Table Band'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:2oy6bRhmrdW8M5IVCNpu1A'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([113554.], dtype=float32)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0542], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.455], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.965], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.959], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'11.0'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.366], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.018], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Festival Party Riddim'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0664], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([160.826], dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:6rAdzenD1M3W0Jpiwzo2Km'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.887], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# check dataset output\n",
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a914a-e3d4-4c5c-a42a-9d39a6bde63c",
   "metadata": {},
   "source": [
    "## Adapt Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fa77-6401-47bc-b198-14c1891ddcac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adapt the text vectorizors - copy/paste to run one time\n",
    "\n",
    "We are accessing the `TextVectorizor` layers in the model via the layer print-outs above\n",
    "\n",
    "```python\n",
    "# adpat the text vectorizors\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 5 # this is set upstream by the BigQuery max length\n",
    "    \n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['pl_name_src']))\n",
    "print('pl_name_src adapts complete')\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['track_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('track_name_pl adapts complete')\n",
    "model.query_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1]))) \n",
    "print('artist_name_pl adapts complete')\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['album_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('album_name_pl adapts complete')\n",
    "model.query_tower.layers[12].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_genres_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('artist_genres_pl adapts complete')\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['tracks_playlist_titles_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "# print('tracks_playlist_titles_pl adapts complete')\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['track_name_can'])) \n",
    "print('track_name_can adapts complete')\n",
    "model.candidate_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_name_can'])) \n",
    "print('artist_name_can adapts complete')\n",
    "model.candidate_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['album_name_can'])) \n",
    "print('album_name_can adapts complete')\n",
    "model.candidate_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_genres_can'])) \n",
    "print('artist_genres_can adapts complete')\n",
    "# model.candidate_tower.layers[11].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: x['track_pl_titles_can'])) \n",
    "# print('track_pl_titles_can adapts complete')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c78fde-5d37-4fb9-a4b7-d4d4d9fd2648",
   "metadata": {
    "tags": []
   },
   "source": [
    "### save vocab dict \n",
    "\n",
    "Save the vocab dictionary for later so you will not have to adapt\n",
    "\n",
    "```python\n",
    "vocab_dict = {\n",
    "    'pl_name_src' : model.query_tower.layers[0].layers[0].get_vocabulary(),\n",
    "    'track_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(),\n",
    "    'artist_name_pl' : model.query_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'album_name_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(),\n",
    "    'artist_genres_pl' : model.query_tower.layers[12].layers[0].get_vocabulary(),\n",
    "    # 'tracks_playlist_titles_pl' : model.query_tower.layers[13].layers[0].get_vocabulary(),\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(),\n",
    "    'artist_name_can' : model.candidate_tower.layers[3].layers[0].get_vocabulary(),\n",
    "    'album_name_can' : model.candidate_tower.layers[5].layers[0].get_vocabulary(),\n",
    "    'artist_genres_can' : model.candidate_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    # 'track_pl_titles_can' : model.candidate_tower.layers[11].layers[0].get_vocabulary(),\n",
    "}\n",
    "```\n",
    "\n",
    "```python\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl', `PROJECT_ID`)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83159b76-b529-4297-ae89-443e15da477b",
   "metadata": {},
   "source": [
    "### load saved vocab dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be17f6f9-1305-4d7d-ac8c-a5777e79e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('gsutil cp gs://two-tower-models/vocabs/vocab_dict.pkl .')  # TODO - paramterize\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'rb')\n",
    "VOCAB_DICT = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# VOCAB_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873a9d8-7dbd-4168-b47c-a9196b6793aa",
   "metadata": {},
   "source": [
    "## Build and Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a8d10-395b-4cb2-9980-85569a880fce",
   "metadata": {},
   "source": [
    "### TODO: config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "535a6c91-ab26-49a1-8140-4fef84d55c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CROSS_LAYER = True\n",
    "USE_DROPOUT = True\n",
    "SEED = 1234\n",
    "MAX_PLAYLIST_LENGTH = 15\n",
    "EMBEDDING_DIM = 128   \n",
    "PROJECTION_DIM = 25  \n",
    "SEED = 1234\n",
    "DROPOUT_RATE = 0.33\n",
    "MAX_TOKENS = 20000\n",
    "LAYER_SIZES=[256,128]\n",
    "\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "model = tt.TheTwoTowers(\n",
    "    layer_sizes=LAYER_SIZES, \n",
    "    vocab_dict=VOCAB_DICT, \n",
    "    parsed_candidate_dataset=parsed_candidate_dataset,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    projection_dim=PROJECTION_DIM,\n",
    "    seed=SEED,\n",
    "    use_cross_layer=USE_CROSS_LAYER,\n",
    "    use_dropout=USE_DROPOUT,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    # max_playlist_length=MAX_PLAYLIST_LENGTH,\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1468308c-ca39-43c8-a09f-1e08f8a1307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec331ba6-0b38-4089-9432-097c43ed3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.two_tower_jt.two_tower.TheTwoTowers at 0x7fea1c5e66d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3414bbf-43af-4e95-96db-95b36a980ce9",
   "metadata": {},
   "source": [
    "### inspect layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_duration_ms_new_emb_model\n",
      "3 num_pl_songs_new_emb_model\n",
      "4 num_pl_artists_new_emb_model\n",
      "5 num_pl_albums_new_emb_model\n",
      "6 track_uri_pl_emb_model\n",
      "7 track_name_pl_emb_model\n",
      "8 artist_uri_pl_emb_model\n",
      "9 artist_name_pl_emb_model\n",
      "10 album_uri_pl_emb_model\n",
      "11 album_name_pl_emb_model\n",
      "12 artist_genres_pl_emb_model\n",
      "13 duration_ms_songs_pl_emb_model\n",
      "14 track_pop_pl_emb_model\n",
      "15 artist_pop_pl_emb_model\n",
      "16 artists_followers_pl_emb_model\n",
      "17 track_danceability_pl_emb_model\n",
      "18 track_energy_pl_emb_model\n",
      "19 track_key_pl_emb_model\n",
      "20 track_loudness_pl_emb_model\n",
      "21 track_mode_pl_emb_model\n",
      "22 track_speechiness_pl_emb_model\n",
      "23 track_acousticness_pl_emb_model\n",
      "24 track_instrumentalness_pl_emb_model\n",
      "25 track_liveness_pl_emb_model\n",
      "26 track_valence_pl_emb_model\n",
      "27 track_tempo_pl_emb_model\n",
      "28 time_signature_pl_emb_model\n",
      "29 pl_cross_layer\n",
      "30 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 time_signature_can_emb_model\n",
      "23 can_cross_layer\n",
      "24 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4de78f-a955-43a2-9940-b8d9f8aa4911",
   "metadata": {},
   "source": [
    "### setup Vertex Exeperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68c84c47-bd82-4ca3-9f37-d3160e3ca376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_NAME: run-20230919-015734\n",
      "LOG_DIR: gs://matching-engine-content/build-local-v4/run-20230919-015734/tb-logs\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = f'build-local-v4'\n",
    "\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME = f'run-{invoke_time}'\n",
    "\n",
    "LOG_DIR = f\"gs://{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/tb-logs\"\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")\n",
    "print(f\"LOG_DIR: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### setup Tensorboard callbacks\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph\n",
    "\n",
    "**TODO:** clean up notebook section \n",
    "\n",
    "> *Note:* While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8238845-82bb-45a2-98b6-df8fb7589d90",
   "metadata": {},
   "source": [
    "#### Managed Tensorboard Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c0f152f-930f-4640-ab6d-7b540e6084b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tensorboard\n",
      "Create Tensorboard backing LRO: projects/934903580331/locations/us-central1/tensorboards/3574019720690532352/operations/2485276366199586816\n",
      "Tensorboard created. Resource name: projects/934903580331/locations/us-central1/tensorboards/3574019720690532352\n",
      "To use this Tensorboard in another session:\n",
      "tb = aiplatform.Tensorboard('projects/934903580331/locations/us-central1/tensorboards/3574019720690532352')\n",
      "TB_RESOURCE_NAME: projects/934903580331/locations/us-central1/tensorboards/3574019720690532352\n"
     ]
    }
   ],
   "source": [
    "# use existing TB instance\n",
    "# TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/472921941339013120'\n",
    "\n",
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "tensorboard = vertex_ai.Tensorboard.create(display_name=TENSORBOARD_DISPLAY_NAME)\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "# tensorboard callback\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    ecapsulates one-shot log uploader via a custom callback\n",
    "\n",
    "    '''\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(\n",
    "            get_upload_logs_to_manged_tb_command(\n",
    "                ttl_hrs = 5, oneshot=\"true\"\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a034b-7959-4bd0-bf9c-45da1b695055",
   "metadata": {},
   "source": [
    "#### train config\n",
    "\n",
    "* consider experiment and experiment-run naming convention so names don't collide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2eeffe1-efc0-4a2d-b168-6f10a43b1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2\n",
    "VALID_FREQUENCY = 5\n",
    "HIST_FREQ = 0\n",
    "EMBED_FREQ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "* train model in-notebook\n",
    "* write metrics to Vertex AI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - ETA: 0s - batch_categorical_accuracy_at_10: 0.0100 - batch_categorical_accuracy_at_50: 0.0494 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8757.9992 - regularization_loss: 0.0000e+00 - total_loss: 8757.9992View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+3574019720690532352+experiments+build-local-v4\n",
      "\u001b[1m[2023-09-19T01:58:33]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2023-09-19T01:58:34]\u001b[0m Total uploaded: 8 scalars, 0 tensors, 1 binary objects (1.1 MB)\n",
      "10/10 [==============================] - 51s 3s/step - batch_categorical_accuracy_at_10: 0.0100 - batch_categorical_accuracy_at_50: 0.0494 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8608.8558 - regularization_loss: 0.0000e+00 - total_loss: 8608.8558\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - ETA: 0s - batch_categorical_accuracy_at_10: 0.0123 - batch_categorical_accuracy_at_50: 0.0501 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7108.0191 - regularization_loss: 0.0000e+00 - total_loss: 7108.0191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 01:59:01.662287 140547048142656 uploader.py:389] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+3574019720690532352+experiments+build-local-v4\n",
      "\u001b[1m[2023-09-19T01:59:01]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2023-09-19T01:59:05]\u001b[0m Total uploaded: 16 scalars, 0 tensors, 1 binary objects (1.1 MB)\n",
      "10/10 [==============================] - 31s 3s/step - batch_categorical_accuracy_at_10: 0.0123 - batch_categorical_accuracy_at_50: 0.0501 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 7107.7820 - regularization_loss: 0.0000e+00 - total_loss: 7107.7820\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=HIST_FREQ, \n",
    "        write_graph=True,\n",
    "        embeddings_freq=EMBED_FREQ,\n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "layer_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=VALID_FREQUENCY,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=10,\n",
    "    validation_steps=100,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        UploadTBLogsBatchEnd()\n",
    "    ], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be04e5-d666-4c3d-af06-4f39ebf42cdc",
   "metadata": {},
   "source": [
    "### log Vertex Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "277cc62b-fa19-4f62-bca1-4aad6a2ac131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/build-local-v4-run-20230919-015734 to Experiment: build-local-v4\n"
     ]
    }
   ],
   "source": [
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params(\n",
    "    {\n",
    "        \"layers\": str(LAYER_SIZES), \n",
    "        \"learning_rate\": LR,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"valid_freq\": VALID_FREQUENCY,\n",
    "    }\n",
    ")\n",
    "\n",
    "# gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "\n",
    "vertex_ai.log_metrics(metrics_dict)\n",
    "\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54ef68ef-2644-4009-92b3-6ec84d704128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 1 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b7373ed-c4d8-4618-b42f-ec3dbda6ffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train-time-minutes': 1,\n",
       " 'batch_categorical_accuracy_at_10': 0.01230468787252903,\n",
       " 'batch_categorical_accuracy_at_50': 0.05009765550494194,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.0,\n",
       " 'loss': 7105.4111328125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 7105.4111328125}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466dd9cf-70f6-475b-ab28-d17dfffe214a",
   "metadata": {},
   "source": [
    "### Save each tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9e83d88-43e1-4ebe-922d-bd4765a6abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://matching-engine-content/build-local-v3/run-20230918-234423/query_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://matching-engine-content/build-local-v3/run-20230918-234423/query_model/assets\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://matching-engine-content/build-local-v3/run-20230918-234423/candidate_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://matching-engine-content/build-local-v3/run-20230918-234423/candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "#save towers (models)\n",
    "tf.saved_model.save(model.query_tower, export_dir=f\"gs://{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=f\"gs://{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450b70a-d6dd-44e9-b7ce-dc439594d0bc",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e0f08e0-7fb7-48d2-99d2-640cd7405b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 32943s 400s/step - batch_categorical_accuracy_at_10: 0.0113 - batch_categorical_accuracy_at_50: 0.0496 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 1.2054e-05 - factorized_top_k/top_100_categorical_accuracy: 3.6162e-05 - loss: 6953.0374 - regularization_loss: 0.0000e+00 - total_loss: 6953.0374\n",
      "elapsed_mins: 549\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "eval_dict_v1 = model.evaluate(valid_dataset, return_dict=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_mins: {elapsed_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f9b0c75-7eaf-466c-b452-680addc20a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_categorical_accuracy_at_10': 0.011282681487500668,\n",
       " 'batch_categorical_accuracy_at_50': 0.049578707665205,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 1.2054147191520315e-05,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 3.616244066506624e-05,\n",
       " 'loss': 40.9329719543457,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 40.9329719543457}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43294b-3a5d-482c-a0fc-ea37f1d6cb78",
   "metadata": {},
   "source": [
    "### Efficient eval\n",
    "\n",
    "* approximate with scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cca1457-4917-4aa3-81c1-6227e4bea23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    num_reordering_candidates=500,\n",
    "    num_leaves_to_search=30\n",
    ")\n",
    "scann.index_from_dataset(\n",
    "    candidates=parsed_candidate_dataset.batch(128).cache().map(\n",
    "        lambda x: (\n",
    "            x['track_uri_can'], \n",
    "            model.candidate_tower(x)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_scann_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_scann_mins: {elapsed_scann_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0607f90f-843e-4d11-b05c-5085d6e61910",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=scann\n",
    ")\n",
    "model.compile()\n",
    "\n",
    "scann_result = model.evaluate(\n",
    "    valid_dataset, \n",
    "    return_dict=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_scann_eval_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_scann_eval_mins: {elapsed_scann_eval_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022d991-70ae-4e54-bc6a-5705df1924d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b2721-0c8b-4d59-905d-c3ac776045b6",
   "metadata": {},
   "source": [
    "<img src=\"./img/experiment-console.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2ba57-5fd1-4493-8d6b-3b14b41aa159",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### After opening the TensorBoard instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345a1b6-5c94-45b7-9181-8111b4fe4466",
   "metadata": {},
   "source": [
    "<img src=\"./img/tensorboard.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c18098-6613-4ebd-a780-fe92f2bbcb1a",
   "metadata": {},
   "source": [
    "<img src=\"./img/tb-metrics.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f4fe8-226c-4c11-939f-04fc71300f7a",
   "metadata": {},
   "source": [
    "<img src=\"./img/tb-loss.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ff295-17b4-4ff4-98cb-3d022384ca7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Also, while this is running - check out the Tensorboard profiler in `utils`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f82997-27f3-44c4-82a7-75a3211bcf43",
   "metadata": {},
   "source": [
    "<img src=\"./img/tb-profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfc3e2-2786-476f-a4bf-d052370ecacc",
   "metadata": {},
   "source": [
    "#### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f78adf-a6b4-4581-803e-252882c82a58",
   "metadata": {},
   "source": [
    "<img src=\"./img/nvtop-optimized.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a tf function to convert any bad null values\n",
    "# def tf_if_null_return_zero(val):\n",
    "#     \"\"\"\n",
    "#     this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "#     this will clean the embedding inputs downstream\n",
    "#     \"\"\"\n",
    "#     return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = parsed_candidate_dataset.batch(10000).map(\n",
    "    lambda x: [\n",
    "        x['track_uri_can'],\n",
    "        train_utils.tf_if_null_return_zero(\n",
    "            model.candidate_tower(x)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_EMB_JSON = 'candidate_embeddings.json'\n",
    "\n",
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "\n",
    "# !rm $CANDIDATE_EMB_JSON > /dev/null\n",
    "!touch $CANDIDATE_EMB_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84921234-92fb-45c2-b6fe-c932360da226",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(CANDIDATE_EMB_JSON, 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File candidate_embeddings.json uploaded to run-20230918-234423/candidates/candidate_embeddings.json.\n"
     ]
    }
   ],
   "source": [
    "train_utils.upload_blob(\n",
    "    bucket_name='two-tower-models',\n",
    "    source_file_name=CANDIDATE_EMB_JSON,\n",
    "    destination_blob_name=f'{RUN_NAME}/candidates/candidate_embeddings.json',\n",
    "    project_id = PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    " wc -l candidate_embeddings.json \n",
    " \n",
    " 2249561 candidate_embeddings.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddc8d3-ea1c-4b6b-af2f-e4f272ec3f1a",
   "metadata": {},
   "source": [
    "<img src=\"./img/embeddings.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0844a4b-084f-4e4d-8f3e-d8d920ec24ec",
   "metadata": {},
   "source": [
    "### Getting test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "728b2fb7-f01d-4804-9416-e52373cd5749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': b'Street Dreams', 'album_name_pl': array([b'The Boy Is Mine', b'The Best Of Brandy', b'Never Say Never',\n",
      "       b'Never Say Never', b'No Way Out (Remastered Edition)'],\n",
      "      dtype=object), 'album_uri_can': b'spotify:album:4zJlHiU3px1lNEsAkoInIh', 'album_uri_pl': array([b'spotify:album:6mIyViyBHV4eoQqI4JZByh',\n",
      "       b'spotify:album:2W8fU1wJz9sGDmwMBcQBRX',\n",
      "       b'spotify:album:1Co6e9ag1gRKcWdG7xKcCi',\n",
      "       b'spotify:album:1Co6e9ag1gRKcWdG7xKcCi',\n",
      "       b'spotify:album:33hEDxsIVGf7R6wRdZBQOw'], dtype=object), 'artist_followers_can': 2502968.0, 'artist_genres_can': b\"'dance pop', 'gangster rap', 'hardcore hip hop', 'hip hop', 'hip pop', 'pop rap', 'r&b', 'rap', 'trap', 'urban contemporary'\", 'artist_genres_pl': array([b\"'contemporary r&b', 'dance pop', 'hip pop', 'neo soul', 'pop r&b', 'r&b', 'urban contemporary'\",\n",
      "       b\"'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'r&b', 'urban contemporary'\",\n",
      "       b\"'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'r&b', 'urban contemporary'\",\n",
      "       b\"'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'r&b', 'urban contemporary'\",\n",
      "       b\"'dance pop', 'east coast hip hop', 'hip hop', 'hip pop', 'pop rap', 'r&b', 'rap'\"],\n",
      "      dtype=object), 'artist_name_can': b'Fabolous', 'artist_name_pl': array([b'Monica', b'Brandy', b'Brandy', b'Brandy', b'Diddy'], dtype=object), 'artist_pop_can': 69.0, 'artist_pop_pl': array([65., 67., 67., 67., 75.], dtype=float32), 'artist_uri_can': b'spotify:artist:0YWxKQj2Go9CGHCp77UOyy', 'artist_uri_pl': array([b'spotify:artist:6nzxy2wXs6tLgzEtqOkEi2',\n",
      "       b'spotify:artist:05oH07COxkXKIMt6mIPRee',\n",
      "       b'spotify:artist:05oH07COxkXKIMt6mIPRee',\n",
      "       b'spotify:artist:05oH07COxkXKIMt6mIPRee',\n",
      "       b'spotify:artist:59wfkuBoNyhDMQGCljbUbA'], dtype=object), 'artists_followers_pl': array([2364580., 3156095., 3156095., 3156095., 1433549.], dtype=float32), 'duration_ms_can': 293840.0, 'duration_ms_songs_pl': array([250173., 291066., 294786., 273440., 306560.], dtype=float32), 'num_pl_albums_new': 24.0, 'num_pl_artists_new': 17.0, 'num_pl_songs_new': 64.0, 'pl_collaborative_src': b'false', 'pl_duration_ms_new': 17696240.0, 'pl_name_src': b'90s rnb', 'track_acousticness_can': 0.201, 'track_acousticness_pl': array([0.00373, 0.288  , 0.539  , 0.111  , 0.542  ], dtype=float32), 'track_danceability_can': 0.681, 'track_danceability_pl': array([0.833, 0.698, 0.791, 0.592, 0.704], dtype=float32), 'track_energy_can': 0.529, 'track_energy_pl': array([0.61 , 0.619, 0.562, 0.707, 0.533], dtype=float32), 'track_instrumentalness_can': 0.0, 'track_instrumentalness_pl': array([1.06e-03, 1.23e-03, 0.00e+00, 2.13e-05, 3.23e-05], dtype=float32), 'track_key_can': b'7.0', 'track_key_pl': array([b'7.0', b'1.0', b'10.0', b'8.0', b'2.0'], dtype=object), 'track_liveness_can': 0.184, 'track_liveness_pl': array([0.333 , 0.159 , 0.0457, 0.318 , 0.223 ], dtype=float32), 'track_loudness_can': -7.897, 'track_loudness_pl': array([-6.246, -5.595, -6.537, -5.408, -6.869], dtype=float32), 'track_mode_can': b'0', 'track_mode_pl': array([b'0', b'0', b'1', b'1', b'0'], dtype=object), 'track_name_can': b'Into You [Main Mix feat. Tamia]', 'track_name_pl': array([b'Angel of Mine - Radio Mix', b\"Sittin' Up In My Room\",\n",
      "       b'The Boy Is Mine', b'Have You Ever',\n",
      "       b\"I'll Be Missing You (feat. Faith Evans & 112)\"], dtype=object), 'track_pop_can': 50.0, 'track_pop_pl': array([63., 49., 69., 56., 66.], dtype=float32), 'track_speechiness_can': 0.0341, 'track_speechiness_pl': array([0.0538, 0.0264, 0.0239, 0.0437, 0.0391], dtype=float32), 'track_tempo_can': 91.081, 'track_tempo_pl': array([ 90.16 , 109.92 ,  93.145, 134.001,  93.277], dtype=float32), 'track_time_signature_can': b'4', 'track_time_signature_pl': array([b'4', b'4', b'4', b'4', b'4'], dtype=object), 'track_uri_can': b'spotify:track:1Jm1I3APcmVz3MqPr5vfTx', 'track_uri_pl': array([b'spotify:track:1AM1o0mKbgAK5oMpY8B3Z7',\n",
      "       b'spotify:track:5Erc0rv16PU4Z5Zt16kGQe',\n",
      "       b'spotify:track:6sHsXIJoEN5JpdkGMQDJxt',\n",
      "       b'spotify:track:6tBD4yjOf9P8rWwUlXdJFm',\n",
      "       b'spotify:track:1yy2DlSDtEt90d54rPDPXz'], dtype=object), 'track_valence_can': 0.568, 'track_valence_pl': array([0.761, 0.275, 0.208, 0.907, 0.901], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for tensor_dict in valid_dataset.unbatch().skip(1000).take(1):\n",
    "    td_keys = tensor_dict.keys()\n",
    "    list_dict = {}\n",
    "    for k in td_keys:\n",
    "        list_dict.update({k: tensor_dict[k].numpy()})\n",
    "    print(list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1318107a-0747-4b7a-9f17-fcf83c975de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album_name_can': b'Street Dreams',\n",
       " 'album_name_pl': array([b'The Boy Is Mine', b'The Best Of Brandy', b'Never Say Never',\n",
       "        b'Never Say Never', b'No Way Out (Remastered Edition)'],\n",
       "       dtype=object),\n",
       " 'album_uri_can': b'spotify:album:4zJlHiU3px1lNEsAkoInIh',\n",
       " 'album_uri_pl': array([b'spotify:album:6mIyViyBHV4eoQqI4JZByh',\n",
       "        b'spotify:album:2W8fU1wJz9sGDmwMBcQBRX',\n",
       "        b'spotify:album:1Co6e9ag1gRKcWdG7xKcCi',\n",
       "        b'spotify:album:1Co6e9ag1gRKcWdG7xKcCi',\n",
       "        b'spotify:album:33hEDxsIVGf7R6wRdZBQOw'], dtype=object),\n",
       " 'artist_followers_can': 2502968.0,\n",
       " 'artist_genres_can': b\"'dance pop', 'gangster rap', 'hardcore hip hop', 'hip hop', 'hip pop', 'pop rap', 'r&b', 'rap', 'trap', 'urban contemporary'\",\n",
       " 'artist_genres_pl': array([b\"'contemporary r&b', 'dance pop', 'hip pop', 'neo soul', 'pop r&b', 'r&b', 'urban contemporary'\",\n",
       "        b\"'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'r&b', 'urban contemporary'\",\n",
       "        b\"'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'r&b', 'urban contemporary'\",\n",
       "        b\"'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'r&b', 'urban contemporary'\",\n",
       "        b\"'dance pop', 'east coast hip hop', 'hip hop', 'hip pop', 'pop rap', 'r&b', 'rap'\"],\n",
       "       dtype=object),\n",
       " 'artist_name_can': b'Fabolous',\n",
       " 'artist_name_pl': array([b'Monica', b'Brandy', b'Brandy', b'Brandy', b'Diddy'], dtype=object),\n",
       " 'artist_pop_can': 69.0,\n",
       " 'artist_pop_pl': array([65., 67., 67., 67., 75.], dtype=float32),\n",
       " 'artist_uri_can': b'spotify:artist:0YWxKQj2Go9CGHCp77UOyy',\n",
       " 'artist_uri_pl': array([b'spotify:artist:6nzxy2wXs6tLgzEtqOkEi2',\n",
       "        b'spotify:artist:05oH07COxkXKIMt6mIPRee',\n",
       "        b'spotify:artist:05oH07COxkXKIMt6mIPRee',\n",
       "        b'spotify:artist:05oH07COxkXKIMt6mIPRee',\n",
       "        b'spotify:artist:59wfkuBoNyhDMQGCljbUbA'], dtype=object),\n",
       " 'artists_followers_pl': array([2364580., 3156095., 3156095., 3156095., 1433549.], dtype=float32),\n",
       " 'duration_ms_can': 293840.0,\n",
       " 'duration_ms_songs_pl': array([250173., 291066., 294786., 273440., 306560.], dtype=float32),\n",
       " 'num_pl_albums_new': 24.0,\n",
       " 'num_pl_artists_new': 17.0,\n",
       " 'num_pl_songs_new': 64.0,\n",
       " 'pl_collaborative_src': b'false',\n",
       " 'pl_duration_ms_new': 17696240.0,\n",
       " 'pl_name_src': b'90s rnb',\n",
       " 'track_acousticness_can': 0.201,\n",
       " 'track_acousticness_pl': array([0.00373, 0.288  , 0.539  , 0.111  , 0.542  ], dtype=float32),\n",
       " 'track_danceability_can': 0.681,\n",
       " 'track_danceability_pl': array([0.833, 0.698, 0.791, 0.592, 0.704], dtype=float32),\n",
       " 'track_energy_can': 0.529,\n",
       " 'track_energy_pl': array([0.61 , 0.619, 0.562, 0.707, 0.533], dtype=float32),\n",
       " 'track_instrumentalness_can': 0.0,\n",
       " 'track_instrumentalness_pl': array([1.06e-03, 1.23e-03, 0.00e+00, 2.13e-05, 3.23e-05], dtype=float32),\n",
       " 'track_key_can': b'7.0',\n",
       " 'track_key_pl': array([b'7.0', b'1.0', b'10.0', b'8.0', b'2.0'], dtype=object),\n",
       " 'track_liveness_can': 0.184,\n",
       " 'track_liveness_pl': array([0.333 , 0.159 , 0.0457, 0.318 , 0.223 ], dtype=float32),\n",
       " 'track_loudness_can': -7.897,\n",
       " 'track_loudness_pl': array([-6.246, -5.595, -6.537, -5.408, -6.869], dtype=float32),\n",
       " 'track_mode_can': b'0',\n",
       " 'track_mode_pl': array([b'0', b'0', b'1', b'1', b'0'], dtype=object),\n",
       " 'track_name_can': b'Into You [Main Mix feat. Tamia]',\n",
       " 'track_name_pl': array([b'Angel of Mine - Radio Mix', b\"Sittin' Up In My Room\",\n",
       "        b'The Boy Is Mine', b'Have You Ever',\n",
       "        b\"I'll Be Missing You (feat. Faith Evans & 112)\"], dtype=object),\n",
       " 'track_pop_can': 50.0,\n",
       " 'track_pop_pl': array([63., 49., 69., 56., 66.], dtype=float32),\n",
       " 'track_speechiness_can': 0.0341,\n",
       " 'track_speechiness_pl': array([0.0538, 0.0264, 0.0239, 0.0437, 0.0391], dtype=float32),\n",
       " 'track_tempo_can': 91.081,\n",
       " 'track_tempo_pl': array([ 90.16 , 109.92 ,  93.145, 134.001,  93.277], dtype=float32),\n",
       " 'track_time_signature_can': b'4',\n",
       " 'track_time_signature_pl': array([b'4', b'4', b'4', b'4', b'4'], dtype=object),\n",
       " 'track_uri_can': b'spotify:track:1Jm1I3APcmVz3MqPr5vfTx',\n",
       " 'track_uri_pl': array([b'spotify:track:1AM1o0mKbgAK5oMpY8B3Z7',\n",
       "        b'spotify:track:5Erc0rv16PU4Z5Zt16kGQe',\n",
       "        b'spotify:track:6sHsXIJoEN5JpdkGMQDJxt',\n",
       "        b'spotify:track:6tBD4yjOf9P8rWwUlXdJFm',\n",
       "        b'spotify:track:1yy2DlSDtEt90d54rPDPXz'], dtype=object),\n",
       " 'track_valence_can': 0.568,\n",
       " 'track_valence_pl': array([0.761, 0.275, 0.208, 0.907, 0.901], dtype=float32)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf02e74-3543-47d3-bebc-3c565bdbcf33",
   "metadata": {},
   "source": [
    "**Finished**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
