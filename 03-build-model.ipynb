{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "* source code for model can be found in `src/`\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders google-cloud-aiplatform --user\n",
    "# ![](img/create-a-tb.png) # TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "### set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "# BUCKET_NAME = f\"{PROJECT_ID}-tfrs-retrieval\"\n",
    "# config = !gsutil cat gs://{BUCKET_NAME}/config/notebook_env.py\n",
    "# print(config.n)\n",
    "# exec(config.n)\n",
    "\n",
    "PROJECT_ID = 'hybrid-vertex' \n",
    "REGION = 'us-central1' \n",
    "BUCKET_NAME = 'jt-tfrs-central-v2'    # location to store output\n",
    "# BUCKET_URI = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "VERSION= \"jtv15-8m\" # version tag for dataflow pipeline\n",
    "\n",
    "BUCKET_DATA_DIR = 'spotify-data-regimes'\n",
    "TRAIN_DIR_PREFIX = f'{VERSION}/valid' # subset: valid_v9 | train_v9\n",
    "VALID_DIR_PREFIX = f'{VERSION}/valid' # valid_v9 | train_v9\n",
    "CANDIDATE_PREFIX = f'{VERSION}/candidates' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 18:17:06.580459: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "os.environ[\"CLOUD_ML_PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "from src.two_tower_jt import two_tower as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34msrc/two_tower_jt\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   ├── train_config.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "├── data-pipeline.py\n",
      "├── interactive_train.py\n",
      "├── requirements.txt\n",
      "├── task.py\n",
      "├── train_config.py\n",
      "├── two_tower.py\n",
      "└── two_tower_lite.py\n",
      "\n",
      "1 directory, 11 files\n"
     ]
    }
   ],
   "source": [
    "!tree src/two_tower_jt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d8dc5-a796-4295-a1da-5474827ef859",
   "metadata": {},
   "source": [
    "## Create Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c26cf3b-6f23-476f-9806-27dd9697d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "\n",
    "batch_size = 1024 #*16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6827209-b916-4291-8f56-6afdb33c26ee",
   "metadata": {},
   "source": [
    "### data input pipeline \n",
    "\n",
    "> interleave --> map --> batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f'{BUCKET_DATA_DIR}', prefix=f'{TRAIN_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(\n",
    "    tt.parse_tfrecord, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0ccf9-4602-49b8-bde7-dbb962d6cc25",
   "metadata": {},
   "source": [
    "### Create Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4983881f-099b-43d6-b296-381cf3e1d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f'{BUCKET_DATA_DIR}', prefix=f'{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(\n",
    "    tt.parse_tfrecord, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "# valid_dataset = valid_dataset.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)\n",
    "\n",
    "# valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf15fc9-5d2d-470c-83d6-29354ff813d9",
   "metadata": {},
   "source": [
    "### Create Candidates dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b115e4b4-f616-4314-ac65-b956bbc2d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_DATA_DIR}\", prefix=f'{CANDIDATE_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "candidate_dataset = tf.data.Dataset.from_tensor_slices(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False\n",
    ").map(\n",
    "    tt.parse_candidate_tfrecord_fn, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "parsed_candidate_dataset = parsed_candidate_dataset.cache() #400 MB on machine mem\n",
    "\n",
    "# parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e25957-1097-457a-aa8d-967f8cb031fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"Nim's Island\"], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:3s9jAEzWINEIDxqbtqkli3'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([72135.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"'british soundtrack', 'hollywood', 'orchestral soundtrack', 'scorecore', 'soundtrack'\"],\n",
      "      dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Patrick Doyle'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([61.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:1W42coQfIlt6btgqpfJWYQ'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([242320.], dtype=float32)>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.928], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.257], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.116], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.722], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'6'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0748], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-21.454], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b\"Nim's Island\"], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0385], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([129.063], dtype=float32)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:6Nx4UYbpHuU4x5mozUDaQQ'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0786], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# check dataset output\n",
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a914a-e3d4-4c5c-a42a-9d39a6bde63c",
   "metadata": {},
   "source": [
    "## Adapt Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fa77-6401-47bc-b198-14c1891ddcac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adapt the text vectorizors - copy/paste to run one time\n",
    "\n",
    "We are accessing the `TextVectorizor` layers in the model via the layer print-outs above\n",
    "\n",
    "```python\n",
    "# adpat the text vectorizors\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 5 # this is set upstream by the BigQuery max length\n",
    "    \n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['pl_name_src']))\n",
    "print('pl_name_src adapts complete')\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['track_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('track_name_pl adapts complete')\n",
    "model.query_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1]))) \n",
    "print('artist_name_pl adapts complete')\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['album_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('album_name_pl adapts complete')\n",
    "model.query_tower.layers[12].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_genres_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('artist_genres_pl adapts complete')\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['tracks_playlist_titles_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "# print('tracks_playlist_titles_pl adapts complete')\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['track_name_can'])) \n",
    "print('track_name_can adapts complete')\n",
    "model.candidate_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_name_can'])) \n",
    "print('artist_name_can adapts complete')\n",
    "model.candidate_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['album_name_can'])) \n",
    "print('album_name_can adapts complete')\n",
    "model.candidate_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_genres_can'])) \n",
    "print('artist_genres_can adapts complete')\n",
    "# model.candidate_tower.layers[11].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: x['track_pl_titles_can'])) \n",
    "# print('track_pl_titles_can adapts complete')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c78fde-5d37-4fb9-a4b7-d4d4d9fd2648",
   "metadata": {
    "tags": []
   },
   "source": [
    "### save vocab dict \n",
    "\n",
    "Save the vocab dictionary for later so you will not have to adapt\n",
    "\n",
    "```python\n",
    "vocab_dict = {\n",
    "    'pl_name_src' : model.query_tower.layers[0].layers[0].get_vocabulary(),\n",
    "    'track_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(),\n",
    "    'artist_name_pl' : model.query_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'album_name_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(),\n",
    "    'artist_genres_pl' : model.query_tower.layers[12].layers[0].get_vocabulary(),\n",
    "    # 'tracks_playlist_titles_pl' : model.query_tower.layers[13].layers[0].get_vocabulary(),\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(),\n",
    "    'artist_name_can' : model.candidate_tower.layers[3].layers[0].get_vocabulary(),\n",
    "    'album_name_can' : model.candidate_tower.layers[5].layers[0].get_vocabulary(),\n",
    "    'artist_genres_can' : model.candidate_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    # 'track_pl_titles_can' : model.candidate_tower.layers[11].layers[0].get_vocabulary(),\n",
    "}\n",
    "```\n",
    "\n",
    "```python\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl')\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83159b76-b529-4297-ae89-443e15da477b",
   "metadata": {},
   "source": [
    "### load saved vocab dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be17f6f9-1305-4d7d-ac8c-a5777e79e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('gsutil cp gs://two-tower-models/vocabs/vocab_dict.pkl .')  # TODO - paramterize\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'rb')\n",
    "VOCAB_DICT = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873a9d8-7dbd-4168-b47c-a9196b6793aa",
   "metadata": {},
   "source": [
    "## Build and Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a8d10-395b-4cb2-9980-85569a880fce",
   "metadata": {},
   "source": [
    "### TODO: config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535a6c91-ab26-49a1-8140-4fef84d55c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CROSS_LAYER = True\n",
    "USE_DROPOUT = True\n",
    "SEED = 1234\n",
    "MAX_PLAYLIST_LENGTH = 15\n",
    "EMBEDDING_DIM = 128   \n",
    "PROJECTION_DIM = 25  \n",
    "SEED = 1234\n",
    "DROPOUT_RATE = 0.33\n",
    "MAX_TOKENS = 20000\n",
    "LAYER_SIZES=[256,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tt.TheTwoTowers(\n",
    "    layer_sizes=LAYER_SIZES, \n",
    "    vocab_dict=VOCAB_DICT, \n",
    "    parsed_candidate_dataset=parsed_candidate_dataset,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    projection_dim=PROJECTION_DIM,\n",
    "    seed=SEED,\n",
    "    use_cross_layer=USE_CROSS_LAYER,\n",
    "    use_dropout=USE_DROPOUT,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    # max_playlist_length=MAX_PLAYLIST_LENGTH,\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")\n",
    "\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec331ba6-0b38-4089-9432-097c43ed3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.two_tower_jt.two_tower.TheTwoTowers at 0x7fb0ef43b910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3414bbf-43af-4e95-96db-95b36a980ce9",
   "metadata": {},
   "source": [
    "### inspect layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_duration_ms_new_emb_model\n",
      "3 num_pl_songs_new_emb_model\n",
      "4 num_pl_artists_new_emb_model\n",
      "5 num_pl_albums_new_emb_model\n",
      "6 track_uri_pl_emb_model\n",
      "7 track_name_pl_emb_model\n",
      "8 artist_uri_pl_emb_model\n",
      "9 artist_name_pl_emb_model\n",
      "10 album_uri_pl_emb_model\n",
      "11 album_name_pl_emb_model\n",
      "12 artist_genres_pl_emb_model\n",
      "13 duration_ms_songs_pl_emb_model\n",
      "14 track_pop_pl_emb_model\n",
      "15 artist_pop_pl_emb_model\n",
      "16 artists_followers_pl_emb_model\n",
      "17 track_danceability_pl_emb_model\n",
      "18 track_energy_pl_emb_model\n",
      "19 track_key_pl_emb_model\n",
      "20 track_loudness_pl_emb_model\n",
      "21 track_mode_pl_emb_model\n",
      "22 track_speechiness_pl_emb_model\n",
      "23 track_acousticness_pl_emb_model\n",
      "24 track_instrumentalness_pl_emb_model\n",
      "25 track_liveness_pl_emb_model\n",
      "26 track_valence_pl_emb_model\n",
      "27 track_tempo_pl_emb_model\n",
      "28 time_signature_pl_emb_model\n",
      "29 pl_cross_layer\n",
      "30 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 time_signature_can_emb_model\n",
      "23 can_cross_layer\n",
      "24 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4de78f-a955-43a2-9940-b8d9f8aa4911",
   "metadata": {},
   "source": [
    "### setup Vertex Exeperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c84c47-bd82-4ca3-9f37-d3160e3ca376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_NAME: run-20230127-181730\n",
      "LOG_DIR: gs://jt-tfrs-central-v2/build-local-testv1/run-20230127-181730/tb-logs\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = f'build-local-testv1'\n",
    "\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME = f'run-{invoke_time}'\n",
    "\n",
    "LOG_DIR = f\"gs://{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/tb-logs\"\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")\n",
    "print(f\"LOG_DIR: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### setup Tensorboard callbacks\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph\n",
    "\n",
    "**TODO:** clean up notebook section \n",
    "\n",
    "> *Note:* While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8238845-82bb-45a2-98b6-df8fb7589d90",
   "metadata": {},
   "source": [
    "#### Managed Tensorboard Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c0f152f-930f-4640-ab6d-7b540e6084b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tensorboard\n",
      "Create Tensorboard backing LRO: projects/934903580331/locations/us-central1/tensorboards/525979974448971776/operations/8020898635560517632\n",
      "Tensorboard created. Resource name: projects/934903580331/locations/us-central1/tensorboards/525979974448971776\n",
      "To use this Tensorboard in another session:\n",
      "tb = aiplatform.Tensorboard('projects/934903580331/locations/us-central1/tensorboards/525979974448971776')\n",
      "TB_RESOURCE_NAME: projects/934903580331/locations/us-central1/tensorboards/525979974448971776\n"
     ]
    }
   ],
   "source": [
    "# use existing TB instance\n",
    "# TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/472921941339013120'\n",
    "\n",
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "tensorboard = vertex_ai.Tensorboard.create(display_name=TENSORBOARD_DISPLAY_NAME)\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a034b-7959-4bd0-bf9c-45da1b695055",
   "metadata": {},
   "source": [
    "#### train config\n",
    "\n",
    "* consider experiment and experiment-run naming convention so names don't collide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2eeffe1-efc0-4a2d-b168-6f10a43b1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "VALID_FREQUENCY=5\n",
    "\n",
    "HIST_FREQ = 0\n",
    "EMBED_FREQ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "* train model in-notebook\n",
    "* write metrics to Vertex AI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/10 [=================>............] - ETA: 1s - batch_categorical_accuracy_at_10: 0.0101 - batch_categorical_accuracy_at_50: 0.0488 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 18812.0692 - regularization_loss: 0.0000e+00 - total_loss: 18812.0692WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1112s vs `on_train_batch_end` time: 0.2395s). Check your callbacks.\n",
      "10/10 [==============================] - ETA: 0s - batch_categorical_accuracy_at_10: 0.0104 - batch_categorical_accuracy_at_50: 0.0489 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14173.6086 - regularization_loss: 0.0000e+00 - total_loss: 14173.6086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 18:18:04.802954: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+525979974448971776+experiments+build-local-testv1\n",
      "\u001b[1m[2023-01-27T18:18:14]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2023-01-27T18:18:14]\u001b[0m Total uploaded: 8 scalars, 0 tensors, 1 binary objects (1.0 MB)\n",
      "10/10 [==============================] - 29s 2s/step - batch_categorical_accuracy_at_10: 0.0104 - batch_categorical_accuracy_at_50: 0.0489 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13534.6991 - regularization_loss: 0.0000e+00 - total_loss: 13534.6991\n",
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/build-local-testv1-run-20230127-181730 to Experiment: build-local-testv1\n"
     ]
    }
   ],
   "source": [
    "# tensorboard callback\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    ecapsulates one-shot log uploader via a custom callback\n",
    "\n",
    "    '''\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))\n",
    "        \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=HIST_FREQ, \n",
    "        write_graph=True,\n",
    "        embeddings_freq=EMBED_FREQ,\n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "layer_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=VALID_FREQUENCY,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=10,\n",
    "    validation_steps=100,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        UploadTBLogsBatchEnd()\n",
    "    ], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params(\n",
    "    {\n",
    "        \"layers\": str(LAYER_SIZES), \n",
    "        \"learning_rate\": LR,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"valid_freq\": VALID_FREQUENCY,\n",
    "    }\n",
    ")\n",
    "\n",
    "# gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "\n",
    "vertex_ai.log_metrics(metrics_dict) # JT TODO removed for 'total_loss' getting nan\n",
    "\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef68ef-2644-4009-92b3-6ec84d704128",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7373ed-c4d8-4618-b42f-ec3dbda6ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466dd9cf-70f6-475b-ab28-d17dfffe214a",
   "metadata": {},
   "source": [
    "### Save each tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e83d88-43e1-4ebe-922d-bd4765a6abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=f\"gs://{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=f\"gs://{BUCKET_NAME}/{EXPERIMENT_NAME}/{RUN_NAME}/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450b70a-d6dd-44e9-b7ce-dc439594d0bc",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f08e0-7fb7-48d2-99d2-640cd7405b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15/Unknown - 5093s 325s/step - batch_categorical_accuracy_at_10: 0.0098 - batch_categorical_accuracy_at_50: 0.0489 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 6.5104e-05 - factorized_top_k/top_100_categorical_accuracy: 1.9531e-04 - loss: 7124.5812 - regularization_loss: 0.0000e+00 - total_loss: 7124.5812"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "eval_dict_v1 = model.evaluate(valid_dataset, return_dict=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_mins: {elapsed_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b0c75-7eaf-466c-b452-680addc20a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43294b-3a5d-482c-a0fc-ea37f1d6cb78",
   "metadata": {},
   "source": [
    "### Efficient eval\n",
    "\n",
    "* approximate with scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cca1457-4917-4aa3-81c1-6227e4bea23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    num_reordering_candidates=500,\n",
    "    num_leaves_to_search=30\n",
    ")\n",
    "scann.index_from_dataset(candidates=parsed_candidate_dataset.batch(128).cache().map(lambda x: (x['track_uri_can'], model.candidate_tower(x))))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_scann_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_scann_mins: {elapsed_scann_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0607f90f-843e-4d11-b05c-5085d6e61910",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=scann\n",
    ")\n",
    "model.compile()\n",
    "\n",
    "scann_result = model.evaluate(valid_dataset, return_dict=True, verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_scann_eval_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_scann_eval_mins: {elapsed_scann_eval_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022d991-70ae-4e54-bc6a-5705df1924d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluating the train job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b2721-0c8b-4d59-905d-c3ac776045b6",
   "metadata": {},
   "source": [
    "<img src=\"./img/experiment-console.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2ba57-5fd1-4493-8d6b-3b14b41aa159",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### After opening the TensorBoard instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345a1b6-5c94-45b7-9181-8111b4fe4466",
   "metadata": {},
   "source": [
    "<img src=\"./img/tensorboard.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c18098-6613-4ebd-a780-fe92f2bbcb1a",
   "metadata": {},
   "source": [
    "<img src=\"./img/tb-metrics.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f4fe8-226c-4c11-939f-04fc71300f7a",
   "metadata": {},
   "source": [
    "<img src=\"./img/tb-loss.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ff295-17b4-4ff4-98cb-3d022384ca7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Also, while this is running - check out the Tensorboard profiler in `utils`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f82997-27f3-44c4-82a7-75a3211bcf43",
   "metadata": {},
   "source": [
    "<img src=\"./img/tb-profiler.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfc3e2-2786-476f-a4bf-d052370ecacc",
   "metadata": {},
   "source": [
    "#### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f78adf-a6b4-4581-803e-252882c82a58",
   "metadata": {},
   "source": [
    "<img src=\"./img/nvtop-optimized.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'candidate_embeddings.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File candidate_embeddings.json uploaded to run-spotify-nb-train-full-jt-20221227-214932/candidates/candidate_embeddings.json.\n"
     ]
    }
   ],
   "source": [
    "tt.upload_blob(\n",
    "    'two-tower-models', \n",
    "    'candidate_embeddings.json', \n",
    "    f'{RUN_NAME}/candidates/candidate_embeddings.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    " wc -l candidate_embeddings.json \n",
    " \n",
    " 2249561 candidate_embeddings.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddc8d3-ea1c-4b6b-af2f-e4f272ec3f1a",
   "metadata": {},
   "source": [
    "<img src=\"./img/embeddings.png\" \n",
    "     align=\"center\" \n",
    "     width=\"750\"\n",
    "     height=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0844a4b-084f-4e4d-8f3e-d8d920ec24ec",
   "metadata": {},
   "source": [
    "### Getting test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "728b2fb7-f01d-4804-9416-e52373cd5749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': b'Capoeira Electronica', 'album_name_pl': array([b'Odilara', b'Capoeira Electronica', b'Capoeira Ultimate',\n",
      "       b'Festa Popular', b'Capoeira Electronica'], dtype=object), 'album_uri_can': b'spotify:album:2FsSSHGt8JM0JgRy6ZX3kR', 'album_uri_pl': array([b'spotify:album:4Y8RfvZzCiApBCIZswj9Ry',\n",
      "       b'spotify:album:2FsSSHGt8JM0JgRy6ZX3kR',\n",
      "       b'spotify:album:55HHBqZ2SefPeaENOgWxYK',\n",
      "       b'spotify:album:150L1V6UUT7fGUI3PbxpkE',\n",
      "       b'spotify:album:2FsSSHGt8JM0JgRy6ZX3kR'], dtype=object), 'artist_followers_can': 5170.0, 'artist_genres_can': b\"'capoeira'\", 'artist_genres_pl': array([b\"'samba moderno'\", b\"'capoeira'\", b\"'capoeira'\", b'NONE',\n",
      "       b\"'capoeira'\"], dtype=object), 'artist_name_can': b'Capoeira Experience', 'artist_name_pl': array([b'Odilara', b'Capoeira Experience', b'Denis Porto', b'Zambe',\n",
      "       b'Capoeira Experience'], dtype=object), 'artist_pop_can': 24.0, 'artist_pop_pl': array([ 4., 24.,  2.,  0., 24.], dtype=float32), 'artist_uri_can': b'spotify:artist:5SKEXbgzIdRl3gQJ23CnUP', 'artist_uri_pl': array([b'spotify:artist:72oameojLOPWYB7nB8rl6c',\n",
      "       b'spotify:artist:5SKEXbgzIdRl3gQJ23CnUP',\n",
      "       b'spotify:artist:67p5GMYQZOgaAfx1YyttQk',\n",
      "       b'spotify:artist:4fH3OXCRcPsaHFE5KhgqZS',\n",
      "       b'spotify:artist:5SKEXbgzIdRl3gQJ23CnUP'], dtype=object), 'artists_followers_pl': array([ 316., 5170.,  448.,   19., 5170.], dtype=float32), 'duration_ms_can': 192640.0, 'duration_ms_songs_pl': array([234612., 226826., 203480., 287946., 271920.], dtype=float32), 'num_pl_albums_new': 9.0, 'num_pl_artists_new': 5.0, 'num_pl_songs_new': 85.0, 'pl_collaborative_src': b'false', 'pl_duration_ms_new': 17971314.0, 'pl_name_src': b'Capoeira', 'time_signature_can': b'4', 'time_signature_pl': array([b'4', b'4', b'4', b'4', b'4'], dtype=object), 'track_acousticness_can': 0.478, 'track_acousticness_pl': array([0.238 , 0.105 , 0.0242, 0.125 , 0.304 ], dtype=float32), 'track_danceability_can': 0.709, 'track_danceability_pl': array([0.703, 0.712, 0.806, 0.529, 0.821], dtype=float32), 'track_energy_can': 0.742, 'track_energy_pl': array([0.743, 0.41 , 0.794, 0.776, 0.947], dtype=float32), 'track_instrumentalness_can': 0.00297, 'track_instrumentalness_pl': array([4.84e-06, 4.30e-01, 7.42e-04, 4.01e-01, 5.07e-03], dtype=float32), 'track_key_can': b'0', 'track_key_pl': array([b'5', b'0', b'1', b'10', b'10'], dtype=object), 'track_liveness_can': 0.0346, 'track_liveness_pl': array([0.128 , 0.0725, 0.191 , 0.105 , 0.0552], dtype=float32), 'track_loudness_can': -7.295, 'track_loudness_pl': array([-8.638, -8.754, -9.084, -7.04 , -6.694], dtype=float32), 'track_mode_can': b'1', 'track_mode_pl': array([b'0', b'1', b'1', b'0', b'1'], dtype=object), 'track_name_can': b'Bezouro Preto - Studio', 'track_name_pl': array([b'O Telefone Tocou Novamente', b'Bem Devagar - Studio',\n",
      "       b'Angola Dream', b'Janaina', b'Louco Berimbau - Studio'],\n",
      "      dtype=object), 'track_pop_can': 3.0, 'track_pop_pl': array([5., 1., 0., 0., 1.], dtype=float32), 'track_speechiness_can': 0.0802, 'track_speechiness_pl': array([0.0367, 0.0272, 0.0407, 0.132 , 0.0734], dtype=float32), 'track_tempo_can': 172.238, 'track_tempo_pl': array([100.039,  89.089, 123.999, 119.963, 119.214], dtype=float32), 'track_uri_can': b'spotify:track:0tlhK4OvpHCYpReTABvKFb', 'track_uri_pl': array([b'spotify:track:1pQkOdcTDfLr84TDCrmGy7',\n",
      "       b'spotify:track:39grEDsAHAjmo2QFo4G8D9',\n",
      "       b'spotify:track:5vxSLdJXqbKYH487YO8LSL',\n",
      "       b'spotify:track:6T9GbmZ6voDM4aTBsG5VDh',\n",
      "       b'spotify:track:7ELt9eslVvWo276pX2garN'], dtype=object), 'track_valence_can': 0.844, 'track_valence_pl': array([0.966, 0.667, 0.696, 0.876, 0.655], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for tensor_dict in valid_dataset.unbatch().skip(1000).take(1):\n",
    "    td_keys = tensor_dict.keys()\n",
    "    list_dict = {}\n",
    "    for k in td_keys:\n",
    "        list_dict.update({k: tensor_dict[k].numpy()})\n",
    "    print(list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1318107a-0747-4b7a-9f17-fcf83c975de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album_name_can': b'Capoeira Electronica',\n",
       " 'album_name_pl': array([b'Odilara', b'Capoeira Electronica', b'Capoeira Ultimate',\n",
       "        b'Festa Popular', b'Capoeira Electronica'], dtype=object),\n",
       " 'album_uri_can': b'spotify:album:2FsSSHGt8JM0JgRy6ZX3kR',\n",
       " 'album_uri_pl': array([b'spotify:album:4Y8RfvZzCiApBCIZswj9Ry',\n",
       "        b'spotify:album:2FsSSHGt8JM0JgRy6ZX3kR',\n",
       "        b'spotify:album:55HHBqZ2SefPeaENOgWxYK',\n",
       "        b'spotify:album:150L1V6UUT7fGUI3PbxpkE',\n",
       "        b'spotify:album:2FsSSHGt8JM0JgRy6ZX3kR'], dtype=object),\n",
       " 'artist_followers_can': 5170.0,\n",
       " 'artist_genres_can': b\"'capoeira'\",\n",
       " 'artist_genres_pl': array([b\"'samba moderno'\", b\"'capoeira'\", b\"'capoeira'\", b'NONE',\n",
       "        b\"'capoeira'\"], dtype=object),\n",
       " 'artist_name_can': b'Capoeira Experience',\n",
       " 'artist_name_pl': array([b'Odilara', b'Capoeira Experience', b'Denis Porto', b'Zambe',\n",
       "        b'Capoeira Experience'], dtype=object),\n",
       " 'artist_pop_can': 24.0,\n",
       " 'artist_pop_pl': array([ 4., 24.,  2.,  0., 24.], dtype=float32),\n",
       " 'artist_uri_can': b'spotify:artist:5SKEXbgzIdRl3gQJ23CnUP',\n",
       " 'artist_uri_pl': array([b'spotify:artist:72oameojLOPWYB7nB8rl6c',\n",
       "        b'spotify:artist:5SKEXbgzIdRl3gQJ23CnUP',\n",
       "        b'spotify:artist:67p5GMYQZOgaAfx1YyttQk',\n",
       "        b'spotify:artist:4fH3OXCRcPsaHFE5KhgqZS',\n",
       "        b'spotify:artist:5SKEXbgzIdRl3gQJ23CnUP'], dtype=object),\n",
       " 'artists_followers_pl': array([ 316., 5170.,  448.,   19., 5170.], dtype=float32),\n",
       " 'duration_ms_can': 192640.0,\n",
       " 'duration_ms_songs_pl': array([234612., 226826., 203480., 287946., 271920.], dtype=float32),\n",
       " 'num_pl_albums_new': 9.0,\n",
       " 'num_pl_artists_new': 5.0,\n",
       " 'num_pl_songs_new': 85.0,\n",
       " 'pl_collaborative_src': b'false',\n",
       " 'pl_duration_ms_new': 17971314.0,\n",
       " 'pl_name_src': b'Capoeira',\n",
       " 'time_signature_can': b'4',\n",
       " 'time_signature_pl': array([b'4', b'4', b'4', b'4', b'4'], dtype=object),\n",
       " 'track_acousticness_can': 0.478,\n",
       " 'track_acousticness_pl': array([0.238 , 0.105 , 0.0242, 0.125 , 0.304 ], dtype=float32),\n",
       " 'track_danceability_can': 0.709,\n",
       " 'track_danceability_pl': array([0.703, 0.712, 0.806, 0.529, 0.821], dtype=float32),\n",
       " 'track_energy_can': 0.742,\n",
       " 'track_energy_pl': array([0.743, 0.41 , 0.794, 0.776, 0.947], dtype=float32),\n",
       " 'track_instrumentalness_can': 0.00297,\n",
       " 'track_instrumentalness_pl': array([4.84e-06, 4.30e-01, 7.42e-04, 4.01e-01, 5.07e-03], dtype=float32),\n",
       " 'track_key_can': b'0',\n",
       " 'track_key_pl': array([b'5', b'0', b'1', b'10', b'10'], dtype=object),\n",
       " 'track_liveness_can': 0.0346,\n",
       " 'track_liveness_pl': array([0.128 , 0.0725, 0.191 , 0.105 , 0.0552], dtype=float32),\n",
       " 'track_loudness_can': -7.295,\n",
       " 'track_loudness_pl': array([-8.638, -8.754, -9.084, -7.04 , -6.694], dtype=float32),\n",
       " 'track_mode_can': b'1',\n",
       " 'track_mode_pl': array([b'0', b'1', b'1', b'0', b'1'], dtype=object),\n",
       " 'track_name_can': b'Bezouro Preto - Studio',\n",
       " 'track_name_pl': array([b'O Telefone Tocou Novamente', b'Bem Devagar - Studio',\n",
       "        b'Angola Dream', b'Janaina', b'Louco Berimbau - Studio'],\n",
       "       dtype=object),\n",
       " 'track_pop_can': 3.0,\n",
       " 'track_pop_pl': array([5., 1., 0., 0., 1.], dtype=float32),\n",
       " 'track_speechiness_can': 0.0802,\n",
       " 'track_speechiness_pl': array([0.0367, 0.0272, 0.0407, 0.132 , 0.0734], dtype=float32),\n",
       " 'track_tempo_can': 172.238,\n",
       " 'track_tempo_pl': array([100.039,  89.089, 123.999, 119.963, 119.214], dtype=float32),\n",
       " 'track_uri_can': b'spotify:track:0tlhK4OvpHCYpReTABvKFb',\n",
       " 'track_uri_pl': array([b'spotify:track:1pQkOdcTDfLr84TDCrmGy7',\n",
       "        b'spotify:track:39grEDsAHAjmo2QFo4G8D9',\n",
       "        b'spotify:track:5vxSLdJXqbKYH487YO8LSL',\n",
       "        b'spotify:track:6T9GbmZ6voDM4aTBsG5VDh',\n",
       "        b'spotify:track:7ELt9eslVvWo276pX2garN'], dtype=object),\n",
       " 'track_valence_can': 0.844,\n",
       " 'track_valence_pl': array([0.966, 0.667, 0.696, 0.876, 0.655], dtype=float32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
