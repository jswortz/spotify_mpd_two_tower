{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f365f-5d78-4114-b741-311ffcc64884",
   "metadata": {},
   "source": [
    "`pip install --upgrade 'apache-beam[gcp]'`\n",
    "\n",
    "#### IMPORTANT - make sure you upgrade Dataflow with the above command then restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176b3bf-c98f-4d44-a410-31f816b1998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil mb -l us-central1 gs://spotify-beam-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e9bb8-c550-414b-9b65-b2124837e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "BUCKET_NAME = 'spotify-beam-v3' # 'spotify-tfrecords-blog' # Set your Bucket name\n",
    "REGION = 'us-central1' # Set the region for Dataflow jobs\n",
    "VERSION = 'v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "### Run the Dataflow app to convert from BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "\n",
    "  Candidate generation \n",
    "  \n",
    "  `beam_candidates\\python3 main.py`\n",
    "   \n",
    "  Training generation\n",
    "  \n",
    "  `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`\n",
    "  \n",
    "  \n",
    "##### Be careful with quotas - running more than two jobs can run into quota issues with defaults\n",
    "\n",
    "Training data generation runs about 1 hour with 10 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2cb50a-b8a7-4b72-bf2e-1ab7290a25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree beam_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d635a3-cdf4-4537-abba-f7a43275ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 main-train.py train_flatten_last_5 train_last_5 2000 88_940 $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 main-train.py train_flatten_valid_last_5 valid_last_5 2000 920 $VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacf47b-bd83-47e8-804b-b53471d00e5d",
   "metadata": {},
   "source": [
    "# Now export the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d12ea7-be9f-49cb-b7dc-663b7b81a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../beam_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350506bc-dadd-4781-84f6-5544fdfc78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "## Test the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing output\n",
    "candidate_features = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "}\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "# # gs://spotify-beam-v3/v3/candidates/*.tfrecords\n",
    "\n",
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/candidates/'\n",
    "\n",
    "candidate_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "def parse_candidate_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn, num_parallel_calls=-1)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn) ### THIS NEEDS TO BE FIXED SO THE UNIQUE PRODUCT DATASET HAS THE SAME FIELD NAMES (goes thru the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in parsed_candidate_dataset.batch(2).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49445d15-3782-42e3-9820-8494ad67ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLAYLIST_LENGTH = 5\n",
    "feats = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'name': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'collaborative': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'n_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_artists_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_albums_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'description_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_name_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artist_name_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'album_name_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'track_uri_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH)),\n",
    "    'duration_ms_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artist_pop_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artists_followers_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'track_pop_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artist_genres_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing output\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "# # gs://spotify-beam-v3/v3/candidates/*.tfrecords\n",
    "\n",
    "train_dir = 'spotify-beam-v3'\n",
    "train_dir_prefix = 'v6/train_last_5_v2/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f\"{train_dir}\", prefix=f'{train_dir_prefix}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn, num_parallel_calls=-1)\n",
    "\n",
    "valid_parsed = valid.map(parse_tfrecord) ### THIS NEEDS TO BE FIXED SO THE UNIQUE PRODUCT DATASET HAS THE SAME FIELD NAMES (goes thru the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in valid_parsed.batch(2).take(1):\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
