{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bc223a-71f3-4771-9429-e0e06d3b6502",
   "metadata": {},
   "source": [
    "# Spotify TFRS - Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac6e70-5bb3-4134-96b4-83d4761831e4",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "* fix pip installs with versions\n",
    "* update env variables \n",
    "* should we use something like the `run_bq_query` function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4457e8-5d91-4b3d-a594-c07b7b87955f",
   "metadata": {},
   "source": [
    "## Install additional packages\n",
    "\n",
    "#### Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449e3c3-3c48-4150-bf6f-e4baa92a5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "# !pip install --upgrade --no-warn-conflicts '{USER_FLAG}' -q \\\n",
    "#     google-cloud-pubsub==2.13.6 \\\n",
    "#     google-api-core==2.8.2 \\\n",
    "#     google-apitools==0.5.32 \\\n",
    "#     plotly==5.10.0 \\\n",
    "#     itables==1.2.0 \\\n",
    "#     xgboost==1.6.2 \\\n",
    "#     apache_beam==2.40.0 \\\n",
    "#     plotly==5.10.0 \\\n",
    "#     google-cloud-pipeline-components \\\n",
    "#     kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0fe621-5a56-4790-bdb4-9fde526a3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade google-cloud-aiplatform -q \\\n",
    "#                          google-cloud-pipeline-components -q \\\n",
    "#                          google-cloud-logging -q \\\n",
    "#                          pyarrow -q \\\n",
    "#                          google-cloud-storage $USER_FLAG \\\n",
    "#                          kfp $USER_FLAG -q\n",
    "# !pip install --upgrade 'apache-beam[gcp]' --user\n",
    "\n",
    "\n",
    "\n",
    "# ! pip3 install jsonobject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ceadf3-f00f-445f-9c3b-d1379daf5daf",
   "metadata": {},
   "source": [
    "After install, retart notebook kernel.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276ca25-f628-44de-93e6-ed256a8fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e38fe-a7bc-41c9-85a0-f240ffd94c16",
   "metadata": {},
   "source": [
    "## Create a Google Cloud Storage bucket and save the config data.\n",
    "Next, we will create a Google Cloud Storage bucket and will save the config data in this bucket. After the cell operation finishes, you can navigate to Google Cloud Storage to see the GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425d575-d038-4a05-8c19-9cb7f4ce7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from typing import Union\n",
    "\n",
    "# Generate unique ID to help w/ unique naming of certain pieces\n",
    "ID = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=5))\n",
    "\n",
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS locations\n",
    "DATA_SOURCE_BUCKET = 'spotify-million-playlist-dataset'              # where MPD gzip stored\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-tfrs-retrieval\"                         # store repo artifacts: models, pipelines, indexes\n",
    "REGION = \"us-central1\"\n",
    "BQ_DATASET = \"mdp_eda_test\"                                          # BQ destination from gzip, BQ source elsewhere\n",
    "BQ_TABLE_TRAIN = 'train'                                             # train table\n",
    "BQ_TABLE_VALID = 'valid'                                             # valid table\n",
    "BQ_TABLE_CANDIDATES = 'candidates'                                   # candidates table\n",
    "VPC_NETWORK = 'ucaip-haystack-vpc-network'                           # VPC network (required to interact with Matching Engine)\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "# MAX_PLAYLIST_LENGTH = 5 # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473da270-f6f9-4101-84e7-5f773d793b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "DATA_SOURCE_BUCKET   = \\\"{DATA_SOURCE_BUCKET}\\\" \n",
    "BUCKET_NAME          = \\\"{BUCKET_NAME}\\\"\n",
    "PROJECT              = \\\"{PROJECT_ID}\\\"\n",
    "REGION               = \\\"{REGION}\\\"\n",
    "ID                   = \\\"{ID}\\\"\n",
    "BQ_DATASET           = \\\"{BQ_DATASET}\\\"\n",
    "BQ_TABLE_TRAIN       = \\\"{BQ_TABLE_TRAIN}\\\"\n",
    "BQ_TABLE_VALID       = \\\"{BQ_TABLE_VALID}\\\"\n",
    "BQ_TABLE_CANDIDATES  = \\\"{BQ_TABLE_CANDIDATES}\\\"\n",
    "VPC_NETWORK          = \\\"{VPC_NETWORK}\\\"\n",
    "VERTEX_SA            = \\\"{VERTEX_SA}\\\"\n",
    "\"\"\"\n",
    "\n",
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}\n",
    "\n",
    "!echo '{config}' | gsutil cp - gs://{BUCKET_NAME}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a57e653-730f-42d8-b3ba-f21f2a8957e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Inspect train_job dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1184af16-4589-4e33-919a-771c7f03063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_JOB_DICT_PICKLE = 'gs://jt-tfrs-central-v2/8m-tfrs-v1-jtv15/run-20230125-172025/train_job_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79478bcc-f39f-484c-825a-19621aaee703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jt-tfrs-central-v2/8m-tfrs-v1-jtv15/run-20230125-172025/train_job_dict.pkl...\n",
      "/ [1 files][  1.9 KiB/  1.9 KiB]                                                \n",
      "Operation completed over 1 objects/1.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $TRAIN_JOB_DICT_PICKLE ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48a938d-74aa-4f9a-a4f4-e00b29f0d278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/customJobs/3241873888052772864',\n",
       " 'displayName': 'train-sp-2tower-tfrs-jtv15-v1-80gb',\n",
       " 'jobSpec': {'workerPoolSpecs': [{'machineSpec': {'machineType': 'a2-highgpu-1g',\n",
       "     'acceleratorType': 'NVIDIA_TESLA_A100',\n",
       "     'acceleratorCount': 1},\n",
       "    'replicaCount': '1',\n",
       "    'diskSpec': {'bootDiskType': 'pd-ssd', 'bootDiskSizeGb': 100},\n",
       "    'containerSpec': {'imageUri': 'gcr.io/hybrid-vertex/sp-2tower-tfrs-jtv15-v1-80gb-training',\n",
       "     'command': ['python', 'two_tower_jt/task.py'],\n",
       "     'args': ['--project=hybrid-vertex',\n",
       "      '--train_output_gcs_bucket=jt-tfrs-central-v2',\n",
       "      '--train_dir=spotify-data-regimes',\n",
       "      '--train_dir_prefix=jtv14-8m/train_v14',\n",
       "      '--valid_dir=spotify-data-regimes',\n",
       "      '--valid_dir_prefix=jtv14-8m/valid_v14',\n",
       "      '--candidate_file_dir=spotify-data-regimes',\n",
       "      '--candidate_files_prefix=jtv14-8m/candidates',\n",
       "      '--experiment_name=8m-tfrs-v1-jtv15',\n",
       "      '--experiment_run=run-20230125-172025',\n",
       "      '--num_epochs=5',\n",
       "      '--batch_size=8192',\n",
       "      '--embedding_dim=128',\n",
       "      '--projection_dim=50',\n",
       "      '--layer_sizes=[512,128]',\n",
       "      '--learning_rate=0.01',\n",
       "      '--valid_frequency=35',\n",
       "      '--valid_steps=10',\n",
       "      '--epoch_steps=1001',\n",
       "      '--distribute=single',\n",
       "      '--model_version=jtv15',\n",
       "      '--pipeline_version=v1-80gb',\n",
       "      '--seed=1234',\n",
       "      '--max_tokens=20000',\n",
       "      '--tb_resource_name=projects/934903580331/locations/us-central1/tensorboards/777055653674876928',\n",
       "      '--embed_frequency=0',\n",
       "      '--hist_frequency=0',\n",
       "      '--tf_gpu_thread_count=8',\n",
       "      '--block_length=64',\n",
       "      '--num_data_shards=4',\n",
       "      '--chkpt_freq=epoch',\n",
       "      '--cache_train',\n",
       "      '--profiler',\n",
       "      '--compute_batch_metrics']}}],\n",
       "  'serviceAccount': 'notebooksa@hybrid-vertex.iam.gserviceaccount.com',\n",
       "  'baseOutputDirectory': {'outputUriPrefix': 'gs://jt-tfrs-central-v2/8m-tfrs-v1-jtv15/run-20230125-172025'},\n",
       "  'tensorboard': 'projects/934903580331/locations/us-central1/tensorboards/777055653674876928',\n",
       "  'enableWebAccess': True},\n",
       " 'state': 'JOB_STATE_SUCCEEDED',\n",
       " 'createTime': '2023-01-25T17:21:47.613539Z',\n",
       " 'startTime': '2023-01-25T17:26:16Z',\n",
       " 'endTime': '2023-01-25T18:55:09Z',\n",
       " 'updateTime': '2023-01-25T18:55:14.484962Z'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('train_job_dict.pkl', 'rb')\n",
    "train_job_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "train_job_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcac6e69-3120-4773-9335-2db5bfd6b773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'machineSpec': {'machineType': 'a2-highgpu-1g',\n",
       "   'acceleratorType': 'NVIDIA_TESLA_A100',\n",
       "   'acceleratorCount': 1},\n",
       "  'replicaCount': '1',\n",
       "  'diskSpec': {'bootDiskType': 'pd-ssd', 'bootDiskSizeGb': 100},\n",
       "  'containerSpec': {'imageUri': 'gcr.io/hybrid-vertex/sp-2tower-tfrs-jtv15-v1-80gb-training',\n",
       "   'command': ['python', 'two_tower_jt/task.py'],\n",
       "   'args': ['--project=hybrid-vertex',\n",
       "    '--train_output_gcs_bucket=jt-tfrs-central-v2',\n",
       "    '--train_dir=spotify-data-regimes',\n",
       "    '--train_dir_prefix=jtv14-8m/train_v14',\n",
       "    '--valid_dir=spotify-data-regimes',\n",
       "    '--valid_dir_prefix=jtv14-8m/valid_v14',\n",
       "    '--candidate_file_dir=spotify-data-regimes',\n",
       "    '--candidate_files_prefix=jtv14-8m/candidates',\n",
       "    '--experiment_name=8m-tfrs-v1-jtv15',\n",
       "    '--experiment_run=run-20230125-172025',\n",
       "    '--num_epochs=5',\n",
       "    '--batch_size=8192',\n",
       "    '--embedding_dim=128',\n",
       "    '--projection_dim=50',\n",
       "    '--layer_sizes=[512,128]',\n",
       "    '--learning_rate=0.01',\n",
       "    '--valid_frequency=35',\n",
       "    '--valid_steps=10',\n",
       "    '--epoch_steps=1001',\n",
       "    '--distribute=single',\n",
       "    '--model_version=jtv15',\n",
       "    '--pipeline_version=v1-80gb',\n",
       "    '--seed=1234',\n",
       "    '--max_tokens=20000',\n",
       "    '--tb_resource_name=projects/934903580331/locations/us-central1/tensorboards/777055653674876928',\n",
       "    '--embed_frequency=0',\n",
       "    '--hist_frequency=0',\n",
       "    '--tf_gpu_thread_count=8',\n",
       "    '--block_length=64',\n",
       "    '--num_data_shards=4',\n",
       "    '--chkpt_freq=epoch',\n",
       "    '--cache_train',\n",
       "    '--profiler',\n",
       "    '--compute_batch_metrics']}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_job_dict['jobSpec']['workerPoolSpecs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55368a8f-47ca-42f0-90a5-85bf59f778af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Check data in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44637a0-8762-4e7a-90b3-62af17101872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client()\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906075d7-df3f-48c3-9cab-aa08d19a1a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
