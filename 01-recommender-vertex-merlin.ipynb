{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c20da6-d8ec-4018-a350-f053884fb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d747c47-2ded-4890-98b6-982884b701c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo Y | pip uninstall merlin-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bf31e4-20ea-4f3d-8b42-970f05de31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/NVIDIA-Merlin/models.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b13a21",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "Push a Nvidia repo to your artifact repository - (create a new repo if not available)\n",
    "\n",
    "### Further instructions on how to build a Merlin container can be found [here](https://github.com/jswortz/merlin-gcp)\n",
    "\n",
    "Guide\n",
    "1. In an notebook instance run from a terminal `git clone https://github.com/jswortz/merlin-gcp`\n",
    "2. Run the notebook - this will build a merlin tensorflow image. You can change the base images from NVidia if you choose - this was tested from the version in the repo\n",
    "3. This will build a container image and save it to artifact registry repository. You may need to enable the artifact repository service\n",
    "4. Create a new custom workbench by clicking \"New Notebook\" > \"Customize\"\n",
    "\n",
    "<img src=\"img/custom_workbench.png\" width=\"500\"/>\n",
    "\n",
    "5. To get to the screen for artifact repository. First select \"Advanced\" then name, select region, then go to \"Environment\"\n",
    "\n",
    "<img src=\"img/workbench-environment.png\" width=\"500\"/>\n",
    "\n",
    "6. Select the your repo and respective image\n",
    "\n",
    "<img src=\"img/image.png\" width=\"500\"/>\n",
    "\n",
    "7. Finally, if you already followed the instructions in notebook 02 setup - make sure the new workbench network is in the VPC peered network used for matching engine\n",
    "\n",
    "# Training with Merlin\n",
    "\n",
    "## Spotify example\n",
    "\n",
    "Our goal is to enable the architecture below with Vertex AI and the Merlin Models framework\n",
    "\n",
    "![](img/arch.png)\n",
    "\n",
    "## Goals\n",
    "\n",
    "The goal of this notebook is to create a simple two tower model with Nvtabular and Merlin Models\n",
    "\n",
    "1. Export data to Parquet for use in Nvtabular\n",
    "2. Create a NVtabular workflow and fit it to the data\n",
    "3. Save the fitted workflow to GCS (contains all dictionary lookups)\n",
    "4. Transform the data into GPU-optimized features from the NVtabular workflow and save to gcs\n",
    "5. Load the data again as a Merlin dataset using the workflow\n",
    "6. Create a two tower model in a few lines of code\n",
    "7. Train a two tower model\n",
    "8. Save the model (for deployment in notebook 03)\n",
    "9. Export the embeddings and save to gcs (for deployment to matching engine)\n",
    "\n",
    "*Based heavily on [this](https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb) NVIDIA resource\n",
    "\n",
    "\n",
    "Data is loaded from BQ - to parquet using the job configuration below\n",
    "\n",
    "\n",
    "Info on the data\n",
    "\n",
    "* track_uri_seed counts: 2249561\n",
    "* artist_uri_seed counts: 294110\n",
    "* album_uri_seed counts: 730377"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebae1b-c48f-4f16-a6b3-a49da98c2341",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Export Data From BigQuery to Parquet on GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decc6184-2fd8-40d7-9a75-c186adfc24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "# path = 'gs://two-tower-models' #TODO change to your model directory\n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "DATASET_ID = 'mdp_eda_test'\n",
    "TABLE = 'train_flatten_last_5'\n",
    "TABLE_VALIDATION = 'train_flatten_valid_last_5'\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "def export_bq_to_parquet(PROJECT, DATASET_ID, TABLE, LOCATION, prefix):\n",
    "    destination_uri = f\"{BUCKET}/{prefix}_data_parquet/*.snappy.parquet\"\n",
    "    dataset_ref = bigquery.DatasetReference(PROJECT, DATASET_ID)\n",
    "    table_ref = dataset_ref.table(TABLE)\n",
    "    job_config = bigquery.job.ExtractJobConfig()\n",
    "    job_config.destination_format = bigquery.DestinationFormat.PARQUET\n",
    "    extract_job = client.extract_table(\n",
    "        table_ref,\n",
    "        destination_uri,\n",
    "        job_config=job_config,\n",
    "        # Location must match that of the source table.\n",
    "        location=LOCATION,\n",
    "    )  # API request\n",
    "    return(extract_job.result())  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49217e-d2d9-4648-8562-9bfdea67be8b",
   "metadata": {},
   "source": [
    "#### Export the data from Bigquery to Parquet\n",
    "\n",
    "*Run only once* Uncomment to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d833ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training\n",
    "# export_bq_to_parquet(PROJECT, DATASET_ID, TABLE, LOCATION, prefix='train')\n",
    "\n",
    "# # # validation\n",
    "# export_bq_to_parquet(PROJECT, DATASET_ID, TABLE_VALIDATION, LOCATION, prefix='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac54435-6c4f-41fa-a8f9-2a947cc0f018",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Create a NVTabular WÂ orkflow To Preprocess The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4a0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nvtabular as nvt\n",
    "from time import time\n",
    "import pandas as pd\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from nvtabular.ops import (\n",
    "    Categorify,\n",
    "    TagAsUserID,\n",
    "    TagAsItemID,\n",
    "    TagAsItemFeatures,\n",
    "    TagAsUserFeatures,\n",
    "    AddMetadata,\n",
    "    ListSlice\n",
    ")\n",
    "import nvtabular.ops as ops\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "# for running this example on CPU, comment out the line below\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64962317",
   "metadata": {},
   "source": [
    "### Create NVTabular Dataset\n",
    "This will be our pre-processor to hash strings and other preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c17d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = nvt.Dataset(f\"{BUCKET}/train_data_parquet/*.snappy.parquet\")\n",
    "valid = nvt.Dataset(f\"{BUCKET}/valid_data_parquet/*.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb299dc",
   "metadata": {},
   "source": [
    "#### Define the NVTabular preprocessing graph\n",
    "\n",
    "Nvtabular takes a tabular dataset and transforms the data into new Parquet files optimized for training. This is equivalent to running a string lookup in tensorflow, and has similar functionality as adpat when a workflow is used\n",
    "\n",
    "The graph is defined as a set of nodes and a node is defined as follows:\n",
    "\n",
    "``` \n",
    "NODE_NAME = LIST_OF_FEATURE_NAMES >> nvt.ops.* >> [NEXT_STEP] >> Tag\n",
    "```\n",
    "\n",
    "Nvt has many ops - one of the most notable is `Categorify` as it is flexible and converts high cardinality text features to indicies\n",
    "\n",
    "Tags are used as a means to label the schema in the metadata and serves as a label for merlin models to interpret for consumption (e.g. which features belong to the query tower and candidate tower have different tags). You will see the tags in the schema in examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6833b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_id = [\"track_uri_can\"] >> Categorify(dtype=\"int32\") >> TagAsItemID() \n",
    "playlist_id = [\"pid\"] >> Categorify(dtype=\"int32\") >> TagAsUserID() \n",
    "\n",
    "\n",
    "item_features_cat = ['artist_name_can',\n",
    "        'track_name_can',\n",
    "        'artist_genres_can',\n",
    "    ]\n",
    "\n",
    "item_features_cont = [\n",
    "        'duration_ms_can',\n",
    "        'track_pop_can',\n",
    "        'artist_pop_can',\n",
    "        'artist_followers_can',\n",
    "    ]\n",
    "\n",
    "playlist_features_cat = [\n",
    "        'description_pl',\n",
    "        'name',\n",
    "        'collaborative',\n",
    "    ]\n",
    "\n",
    "playlist_features_cont = [\n",
    "        'duration_ms_seed_pl',\n",
    "        'n_songs_pl',\n",
    "        'num_artists_pl',\n",
    "        'num_albums_pl',\n",
    "    ]\n",
    "\n",
    "seq_feats_cat = [\n",
    "        'artist_name_pl',\n",
    "        'track_uri_pl',\n",
    "        'track_name_pl',\n",
    "        'album_name_pl',\n",
    "        'artist_genres_pl',\n",
    "    ]\n",
    "\n",
    "CAT = playlist_features_cat + item_features_cat\n",
    "CONT = item_features_cont + playlist_features_cont\n",
    "\n",
    "item_feature_cat_node = item_features_cat >> nvt.ops.FillMissing()>> Categorify(dtype=\"int32\") >> TagAsItemFeatures()\n",
    "\n",
    "item_feature_cont_node =  item_features_cont >> nvt.ops.FillMissing() >>  nvt.ops.Normalize() >> TagAsItemFeatures()\n",
    "\n",
    "playlist_feature_cat_node = playlist_features_cat >> nvt.ops.FillMissing() >> Categorify(dtype=\"int32\") >> TagAsUserFeatures() \n",
    "\n",
    "playlist_feature_cont_node = playlist_features_cont >> nvt.ops.FillMissing() >>  nvt.ops.Normalize() >> TagAsUserFeatures()\n",
    "\n",
    "playlist_feature_cat_seq_node = seq_feats_cat >> nvt.ops.FillMissing() >> Categorify(dtype=\"int32\") >> TagAsUserFeatures() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d819-38c9-4973-9cc5-a86af987b340",
   "metadata": {},
   "source": [
    "### Define a workflow\n",
    "This is an easy step by adding all nodes that need to run in parallel. A graphviz visualization of the graph is available below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1744279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a workflow\n",
    "output = playlist_id + item_id \\\n",
    "+ item_feature_cat_node \\\n",
    "+ item_feature_cont_node \\\n",
    "+ playlist_feature_cat_node \\\n",
    "+ playlist_feature_cont_node \\\n",
    "+ playlist_feature_cat_seq_node \n",
    "\n",
    "\n",
    "workflow = nvt.Workflow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b842eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"3221pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 3221.13 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 3217.13,-472 3217.13,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2208.01\" cy=\"-234\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2208.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2182.01\" cy=\"-162\" rx=\"100.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2182.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsItemFeatures</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2201.72,-216.05C2198.79,-208.18 2195.24,-198.62 2191.97,-189.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2195.19,-188.43 2188.43,-180.28 2188.63,-190.87 2195.19,-188.43\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>25</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2415.01\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2415.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>25&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2376.08,-291.83C2342.04,-280.32 2292.48,-263.56 2256,-251.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2256.67,-247.76 2246.08,-247.87 2254.43,-254.39 2256.67,-247.76\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1013.01\" cy=\"-306\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1013.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1013.01\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1013.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1013.01,-287.7C1013.01,-279.98 1013.01,-270.71 1013.01,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1016.51,-262.1 1013.01,-252.1 1009.51,-262.1 1016.51,-262.1\"/>\n",
       "</g>\n",
       "<!-- 1_selector -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1013.01\" cy=\"-378\" rx=\"84.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1013.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;track_uri_can&#39;]</text>\n",
       "</g>\n",
       "<!-- 1_selector&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1_selector&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1013.01,-359.7C1013.01,-351.98 1013.01,-342.71 1013.01,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1016.51,-334.1 1013.01,-324.1 1009.51,-334.1 1016.51,-334.1\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"796.01\" cy=\"-162\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"796.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserFeatures</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1363.01\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1363.01\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;9 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>2&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M876.79,-150.97C895.26,-148.67 914.82,-146.25 933.01,-144 1078.52,-126.01 1251.73,-104.69 1326.1,-95.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1326.85,-98.97 1336.34,-94.28 1325.99,-92.03 1326.85,-98.97\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>26</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"769.01\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"769.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>26&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M775.55,-216.05C778.59,-208.18 782.28,-198.62 785.68,-189.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"789.02,-190.86 789.35,-180.28 782.49,-188.35 789.02,-190.86\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;9 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>3&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2098.39,-151.84C2073.21,-149.18 2045.5,-146.36 2020.01,-144 1784.2,-122.12 1500.27,-100.98 1400.15,-93.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1400.17,-90.17 1389.94,-92.94 1399.66,-97.16 1400.17,-90.17\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1013.01\" cy=\"-162\" rx=\"70.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1013.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsItemID</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1013.01,-215.7C1013.01,-207.98 1013.01,-198.71 1013.01,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1016.51,-190.1 1013.01,-180.1 1009.51,-190.1 1016.51,-190.1\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1065.49,-149.73C1074.66,-147.79 1084.11,-145.82 1093.01,-144 1176.86,-126.86 1275.59,-107.75 1327.3,-97.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1328.14,-101.23 1337.3,-95.91 1326.82,-94.36 1328.14,-101.23\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1584.01\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1584.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1584.01\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1584.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1584.01,-359.7C1584.01,-351.98 1584.01,-342.71 1584.01,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1587.51,-334.1 1584.01,-324.1 1580.51,-334.1 1587.51,-334.1\"/>\n",
       "</g>\n",
       "<!-- 6_selector -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1584.01\" cy=\"-450\" rx=\"194.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1584.01\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;description_pl&#39;, &#39;name&#39;, &#39;collaborative&#39;]</text>\n",
       "</g>\n",
       "<!-- 6_selector&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6_selector&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1584.01,-431.7C1584.01,-423.98 1584.01,-414.71 1584.01,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1587.51,-406.1 1584.01,-396.1 1580.51,-406.1 1587.51,-406.1\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1173.01\" cy=\"-306\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1173.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1173.01\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1173.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1173.01,-287.7C1173.01,-279.98 1173.01,-270.71 1173.01,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1176.51,-262.1 1173.01,-252.1 1169.51,-262.1 1176.51,-262.1\"/>\n",
       "</g>\n",
       "<!-- 7_selector -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>7_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1173.01\" cy=\"-378\" rx=\"37.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1173.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;pid&#39;]</text>\n",
       "</g>\n",
       "<!-- 7_selector&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7_selector&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1173.01,-359.7C1173.01,-351.98 1173.01,-342.71 1173.01,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1176.51,-334.1 1173.01,-324.1 1169.51,-334.1 1176.51,-334.1\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1584.01\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1584.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1584.01,-287.7C1584.01,-279.98 1584.01,-270.71 1584.01,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1587.51,-262.1 1584.01,-252.1 1580.51,-262.1 1587.51,-262.1\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>27</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1363.01\" cy=\"-18\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1363.01\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;27 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>9&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1363.01,-71.7C1363.01,-63.98 1363.01,-54.71 1363.01,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1366.51,-46.1 1363.01,-36.1 1359.51,-46.1 1366.51,-46.1\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1173.01\" cy=\"-162\" rx=\"71.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1173.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserID</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>13&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1211.92,-146.67C1246.85,-133.8 1297.54,-115.12 1330.39,-103.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1331.81,-106.23 1339.98,-99.49 1329.39,-99.66 1331.81,-106.23\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>21</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1363.01\" cy=\"-162\" rx=\"100.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1363.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsItemFeatures</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;9 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>21&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1363.01,-143.7C1363.01,-135.98 1363.01,-126.71 1363.01,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1366.51,-118.1 1363.01,-108.1 1359.51,-118.1 1366.51,-118.1\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1584.01\" cy=\"-162\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1584.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserFeatures</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;9 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1536.6,-145.98C1494.52,-132.65 1434.08,-113.51 1396.75,-101.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1397.45,-98.24 1386.86,-98.55 1395.34,-104.91 1397.45,-98.24\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1909.01\" cy=\"-162\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1909.01\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserFeatures</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;9 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>20&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1829.04,-150.75C1708.78,-135.33 1486.21,-106.79 1399.21,-95.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1399.65,-92.17 1389.28,-94.37 1398.76,-99.11 1399.65,-92.17\"/>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1584.01,-215.7C1584.01,-207.98 1584.01,-198.71 1584.01,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1587.51,-190.1 1584.01,-180.1 1580.51,-190.1 1587.51,-190.1\"/>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>11&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1173.01,-215.7C1173.01,-207.98 1173.01,-198.71 1173.01,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1176.51,-190.1 1173.01,-180.1 1169.51,-190.1 1176.51,-190.1\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2060.01\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2060.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2026.01\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2026.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;16 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>14&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2051.78,-360.05C2047.92,-352.09 2043.21,-342.41 2038.89,-333.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2041.92,-331.74 2034.41,-324.28 2035.63,-334.8 2041.92,-331.74\"/>\n",
       "</g>\n",
       "<!-- 14_selector -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>14_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2138.01\" cy=\"-450\" rx=\"341.44\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2138.01\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;duration_ms_seed_pl&#39;, &#39;n_songs_pl&#39;, &#39;num_artists_pl&#39;, &#39;num_albums_pl&#39;]</text>\n",
       "</g>\n",
       "<!-- 14_selector&#45;&gt;14 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>14_selector&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2118.73,-431.7C2108.79,-422.77 2096.52,-411.76 2085.77,-402.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2088.05,-399.46 2078.27,-395.38 2083.37,-404.67 2088.05,-399.46\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1318.01\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1318.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1341.01\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1341.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1323.58,-360.05C1326.17,-352.18 1329.31,-342.62 1332.21,-333.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1335.54,-334.87 1335.34,-324.28 1328.89,-332.68 1335.54,-334.87\"/>\n",
       "</g>\n",
       "<!-- 15_selector -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>15_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1096.01\" cy=\"-450\" rx=\"275.65\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1096.01\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;artist_name_can&#39;, &#39;track_name_can&#39;, &#39;artist_genres_can&#39;]</text>\n",
       "</g>\n",
       "<!-- 15_selector&#45;&gt;15 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>15_selector&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1148.91,-432.32C1184.54,-421.09 1231.31,-406.34 1266.63,-395.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1267.78,-398.51 1276.27,-392.16 1265.68,-391.83 1267.78,-398.51\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1987.01\" cy=\"-234\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1987.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;18 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>16&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2016.57,-288.05C2011.97,-279.8 2006.35,-269.7 2001.24,-260.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2004.29,-258.82 1996.37,-251.79 1998.18,-262.23 2004.29,-258.82\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1352.01\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1352.01\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;19 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>17&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1343.73,-287.7C1344.95,-279.98 1346.4,-270.71 1347.75,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1351.23,-262.53 1349.33,-252.1 1344.32,-261.44 1351.23,-262.53\"/>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1968.92,-216.76C1959,-207.86 1946.51,-196.65 1935.51,-186.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1937.6,-183.95 1927.82,-179.88 1932.93,-189.16 1937.6,-183.95\"/>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;21 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>19&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1354.73,-215.7C1355.95,-207.98 1357.4,-198.71 1358.75,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1362.23,-190.53 1360.33,-180.1 1355.32,-189.44 1362.23,-190.53\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>22</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"454.01\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"454.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>24</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"559.01\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"559.01\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;24 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>22&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M477.84,-361.12C492.34,-351.45 511.05,-338.98 526.85,-328.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"528.9,-331.28 535.28,-322.82 525.02,-325.46 528.9,-331.28\"/>\n",
       "</g>\n",
       "<!-- 22_selector -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>22_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"401.01\" cy=\"-450\" rx=\"401.03\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"401.01\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;artist_name_pl&#39;, &#39;track_uri_pl&#39;, &#39;track_name_pl&#39;, &#39;album_name_pl&#39;, &#39;artist_genres_pl&#39;]</text>\n",
       "</g>\n",
       "<!-- 22_selector&#45;&gt;22 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>22_selector&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M414.12,-431.7C420.41,-423.39 428.06,-413.28 434.98,-404.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"437.82,-406.19 441.06,-396.1 432.24,-401.96 437.82,-406.19\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>23</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2829.01\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2829.01\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;25 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>23&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2774.04,-367.7C2697.15,-354.7 2557.91,-331.16 2477.29,-317.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2477.72,-314.05 2467.27,-315.84 2476.55,-320.95 2477.72,-314.05\"/>\n",
       "</g>\n",
       "<!-- 23_selector -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>23_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2855.01\" cy=\"-450\" rx=\"358.24\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2855.01\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;duration_ms_can&#39;, &#39;track_pop_can&#39;, &#39;artist_pop_can&#39;, &#39;artist_followers_can&#39;]</text>\n",
       "</g>\n",
       "<!-- 23_selector&#45;&gt;23 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>23_selector&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2848.59,-431.7C2845.66,-423.81 2842.13,-414.3 2838.87,-405.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2842.13,-404.26 2835.37,-396.1 2835.57,-406.7 2842.13,-404.26\"/>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;26 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>24&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M598.51,-291.83C633.2,-280.27 683.75,-263.42 720.81,-251.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"722.02,-254.35 730.4,-247.87 719.81,-247.71 722.02,-254.35\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f7fe41974f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577993c5-ff3c-4e0d-89ef-e49ed93d7017",
   "metadata": {},
   "source": [
    "### Before we transform the data, let's look at an original record\n",
    "This loads the data into a dask pandas dataframe. `.to_ddf()` converts the dataset into a dask df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eea53fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>collaborative</th>\n",
       "      <th>pid</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>pid_pos_id</th>\n",
       "      <th>pos_can</th>\n",
       "      <th>artist_name_can</th>\n",
       "      <th>track_uri_can</th>\n",
       "      <th>album_uri_can</th>\n",
       "      <th>track_name_can</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_pl</th>\n",
       "      <th>artist_name_pl</th>\n",
       "      <th>track_uri_pl</th>\n",
       "      <th>track_name_pl</th>\n",
       "      <th>duration_ms_songs_pl</th>\n",
       "      <th>album_name_pl</th>\n",
       "      <th>artist_pop_pl</th>\n",
       "      <th>artists_followers_pl</th>\n",
       "      <th>track_pop_pl</th>\n",
       "      <th>artist_genres_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{november '15}</td>\n",
       "      <td>false</td>\n",
       "      <td>914400</td>\n",
       "      <td>1452816000</td>\n",
       "      <td>914400-13</td>\n",
       "      <td>13</td>\n",
       "      <td>Tossing Copper</td>\n",
       "      <td>spotify:track:2BQSlFrFfxHjv2O738IzRm</td>\n",
       "      <td>spotify:album:7Bc9G6iDUH9u6pYj6Q5jr7</td>\n",
       "      <td>Edge of Eden</td>\n",
       "      <td>...</td>\n",
       "      <td>[8, 9, 10, 11, 12]</td>\n",
       "      <td>[Tossing Copper, Tossing Copper, Tossing Copper, Tossing Copper, Tossing Copper]</td>\n",
       "      <td>[spotify:track:4w3eTXloQVxhvc2U3KuuOb, spotify:track:5xdYaI97V4m7pypIhfpkoO, spotify:track:0UDpAmtvdeWJzowyiaE9tI, spotify:track:1sZ2RArZ2F86achracJBBw, spotify:track:7BO96T4UFKUbK96XujhaB2]</td>\n",
       "      <td>[Hello Darling, Silhouettes &amp; Sand, The Bridegroom, Ships of Cortez, Dancing in the Dawn]</td>\n",
       "      <td>[256000.0, 221786.0, 248613.0, 197253.0, 176733.0]</td>\n",
       "      <td>[Silhouettes &amp; Sand, Silhouettes &amp; Sand, Silhouettes &amp; Sand, Silhouettes &amp; Sand, Silhouettes &amp; Sand]</td>\n",
       "      <td>[68.0, 68.0, 68.0, 68.0, 68.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[36.0, 33.0, 32.0, 40.0, 61.0]</td>\n",
       "      <td>['alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name collaborative     pid  modified_at pid_pos_id  pos_can  \\\n",
       "0  {november '15}         false  914400   1452816000  914400-13       13   \n",
       "\n",
       "  artist_name_can                         track_uri_can  \\\n",
       "0  Tossing Copper  spotify:track:2BQSlFrFfxHjv2O738IzRm   \n",
       "\n",
       "                          album_uri_can track_name_can  ...  \\\n",
       "0  spotify:album:7Bc9G6iDUH9u6pYj6Q5jr7   Edge of Eden  ...   \n",
       "\n",
       "               pos_pl  \\\n",
       "0  [8, 9, 10, 11, 12]   \n",
       "\n",
       "                                                                     artist_name_pl  \\\n",
       "0  [Tossing Copper, Tossing Copper, Tossing Copper, Tossing Copper, Tossing Copper]   \n",
       "\n",
       "                                                                                                                                                                                     track_uri_pl  \\\n",
       "0  [spotify:track:4w3eTXloQVxhvc2U3KuuOb, spotify:track:5xdYaI97V4m7pypIhfpkoO, spotify:track:0UDpAmtvdeWJzowyiaE9tI, spotify:track:1sZ2RArZ2F86achracJBBw, spotify:track:7BO96T4UFKUbK96XujhaB2]   \n",
       "\n",
       "                                                                               track_name_pl  \\\n",
       "0  [Hello Darling, Silhouettes & Sand, The Bridegroom, Ships of Cortez, Dancing in the Dawn]   \n",
       "\n",
       "                                 duration_ms_songs_pl  \\\n",
       "0  [256000.0, 221786.0, 248613.0, 197253.0, 176733.0]   \n",
       "\n",
       "                                                                                          album_name_pl  \\\n",
       "0  [Silhouettes & Sand, Silhouettes & Sand, Silhouettes & Sand, Silhouettes & Sand, Silhouettes & Sand]   \n",
       "\n",
       "                    artist_pop_pl       artists_followers_pl  \\\n",
       "0  [68.0, 68.0, 68.0, 68.0, 68.0]  [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                     track_pop_pl  \\\n",
       "0  [36.0, 33.0, 32.0, 40.0, 61.0]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                               artist_genres_pl  \n",
       "0  ['alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop', 'alt z', 'indiecoustica', 'neo mellow', 'pop', 'pop rock', 'post-teen pop']  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "valid.to_ddf().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8966c52",
   "metadata": {},
   "source": [
    "### Now set the output buckets for the validation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f65eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data dir: gs://spotify-beam-v3/merlin-processed/train/\n",
      "Valid data dir: gs://spotify-beam-v3/merlin-processed/valid/\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(BUCKET, \"merlin-processed\")\n",
    "output_train_dir = os.path.join(output_path, 'train/')\n",
    "output_valid_dir = os.path.join(output_path, 'valid/')\n",
    "output_workflow_dir = os.path.join(output_path, 'workflow/')\n",
    "\n",
    "\n",
    "print(f\"Train data dir: {output_train_dir}\\nValid data dir: {output_valid_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bc597",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and preprocess training data back to Parquet GCS\n",
    "helpful resources https://cloud.google.com/compute/docs/gpus/monitor-gpus\n",
    "\n",
    "## Also, be sure to install `nvtop` the install script is in `utils/install_nvtop.sh`\n",
    "\n",
    "## Fit Transform is called on the workflow to pass over the data\n",
    "The categorical and continuous features must be specified. In this example shuffling is enabled so we only shuflle one time. You can size your output and experiment with number of output files - depending on your use case think of your GPU memory available with respective file sizes\n",
    "\n",
    "## ** This can take some time (about an hour) but is a one-time save to gcs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89ed414f-8513-453b-815d-bda239db9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f3001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.USER_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.USER: 'user'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc = 0\n",
    "time_preproc_start = time.time()\n",
    "\n",
    "workflow.fit_transform(train).to_parquet(output_path=output_train_dir, \n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=CAT,\n",
    "                                         conts=CONT, \n",
    "                                         output_files = 100\n",
    "                                         ) #preserve_files=True keeps the original file sharding\n",
    "\n",
    "\n",
    "time_preproc += time.time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9d020-2f13-4c55-8c8b-da07b247c671",
   "metadata": {},
   "source": [
    "### Saving to GCS is simple with GCS Fuse, which is already included in the if you built an image from [here](https://github.com/jswortz/merlin-gcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the workflow to disk (GCS here via ) after it has been fit\n",
    "workflow.save(os.path.join(output_workflow_dir,'2t-spotify-workflow'))\n",
    "\n",
    "#locally for demo too\n",
    "workflow.save('2t-spotify-workflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8433d",
   "metadata": {},
   "source": [
    "## Transform validation data using the same workflow\n",
    "\n",
    "This works similarly to a sklearn object where you can fit then transform after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6000545",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time.time()\n",
    "workflow.transform(valid).to_parquet(output_path=output_valid_dir, \n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=CAT,\n",
    "                                         conts=CONT,\n",
    "                                         output_files=10\n",
    "                                         )\n",
    "\n",
    "\n",
    "time_preproc += time.time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8922d66-c947-411b-9442-a34ce34b2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.input_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f8f32",
   "metadata": {},
   "source": [
    "### Examine some of the output data from nvtabular\n",
    "\n",
    "The data is presented as a Dask Pandas DF - so the interface is very familiar if you know Pandas\n",
    "\n",
    "Now the data has encoded the values of the strings with categorify, filled missing values, and normalized continuous variables. Now when you look at categorical data like `track_name_pl`, you will see the data represented as an integer, ready to quickly load to an embedding layer, as opposed to hashing each Epoch like when including stringlookups or hash functions in a tfrs model. This ensures the unven profile caused by cpu/gpu bottlnecks during lookup functions are processed just once and efficiently.\n",
    "\n",
    "#### Example of NVTabular Gpu Consumption Pattern\n",
    "A100 a1-high-gpu\n",
    "![Example of Nvtop](img/nvtop.png)\n",
    "\n",
    "Note that the lookup tables for the various categorified data can be found in the `categories/` folder of the workflow. You also will notice a link in the data schema (more on that below) to the files by each field - this is how you can do reverse lookups later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvtdata = pd.read_parquet(output_train_dir+'part_0.parquet')\n",
    "nvtdata['track_name_pl'].head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvtdata = pd.read_parquet(output_train_dir+'part_0.parquet')\n",
    "nvtdata['artist_name_can'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2012c18-eda7-49bb-b45c-c3d953ff330f",
   "metadata": {},
   "source": [
    "### Total rows for `part_0.parquet`\n",
    "Total rows x number of partitions (`output_files` in `workflow.to_parquet()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nvtdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ffee50-6fc4-4628-b057-57fc1e485be0",
   "metadata": {},
   "source": [
    "#### Quick view of the embedding dimensions\n",
    "`(INPUT_CARDINALITY, EMB_DIM)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb04de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ops.get_embedding_sizes(workflow)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([embeddings[0][x] for x in item_feature_cat_node.output_columns.names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_feature_cont_node.output_columns.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24b35b",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Load the processed data into a Merlin Dataset and Train a Two Tower Model\n",
    "\n",
    "Now that data inspection is over, the workflow is saved and data is processed to the `output_path`\n",
    "\n",
    "The above only needs to be run once as well - the workflow and transformed files can be directly loaded from gcs from now on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f616eb",
   "metadata": {},
   "source": [
    "### Get the embedding dimensions from the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81777c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load back the workflow and schema\n",
    "# spotify-builtin-2t/merlin-processed/workflow/2t-spotify-workflow\n",
    "workflow = nvt.Workflow.load(os.path.join(BUCKET, \"merlin-processed/workflow/2t-spotify-workflow\"))\n",
    "schema = workflow.output_schema\n",
    "embeddings = ops.get_embedding_sizes(workflow)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.utils.example_utils import workflow_fit_transform\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset as MerlinDataset\n",
    "\n",
    "train = MerlinDataset(os.path.join(output_train_dir, \"*.parquet\"), schema=schema, part_size=\"1GB\")\n",
    "valid = MerlinDataset(os.path.join(output_valid_dir, \"*.parquet\"), schema=schema, part_size=\"1GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6279f",
   "metadata": {},
   "source": [
    "Direct quote from [here](https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb)\n",
    "\n",
    "Other info on modeling setup\n",
    "\n",
    "### Negative sampling\n",
    "Many datasets for recommender systems contain implicit feedback with logs of user interactions like clicks, add-to-cart, purchases, music listening events, rather than explicit ratings that reflects user preferences over items. To be able to learn from implicit feedback, we use the general (and naive) assumption that the interacted items are more relevant for the user than the non-interacted ones. In Merlin Models we provide some scaleable negative sampling algorithms for the Item Retrieval Task. In particular, we use in this example the in-batch sampling algorithm which uses the items interacted by other users as negatives within the same mini-batch.\n",
    "\n",
    "### Building the Model\n",
    "Now, let's build our Two-Tower model. In a nutshell, we aggregate all user features to feed in user tower and feed the item features to the item tower. Then we compute the positive score by multiplying the user embedding with the item embedding and sample negative items (read more about negative sampling here and here), whose item embeddings are also multiplied by the user embedding. Then we apply the loss function on top of the positive and negative scores.\n",
    "\n",
    "- Other model types can be found on the [Merlin Models API Documentation Page](https://nvidia-merlin.github.io/models/main/api.html#tensorflow-models)\n",
    "\n",
    "### Vertex Experiments\n",
    "\n",
    "We will organize all of our runs with Merlin in one experiment id `spotify-merlin-train-full-data-v1`. Under this experiment, we will have multiple runs that will be tracked in the experiment interface as well as Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wone_shot_cmd use this to track data in tensorboard\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "EXPERIMENT_NAME = f'spotify-merlin-train-full-data-v4-2'\n",
    "RUN_NAME = f'run-{EXPERIMENT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'#be sure to think about run and experiment naming strategies so names don't collide\n",
    "logs_dir = f'{output_path}/tb_logs/{EXPERIMENT_NAME}'\n",
    "\n",
    "#helper function to get the tb-uploader command\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={logs_dir} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "vertex_ai.init(experiment=EXPERIMENT_NAME)\n",
    "    \n",
    "\n",
    "# we are going to ecapsulate this one-shot log uploader via a custom callback:\n",
    "\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))\n",
    "    \n",
    "layers = [512, 256, 128]\n",
    "LR = .001\n",
    "BS = 4096 * 4\n",
    "epoch = 60\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logs_dir,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec3d2e-0c20-4a2b-8f59-3ca93d16470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.outputs.base import DotProduct, MetricsFn, ModelOutput\n",
    "\n",
    "user_schema = schema.select_by_tag(Tags.USER)\n",
    "user_inputs = mm.InputBlockV2(user_schema)\n",
    "\n",
    "query = mm.Encoder(user_inputs, mm.MLPBlock(layers))\n",
    "\n",
    "item_schema = schema.select_by_tag(Tags.ITEM)\n",
    "item_inputs = mm.InputBlockV2(\n",
    "        item_schema,)\n",
    "candidate = mm.Encoder(item_inputs, mm.MLPBlock(layers))\n",
    "\n",
    "model = mm.RetrievalModelV2(\n",
    "        query=query,\n",
    "        candidate=candidate,\n",
    "        output=mm.ContrastiveOutput(\n",
    "            to_call=DotProduct(),\n",
    "            negative_samplers=\"in-batch\",\n",
    "            schema=item_schema.select_by_tag(Tags.ITEM_ID),\n",
    "            candidate_name=\"item\",\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dff1e",
   "metadata": {},
   "source": [
    "Let's explain the parameters in the TwoTowerModel():\n",
    "\n",
    "* `no_activation_last_layer`: when set True, no activation is used for top hidden layer. Learn more here.\n",
    "* `infer_embedding_sizes`: when set True, automatically defines the embedding dimension from the feature cardinality in the schema\n",
    "\n",
    "**Metrics:**\n",
    "\n",
    "The following information retrieval metrics are used to compute the Top-10 accuracy of recommendation lists containing all items:\n",
    "\n",
    "* **Normalized Discounted Cumulative Gain (NDCG@10)**: NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.\n",
    "\n",
    "* **Recall@10:** Also known as HitRate@n when there is only one relevant item in the recommendation list. Recall just verifies whether the relevant item is among the top-n items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716afa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.set_retrieval_candidates_for_evaluation(train)\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=LR)\n",
    "model.compile(optimizer=opt, run_eagerly=False, \n",
    "              metrics=[mm.RecallAt(1), \n",
    "                       mm.RecallAt(10), \n",
    "                       mm.NDCGAt(10)],\n",
    "             )\n",
    "\n",
    "# one_shot_cmd = get_upload_logs_to_manged_tb_command(oneshot=\"true\")\n",
    "# ! $one_shot_cmd\n",
    "\n",
    "model.fit(train, \n",
    "          validation_data=valid, \n",
    "          batch_size=BS, \n",
    "          epochs=epoch,\n",
    "          # steps_per_epoch=20, \n",
    "          callbacks=[tensorboard_callback, \n",
    "                     UploadTBLogsBatchEnd()],)\n",
    "\n",
    "#get the metrics for the experiment run\n",
    "history_keys = model.history.history.keys()\n",
    "\n",
    "#upload everything to  tb only do this if you were not streaming with the above command\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params({\"layers\": str(layers), \n",
    "                      \"learning_rate\": LR,\n",
    "                        \"num_epochs\": epoch,\n",
    "                        \"batch_size\": BS,\n",
    "                     })\n",
    "\n",
    "metrics_dict = {}\n",
    "_ = [metrics_dict.update({key: model.history.history[key][-1]}) for key in history_keys]\n",
    "metrics_dict\n",
    "vertex_ai.log_metrics(metrics_dict)\n",
    "vertex_ai.end_run() #end collecting metrics and the run is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2679030-e501-4b45-8cc1-88127c06f35c",
   "metadata": {},
   "source": [
    "- The One-shot command above will download your metrics to tensorboard - and will be avialble in the Experiments tab of Vertex\n",
    " \n",
    "#### Ideally you should be seeing GPU utilization like this - play with batch size to target ~ 70-80% utilization\n",
    "![](img/merlin-training-nvtop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f1bf8-26e8-44a3-b2f6-dae3852e5589",
   "metadata": {},
   "source": [
    "### Plotting performance of loss and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a534cc-fe0a-4c7c-a3d5-22b654154077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_performance(x, y1, y2, label_1, label_2, label_y):\n",
    "    plt.plot(x, y1, label = label_1)\n",
    "    plt.plot(x, y2, label = label_2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(label_y)\n",
    "    plt.title(label_y)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_performance(x=range(epoch), \n",
    "                 y1=model.history.history['loss'], \n",
    "                 y2=model.history.history['val_loss'], \n",
    "                 label_1='train-loss', \n",
    "                 label_2='val-los', \n",
    "                 label_y='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30920ba2-f595-410c-8d75-97b71c508d27",
   "metadata": {},
   "source": [
    "#### Looking at the recall of predicting the next song by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee7064-2950-4488-bb93-80a644cfc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(x=range(epoch), \n",
    "                 y1=model.history.history['recall_at_1'], \n",
    "                 y2=model.history.history['val_recall_at_1'], \n",
    "                 label_1='recall_at_1', \n",
    "                 label_2='recall_at_1_val', \n",
    "                 label_y='recall_at_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9ec19",
   "metadata": {},
   "source": [
    "#### Save the Query Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad64ae-08f1-41b8-b816-cf535df9f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tower = model.query_encoder\n",
    "query_tower.save(os.path.join(output_path, 'query_model_merlin'))\n",
    "\n",
    "query_tower_loaded = tf.keras.models.load_model(os.path.join(output_path, 'query_model_merlin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b6bc0",
   "metadata": {},
   "source": [
    "### Save embeddings to GCS for each song - this will become our Matching Engine index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "\n",
    "item_features = (\n",
    "    unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID)\n",
    "    .compute()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "item_embs = model.item_embeddings(\n",
    "    MerlinDataset(item_features, schema=schema), batch_size=10000\n",
    ")\n",
    "\n",
    "item_embs_df = item_embs.compute(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888277b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f33c17-d679-4fca-a840-a17b78b3e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "\n",
    "def format_for_matching_engine(data) -> None:\n",
    "    emb = [data[i] for i in range(layers[-1])] # get the embeddings\n",
    "    formatted_emb = '{\"id\":\"' + str(data['track_uri_can']) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}'\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        f.write(formatted_emb)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "item_emb_pd = item_embs_df.to_pandas().fillna(1e-10) #filling blanks with an epsilon value\n",
    "_ = item_emb_pd.apply(format_for_matching_engine, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690eaae6-2059-4c09-84f2-cbde275ccc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l candidate_embeddings.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709feedd-2fc3-44c5-b7aa-1c3d12cffd7e",
   "metadata": {},
   "source": [
    "### BE SURE TO RUN `gsutil config` IN TERMINAL TO LOG IN WITH YOUR CREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad520f8-ef7f-4c97-9eb7-6969e56b4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gsutil\n",
    "import os\n",
    "candidate_path = os.path.join(BUCKET, 'merlin_processed/embeddings/candidate_embeddings.json')\n",
    "\n",
    "candidate_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8d413-1845-4fa3-98d9-2e1162a38316",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp candidate_embeddings.json $candidate_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a554e-6358-46e3-b614-2872de6858b1",
   "metadata": {},
   "source": [
    "## All set move to the next notebook - your bucket now should look something like this:\n",
    "\n",
    "![](img/merlin-bucket.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
