{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c20da6-d8ec-4018-a350-f053884fb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b13a21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "Push a Nvidia repo to your artifact repository - (create a new repo if not available)\n",
    "\n",
    "### Further instructions on how to build a Merlin container can be found [here](https://github.com/jswortz/merlin-gcp)\n",
    "\n",
    "Guide\n",
    "1. In an notebook instance run from a terminal `git clone https://github.com/jswortz/merlin-gcp`\n",
    "2. Run the notebook - this will build a merlin tensorflow image. You can change the base images from NVidia if you choose - this was tested from the version in the repo\n",
    "3. This will build a container image and save it to artifact registry repository. You may need to enable the artifact repository service\n",
    "4. Create a new custom workbench by clicking \"New Notebook\" > \"Customize\"\n",
    "\n",
    "<img src=\"img/custom_workbench.png\" width=\"500\"/>\n",
    "\n",
    "5. To get to the screen for artifact repository. First select \"Advanced\" then name, select region, then go to \"Environment\"\n",
    "\n",
    "<img src=\"img/workbench-environment.png\" width=\"500\"/>\n",
    "\n",
    "6. Select the your repo and respective image\n",
    "\n",
    "<img src=\"img/image.png\" width=\"500\"/>\n",
    "\n",
    "7. Finally, if you already followed the instructions in notebook 02 setup - make sure the new workbench network is in the VPC peered network used for matching engine\n",
    "\n",
    "# Training with Merlin\n",
    "\n",
    "## Spotify example\n",
    "\n",
    "Our goal is to enable the architecture below with Vertex AI and the Merlin Models framework\n",
    "\n",
    "![](img/arch.png)\n",
    "\n",
    "## Goals\n",
    "\n",
    "The goal of this notebook is to create a simple two tower model with Nvtabular and Merlin Models\n",
    "\n",
    "1. Export data to Parquet for use in Nvtabular\n",
    "2. Create a NVtabular workflow and fit it to the data\n",
    "3. Save the fitted workflow to GCS (contains all dictionary lookups)\n",
    "4. Transform the data into GPU-optimized features from the NVtabular workflow and save to gcs\n",
    "5. Load the data again as a Merlin dataset using the workflow\n",
    "6. Create a two tower model in a few lines of code\n",
    "7. Train a two tower model\n",
    "8. Save the model (for deployment in notebook 03)\n",
    "9. Export the embeddings and save to gcs (for deployment to matching engine)\n",
    "\n",
    "*Based heavily on [this](https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb) NVIDIA resource\n",
    "\n",
    "\n",
    "Data is loaded from BQ - to parquet using the job configuration below\n",
    "\n",
    "\n",
    "Info on the data\n",
    "\n",
    "* track_uri_seed counts: 2249561\n",
    "* artist_uri_seed counts: 294110\n",
    "* album_uri_seed counts: 730377"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebae1b-c48f-4f16-a6b3-a49da98c2341",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Export Data From BigQuery to Parquet on GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decc6184-2fd8-40d7-9a75-c186adfc24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "# path = 'gs://two-tower-models' #TODO change to your model directory\n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "DATASET_ID = 'mdp_eda_test'\n",
    "TABLE = 'train_flatten_last_5'\n",
    "TABLE_VALIDATION = 'train_flatten_valid_last_5'\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "def export_bq_to_parquet(PROJECT, DATASET_ID, TABLE, LOCATION, prefix):\n",
    "    destination_uri = f\"{BUCKET}/{prefix}_data_parquet/*.snappy.parquet\"\n",
    "    dataset_ref = bigquery.DatasetReference(PROJECT, DATASET_ID)\n",
    "    table_ref = dataset_ref.table(TABLE)\n",
    "    job_config = bigquery.job.ExtractJobConfig()\n",
    "    job_config.destination_format = bigquery.DestinationFormat.PARQUET\n",
    "    extract_job = client.extract_table(\n",
    "        table_ref,\n",
    "        destination_uri,\n",
    "        job_config=job_config,\n",
    "        # Location must match that of the source table.\n",
    "        location=LOCATION,\n",
    "    )  # API request\n",
    "    return(extract_job.result())  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49217e-d2d9-4648-8562-9bfdea67be8b",
   "metadata": {},
   "source": [
    "#### Export the data from Bigquery to Parquet\n",
    "\n",
    "*Run only once* Uncomment to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d833ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractJob<project=hybrid-vertex, location=us-central1, id=afea0380-2bb4-4b39-a815-3e42cd8ff1d8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "export_bq_to_parquet(PROJECT, DATASET_ID, TABLE, LOCATION, prefix='train')\n",
    "\n",
    "# # validation\n",
    "export_bq_to_parquet(PROJECT, DATASET_ID, TABLE_VALIDATION, LOCATION, prefix='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac54435-6c4f-41fa-a8f9-2a947cc0f018",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Create a NVTabular W orkflow To Preprocess The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4a0787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:31:37.108078: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-16 04:31:39.035387: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-16 04:31:40.354298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20480 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nvtabular as nvt\n",
    "from time import time\n",
    "import pandas as pd\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from nvtabular.ops import (\n",
    "    Categorify,\n",
    "    TagAsUserID,\n",
    "    TagAsItemID,\n",
    "    TagAsItemFeatures,\n",
    "    TagAsUserFeatures,\n",
    "    AddMetadata,\n",
    "    ListSlice\n",
    ")\n",
    "import nvtabular.ops as ops\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "# for running this example on CPU, comment out the line below\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64962317",
   "metadata": {},
   "source": [
    "### Create NVTabular Dataset\n",
    "This will be our pre-processor to hash strings and other preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c17d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:384: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = nvt.Dataset(f\"{BUCKET}/train_data_parquet/*.snappy.parquet\")\n",
    "valid = nvt.Dataset(f\"{BUCKET}/valid_data_parquet/*.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb299dc",
   "metadata": {},
   "source": [
    "#### Define the NVTabular preprocessing graph\n",
    "\n",
    "Nvtabular takes a tabular dataset and transforms the data into new Parquet files optimized for training. This is equivalent to running a string lookup in tensorflow, and has similar functionality as adpat when a workflow is used\n",
    "\n",
    "The graph is defined as a set of nodes and a node is defined as follows:\n",
    "\n",
    "``` \n",
    "NODE_NAME = LIST_OF_FEATURE_NAMES >> nvt.ops.* >> [NEXT_STEP] >> Tag\n",
    "```\n",
    "\n",
    "Nvt has many ops - one of the most notable is `Categorify` as it is flexible and converts high cardinality text features to indicies\n",
    "\n",
    "Tags are used as a means to label the schema in the metadata and serves as a label for merlin models to interpret for consumption (e.g. which features belong to the query tower and candidate tower have different tags). You will see the tags in the schema in examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6833b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_id = [\"track_uri_can\"] >> Categorify(dtype=\"int32\") >> TagAsItemID() \n",
    "playlist_id = [\"pid\"] >> Categorify(dtype=\"int32\") >> TagAsUserID() \n",
    "\n",
    "\n",
    "item_features_cat = ['artist_name_can',\n",
    "        'track_name_can',\n",
    "        'artist_genres_can',\n",
    "    ]\n",
    "\n",
    "item_features_cont = [\n",
    "        'duration_ms_can',\n",
    "        'track_pop_can',\n",
    "        'artist_pop_can',\n",
    "        'artist_followers_can',\n",
    "    ]\n",
    "\n",
    "playlist_features_cat = [\n",
    "        'description_pl',\n",
    "        'name',\n",
    "        'collaborative',\n",
    "    ]\n",
    "\n",
    "playlist_features_cont = [\n",
    "        'duration_ms_seed_pl',\n",
    "        'n_songs_pl',\n",
    "        'num_artists_pl',\n",
    "        'num_albums_pl',\n",
    "    ]\n",
    "\n",
    "seq_feats_cat = [\n",
    "        'artist_name_pl',\n",
    "        'track_uri_pl',\n",
    "        'track_name_pl',\n",
    "        'album_name_pl',\n",
    "        'artist_genres_pl',\n",
    "    ]\n",
    "\n",
    "CAT = playlist_features_cat + item_features_cat\n",
    "CONT = item_features_cont + playlist_features_cont\n",
    "\n",
    "item_feature_cat_node = item_features_cat >> nvt.ops.FillMissing()>> Categorify(dtype=\"int32\") >> TagAsItemFeatures()\n",
    "\n",
    "item_feature_cont_node =  item_features_cont >> nvt.ops.FillMissing() >>  nvt.ops.Normalize() >> TagAsItemFeatures()\n",
    "\n",
    "playlist_feature_cat_node = playlist_features_cat >> nvt.ops.FillMissing() >> Categorify(dtype=\"int32\") >> TagAsUserFeatures() \n",
    "\n",
    "playlist_feature_cont_node = playlist_features_cont >> nvt.ops.FillMissing() >>  nvt.ops.Normalize() >> TagAsUserFeatures()\n",
    "\n",
    "playlist_feature_cat_seq_node = seq_feats_cat >> nvt.ops.FillMissing() >> Categorify(dtype=\"int32\") >> TagAsUserFeatures() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d819-38c9-4973-9cc5-a86af987b340",
   "metadata": {},
   "source": [
    "### Define a workflow\n",
    "This is an easy step by adding all nodes that need to run in parallel. A graphviz visualization of the graph is available below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1744279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a workflow\n",
    "output = playlist_id + item_id \\\n",
    "+ item_feature_cat_node \\\n",
    "+ item_feature_cont_node \\\n",
    "+ playlist_feature_cat_node \\\n",
    "+ playlist_feature_cont_node \\\n",
    "+ playlist_feature_cat_seq_node \n",
    "\n",
    "\n",
    "workflow = nvt.Workflow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b842eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"3221pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 3221.23 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 3217.23,-472 3217.23,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2014.22\" cy=\"-162\" rx=\"70.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2014.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsItemID</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>22</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;22 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>0&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1963.59,-149.34C1953.88,-147.36 1943.76,-145.47 1934.22,-144 1741.86,-114.41 1509.02,-98.47 1420.13,-93.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1420.21,-89.6 1410.02,-92.5 1419.79,-96.58 1420.21,-89.6\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>25</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2014.22\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2014.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>25&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2014.22,-215.7C2014.22,-207.98 2014.22,-198.71 2014.22,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2017.72,-190.1 2014.22,-180.1 2010.72,-190.1 2017.72,-190.1\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1070.22\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1070.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1111.22\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1111.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1080.14,-360.05C1084.98,-351.8 1090.89,-341.7 1096.26,-332.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1099.35,-334.19 1101.39,-323.79 1093.31,-330.65 1099.35,-334.19\"/>\n",
       "</g>\n",
       "<!-- 1_selector -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"895.22\" cy=\"-450\" rx=\"194.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"895.22\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;description_pl&#39;, &#39;name&#39;, &#39;collaborative&#39;]</text>\n",
       "</g>\n",
       "<!-- 1_selector&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1_selector&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M936.69,-432.41C963.27,-421.78 997.78,-407.98 1025.05,-397.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1026.39,-400.3 1034.37,-393.34 1023.79,-393.8 1026.39,-400.3\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"748.22\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"748.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"748.22\" cy=\"-162\" rx=\"71.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"748.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserID</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M748.22,-215.7C748.22,-207.98 748.22,-198.71 748.22,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"751.72,-190.1 748.22,-180.1 744.72,-190.1 751.72,-190.1\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"748.22\" cy=\"-306\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"748.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M748.22,-287.7C748.22,-279.98 748.22,-270.71 748.22,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"751.72,-262.1 748.22,-252.1 744.72,-262.1 751.72,-262.1\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1136.22\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1136.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1117.27,-288.05C1120.09,-280.18 1123.5,-270.62 1126.65,-261.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1129.98,-262.87 1130.05,-252.28 1123.39,-260.52 1129.98,-262.87\"/>\n",
       "</g>\n",
       "<!-- 4_selector -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>4_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"748.22\" cy=\"-378\" rx=\"37.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"748.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;pid&#39;]</text>\n",
       "</g>\n",
       "<!-- 4_selector&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4_selector&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M748.22,-359.7C748.22,-351.98 748.22,-342.71 748.22,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"751.72,-334.1 748.22,-324.1 744.72,-334.1 751.72,-334.1\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1162.22\" cy=\"-162\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1162.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserFeatures</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1142.51,-216.05C1145.44,-208.18 1148.99,-198.62 1152.27,-189.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1155.6,-190.87 1155.8,-180.28 1149.04,-188.43 1155.6,-190.87\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;22 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>6&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M799.48,-149.34C809.32,-147.36 819.56,-145.47 829.22,-144 1022.66,-114.54 1256.75,-98.52 1346.11,-93.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1346.51,-96.6 1356.28,-92.51 1346.09,-89.61 1346.51,-96.6\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"940.22\" cy=\"-162\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"940.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserFeatures</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;22 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>7&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1013.37,-149.44C1109.41,-134.27 1274.3,-108.21 1346.99,-96.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1347.7,-100.16 1357.03,-95.14 1346.61,-93.24 1347.7,-100.16\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"928.22\" cy=\"-234\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"928.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>14&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M931.19,-215.7C932.51,-207.98 934.1,-198.71 935.57,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"939.05,-190.55 937.29,-180.1 932.15,-189.37 939.05,-190.55\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;11 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1383.22,-359.7C1383.22,-351.98 1383.22,-342.71 1383.22,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.72,-334.1 1383.22,-324.1 1379.72,-334.1 1386.72,-334.1\"/>\n",
       "</g>\n",
       "<!-- 8_selector -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>8_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-450\" rx=\"275.65\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;artist_name_can&#39;, &#39;track_name_can&#39;, &#39;artist_genres_can&#39;]</text>\n",
       "</g>\n",
       "<!-- 8_selector&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8_selector&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1383.22,-431.7C1383.22,-423.98 1383.22,-414.71 1383.22,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.72,-406.1 1383.22,-396.1 1379.72,-406.1 1386.72,-406.1\"/>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;22 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>9&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1209.63,-145.98C1251.71,-132.65 1312.16,-113.51 1349.49,-101.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1350.89,-104.91 1359.37,-98.55 1348.78,-98.24 1350.89,-104.91\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"878.22\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"878.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"917.22\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"917.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M887.66,-360.05C892.14,-352.01 897.61,-342.2 902.61,-333.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"905.79,-334.71 907.59,-324.28 899.67,-331.31 905.79,-334.71\"/>\n",
       "</g>\n",
       "<!-- 10_selector -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>10_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"341.22\" cy=\"-450\" rx=\"341.44\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.22\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;duration_ms_seed_pl&#39;, &#39;n_songs_pl&#39;, &#39;num_artists_pl&#39;, &#39;num_albums_pl&#39;]</text>\n",
       "</g>\n",
       "<!-- 10_selector&#45;&gt;10 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10_selector&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.33,-433.97C584.86,-424.74 695.89,-411.67 794.22,-396 801.86,-394.78 809.87,-393.36 817.78,-391.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"818.56,-395.27 827.71,-389.93 817.22,-388.4 818.56,-395.27\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>11&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1383.22,-287.7C1383.22,-279.98 1383.22,-270.71 1383.22,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.72,-262.1 1383.22,-252.1 1379.72,-262.1 1386.72,-262.1\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M919.94,-287.7C921.15,-279.98 922.61,-270.71 923.96,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"927.44,-262.53 925.53,-252.1 920.52,-261.44 927.44,-262.53\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-162\" rx=\"100.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsItemFeatures</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;16 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>13&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1383.22,-215.7C1383.22,-207.98 1383.22,-198.71 1383.22,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.72,-190.1 1383.22,-180.1 1379.72,-190.1 1386.72,-190.1\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2014.22\" cy=\"-306\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2014.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;25 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>15&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2014.22,-287.7C2014.22,-279.98 2014.22,-270.71 2014.22,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2017.72,-262.1 2014.22,-252.1 2010.72,-262.1 2017.72,-262.1\"/>\n",
       "</g>\n",
       "<!-- 15_selector -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>15_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2014.22\" cy=\"-378\" rx=\"84.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2014.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;track_uri_can&#39;]</text>\n",
       "</g>\n",
       "<!-- 15_selector&#45;&gt;15 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>15_selector&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2014.22,-359.7C2014.22,-351.98 2014.22,-342.71 2014.22,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2017.72,-334.1 2014.22,-324.1 2010.72,-334.1 2017.72,-334.1\"/>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;22 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>16&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1383.22,-143.7C1383.22,-135.98 1383.22,-126.71 1383.22,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.72,-118.1 1383.22,-108.1 1379.72,-118.1 1386.72,-118.1\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1842.22\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1842.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1831.22\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1831.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1839.5,-359.7C1838.29,-351.98 1836.83,-342.71 1835.48,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1838.92,-333.44 1833.91,-324.1 1832,-334.53 1838.92,-333.44\"/>\n",
       "</g>\n",
       "<!-- 17_selector -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>17_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2812.22\" cy=\"-450\" rx=\"401.03\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2812.22\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;artist_name_pl&#39;, &#39;track_uri_pl&#39;, &#39;track_name_pl&#39;, &#39;album_name_pl&#39;, &#39;artist_genres_pl&#39;]</text>\n",
       "</g>\n",
       "<!-- 17_selector&#45;&gt;17 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17_selector&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2533.41,-437.06C2317.01,-426.92 2035.27,-411.57 1921.22,-396 1914.5,-395.08 1907.49,-393.9 1900.55,-392.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1900.97,-389.11 1890.48,-390.6 1899.61,-395.98 1900.97,-389.11\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1826.22\" cy=\"-234\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1826.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1829.98,-287.7C1829.43,-279.98 1828.77,-270.71 1828.16,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1831.65,-261.83 1827.44,-252.1 1824.66,-262.33 1831.65,-261.83\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1673.22\" cy=\"-378\" rx=\"66.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1673.22\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">SelectionOp</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>21</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1639.22\" cy=\"-306\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1639.22\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;21 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>19&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1664.99,-360.05C1661.12,-352.09 1656.42,-342.41 1652.1,-333.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1655.13,-331.74 1647.61,-324.28 1648.83,-334.8 1655.13,-331.74\"/>\n",
       "</g>\n",
       "<!-- 19_selector -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>19_selector</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2035.22\" cy=\"-450\" rx=\"358.24\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2035.22\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">[&#39;duration_ms_can&#39;, &#39;track_pop_can&#39;, &#39;artist_pop_can&#39;, &#39;artist_followers_can&#39;]</text>\n",
       "</g>\n",
       "<!-- 19_selector&#45;&gt;19 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>19_selector&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1949.89,-432.5C1884.19,-419.79 1794.89,-402.53 1735.72,-391.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1736.25,-387.62 1725.77,-389.16 1734.92,-394.5 1736.25,-387.62\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>23</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1823.22\" cy=\"-162\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1823.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsUserFeatures</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;23 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>20&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1825.48,-215.7C1825.15,-207.98 1824.75,-198.71 1824.38,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1827.88,-189.95 1823.95,-180.1 1820.88,-190.25 1827.88,-189.95\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>24</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1616.22\" cy=\"-234\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1616.22\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;24 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>21&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1633.65,-288.05C1631.06,-280.18 1627.92,-270.62 1625.02,-261.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1628.34,-260.68 1621.9,-252.28 1621.69,-262.87 1628.34,-260.68\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>27</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1383.22\" cy=\"-18\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1383.22\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;27 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>22&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1383.22,-71.7C1383.22,-63.98 1383.22,-54.71 1383.22,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1386.72,-46.1 1383.22,-36.1 1379.72,-46.1 1386.72,-46.1\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>26</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1602.22\" cy=\"-162\" rx=\"100.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1602.22\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">TagAsItemFeatures</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;22 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>26&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1555.24,-145.98C1513.65,-132.69 1453.97,-113.61 1416.95,-101.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1417.74,-98.36 1407.15,-98.65 1415.61,-105.03 1417.74,-98.36\"/>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1750.07,-149.36C1654.57,-134.17 1491.15,-108.17 1419.11,-96.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1419.59,-93.24 1409.17,-95.13 1418.49,-100.16 1419.59,-93.24\"/>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;26 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>24&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1612.76,-215.7C1611.22,-207.98 1609.36,-198.71 1607.64,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1611.03,-189.22 1605.64,-180.1 1604.17,-190.6 1611.03,-189.22\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f4c3cf91760>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577993c5-ff3c-4e0d-89ef-e49ed93d7017",
   "metadata": {},
   "source": [
    "### Before we transform the data, let's look at an original record\n",
    "This loads the data into a dask pandas dataframe. `.to_ddf()` converts the dataset into a dask df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eea53fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>collaborative</th>\n",
       "      <th>pid</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>pid_pos_id</th>\n",
       "      <th>pos_can</th>\n",
       "      <th>artist_name_can</th>\n",
       "      <th>track_uri_can</th>\n",
       "      <th>album_uri_can</th>\n",
       "      <th>track_name_can</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_pl</th>\n",
       "      <th>artist_name_pl</th>\n",
       "      <th>track_uri_pl</th>\n",
       "      <th>track_name_pl</th>\n",
       "      <th>duration_ms_songs_pl</th>\n",
       "      <th>album_name_pl</th>\n",
       "      <th>artist_pop_pl</th>\n",
       "      <th>artists_followers_pl</th>\n",
       "      <th>track_pop_pl</th>\n",
       "      <th>artist_genres_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camp</td>\n",
       "      <td>false</td>\n",
       "      <td>498400</td>\n",
       "      <td>1472515200</td>\n",
       "      <td>498400-14</td>\n",
       "      <td>14</td>\n",
       "      <td>kinderlach</td>\n",
       "      <td>spotify:track:6wJHCHwzoP9reqwoJuFgQR</td>\n",
       "      <td>spotify:album:1RLivltCCWzZmeLUY0Siew</td>\n",
       "      <td>Just Do It</td>\n",
       "      <td>...</td>\n",
       "      <td>[9, 10, 11, 12, 13]</td>\n",
       "      <td>[Gad Elbaz, Gad Elbaz, Omer Adam, Ari Goldwag, kinderlach]</td>\n",
       "      <td>[spotify:track:7j3BEtlXoPddHi7ateZyOJ, spotify:track:1UjR2tFIxm57eZuTyreuew, spotify:track:2bIFsmffovIlzqXeJGOB5X, spotify:track:0wmlo7aL8mlGRzLuC10rhb, spotify:track:0OjGNqjiQg06GcfvyKrYWI]</td>\n",
       "      <td>[Open Up, Hava Nagila, Mahapecha Shel SimcHa, Am Echad, Make It Happen]</td>\n",
       "      <td>[243466.0, 235320.0, 239128.0, 270778.0, 208023.0]</td>\n",
       "      <td>[L'Chaim, L'Chaim, Mode Ani, עם אחד (Am Echad), Kinderlach, Vol. 3]</td>\n",
       "      <td>[44.0, 44.0, 63.0, 34.0, 33.0]</td>\n",
       "      <td>[39988.0, 39988.0, 7.0, 0.0, 0.0]</td>\n",
       "      <td>[38.0, 37.0, 0.0, 35.0, 36.0]</td>\n",
       "      <td>['jewish pop', 'jewish pop', 'israeli mediterranean', 'israeli pop', 'mizrahi', 'jewish pop', 'jewish pop']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   name collaborative     pid  modified_at pid_pos_id  pos_can  \\\n",
       "0  Camp         false  498400   1472515200  498400-14       14   \n",
       "\n",
       "  artist_name_can                         track_uri_can  \\\n",
       "0      kinderlach  spotify:track:6wJHCHwzoP9reqwoJuFgQR   \n",
       "\n",
       "                          album_uri_can track_name_can  ...  \\\n",
       "0  spotify:album:1RLivltCCWzZmeLUY0Siew     Just Do It  ...   \n",
       "\n",
       "                pos_pl  \\\n",
       "0  [9, 10, 11, 12, 13]   \n",
       "\n",
       "                                               artist_name_pl  \\\n",
       "0  [Gad Elbaz, Gad Elbaz, Omer Adam, Ari Goldwag, kinderlach]   \n",
       "\n",
       "                                                                                                                                                                                     track_uri_pl  \\\n",
       "0  [spotify:track:7j3BEtlXoPddHi7ateZyOJ, spotify:track:1UjR2tFIxm57eZuTyreuew, spotify:track:2bIFsmffovIlzqXeJGOB5X, spotify:track:0wmlo7aL8mlGRzLuC10rhb, spotify:track:0OjGNqjiQg06GcfvyKrYWI]   \n",
       "\n",
       "                                                             track_name_pl  \\\n",
       "0  [Open Up, Hava Nagila, Mahapecha Shel SimcHa, Am Echad, Make It Happen]   \n",
       "\n",
       "                                 duration_ms_songs_pl  \\\n",
       "0  [243466.0, 235320.0, 239128.0, 270778.0, 208023.0]   \n",
       "\n",
       "                                                         album_name_pl  \\\n",
       "0  [L'Chaim, L'Chaim, Mode Ani, עם אחד (Am Echad), Kinderlach, Vol. 3]   \n",
       "\n",
       "                    artist_pop_pl               artists_followers_pl  \\\n",
       "0  [44.0, 44.0, 63.0, 34.0, 33.0]  [39988.0, 39988.0, 7.0, 0.0, 0.0]   \n",
       "\n",
       "                    track_pop_pl  \\\n",
       "0  [38.0, 37.0, 0.0, 35.0, 36.0]   \n",
       "\n",
       "                                                                                              artist_genres_pl  \n",
       "0  ['jewish pop', 'jewish pop', 'israeli mediterranean', 'israeli pop', 'mizrahi', 'jewish pop', 'jewish pop']  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "valid.to_ddf().head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8966c52",
   "metadata": {},
   "source": [
    "### Now set the output buckets for the validation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f65eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data dir: gs://spotify-beam-v3/merlin-processed/train/\n",
      "Valid data dir: gs://spotify-beam-v3/merlin-processed/valid/\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(BUCKET, \"merlin-processed\")\n",
    "output_train_dir = os.path.join(output_path, 'train/')\n",
    "output_valid_dir = os.path.join(output_path, 'valid/')\n",
    "output_workflow_dir = os.path.join(output_path, 'workflow/')\n",
    "\n",
    "\n",
    "print(f\"Train data dir: {output_train_dir}\\nValid data dir: {output_valid_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bc597",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and preprocess training data back to Parquet GCS\n",
    "helpful resources https://cloud.google.com/compute/docs/gpus/monitor-gpus\n",
    "\n",
    "## Also, be sure to install `nvtop` the install script is in `utils/install_nvtop.sh`\n",
    "\n",
    "## Fit Transform is called on the workflow to pass over the data\n",
    "The categorical and continuous features must be specified. In this example shuffling is enabled so we only shuflle one time. You can size your output and experiment with number of output files - depending on your use case think of your GPU memory available with respective file sizes\n",
    "\n",
    "## ** This can take some time (about an hour) but is a one-time save to gcs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ed414f-8513-453b-815d-bda239db9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc = 0\n",
    "time_preproc_start = time.time()\n",
    "\n",
    "workflow.fit_transform(train).to_parquet(output_path=output_train_dir, \n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=CAT,\n",
    "                                         conts=CONT, \n",
    "                                         output_files = 100\n",
    "                                         ) #preserve_files=True keeps the original file sharding\n",
    "\n",
    "\n",
    "time_preproc += time.time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9d020-2f13-4c55-8c8b-da07b247c671",
   "metadata": {},
   "source": [
    "### Saving to GCS is simple with GCS Fuse, which is already included in the if you built an image from [here](https://github.com/jswortz/merlin-gcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the workflow to disk (GCS here via ) after it has been fit\n",
    "workflow.save(os.path.join(output_workflow_dir,'2t-spotify-workflow'))\n",
    "\n",
    "#locally for demo too\n",
    "workflow.save('2t-spotify-workflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8433d",
   "metadata": {},
   "source": [
    "## Transform validation data using the same workflow\n",
    "\n",
    "This works similarly to a sklearn object where you can fit then transform after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6000545",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time.time()\n",
    "workflow.transform(valid).to_parquet(output_path=output_valid_dir, \n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=CAT,\n",
    "                                         conts=CONT,\n",
    "                                         output_files=10\n",
    "                                         )\n",
    "\n",
    "\n",
    "time_preproc += time.time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8922d66-c947-411b-9442-a34ce34b2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.input_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f8f32",
   "metadata": {},
   "source": [
    "### Examine some of the output data from nvtabular\n",
    "\n",
    "The data is presented as a Dask Pandas DF - so the interface is very familiar if you know Pandas\n",
    "\n",
    "Now the data has encoded the values of the strings with categorify, filled missing values, and normalized continuous variables. Now when you look at categorical data like `track_name_pl`, you will see the data represented as an integer, ready to quickly load to an embedding layer, as opposed to hashing each Epoch like when including stringlookups or hash functions in a tfrs model. This ensures the unven profile caused by cpu/gpu bottlnecks during lookup functions are processed just once and efficiently.\n",
    "\n",
    "#### Example of NVTabular Gpu Consumption Pattern\n",
    "A100 a1-high-gpu\n",
    "![Example of Nvtop](img/nvtop.png)\n",
    "\n",
    "Note that the lookup tables for the various categorified data can be found in the `categories/` folder of the workflow. You also will notice a link in the data schema (more on that below) to the files by each field - this is how you can do reverse lookups later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvtdata = pd.read_parquet(output_train_dir+'part_0.parquet')\n",
    "nvtdata['track_name_pl'].head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvtdata = pd.read_parquet(output_train_dir+'part_0.parquet')\n",
    "nvtdata['artist_name_can'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2012c18-eda7-49bb-b45c-c3d953ff330f",
   "metadata": {},
   "source": [
    "### Total rows for `part_0.parquet`\n",
    "Total rows x number of partitions (`output_files` in `workflow.to_parquet()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nvtdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ffee50-6fc4-4628-b057-57fc1e485be0",
   "metadata": {},
   "source": [
    "#### Quick view of the embedding dimensions\n",
    "`(INPUT_CARDINALITY, EMB_DIM)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb04de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ops.get_embedding_sizes(workflow)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([embeddings[0][x] for x in item_feature_cat_node.output_columns.names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_feature_cont_node.output_columns.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24b35b",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Load the processed data into a Merlin Dataset and Train a Two Tower Model\n",
    "\n",
    "Now that data inspection is over, the workflow is saved and data is processed to the `output_path`\n",
    "\n",
    "The above only needs to be run once as well - the workflow and transformed files can be directly loaded from gcs from now on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f616eb",
   "metadata": {},
   "source": [
    "### Get the embedding dimensions from the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81777c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'pid': (984638, 512),\n",
       "  'track_uri_can': (2183658, 512),\n",
       "  'artist_name_can': (278452, 512),\n",
       "  'track_name_can': (1435485, 512),\n",
       "  'artist_genres_can': (38183, 512),\n",
       "  'description_pl': (17909, 385),\n",
       "  'name': (92266, 512),\n",
       "  'collaborative': (3, 16)},\n",
       " {'artist_name_pl': (283353, 512),\n",
       "  'track_uri_pl': (2231210, 512),\n",
       "  'track_name_pl': (1464629, 512),\n",
       "  'album_name_pl': (563481, 512),\n",
       "  'artist_genres_pl': (38373, 512)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load back the workflow and schema\n",
    "# spotify-builtin-2t/merlin-processed/workflow/2t-spotify-workflow\n",
    "workflow = nvt.Workflow.load(os.path.join(BUCKET, \"merlin-processed/workflow/2t-spotify-workflow\"))\n",
    "schema = workflow.output_schema\n",
    "embeddings = ops.get_embedding_sizes(workflow)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feed4018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:384: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.models.utils.example_utils import workflow_fit_transform\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset as MerlinDataset\n",
    "\n",
    "train = MerlinDataset(os.path.join(output_train_dir, \"*.parquet\"), schema=schema, part_size=\"1GB\")\n",
    "valid = MerlinDataset(os.path.join(output_valid_dir, \"*.parquet\"), schema=schema, part_size=\"1GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6279f",
   "metadata": {},
   "source": [
    "Direct quote from [here](https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb)\n",
    "\n",
    "Other info on modeling setup\n",
    "\n",
    "### Negative sampling\n",
    "Many datasets for recommender systems contain implicit feedback with logs of user interactions like clicks, add-to-cart, purchases, music listening events, rather than explicit ratings that reflects user preferences over items. To be able to learn from implicit feedback, we use the general (and naive) assumption that the interacted items are more relevant for the user than the non-interacted ones. In Merlin Models we provide some scaleable negative sampling algorithms for the Item Retrieval Task. In particular, we use in this example the in-batch sampling algorithm which uses the items interacted by other users as negatives within the same mini-batch.\n",
    "\n",
    "### Building the Model\n",
    "Now, let's build our Two-Tower model. In a nutshell, we aggregate all user features to feed in user tower and feed the item features to the item tower. Then we compute the positive score by multiplying the user embedding with the item embedding and sample negative items (read more about negative sampling here and here), whose item embeddings are also multiplied by the user embedding. Then we apply the loss function on top of the positive and negative scores.\n",
    "\n",
    "- Other model types can be found on the [Merlin Models API Documentation Page](https://nvidia-merlin.github.io/models/main/api.html#tensorflow-models)\n",
    "\n",
    "### Vertex Experiments\n",
    "\n",
    "We will organize all of our runs with Merlin in one experiment id `spotify-merlin-train-full-data-v1`. Under this experiment, we will have multiple runs that will be tracked in the experiment interface as well as Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f4d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:31:50.171283: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-16 04:31:50.171366: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2022-10-16 04:31:50.225803: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2022-10-16 04:31:50.995305: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-16 04:31:50.995513: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "# wone_shot_cmd use this to track data in tensorboard\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "EXPERIMENT_NAME = f'spotify-merlin-train-full-data-v2-2'\n",
    "RUN_NAME = f'run-{EXPERIMENT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'#be sure to think about run and experiment naming strategies so names don't collide\n",
    "logs_dir = f'{output_path}/tb_logs/{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "\n",
    "#helper function to get the tb-uploader command\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={logs_dir} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "vertex_ai.init(experiment=EXPERIMENT_NAME)\n",
    "    \n",
    "\n",
    "# we are going to ecapsulate this one-shot log uploader via a custom callback:\n",
    "\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))\n",
    "    \n",
    "layers = [512, 256, 128]\n",
    "LR = .001\n",
    "BS = 4096 * 2\n",
    "epoch = 30\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logs_dir,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ec3d2e-0c20-4a2b-8f59-3ca93d16470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.TwoTowerModel(\n",
    "    schema,\n",
    "    query_tower=mm.MLPBlock(layers, no_activation_last_layer=True),\n",
    "    item_tower=mm.MLPBlock(layers, no_activation_last_layer=True),\n",
    "    samplers=[mm.InBatchSampler()],\n",
    "    embedding_options=mm.EmbeddingOptions(infer_embedding_sizes=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dff1e",
   "metadata": {},
   "source": [
    "Let's explain the parameters in the TwoTowerModel():\n",
    "\n",
    "* `no_activation_last_layer`: when set True, no activation is used for top hidden layer. Learn more here.\n",
    "* `infer_embedding_sizes`: when set True, automatically defines the embedding dimension from the feature cardinality in the schema\n",
    "\n",
    "**Metrics:**\n",
    "\n",
    "The following information retrieval metrics are used to compute the Top-10 accuracy of recommendation lists containing all items:\n",
    "\n",
    "* **Normalized Discounted Cumulative Gain (NDCG@10)**: NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.\n",
    "\n",
    "* **Recall@10:** Also known as HitRate@n when there is only one relevant item in the recommendation list. Recall just verifies whether the relevant item is among the top-n items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f716afa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:32:00.678505: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  19/7414 [..............................] - ETA: 8:46 - loss: 9.0119 - recall_at_1: 1.8632e-04 - recall_at_10: 0.0012 - ndcg_at_10: 5.8881e-04 - regularization_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:32:17.673334: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2022-10-16 04:32:17.673378: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  49/7414 [..............................] - ETA: 10:07 - loss: 9.0119 - recall_at_1: 1.7688e-04 - recall_at_10: 0.0012 - ndcg_at_10: 5.9327e-04 - regularization_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:32:20.566303: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-10-16 04:32:20.569653: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2022-10-16 04:32:20.873329: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 37732 callback api events and 35702 activity events. \n",
      "2022-10-16 04:32:21.565498: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2022-10-16 04:32:23.381933: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21\n",
      "\n",
      "2022-10-16 04:32:24.470645: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.trace.json.gz\n",
      "2022-10-16 04:32:25.235214: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21\n",
      "\n",
      "2022-10-16 04:32:25.454554: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.memory_profile.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50/7414 [..............................] - ETA: 25:25 - loss: 9.0119 - recall_at_1: 1.7822e-04 - recall_at_10: 0.0012 - ndcg_at_10: 5.9692e-04 - regularization_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:32:26.386978: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21\n",
      "Dumped tool data for xplane.pb to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.xplane.pb\n",
      "Dumped tool data for overview_page.pb to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to gs://spotify-beam-v3/merlin-processed/tb_logs/spotify-merlin-train-full-data-v2-2/run-spotify-merlin-train-full-data-v2-2-20221016-043149/plugins/profile/2022_10_16_04_32_21/6b502b33cf68.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7413/7414 [============================>.] - ETA: 0s - loss: 9.0071 - recall_at_1: 2.0836e-04 - recall_at_10: 0.0017 - ndcg_at_10: 8.1099e-04 - regularization_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 04:40:53.035631: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (mklcpu) ran out of memory trying to allocate 38.90GiB (rounded to 41768270080)requested by op OneHot\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-10-16 04:40:53.035891: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for mklcpu\n",
      "2022-10-16 04:40:53.035909: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035917: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035923: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035930: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035936: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035942: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035952: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 16, Chunks in use: 16. 411.5KiB allocated for chunks. 411.5KiB in use in bin. 409.0KiB client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035960: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 10, Chunks in use: 10. 343.8KiB allocated for chunks. 343.8KiB in use in bin. 247.2KiB client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035968: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 2, Chunks in use: 1. 233.0KiB allocated for chunks. 127.0KiB in use in bin. 119.7KiB client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035975: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 11, Chunks in use: 10. 1.58MiB allocated for chunks. 1.46MiB in use in bin. 1.32MiB client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035984: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 3, Chunks in use: 1. 995.0KiB allocated for chunks. 288.2KiB in use in bin. 191.6KiB client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035990: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.035996: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 0. 3.82MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036003: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 0. 7.34MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036010: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 0. 4.72MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036017: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 0. 15.97MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036024: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 6, Chunks in use: 0. 122.22MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036030: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 32.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036038: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 0. 322.41MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036048: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036055: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 10, Chunks in use: 5. 57.50GiB allocated for chunks. 4.54GiB in use in bin. 4.54GiB client-requested in use in bin.\n",
      "2022-10-16 04:40:53.036063: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 38.90GiB was 256.00MiB, Chunk State: \n",
      "2022-10-16 04:40:53.036078: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 360.11MiB | Requested Size: 240.39MiB | in_use: 0 | bin_num: 20, prev:   Size: 663.89MiB | Requested Size: 663.89MiB | in_use: 1 | bin_num: -1\n",
      "2022-10-16 04:40:53.036085: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 512.00MiB | Requested Size: 391.10MiB | in_use: 0 | bin_num: 20\n",
      "2022-10-16 04:40:53.036094: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 4.11GiB | Requested Size: 1.30GiB | in_use: 0 | bin_num: 20, prev:   Size: 663.89MiB | Requested Size: 663.89MiB | in_use: 1 | bin_num: -1\n",
      "2022-10-16 04:40:53.036109: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 16.00GiB | Requested Size: 14.08GiB | in_use: 0 | bin_num: 20\n",
      "2022-10-16 04:40:53.036118: I tensorflow/core/common_runtime/bfc_allocator.cc:1056]   Size: 32.00GiB | Requested Size: 22.92GiB | in_use: 0 | bin_num: 20\n",
      "2022-10-16 04:40:53.036124: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 536870912\n",
      "2022-10-16 04:40:53.036132: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 919ec1c0 of size 536870912 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036138: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 34359738368\n",
      "2022-10-16 04:40:53.036145: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f36afffa040 of size 34359738368 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036151: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 17179869184\n",
      "2022-10-16 04:40:53.036156: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f3ecfffc040 of size 17179869184 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036161: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 8589934592\n",
      "2022-10-16 04:40:53.036168: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f42dfffe040 of size 1392275712 next 2888\n",
      "2022-10-16 04:40:53.036174: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4332fc5140 of size 1392275712 next 175\n",
      "2022-10-16 04:40:53.036180: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4385f8c240 of size 696137984 next 2388\n",
      "2022-10-16 04:40:53.036186: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f43af76fb40 of size 696137984 next 2530\n",
      "2022-10-16 04:40:53.036192: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f43d8f53440 of size 4413107200 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036197: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 1073741824\n",
      "2022-10-16 04:40:53.036202: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f44dffff040 of size 696137984 next 285\n",
      "2022-10-16 04:40:53.036208: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45097e2940 of size 377603840 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036214: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 268435456\n",
      "2022-10-16 04:40:53.036220: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45bffff040 of size 19596032 next 1864\n",
      "2022-10-16 04:40:53.036226: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f45c12af340 of size 131072 next 728\n",
      "2022-10-16 04:40:53.036233: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45c12cf340 of size 98572544 next 1370\n",
      "2022-10-16 04:40:53.036239: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f45c70d0c40 of size 163840 next 2096\n",
      "2022-10-16 04:40:53.036245: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45c70f8c40 of size 71897088 next 2196\n",
      "2022-10-16 04:40:53.036250: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f45cb589c40 of size 163840 next 2901\n",
      "2022-10-16 04:40:53.036256: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f45cb5b1c40 of size 229376 next 2457\n",
      "2022-10-16 04:40:53.036263: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45cb5e9c40 of size 4948736 next 26\n",
      "2022-10-16 04:40:53.036268: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f45cbaa1f40 of size 130048 next 871\n",
      "2022-10-16 04:40:53.036274: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45cbac1b40 of size 72602880 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036279: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 134217728\n",
      "2022-10-16 04:40:53.036286: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f45ffffe040 of size 94996224 next 296\n",
      "2022-10-16 04:40:53.036292: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605a96740 of size 32768 next 1141\n",
      "2022-10-16 04:40:53.036298: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4605a9e740 of size 3768576 next 436\n",
      "2022-10-16 04:40:53.036305: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605e36840 of size 135936 next 2832\n",
      "2022-10-16 04:40:53.036312: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605e57b40 of size 135936 next 2850\n",
      "2022-10-16 04:40:53.036318: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605e78e40 of size 135936 next 894\n",
      "2022-10-16 04:40:53.036324: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605e9a140 of size 135936 next 1561\n",
      "2022-10-16 04:40:53.036331: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605ebb440 of size 27392 next 2936\n",
      "2022-10-16 04:40:53.036338: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605ec1f40 of size 38144 next 2987\n",
      "2022-10-16 04:40:53.036345: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4605ecb440 of size 131072 next 97\n",
      "2022-10-16 04:40:53.036351: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605eeb440 of size 135936 next 2909\n",
      "2022-10-16 04:40:53.036358: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f0c740 of size 27392 next 484\n",
      "2022-10-16 04:40:53.036365: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f13240 of size 27392 next 1826\n",
      "2022-10-16 04:40:53.036371: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4605f19d40 of size 108544 next 1718\n",
      "2022-10-16 04:40:53.036378: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f34540 of size 27392 next 1815\n",
      "2022-10-16 04:40:53.036384: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f3b040 of size 27392 next 2324\n",
      "2022-10-16 04:40:53.036391: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f41b40 of size 27392 next 2948\n",
      "2022-10-16 04:40:53.036397: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f48640 of size 27392 next 1287\n",
      "2022-10-16 04:40:53.036404: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605f4f140 of size 27392 next 1267\n",
      "2022-10-16 04:40:53.036411: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4605f55c40 of size 396032 next 406\n",
      "2022-10-16 04:40:53.036417: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605fb6740 of size 32768 next 1112\n",
      "2022-10-16 04:40:53.036425: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605fbe740 of size 27392 next 1881\n",
      "2022-10-16 04:40:53.036434: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4605fc5240 of size 38144 next 366\n",
      "2022-10-16 04:40:53.036443: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4605fce740 of size 2064640 next 2986\n",
      "2022-10-16 04:40:53.036451: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f46061c6840 of size 32768 next 2612\n",
      "2022-10-16 04:40:53.036459: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f46061ce840 of size 3932160 next 2830\n",
      "2022-10-16 04:40:53.036466: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460658e840 of size 32768 next 335\n",
      "2022-10-16 04:40:53.036474: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4606596840 of size 24576 next 1553\n",
      "2022-10-16 04:40:53.036484: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f460659c840 of size 1941504 next 297\n",
      "2022-10-16 04:40:53.036492: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4606776840 of size 163840 next 2402\n",
      "2022-10-16 04:40:53.036500: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f460679e840 of size 25556992 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036508: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 67108864\n",
      "2022-10-16 04:40:53.036517: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4607fff040 of size 27756800 next 562\n",
      "2022-10-16 04:40:53.036526: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f4609a77940 of size 32768 next 1462\n",
      "2022-10-16 04:40:53.036531: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4609a7f940 of size 16745216 next 2585\n",
      "2022-10-16 04:40:53.036537: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa77c40 of size 24576 next 740\n",
      "2022-10-16 04:40:53.036543: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa7dc40 of size 24576 next 1208\n",
      "2022-10-16 04:40:53.036549: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa83c40 of size 24576 next 1795\n",
      "2022-10-16 04:40:53.036554: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa89c40 of size 24576 next 1348\n",
      "2022-10-16 04:40:53.036559: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa8fc40 of size 32768 next 2807\n",
      "2022-10-16 04:40:53.036565: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa97c40 of size 27392 next 1170\n",
      "2022-10-16 04:40:53.036571: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aa9e740 of size 38144 next 2004\n",
      "2022-10-16 04:40:53.036576: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460aaa7c40 of size 295168 next 1871\n",
      "2022-10-16 04:40:53.036582: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f460aaefd40 of size 327680 next 281\n",
      "2022-10-16 04:40:53.036588: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460ab3fd40 of size 24576 next 2144\n",
      "2022-10-16 04:40:53.036594: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f460ab45d40 of size 40960 next 923\n",
      "2022-10-16 04:40:53.036599: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f460ab4fd40 of size 21689088 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036605: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 33554432\n",
      "2022-10-16 04:40:53.036611: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4611fff040 of size 33554432 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036617: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 16777216\n",
      "2022-10-16 04:40:53.036622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4634e67840 of size 16777216 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036627: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 16777216\n",
      "2022-10-16 04:40:53.036633: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f4635e678c0 of size 16777216 next 18446744073709551615\n",
      "2022-10-16 04:40:53.036640: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2022-10-16 04:40:53.036651: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 6 Chunks of size 24576 totalling 144.0KiB\n",
      "2022-10-16 04:40:53.036663: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 10 Chunks of size 27392 totalling 267.5KiB\n",
      "2022-10-16 04:40:53.036674: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 6 Chunks of size 32768 totalling 192.0KiB\n",
      "2022-10-16 04:40:53.036683: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 38144 totalling 111.8KiB\n",
      "2022-10-16 04:40:53.036691: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 40960 totalling 40.0KiB\n",
      "2022-10-16 04:40:53.036701: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 130048 totalling 127.0KiB\n",
      "2022-10-16 04:40:53.036713: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2022-10-16 04:40:53.036722: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 5 Chunks of size 135936 totalling 663.8KiB\n",
      "2022-10-16 04:40:53.036732: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 163840 totalling 480.0KiB\n",
      "2022-10-16 04:40:53.036742: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 229376 totalling 224.0KiB\n",
      "2022-10-16 04:40:53.036752: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 295168 totalling 288.2KiB\n",
      "2022-10-16 04:40:53.036762: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 696137984 totalling 1.94GiB\n",
      "2022-10-16 04:40:53.036771: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 1392275712 totalling 2.59GiB\n",
      "2022-10-16 04:40:53.036780: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 4.54GiB\n",
      "2022-10-16 04:40:53.036787: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 62277025792 memory_limit_: 89749843968 available bytes: 27472818176 curr_region_allocation_bytes_: 34359738368\n",
      "2022-10-16 04:40:53.036819: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                     89749843968\n",
      "InUse:                      4875695616\n",
      "MaxInUse:                  27605964544\n",
      "NumAllocs:                      380823\n",
      "MaxAllocSize:              24605784064\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-10-16 04:40:53.036833: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ___________________________________________________________________________________********______***\n",
      "2022-10-16 04:40:53.037123: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at one_hot_op.cc:97 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[174034458,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[174034458,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:OneHot]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, run_eagerly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[mm\u001b[38;5;241m.\u001b[39mRecallAt(\u001b[38;5;241m1\u001b[39m), \n\u001b[1;32m      5\u001b[0m                        mm\u001b[38;5;241m.\u001b[39mRecallAt(\u001b[38;5;241m10\u001b[39m), \n\u001b[1;32m      6\u001b[0m                        mm\u001b[38;5;241m.\u001b[39mNDCGAt(\u001b[38;5;241m10\u001b[39m)],\n\u001b[1;32m      7\u001b[0m              )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# one_shot_cmd = get_upload_logs_to_manged_tb_command(oneshot=\"true\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ! $one_shot_cmd\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# steps_per_epoch=20, \u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mUploadTBLogsBatchEnd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#get the metrics for the experiment run\u001b[39;00m\n\u001b[1;32m     21\u001b[0m history_keys \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py:536\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, train_metrics_steps, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_metrics_callback(callbacks, train_metrics_steps)\n\u001b[1;32m    530\u001b[0m fit_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    531\u001b[0m     k: v\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_metrics_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__class__\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    534\u001b[0m }\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/plugins/histogram/summary_v2.py:194\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _buckets(data, buckets)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m    195\u001b[0m     tag\u001b[38;5;241m=\u001b[39mtag,\n\u001b[1;32m    196\u001b[0m     tensor\u001b[38;5;241m=\u001b[39mlazy_tensor,\n\u001b[1;32m    197\u001b[0m     step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m    198\u001b[0m     metadata\u001b[38;5;241m=\u001b[39msummary_metadata,\n\u001b[1;32m    199\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/util/lazy_tensor_creator.py:66\u001b[0m, in \u001b[0;36mLazyTensorCreator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m _CALL_IN_PROGRESS_SENTINEL\n\u001b[0;32m---> 66\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_callable()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/plugins/histogram/summary_v2.py:192\u001b[0m, in \u001b[0;36mhistogram.<locals>.lazy_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_buckets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/plugins/histogram/summary_v2.py:291\u001b[0m, in \u001b[0;36m_buckets\u001b[0;34m(data, bucket_count)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    288\u001b[0m         has_single_value, when_single_value, when_multiple_values\n\u001b[1;32m    289\u001b[0m     )\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(is_empty, when_empty, when_nonempty)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/plugins/histogram/summary_v2.py:287\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m     bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m    282\u001b[0m         tf\u001b[38;5;241m.\u001b[39mconcat([zeroes[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], [data_size]], \u001b[38;5;241m0\u001b[39m)[:bucket_count],\n\u001b[1;32m    283\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_single_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_single_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_multiple_values\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorboard/plugins/histogram/summary_v2.py:256\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty.<locals>.when_multiple_values\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m clamped_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mminimum(bucket_indices, bucket_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Use float64 instead of float32 to avoid accumulating floating point error\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# later in tf.reduce_sum when summing more than 2^24 individual `1.0` values.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# See https://github.com/tensorflow/tensorflow/issues/51419 for details.\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m one_hots \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclamped_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m    260\u001b[0m     tf\u001b[38;5;241m.\u001b[39mreduce_sum(input_tensor\u001b[38;5;241m=\u001b[39mone_hots, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    261\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    263\u001b[0m edges \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinspace(min_, max_, bucket_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[174034458,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:OneHot]"
     ]
    }
   ],
   "source": [
    "# model.set_retrieval_candidates_for_evaluation(train)\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=LR)\n",
    "model.compile(optimizer=opt, run_eagerly=False, \n",
    "              metrics=[mm.RecallAt(1), \n",
    "                       mm.RecallAt(10), \n",
    "                       mm.NDCGAt(10)],\n",
    "             )\n",
    "\n",
    "# one_shot_cmd = get_upload_logs_to_manged_tb_command(oneshot=\"true\")\n",
    "# ! $one_shot_cmd\n",
    "\n",
    "model.fit(train, \n",
    "          validation_data=valid, \n",
    "          batch_size=BS, \n",
    "          epochs=epoch,\n",
    "          # steps_per_epoch=20, \n",
    "          callbacks=[tensorboard_callback, \n",
    "                     UploadTBLogsBatchEnd()],)\n",
    "\n",
    "#get the metrics for the experiment run\n",
    "history_keys = model.history.history.keys()\n",
    "\n",
    "#upload everything to  tb only do this if you were not streaming with the above command\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params({\"layers\": str(layers), \n",
    "                      \"learning_rate\": LR,\n",
    "                        \"num_epochs\": epoch,\n",
    "                        \"batch_size\": BS,\n",
    "                     })\n",
    "\n",
    "metrics_dict = {}\n",
    "_ = [metrics_dict.update({key: model.history.history[key][-1]}) for key in history_keys]\n",
    "metrics_dict\n",
    "vertex_ai.log_metrics(metrics_dict)\n",
    "vertex_ai.end_run() #end collecting metrics and the run is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2679030-e501-4b45-8cc1-88127c06f35c",
   "metadata": {},
   "source": [
    "- The One-shot command above will download your metrics to tensorboard - and will be avialble in the Experiments tab of Vertex\n",
    " \n",
    "#### Ideally you should be seeing GPU utilization like this - play with batch size to target ~ 70-80% utilization\n",
    "![](img/merlin-training-nvtop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f1bf8-26e8-44a3-b2f6-dae3852e5589",
   "metadata": {},
   "source": [
    "### Plotting performance of loss and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a534cc-fe0a-4c7c-a3d5-22b654154077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_performance(x, y1, y2, label_1, label_2, label_y):\n",
    "    plt.plot(x, y1, label = label_1)\n",
    "    plt.plot(x, y2, label = label_2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(label_y)\n",
    "    plt.title(label_y)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_performance(x=range(epoch), \n",
    "                 y1=model.history.history['loss'], \n",
    "                 y2=model.history.history['val_loss'], \n",
    "                 label_1='train-loss', \n",
    "                 label_2='val-los', \n",
    "                 label_y='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30920ba2-f595-410c-8d75-97b71c508d27",
   "metadata": {},
   "source": [
    "#### Looking at the recall of predicting the next song by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee7064-2950-4488-bb93-80a644cfc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(x=range(epoch), \n",
    "                 y1=model.history.history['recall_at_1'], \n",
    "                 y2=model.history.history['val_recall_at_1'], \n",
    "                 label_1='recall_at_1', \n",
    "                 label_2='recall_at_1_val', \n",
    "                 label_y='recall_at_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9ec19",
   "metadata": {},
   "source": [
    "#### Save the 2t model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad64ae-08f1-41b8-b816-cf535df9f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(output_path, 'merlin-spotify-two-tower'))\n",
    "\n",
    "# query_tower = model.retrieval_block.query_block()\n",
    "# query_tower.save(os.path.join(output_path, 'query_model_merlin'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b6bc0",
   "metadata": {},
   "source": [
    "### Save embeddings to GCS for each song - this will become our Matching Engine index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "\n",
    "item_features = (\n",
    "    unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID)\n",
    "    .compute()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "item_embs = model.item_embeddings(\n",
    "    MerlinDataset(item_features, schema=schema), batch_size=10000\n",
    ")\n",
    "\n",
    "item_embs_df = item_embs.compute(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888277b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f33c17-d679-4fca-a840-a17b78b3e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "\n",
    "def format_for_matching_engine(data) -> None:\n",
    "    emb = [data[i] for i in range(layers[-1])] # get the embeddings\n",
    "    formatted_emb = '{\"id\":\"' + str(data['track_uri_can']) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}'\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        f.write(formatted_emb)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "item_emb_pd = item_embs_df.to_pandas().fillna(1e-10) #filling blanks with an epsilon value\n",
    "_ = item_emb_pd.apply(format_for_matching_engine, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690eaae6-2059-4c09-84f2-cbde275ccc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l candidate_embeddings.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709feedd-2fc3-44c5-b7aa-1c3d12cffd7e",
   "metadata": {},
   "source": [
    "### BE SURE TO RUN `gsutil config` IN TERMINAL TO LOG IN WITH YOUR CREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad520f8-ef7f-4c97-9eb7-6969e56b4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gsutil\n",
    "import os\n",
    "candidate_path = os.path.join(BUCKET, 'merlin_processed/embeddings/candidate_embeddings.json')\n",
    "\n",
    "candidate_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8d413-1845-4fa3-98d9-2e1162a38316",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp candidate_embeddings.json $candidate_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a554e-6358-46e3-b614-2872de6858b1",
   "metadata": {},
   "source": [
    "## All set move to the next notebook - your bucket now should look something like this:\n",
    "\n",
    "![](img/merlin-bucket.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
