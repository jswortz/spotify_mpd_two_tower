{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f523ce16-b93d-4107-8905-f3e07176174c",
   "metadata": {},
   "source": [
    "# Implementing Recommendation Engines with Matching Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c8ed5-f34b-44f8-9028-b8b716165b08",
   "metadata": {},
   "source": [
    "### VPC Network peering\n",
    "Matching engine is a high performance vector matching service that requires a seperate VPC to ensure performance. \n",
    "\n",
    "Below are the one-time instructions to set up a peering network. \n",
    "\n",
    "**Once created, be sure to your notebook instance running this particular notebook is in the subnetwork... https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup**\n",
    "\n",
    "Steps in this notebook:\n",
    "1. Build and deploy a brute force and ANN index\n",
    "2. Test the recall accuracy between BF and ANN\n",
    "Note BF will always be 100% recall but at cost of speed and computational complexity\n",
    "Here's a good benchmark of Matching Engine (ScaNN is the algorithm)\n",
    "\n",
    "![](https://1.bp.blogspot.com/--mbMV8fQY28/XxsvbGL_l-I/AAAAAAAAGQ0/Br9B3XGnBa07barUxC4XTi8hSDxYzwAEgCLcBGAsYHQ/s640/image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10943eed-f2af-4201-9e62-5f2ef91128cb",
   "metadata": {},
   "source": [
    "## Load env config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8a1a95-6cd5-4d1f-94a0-d5762ebffaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ndr-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"                  # TODO\n",
    "PREFIX         = f'ndr-{VERSION}'      # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7964af95-f749-418f-a0b1-4012864aff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ndr-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "APP                      = \"sp\"\n",
      "MODEL_TYPE               = \"2tower\"\n",
      "FRAMEWORK                = \"tfrs\"\n",
      "DATA_VERSION             = \"v1\"\n",
      "TRACK_HISTORY            = \"5\"\n",
      "\n",
      "BUCKET_NAME              = \"ndr-v1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://ndr-v1-hybrid-vertex-bucket\"\n",
      "SOURCE_BUCKET            = \"spotify-million-playlist-dataset\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ndr-v1-hybrid-vertex-bucket/data\"\n",
      "VOCAB_SUBDIR             = \"vocabs\"\n",
      "VOCAB_FILENAME           = \"vocab_dict.pkl\"\n",
      "\n",
      "CANDIDATE_PREFIX         = \"candidates\"\n",
      "TRAIN_DIR_PREFIX         = \"train\"\n",
      "VALID_DIR_PREFIX         = \"valid\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n",
      "BQ_DATASET               = \"spotify_e2e_test\"\n",
      "BQ_TABLE_TRAIN           = \"v2_train_flatten_last_5\"\n",
      "BQ_TABLE_VALID           = \"v2_train_flatten_valid_last_5\"\n",
      "BQ_TABLE_CANDIDATES      = \"candidates\"\n",
      "\n",
      "REPO_SRC                 = \"src\"\n",
      "PIPELINES_SUB_DIR        = \"feature_pipes\"\n",
      "\n",
      "REPOSITORY               = \"ndr-v1-spotify\"\n",
      "IMAGE_NAME               = \"train-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/ndr-v1-spotify/train-v1\"\n",
      "DOCKERNAME               = \"tfrs\"\n",
      "\n",
      "SERVING_IMAGE_URI_CPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\"\n",
      "SERVING_IMAGE_URI_GPU    = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233ca33-d18e-4bba-a016-67b2b691c83d",
   "metadata": {},
   "source": [
    "## TODO: define these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0c55f4-97e4-4b22-9ed2-4b3e0149f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_NEW_ASSETS     = False # True | False\n",
    "ENABLE_XAI_MONITORING = False # True | False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e0d3f3-3455-4cb1-88fe-cfd97382f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME : tfrs-pipe-v1\n",
      "RUN_NAME        : run-20230919-173845\n",
      "RUN_DIR_PATH    : tfrs-pipe-v1/run-20230919-173845\n"
     ]
    }
   ],
   "source": [
    "# local-train-v1/run-20230919-150451/candidates/candidate_embeddings.json\n",
    "\n",
    "EXPERIMENT_NAME       = \"tfrs-pipe-v1\"         # local-train-v1\" \n",
    "RUN_NAME              = \"run-20230919-173845\"  # \"run-20230919-150451\"\n",
    "\n",
    "RUN_DIR_PATH = f'{EXPERIMENT_NAME}/{RUN_NAME}'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME : {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME        : {RUN_NAME}\")\n",
    "print(f\"RUN_DIR_PATH    : {RUN_DIR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6f278-8edf-4eb7-b355-d85f94bb044e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18bc2342-4c0b-43e0-ac8a-da94d007342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# google cloud SDKs\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import model_monitoring\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.two_tower_jt import test_instances as test_instances\n",
    "# from src.vertex.MatchingEngineCRUD import MatchingEngineCRUD\n",
    "\n",
    "from util import feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831bb4e2-7f81-4f3a-864b-333db47961ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0873449-09f4-4fa3-8683-2d413ce84540",
   "metadata": {},
   "source": [
    "### Create a matching engine index\n",
    "\n",
    "The matching engine loads an index from a file of embeddings created from the last notebook. \n",
    "\n",
    "Many of the optimization options for matching engine are found in the ah tree settings and testing is recommended depending on each use case\n",
    "\n",
    "Recall we saved our two tower models and query embeddings (newline json) in a candidate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b770f6-fffe-453d-8cd4-23a968321091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS_INITIAL_URI: gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/candidate-embeddings-v1\n"
     ]
    }
   ],
   "source": [
    "# EMBEDDINGS_INITIAL_URI = f'{BUCKET_URI}/{RUN_DIR_PATH}/candidates-index-local/'\n",
    "EMBEDDINGS_INITIAL_URI = f'{BUCKET_URI}/{RUN_DIR_PATH}/candidate-embeddings-v1'\n",
    "\n",
    "print(f\"EMBEDDINGS_INITIAL_URI: {EMBEDDINGS_INITIAL_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7ee31-24bd-4157-98c0-b7992411df3a",
   "metadata": {},
   "source": [
    "`EMBEDDINGS_INITIAL_URI` should lead to a folder with just the candidate json file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a286eae-f5fa-45d9-8765-67dc5b71eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/candidate-embeddings-v1/candidate_embs_v1_20230919-203806.json\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $EMBEDDINGS_INITIAL_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe29a0e-5f1c-4c1d-930a-fec71bbc0ef4",
   "metadata": {},
   "source": [
    "### Create ANN index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "807058c1-ab1f-4cd1-92e2-90b26cb07790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN_INDEX_DISPLAY_NAME   : tfrs_128dim_v1\n",
      "BF_DISPLAY_NAME          : tfrs_128dim_v1_bf\n"
     ]
    }
   ],
   "source": [
    "# ANN index config\n",
    "APPROX_NEIGHBORS           = 50\n",
    "DISTANCE_MEASURE           = \"DOT_PRODUCT_DISTANCE\"\n",
    "LEAF_NODE_EMB_COUNT        = 500\n",
    "LEAF_NODES_SEARCH_PERCENT  = 7\n",
    "DIMENSIONS                 = 128 # must match output dimensions\n",
    "\n",
    "# matching engine (vector search)\n",
    "ANN_INDEX_DISPLAY_NAME    = f\"tfrs_{DIMENSIONS}dim_{VERSION}\"\n",
    "ANN_ENDPOINT_DISPLAY_NAME = f'{ANN_INDEX_DISPLAY_NAME}_endpoint'\n",
    "\n",
    "BF_DISPLAY_NAME           = f\"{ANN_INDEX_DISPLAY_NAME}_bf\"\n",
    "BF_ENDPOINT_DISPLAY_NAME  = f'{BF_DISPLAY_NAME}_endpoint'\n",
    "\n",
    "# labels\n",
    "DATA_REGIME               = 'full-65m'\n",
    "\n",
    "print(f\"ANN_INDEX_DISPLAY_NAME   : {ANN_INDEX_DISPLAY_NAME}\")\n",
    "print(f\"BF_DISPLAY_NAME          : {BF_DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48b356-6e35-47ce-9fe9-e0ad4a579615",
   "metadata": {},
   "source": [
    "> *Note: setting `sync=False` will allow us to proceed with the notebook while these operations complete*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b28494-3f1d-4215-a41b-99b8686a524c",
   "metadata": {},
   "source": [
    "# Matching Engine Index: initialize existing or create a new one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53a1af-3f9b-477c-960c-fe9763f74b2a",
   "metadata": {},
   "source": [
    "## Create new or initialize existing (index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54186a9e-2e66-4d1e-a58c-46b8fa335bfa",
   "metadata": {},
   "source": [
    "### Create ANN index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a872d85-7651-436d-aa33-6ac6049d0ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7f0987b30090> \n",
       "resource name: projects/934903580331/locations/us-central1/indexes/5215441047378722816"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    tree_ah_index = vertex_ai.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=ANN_INDEX_DISPLAY_NAME,\n",
    "        contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "        dimensions=DIMENSIONS,\n",
    "        approximate_neighbors_count=APPROX_NEIGHBORS,\n",
    "        distance_measure_type=DISTANCE_MEASURE,\n",
    "        leaf_node_embedding_count=LEAF_NODE_EMB_COUNT,\n",
    "        leaf_nodes_to_search_percent=LEAF_NODES_SEARCH_PERCENT,\n",
    "        description=\"Songs embeddings from MPD\",\n",
    "        sync=False,\n",
    "        labels={\n",
    "            \"experiment_name\": f'{EXPERIMENT_NAME}',\n",
    "            \"experiment_run\": f'{RUN_NAME}',\n",
    "            \"data_regime\": f'{DATA_REGIME}',\n",
    "        },\n",
    "    )\n",
    "else:\n",
    "    \n",
    "    EXISTING_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexes/5215441047378722816'\n",
    "    tree_ah_index = vertex_ai.MatchingEngineIndex(EXISTING_INDEX_NAME)\n",
    "    \n",
    "tree_ah_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "986e4110-44e8-492c-ba7f-3c282e5561c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ann_index_v1-v1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_ah_index.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32491d2c-bfb1-45cb-bd5e-6eae5c16abcc",
   "metadata": {},
   "source": [
    "### Create Brute Force index\n",
    "\n",
    "used to evaluate ANN retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75924a13-1b2b-4de9-84ab-84f9729c1458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7f098722a210> \n",
       "resource name: projects/934903580331/locations/us-central1/indexes/6250846749208870912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    brute_force_index = vertex_ai.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name=BF_DISPLAY_NAME,\n",
    "        contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "        dimensions=DIMENSIONS,\n",
    "        distance_measure_type=DISTANCE_MEASURE,\n",
    "        sync=False,\n",
    "        labels={\n",
    "            \"experiment_name\": f'{EXPERIMENT_NAME}',\n",
    "            \"experiment_run\": f'{RUN_NAME}',\n",
    "            \"data_regime\": f'{DATA_REGIME}',\n",
    "        },\n",
    "    )\n",
    "else: #6250846749208870912 | 5708585206575792128\n",
    "    EXISTING_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexes/6250846749208870912'\n",
    "    brute_force_index = vertex_ai.MatchingEngineIndex(EXISTING_INDEX_NAME)\n",
    "    \n",
    "brute_force_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8894e292-6441-42b2-94d6-f8d5ee3125ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bf_index_v1_v1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force_index.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3545b2-6aab-4be7-8551-3b9bf3152c00",
   "metadata": {},
   "source": [
    "## Create Matching Engine endpoint(s)\n",
    "\n",
    "* both the ANN and brute force indices can be deployed to a single endpoint\n",
    "* alternatively, we can create seperate endpoints, one for each index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9745a8-6411-465c-b880-da8352696d11",
   "metadata": {},
   "source": [
    "**index endpoint config:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c46a273-11f9-4aa1-898b-a16749364495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPC_NETWORK_FULL: projects/934903580331/global/networks/ucaip-haystack-vpc-network\n",
      "ANN_ENDPOINT_DISPLAY_NAME: tfrs_128dim_v1_endpoint\n",
      "BF_ENDPOINT_DISPLAY_NAME: tfrs_128dim_v1_bf_endpoint\n"
     ]
    }
   ],
   "source": [
    "print(f\"VPC_NETWORK_FULL: {VPC_NETWORK_FULL}\")\n",
    "print(f\"ANN_ENDPOINT_DISPLAY_NAME: {ANN_ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"BF_ENDPOINT_DISPLAY_NAME: {BF_ENDPOINT_DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c04e57-dcfa-48e4-8fdf-221f6ed55cf5",
   "metadata": {},
   "source": [
    "### ANN index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee82888-959b-4e84-a455-dab666958e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f09d60ec6d0> \n",
       "resource name: projects/934903580331/locations/us-central1/indexEndpoints/5661297410488401920"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    my_ann_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{ANN_ENDPOINT_DISPLAY_NAME}',\n",
    "        description=\"index endpoint for ANN index\",\n",
    "        network=VPC_NETWORK_FULL,\n",
    "        sync=False,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    EXISTING_INDEX_ENDPOINT = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/5661297410488401920'\n",
    "    my_ann_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(EXISTING_INDEX_ENDPOINT)\n",
    "    \n",
    "my_ann_index_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "358933fd-f802-40fa-acec-55b4d2aaec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    deployedann_v1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in my_ann_index_endpoint.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272dc3e-b33b-4ce6-a4b4-d5211b47e937",
   "metadata": {},
   "source": [
    "### brute-force index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0abda7b-49d2-4229-8ec6-b283c3803680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7f0a23eae510> \n",
       "resource name: projects/934903580331/locations/us-central1/indexEndpoints/1049611392061014016"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    my_bf_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{BF_ENDPOINT_DISPLAY_NAME}',\n",
    "        description=\"index endpoint for ANN index\",\n",
    "        network=VPC_NETWORK_FULL,\n",
    "        sync=False,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    EXISTING_INDEX_ENDPOINT = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/1049611392061014016'\n",
    "    my_bf_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(EXISTING_INDEX_ENDPOINT)\n",
    "    \n",
    "my_bf_index_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b5d6587-6200-4aef-b132-c70891ce7f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    deployedbf_v1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in my_bf_index_endpoint.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5110d-d09f-407f-8d3a-57c70157809b",
   "metadata": {},
   "source": [
    "## Deploy Indexes to endpoints\n",
    "\n",
    "> *Note: wait for indexes to be created (~40 mins) before deploying to endpoint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6334f7c-ab47-47cf-a292-308bcf688193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud ai indexes list \\\n",
    "#   --project=$PROJECT_ID \\\n",
    "#   --region=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a0e19-9f38-437a-805d-ef9bedbbdfed",
   "metadata": {},
   "source": [
    "**Get resource names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b69ed141-785e-4881-9813-7140aa8af0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN_INDEX_NAME          : ann_index_v1-v1\n",
      "BF_INDEX_NAME           : bf_index_v1_v1\n",
      "ANN_INDEX_ENDPOINT_NAME : ann_index_endpoint_v1\n",
      "BF_INDEX_ENDPOINT_NAME  : bf_index_endpoint_v1\n",
      "DEPLOYED_ANN_INDEX_ID   : deployed_ann_index_v1-v1\n",
      "DEPLOYED_BF_INDEX_ID    : deployed_bf_index_v1_v1\n"
     ]
    }
   ],
   "source": [
    "ANN_INDEX_NAME = tree_ah_index.display_name\n",
    "BF_INDEX_NAME = brute_force_index.display_name\n",
    "\n",
    "ANN_INDEX_ENDPOINT_NAME = my_ann_index_endpoint.display_name\n",
    "BF_INDEX_ENDPOINT_NAME = my_bf_index_endpoint.display_name\n",
    "\n",
    "DEPLOYED_ANN_INDEX_ID = f\"deployed_{ANN_INDEX_NAME}\"\n",
    "DEPLOYED_BF_INDEX_ID = f\"deployed_{BF_INDEX_NAME}\"\n",
    "\n",
    "print(f\"ANN_INDEX_NAME          : {ANN_INDEX_NAME}\")\n",
    "print(f\"BF_INDEX_NAME           : {BF_INDEX_NAME}\")\n",
    "print(f\"ANN_INDEX_ENDPOINT_NAME : {ANN_INDEX_ENDPOINT_NAME}\")\n",
    "print(f\"BF_INDEX_ENDPOINT_NAME  : {BF_INDEX_ENDPOINT_NAME}\")\n",
    "print(f\"DEPLOYED_ANN_INDEX_ID   : {DEPLOYED_ANN_INDEX_ID}\")\n",
    "print(f\"DEPLOYED_BF_INDEX_ID    : {DEPLOYED_BF_INDEX_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a19464-f673-464f-8367-8c214b06dca0",
   "metadata": {},
   "source": [
    "### Deploy ANN index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ed14d5-087b-4995-a8b8-2d5a84e4d104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tfrs_128dim_v1_endpoint'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    deployed_ann_index = my_ann_index_endpoint.deploy_index(\n",
    "        index=tree_ah_index, \n",
    "        deployed_index_id=DEPLOYED_ANN_INDEX_ID\n",
    "    )\n",
    "    \n",
    "else: # 5661297410488401920 | 3370091100063662080\n",
    "    EXISTING_DEPLOYED_ENDPOINT = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/3370091100063662080'\n",
    "    deployed_ann_index = vertex_ai.MatchingEngineIndexEndpoint(EXISTING_DEPLOYED_ENDPOINT)\n",
    "    \n",
    "deployed_ann_index.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7534d1b5-0156-4673-8ca7-aa77df0b2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    tfrs_128dim_v1_20230921202909\n",
      "    deployed_tfrs_128dim_v1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in deployed_ann_index.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1872343a-9b96-4e5d-9f8d-2b53b8f575d6",
   "metadata": {},
   "source": [
    "### Deploy brute-force index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4811e2e7-9c80-4379-971f-911dc81726d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tfrs_128dim_v1_bf_endpoint'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    deployed_bf_index = my_bf_index_endpoint.deploy_index(\n",
    "        index=brute_force_index, \n",
    "        deployed_index_id=DEPLOYED_BF_INDEX_ID\n",
    "    )\n",
    "else: # 4346246319296217088 | 1049611392061014016\n",
    "    EXISTING_DEPLOYED_ENDPOINT = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/4346246319296217088'\n",
    "    deployed_bf_index = vertex_ai.MatchingEngineIndexEndpoint(EXISTING_DEPLOYED_ENDPOINT)\n",
    "    \n",
    "deployed_bf_index.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f34967d-1582-46a3-91ac-e1bd3774c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    deployed_tfrs_128dim_v1_bf\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in deployed_bf_index.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018ab2c-398a-45d8-8471-30fba3242086",
   "metadata": {},
   "source": [
    "# Retrieve nearest neighbors from index\n",
    "\n",
    "* use query_model to convert test instance to embeddings\n",
    "* use embeddings to search for NN in ANN index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3828950-800e-40c2-849f-6fb7fcf58fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_ANN_INDEX_ID: tfrs_128dim_v1_20230921202909\n",
      "DEPLOYED_BF_INDEX_ID: deployed_tfrs_128dim_v1_bf\n"
     ]
    }
   ],
   "source": [
    "# DEPLOYED_ANN_INDEX_ID = deployed_ann_index.deployed_indexes[0].id\n",
    "# DEPLOYED_BF_INDEX_ID = deployed_bf_index.deployed_indexes[0].id\n",
    "\n",
    "# print(f\"DEPLOYED_ANN_INDEX_ID: {DEPLOYED_ANN_INDEX_ID}\")\n",
    "# print(f\"DEPLOYED_BF_INDEX_ID: {DEPLOYED_BF_INDEX_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "299c579f-5e8f-4cf6-bf2c-dc7045fb2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRACK_HISTORY == '5':\n",
    "#     TEST_INSTANCE = test_instances.TEST_INSTANCE_5\n",
    "# elif TRACK_HISTORY == '15':\n",
    "#     TEST_INSTANCE = test_instances.TEST_INSTANCE_15\n",
    "# else:\n",
    "#     TEST_INSTANCE = None\n",
    "#     print(\"Track History length not supported\")\n",
    "    \n",
    "# # TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10baf601-01a3-4ece-b78b-e4b61a163130",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deployed_query_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_30599/3802685499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplaylist_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeployed_query_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_INSTANCE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplaylist_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deployed_query_model' is not defined"
     ]
    }
   ],
   "source": [
    "# playlist_emb = deployed_query_model.predict([TEST_INSTANCE])\n",
    "# playlist_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8d536-be8e-4443-acf9-643cc7e80a2f",
   "metadata": {},
   "source": [
    "### ANN search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de9b9a-7e83-4f5d-9ef7-d219ee9e198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit \n",
    "# start_time = time.time()\n",
    "\n",
    "# ANN_response = deployed_ann_index.match(\n",
    "#     deployed_index_id=DEPLOYED_ANN_INDEX_ID,\n",
    "#     queries=playlist_emb.predictions,\n",
    "#     num_neighbors=10\n",
    "# )\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = (end_time - start_time) / 60\n",
    "# print(f\"elapsed_time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefd0c1-a6aa-4e49-9c51-8c41eae3838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00240a-db27-43e2-be4d-ee6d0e50795f",
   "metadata": {},
   "source": [
    "### Brute-force search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88ac42-de83-4aa1-89bb-5e04a65b46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit \n",
    "# start_time = time.time()\n",
    "\n",
    "# BF_response = deployed_bf_index.match(\n",
    "#     deployed_index_id=DEPLOYED_BF_INDEX_ID,\n",
    "#     queries=playlist_emb.predictions,\n",
    "#     num_neighbors=10\n",
    "# )\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = (end_time - start_time) / 60\n",
    "# print(f\"elapsed_time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180d42f-5b62-4f38-88fb-69893515790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BF_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b8e77-4fcb-459b-9f04-47a698cc9c30",
   "metadata": {},
   "source": [
    "## Compute Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3723ffe-8a1a-4005-bcd9-6ca4fedcb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
    "# recalled_neighbors = 0\n",
    "# for tree_ah_neighbors, brute_force_neighbors in zip(\n",
    "#     ANN_response, BF_response\n",
    "# ):\n",
    "#     tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
    "#     brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
    "\n",
    "#     recalled_neighbors += len(\n",
    "#         set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
    "#     )\n",
    "\n",
    "# recall = recalled_neighbors / len(\n",
    "#     [neighbor for neighbors in BF_response for neighbor in neighbors]\n",
    "# )\n",
    "\n",
    "# print(\"Recall: {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c9a05-7794-40d7-bff2-0ed3cf5a07d7",
   "metadata": {},
   "source": [
    "# Deploy Query Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724761b6-697b-4716-bd60-6e95f0702f3e",
   "metadata": {},
   "source": [
    "## Register Query model to Vertex Model Registry\n",
    "\n",
    "**TODO:** parametrize new vs existing assets\n",
    "\n",
    "```\n",
    "model = vertex_ai.Model.list(filter=f\"display_name=bqml_fraud_classifier\")[-1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42779994-fa65-4469-9d3e-e2edf691fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY_MODEL_DIR: gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/model-dir/query_model\n"
     ]
    }
   ],
   "source": [
    "QUERY_MODEL_DIR = f\"{BUCKET_URI}/{RUN_DIR_PATH}/model-dir/query_model\"\n",
    "\n",
    "print(f\"QUERY_MODEL_DIR: {QUERY_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17b220ea-8c86-4349-9d1f-efa83a8cfd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/model-dir/query_model/\n",
      "gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/model-dir/query_model/fingerprint.pb\n",
      "gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/model-dir/query_model/saved_model.pb\n",
      "gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/model-dir/query_model/assets/\n",
      "gs://ndr-v1-hybrid-vertex-bucket/tfrs-pipe-v1/run-20230919-173845/model-dir/query_model/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $QUERY_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12da6c87-988d-47a6-8b87-0644edd5a5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7f098726f850> \n",
       "resource name: projects/934903580331/locations/us-central1/models/2404541769992634368"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    uploaded_query_model = vertex_ai.Model.upload(\n",
    "        display_name=f'query_model_{DISPLAY_NAME}',\n",
    "        artifact_uri=QUERY_MODEL_DIR,\n",
    "        serving_container_image_uri=SERVING_IMAGE_URI_CPU,\n",
    "        description=\"Top of the query tower, meant to return an embedding for each playlist instance\",\n",
    "        sync=True,\n",
    "    )\n",
    "else:\n",
    "    # use existing\n",
    "    uploaded_query_model = vertex_ai.Model('projects/934903580331/locations/us-central1/models/2404541769992634368@1')\n",
    "\n",
    "uploaded_query_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b3be84c9-d6e4-4758-9848-52d80a9e9efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uploaded_query_model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35268707-4be6-43ed-a8de-e95e2fc4e046",
   "metadata": {},
   "source": [
    "## Deploy registered model to online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa3fc4-2889-4de4-bb95-d7fe2b9905a2",
   "metadata": {},
   "source": [
    "**Create model endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0af496a-7ebd-4cc9-ae1a-b29e205c15ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f09870aef10> \n",
       "resource name: projects/934903580331/locations/us-central1/endpoints/7270536031831588864"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    endpoint = vertex_ai.Endpoint.create(\n",
    "        display_name=f'endpoint_{DISPLAY_NAME}',\n",
    "        project=PROJECT_ID,\n",
    "        location=LOCATION,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    endpoint = vertex_ai.Endpoint('projects/934903580331/locations/us-central1/endpoints/7270536031831588864')\n",
    "\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e93ad1-b812-491b-8ed2-b2c47fd3a5b9",
   "metadata": {},
   "source": [
    "**Deploy to endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "000fe6b3-095c-4473-971f-3e2d71e13f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f0987268910> \n",
       "resource name: projects/934903580331/locations/us-central1/endpoints/7270536031831588864"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS == True:\n",
    "    \n",
    "    deployed_query_model = uploaded_query_model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=f'deployed_qmodel_{DISPLAY_NAME}',\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        accelerator_type=None,\n",
    "        accelerator_count=0,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    deployed_query_model = vertex_ai.Endpoint('projects/934903580331/locations/us-central1/endpoints/7270536031831588864')\n",
    "\n",
    "deployed_query_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "121573c3-a437-4856-8802-11769ecec489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endpoint_tfrs_128dim_v1'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_query_model.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c97c86-2552-4e7f-abbe-59751353d883",
   "metadata": {},
   "source": [
    "# Set Model Monitoring for Query Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c624b7-eafa-4303-8709-12dd49082ba0",
   "metadata": {},
   "source": [
    "### Define and create a Model Monitoring job\n",
    "To set up either skew detection or drift detection, create a model deployment monitoring job.\n",
    "\n",
    "The job requires the following specifications:\n",
    "\n",
    "* `alert_config`: Configures how alerts are sent to the user. Right now only email alert is supported.\n",
    "* `schedule_config`: Configures model monitoring job scheduling interval in hours. This defines how often the monitoring jobs are triggered.\n",
    "* `logging_sampling_strategy`: Sample Strategy for logging.\n",
    "* `drift_config`: Configures drift thresholds per each feature to monitor.\n",
    "* `skew_config`: Configures skew thresholds per each feature to monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f22f3-d83f-4b09-9a1a-d12eea0818d2",
   "metadata": {},
   "source": [
    "#### Define the alerting configuration\n",
    "\n",
    "The alerting configuration contains the mails to send alerts to. Also you can use the configuration to stream anomalies to Cloud Logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1681284-b470-474c-b6a5-3943f73935f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.model_monitoring.alert.EmailAlertConfig at 0x7f4ae67c6190>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spotipy_secret_creds as creds\n",
    "\n",
    "USER_EMAILS = [creds.USER_EMAIL] #'recipient1@domain.com', 'recipient2@domain.com'\n",
    "alert_config = model_monitoring.EmailAlertConfig(USER_EMAILS, enable_logging=True)\n",
    "alert_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3c600-b294-4962-8916-4c9566711ade",
   "metadata": {},
   "source": [
    "#### Define the schedule configuration\n",
    "\n",
    "The schedule configuration sets the hourly model monitoring job scheduling interval.\n",
    "\n",
    "> Sets the model monitoring job scheduling interval in hours. This defines how often the monitoring jobs are triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37be31fb-379a-40ca-8932-4746c3c10cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.model_monitoring.schedule.ScheduleConfig at 0x7f4b71ad9fd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MONITOR_INTERVAL = 1\n",
    "schedule_config = model_monitoring.ScheduleConfig(monitor_interval=MONITOR_INTERVAL)\n",
    "schedule_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26d368-5d11-4b78-9b49-809f05d4980c",
   "metadata": {},
   "source": [
    "#### Define the logging sample strategy\n",
    "\n",
    "With the logging sample strategy, you configure how the model monitoring service randomly sample predictions to calculate monitoring metrics. The selected samples are logged to a BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d70136de-ee26-4309-a0fe-bec7985a080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.model_monitoring.sampling.RandomSampleConfig at 0x7f4ae65a3fd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_RATE = 0.8\n",
    "\n",
    "logging_sampling_strategy = model_monitoring.RandomSampleConfig(sample_rate=SAMPLE_RATE)\n",
    "logging_sampling_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4b98f-edef-4827-8fed-fbe5d875e7b7",
   "metadata": {},
   "source": [
    "#### Define the drift detection configuration\n",
    "\n",
    "With the drift detection configuration, you define the input features and the associated thresholds for monitoring feature distribution drift and (TODO) feature attribution drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcc8c0e5-8f3a-4a01-932d-0031778b3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = feature_sets.get_all_features(TRACK_HISTORY)\n",
    "# feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0408a464-e255-461a-9be6-d0321ee9bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(feature_dict.keys())\n",
    "# feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5783284c-c561-4098-bb38-13fe9a4f84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_thresholds      : {'track_uri_can': 0.05, 'track_name_can': 0.05, 'artist_uri_can': 0.05, 'artist_name_can': 0.05, 'album_uri_can': 0.05, 'album_name_can': 0.05, 'duration_ms_can': 0.05, 'track_pop_can': 0.05, 'artist_pop_can': 0.05, 'artist_genres_can': 0.05, 'artist_followers_can': 0.05, 'track_danceability_can': 0.05, 'track_energy_can': 0.05, 'track_key_can': 0.05, 'track_loudness_can': 0.05, 'track_mode_can': 0.05, 'track_speechiness_can': 0.05, 'track_acousticness_can': 0.05, 'track_instrumentalness_can': 0.05, 'track_liveness_can': 0.05, 'track_valence_can': 0.05, 'track_tempo_can': 0.05, 'track_time_signature_can': 0.05, 'pl_name_src': 0.05, 'pl_collaborative_src': 0.05, 'pl_duration_ms_new': 0.05, 'num_pl_songs_new': 0.05, 'num_pl_artists_new': 0.05, 'num_pl_albums_new': 0.05, 'track_uri_pl': 0.05, 'track_name_pl': 0.05, 'artist_uri_pl': 0.05, 'artist_name_pl': 0.05, 'album_uri_pl': 0.05, 'album_name_pl': 0.05, 'artist_genres_pl': 0.05, 'duration_ms_songs_pl': 0.05, 'track_pop_pl': 0.05, 'artist_pop_pl': 0.05, 'artists_followers_pl': 0.05, 'track_danceability_pl': 0.05, 'track_energy_pl': 0.05, 'track_key_pl': 0.05, 'track_loudness_pl': 0.05, 'track_mode_pl': 0.05, 'track_speechiness_pl': 0.05, 'track_acousticness_pl': 0.05, 'track_instrumentalness_pl': 0.05, 'track_liveness_pl': 0.05, 'track_valence_pl': 0.05, 'track_tempo_pl': 0.05, 'track_time_signature_pl': 0.05}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DRIFT_THRESHOLD_VALUE = 0.05\n",
    "ATTRIBUTION_DRIFT_THRESHOLD_VALUE = 0.05\n",
    "\n",
    "# =========================== #\n",
    "##   Feature value drift     ##\n",
    "# =========================== #\n",
    "drift_thresholds = dict()\n",
    "\n",
    "for feature in feature_names:\n",
    "    if feature in drift_thresholds:\n",
    "        print(\"feature name already in dict\")\n",
    "    else:\n",
    "        drift_thresholds[feature] = DRIFT_THRESHOLD_VALUE\n",
    "        \n",
    "print(f\"drift_thresholds      : {drift_thresholds}\\n\")\n",
    "\n",
    "# =========================== #\n",
    "## Feature attribution drift ##\n",
    "# =========================== #\n",
    "# attr_drift_thresholds = dict()\n",
    "\n",
    "# for feature in feature_names:\n",
    "#     if feature in attr_drift_thresholds:\n",
    "#         print(\"feature name already in dict\")\n",
    "#     else:\n",
    "#         attr_drift_thresholds[feature] = ATTRIBUTION_DRIFT_THRESHOLD_VALUE\n",
    "\n",
    "# print(f\"attr_drift_thresholds : {attr_drift_thresholds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f339bdf-6129-454b-8580-ae858e35288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.model_monitoring.objective.DriftDetectionConfig at 0x7f4ae4164390>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_config = model_monitoring.DriftDetectionConfig(\n",
    "    drift_thresholds=drift_thresholds,\n",
    "    # attribute_drift_thresholds=attr_drift_thresholds,\n",
    ")\n",
    "\n",
    "drift_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6b468-35b4-49da-9c3c-1284cc222ed2",
   "metadata": {},
   "source": [
    "#### Define the skew detection configuration\n",
    "\n",
    "With the skew detection configuration, you define the input features and the associated thresholds for monitoring feature distribution skew and feature attribution skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14fcf5a7-0bf0-4e01-8eac-7b7cd7879a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skew_thresholds      : {'track_uri_can': 0.05, 'track_name_can': 0.05, 'artist_uri_can': 0.05, 'artist_name_can': 0.05, 'album_uri_can': 0.05, 'album_name_can': 0.05, 'duration_ms_can': 0.05, 'track_pop_can': 0.05, 'artist_pop_can': 0.05, 'artist_genres_can': 0.05, 'artist_followers_can': 0.05, 'track_danceability_can': 0.05, 'track_energy_can': 0.05, 'track_key_can': 0.05, 'track_loudness_can': 0.05, 'track_mode_can': 0.05, 'track_speechiness_can': 0.05, 'track_acousticness_can': 0.05, 'track_instrumentalness_can': 0.05, 'track_liveness_can': 0.05, 'track_valence_can': 0.05, 'track_tempo_can': 0.05, 'track_time_signature_can': 0.05, 'pl_name_src': 0.05, 'pl_collaborative_src': 0.05, 'pl_duration_ms_new': 0.05, 'num_pl_songs_new': 0.05, 'num_pl_artists_new': 0.05, 'num_pl_albums_new': 0.05, 'track_uri_pl': 0.05, 'track_name_pl': 0.05, 'artist_uri_pl': 0.05, 'artist_name_pl': 0.05, 'album_uri_pl': 0.05, 'album_name_pl': 0.05, 'artist_genres_pl': 0.05, 'duration_ms_songs_pl': 0.05, 'track_pop_pl': 0.05, 'artist_pop_pl': 0.05, 'artists_followers_pl': 0.05, 'track_danceability_pl': 0.05, 'track_energy_pl': 0.05, 'track_key_pl': 0.05, 'track_loudness_pl': 0.05, 'track_mode_pl': 0.05, 'track_speechiness_pl': 0.05, 'track_acousticness_pl': 0.05, 'track_instrumentalness_pl': 0.05, 'track_liveness_pl': 0.05, 'track_valence_pl': 0.05, 'track_tempo_pl': 0.05, 'track_time_signature_pl': 0.05}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SKEW_THRESHOLD_VALUE = 0.05\n",
    "ATTRIBUTION_SKEW_THRESHOLD_VALUE = 0.05\n",
    "\n",
    "# =========================== #\n",
    "##   Feature value skew      ##\n",
    "# =========================== #\n",
    "skew_thresholds = dict()\n",
    "\n",
    "for feature in feature_names:\n",
    "    if feature in skew_thresholds:\n",
    "        print(\"feature name already in dict\")\n",
    "    else:\n",
    "        skew_thresholds[feature] = SKEW_THRESHOLD_VALUE        \n",
    "print(f\"skew_thresholds      : {skew_thresholds}\\n\")\n",
    "\n",
    "# =========================== #\n",
    "## Feature attribution skew  ##\n",
    "# =========================== #\n",
    "# attr_skew_thresholds = dict()\n",
    "\n",
    "# for feature in feature_names:\n",
    "#     if feature in attr_skew_thresholds:\n",
    "#         print(\"feature name already in dict\")\n",
    "#     else:\n",
    "#         attr_skew_thresholds[feature] = ATTRIBUTION_SKEW_THRESHOLD_VALUE\n",
    "# print(f\"attr_skew_thresholds : {attr_skew_thresholds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4776b603-11ea-4aad-bcd4-5660a2cf18e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.model_monitoring.objective.SkewDetectionConfig at 0x7f4ae416b310>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN_DATA_SOURCE_URI = f\"gs://{BUCKET_NAME}/data/{DATA_VERSION}/{TRAIN_DIR_PREFIX}/\"\n",
    "# TRAIN_DATA_FORMAT = \"tf-record\"\n",
    "\n",
    "TRAIN_DATA_SOURCE_URI = f\"bq://{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_TRAIN}\"\n",
    "TRAIN_DATA_FORMAT = None\n",
    "\n",
    "if TRAIN_DATA_FORMAT:\n",
    "    skew_config = model_monitoring.SkewDetectionConfig(\n",
    "        data_source=TRAIN_DATA_SOURCE_URI,\n",
    "        data_format = TRAIN_DATA_FORMAT,\n",
    "        skew_thresholds=skew_thresholds,\n",
    "        # attribute_skew_thresholds=attribute_skew_thresholds,\n",
    "        # target_field=TARGET, # no target; embedding model\n",
    "    )\n",
    "else:\n",
    "    skew_config = model_monitoring.SkewDetectionConfig(\n",
    "        data_source=TRAIN_DATA_SOURCE_URI,\n",
    "        # data_format = TRAIN_DATA_FORMAT, # only used if source in GCS\n",
    "        skew_thresholds=skew_thresholds,\n",
    "        # attribute_skew_thresholds=attribute_skew_thresholds,\n",
    "        # target_field=TARGET, # no target; embedding model\n",
    "    )\n",
    "    \n",
    "skew_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a86a9-df3e-4a2d-8042-9121917ee794",
   "metadata": {},
   "source": [
    "#### Define Explanation Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ade45a-549d-4fc7-8b75-b8de5653d6e6",
   "metadata": {},
   "source": [
    "* If you are enabling skew detection, upload your training data or output of a [batch explanation job](https://cloud.google.com/vertex-ai/docs/explainable-ai/getting-explanations#batch) for your training dataset to `Cloud Storage` or `BigQuery`. Obtain the URI link to the data. For drift detection, training data or explanation baseline isn't required.\n",
    "\n",
    "* An imported custom-trained model must be [configured for Vertex Explainable AI](https://cloud.google.com/vertex-ai/docs/model-monitoring/monitor-explainable-ai#enable-feature-attribution-skew-or-drift-detection) when you create, import, or deploy the model.\n",
    "\n",
    "* [Configure your model](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations) to use Vertex Explainable AI when you create, import, or deploy the model. The `ExplanationSpec.ExplanationParameters` field must be populated for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12ec023f-c9ad-4011-a79a-bf7cae60d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_XAI_MONITORING:\n",
    "    explanation_config = model_monitoring.ExplanationConfig()\n",
    "else:\n",
    "    explanation_config = None\n",
    "    \n",
    "explanation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcee6e-cdbd-4f79-a196-560ced92c66c",
   "metadata": {},
   "source": [
    "### Create job config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71d2766a-1910-44b1-bd92-de36355d1add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.model_monitoring.objective.ObjectiveConfig at 0x7f4ae415bed0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_config = model_monitoring.ObjectiveConfig(\n",
    "    skew_detection_config=skew_config,\n",
    "    drift_detection_config=drift_config,\n",
    "    explanation_config=explanation_config,\n",
    ")\n",
    "\n",
    "objective_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f453a-48ce-4542-b944-e3ab8551c106",
   "metadata": {},
   "source": [
    "## Create Model Monitoring Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b9a1cb5-02f0-4b00-b3ac-e7c338ea6e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_DISPLAY_NAME: 2tower_ndr-v1_monitoring\n",
      "Creating ModelDeploymentMonitoringJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating ModelDeploymentMonitoringJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDeploymentMonitoringJob created. Resource name: projects/934903580331/locations/us-central1/modelDeploymentMonitoringJobs/5182827677073014784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:ModelDeploymentMonitoringJob created. Resource name: projects/934903580331/locations/us-central1/modelDeploymentMonitoringJobs/5182827677073014784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this ModelDeploymentMonitoringJob in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:To use this ModelDeploymentMonitoringJob in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdm_job = aiplatform.ModelDeploymentMonitoringJob('projects/934903580331/locations/us-central1/modelDeploymentMonitoringJobs/5182827677073014784')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:mdm_job = aiplatform.ModelDeploymentMonitoringJob('projects/934903580331/locations/us-central1/modelDeploymentMonitoringJobs/5182827677073014784')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Model Deployment Monitoring Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/model-deployment-monitoring/5182827677073014784?project=934903580331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:View Model Deployment Monitoring Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/model-deployment-monitoring/5182827677073014784?project=934903580331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.jobs.ModelDeploymentMonitoringJob object at 0x7f4ae415b5d0> \n",
       "resource name: projects/934903580331/locations/us-central1/modelDeploymentMonitoringJobs/5182827677073014784"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOB_DISPLAY_NAME = f\"{MODEL_TYPE}_{PREFIX}_monitoring\"\n",
    "print(f\"JOB_DISPLAY_NAME: {JOB_DISPLAY_NAME}\")\n",
    "\n",
    "monitoring_job = vertex_ai.ModelDeploymentMonitoringJob.create(\n",
    "    display_name=JOB_DISPLAY_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    endpoint=deployed_query_model,\n",
    "    logging_sampling_strategy=logging_sampling_strategy,\n",
    "    schedule_config=schedule_config,\n",
    "    alert_config=alert_config,\n",
    "    objective_configs=objective_config,\n",
    ")\n",
    "\n",
    "monitoring_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197bbfc-377c-44f0-8c23-d009f3c4014e",
   "metadata": {},
   "source": [
    "Check the monitoring job state\n",
    "\n",
    "You can check the status of the model monitoring job using the state attribute of the job instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1e687cb-718d-419e-a874-c9857703b1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2tower_ndr-v1_monitoring'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOB_DISPLAY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac9dbac6-5239-4e0f-9588-eb16bc37b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "jobs = monitoring_job.list(filter=f\"display_name={JOB_DISPLAY_NAME}\")\n",
    "job = jobs[0]\n",
    "print(job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707d9e4-3a01-41ab-9ebf-6135fa9c1e5b",
   "metadata": {},
   "source": [
    "**Receiving email alert**\n",
    "\n",
    "> After a minute or two, you should receive email at the address you configured above for `USER_EMAIL`. This email confirms successful deployment of your monitoring job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ba468-1156-4860-a43d-a60215e8302d",
   "metadata": {},
   "source": [
    "**Monitoring results in the Cloud Console**\n",
    "\n",
    "> After one hour, you can examine your model monitoring data from the Cloud Console.\n",
    "\n",
    "**See `Notes` at end of notebook for details on interpreting Model Monitoring results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e143b-df43-4bbb-b2be-967463b3d612",
   "metadata": {},
   "source": [
    "# Test endpoint deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19318841-f6e1-42d9-9210-148bc6b98932",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRACK_HISTORY == '5':\n",
    "    TEST_INSTANCE = test_instances.TEST_INSTANCE_5\n",
    "elif TRACK_HISTORY == '15':\n",
    "    TEST_INSTANCE = test_instances.TEST_INSTANCE_15\n",
    "else:\n",
    "    TEST_INSTANCE = None\n",
    "    print(\"Track History length not supported\")\n",
    "    \n",
    "# TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3cf852b-efe9-4a73-81a5-6f1b6980c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = TEST_INSTANCE\n",
    "\n",
    "# print(f\"instances: {instances}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b8faa-960a-49a1-afc8-a88a01597890",
   "metadata": {},
   "source": [
    "### Make prediction request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113da48-48a6-4492-a529-dee96ba1d8b3",
   "metadata": {},
   "source": [
    "test single prediction request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d279b029-dd5e-428f-876a-5fa617a9fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.319549441, -0.736324608, -0.999139726, 0.936678231, 0.140084431, -0.413407475, 0.878894806, -0.970329106, -0.659263194, -1.60079765, 1.11298513, 0.534306586, 1.12248015, -0.79353, -0.221303761, 0.214388043, 0.851346672, -1.70991278, -0.428875, -0.796241462, -0.130663425, 0.679144442, 1.57031, -1.71820736, -0.0138283893, -0.696535349, 0.518329501, -1.51568925, -0.54820931, 0.00688769668, -1.16123128, 1.08391941, -0.113285184, 0.457706213, 0.0641227961, 0.416062444, -1.27625763, 0.214524657, -1.79184937, 0.368900865, -0.097617425, -2.05919147, -0.195343286, 0.136424914, -1.31718016, -0.237893417, 1.59560561, -0.966435671, 1.97090781, 0.787532568, -0.221562356, -0.302150905, 1.45196605, 0.0823364705, -1.3538276, 1.40799367, -1.17275703, 2.04082108, -0.43333602, 0.913677335, 0.126593262, -0.656877041, 0.239591926, 0.283293277, 0.875116467, -0.861238241, 0.537754834, 0.748203337, 0.236702815, -0.605949759, -0.857457638, -1.20023417, -1.0099895, -0.0130776241, -0.00597327948, -0.293667614, -0.201426148, 0.173060417, 1.38165593, 0.0985977352, 0.208134055, -0.716558337, 0.490972489, -0.158909678, 1.46330917, 0.303305387, 1.35440958, 0.503082812, 0.763622522, 0.78609848, -0.980907321, 1.18656552, -0.722483218, -0.131771222, 1.12935841, -0.390786767, -0.494330049, -1.45349109, -0.350742966, 0.60110724, 0.487943262, 0.336191267, -0.978412747, -0.0483992472, -0.642347634, 2.32962751, 0.705823898, -0.438072264, -0.999286592, -1.35016441, 0.641670406, 0.318202496, 1.40196693, 1.52482724, 1.30487597, 0.57906872, -1.29293466, 0.380096912, -0.184833914, -2.22611952, -0.370139569, -0.29136616, 0.132395029, -1.49185872, 0.849699259, 1.29289389, 1.93756354, -0.0493374951]\n"
     ]
    }
   ],
   "source": [
    "response = deployed_query_model.predict(instances=[instances])\n",
    "\n",
    "prediction = response[0]\n",
    "\n",
    "# print the prediction for the first instance\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06916856-115c-4f0f-8e0f-c52edee8ddc9",
   "metadata": {},
   "source": [
    "### Write test instances to file\n",
    "\n",
    "> test endpoint monitoring with >= 1000 prediction requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b63e4dc-5796-4692-8654-366a1d3e962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED_REQUEST_N : 50\n",
      "INTERVAL       : 25\n"
     ]
    }
   ],
   "source": [
    "PRED_REQUEST_N = 50\n",
    "INTERVAL       = PRED_REQUEST_N // 2\n",
    "SKIP_N         = INTERVAL\n",
    "\n",
    "print(f\"PRED_REQUEST_N : {PRED_REQUEST_N}\")\n",
    "print(f\"INTERVAL       : {INTERVAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e69b724-110e-47f4-a161-3ffeac3d6820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f\"{BUCKET_NAME}\", prefix=f'data/{DATA_VERSION}/{VALID_DIR_PREFIX}/'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "valid_parsed = valid.map(feature_sets.parse_tfrecord)\n",
    "# valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3337331-5dda-459b-a788-78ea5632dc94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "subset_val = valid_parsed.skip(SKIP_N).take(PRED_REQUEST_N)\n",
    "\n",
    "list_of_dicts = []\n",
    "\n",
    "for tensor_dict in subset_val:\n",
    "    list_dict = {}\n",
    "    td_keys = tensor_dict.keys()\n",
    "    for k in td_keys:\n",
    "        \n",
    "        value = tensor_dict[k].numpy()\n",
    "        \n",
    "        if type(value) == bytes:\n",
    "\n",
    "            list_dict.update({k: value.decode()})\n",
    "        \n",
    "        elif type(value) == numpy.ndarray:\n",
    "            \n",
    "            if type(value[0]) != bytes:\n",
    "                list_dict.update({k: value.tolist()})\n",
    "            else:\n",
    "\n",
    "                tmp_list = []\n",
    "\n",
    "                for ele in value:\n",
    "                    tmp_list.append(ele.decode())\n",
    "\n",
    "                list_dict.update({k: tmp_list})\n",
    "                \n",
    "        elif type(value) == numpy.float32:\n",
    "            list_dict.update({k: value.item()})\n",
    "                \n",
    "        else:\n",
    "            list_dict.update({k: value})\n",
    "            \n",
    "        list_of_dicts.append(list_dict)\n",
    "    \n",
    "# list_dict\n",
    "len(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af75be56-86ef-4122-9dfd-6ed60e4952b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 prediciton requests..\n",
      "50 prediciton requests..\n",
      "75 prediciton requests..\n",
      "100 prediciton requests..\n",
      "125 prediciton requests..\n",
      "150 prediciton requests..\n",
      "175 prediciton requests..\n",
      "200 prediciton requests..\n",
      "225 prediciton requests..\n",
      "250 prediciton requests..\n",
      "275 prediciton requests..\n",
      "300 prediciton requests..\n",
      "325 prediciton requests..\n",
      "350 prediciton requests..\n",
      "375 prediciton requests..\n",
      "400 prediciton requests..\n",
      "425 prediciton requests..\n",
      "450 prediciton requests..\n",
      "475 prediciton requests..\n",
      "500 prediciton requests..\n",
      "525 prediciton requests..\n",
      "550 prediciton requests..\n",
      "575 prediciton requests..\n",
      "600 prediciton requests..\n",
      "625 prediciton requests..\n",
      "650 prediciton requests..\n",
      "675 prediciton requests..\n",
      "700 prediciton requests..\n",
      "725 prediciton requests..\n",
      "750 prediciton requests..\n",
      "775 prediciton requests..\n",
      "800 prediciton requests..\n",
      "825 prediciton requests..\n",
      "850 prediciton requests..\n",
      "875 prediciton requests..\n",
      "900 prediciton requests..\n",
      "925 prediciton requests..\n",
      "950 prediciton requests..\n",
      "975 prediciton requests..\n",
      "1000 prediciton requests..\n",
      "1025 prediciton requests..\n",
      "1050 prediciton requests..\n",
      "1075 prediciton requests..\n",
      "1100 prediciton requests..\n",
      "1125 prediciton requests..\n",
      "1150 prediciton requests..\n",
      "1175 prediciton requests..\n",
      "1200 prediciton requests..\n",
      "1225 prediciton requests..\n",
      "1250 prediciton requests..\n",
      "1275 prediciton requests..\n",
      "1300 prediciton requests..\n",
      "1325 prediciton requests..\n",
      "1350 prediciton requests..\n",
      "1375 prediciton requests..\n",
      "1400 prediciton requests..\n",
      "1425 prediciton requests..\n",
      "1450 prediciton requests..\n",
      "1475 prediciton requests..\n",
      "1500 prediciton requests..\n",
      "1525 prediciton requests..\n",
      "1550 prediciton requests..\n",
      "1575 prediciton requests..\n",
      "1600 prediciton requests..\n",
      "1625 prediciton requests..\n",
      "1650 prediciton requests..\n",
      "1675 prediciton requests..\n",
      "1700 prediciton requests..\n",
      "1725 prediciton requests..\n",
      "1750 prediciton requests..\n",
      "1775 prediciton requests..\n",
      "1800 prediciton requests..\n",
      "1825 prediciton requests..\n",
      "1850 prediciton requests..\n",
      "1875 prediciton requests..\n",
      "1900 prediciton requests..\n",
      "1925 prediciton requests..\n",
      "1950 prediciton requests..\n",
      "1975 prediciton requests..\n",
      "2000 prediciton requests..\n",
      "2025 prediciton requests..\n",
      "2050 prediciton requests..\n",
      "2075 prediciton requests..\n",
      "2100 prediciton requests..\n",
      "2125 prediciton requests..\n",
      "2150 prediciton requests..\n",
      "2175 prediciton requests..\n",
      "2200 prediciton requests..\n",
      "2225 prediciton requests..\n",
      "2250 prediciton requests..\n",
      "2275 prediciton requests..\n",
      "2300 prediciton requests..\n",
      "2325 prediciton requests..\n",
      "2350 prediciton requests..\n",
      "2375 prediciton requests..\n",
      "2400 prediciton requests..\n",
      "2425 prediciton requests..\n",
      "2450 prediciton requests..\n",
      "2475 prediciton requests..\n",
      "2500 prediciton requests..\n",
      "2525 prediciton requests..\n",
      "2550 prediciton requests..\n",
      "2575 prediciton requests..\n",
      "[-0.316191614, -0.736632228, -1.00103509, 0.936801553, 0.143262073, -0.413035601, 0.881459951, -0.968677163, -0.657993495, -1.60177445, 1.11540341, 0.534450293, 1.12290382, -0.79562974, -0.218611151, 0.216911197, 0.852999747, -1.70970297, -0.431490481, -0.796719253, -0.131098747, 0.678861737, 1.57433116, -1.71849513, -0.0131717063, -0.695032, 0.519422233, -1.51515913, -0.545648158, 0.00587499887, -1.16022086, 1.08450854, -0.109293938, 0.456809044, 0.0663500577, 0.415968299, -1.28065646, 0.211853147, -1.79086161, 0.36914134, -0.098710157, -2.06009436, -0.192913979, 0.135118887, -1.31829643, -0.238816991, 1.5937041, -0.967884064, 1.97131979, 0.786653876, -0.222255349, -0.301919788, 1.45176435, 0.0821444541, -1.35433638, 1.41081405, -1.17567897, 2.04352641, -0.430950701, 0.915213168, 0.124549598, -0.660427809, 0.242982119, 0.287387937, 0.876281738, -0.863683343, 0.536886334, 0.749792755, 0.23666884, -0.605295241, -0.859842956, -1.20190716, -1.00890052, -0.0171246603, -0.0018113181, -0.294076264, -0.197285056, 0.17216754, 1.38053346, 0.0969397649, 0.207888216, -0.716749966, 0.490655273, -0.159256935, 1.46190953, 0.30212304, 1.35271168, 0.50382483, 0.763873816, 0.786258, -0.980145335, 1.18392801, -0.724787176, -0.128117606, 1.12640297, -0.395618558, -0.49375689, -1.45199978, -0.349447608, 0.601396322, 0.48471114, 0.337583274, -0.9782933, -0.0502888262, -0.644129455, 2.3293643, 0.708969831, -0.434916556, -0.998240054, -1.35022128, 0.642638624, 0.315309107, 1.40024364, 1.52585, 1.30187464, 0.575985253, -1.29062474, 0.379185259, -0.185181409, -2.22602654, -0.370215207, -0.292384863, 0.133326396, -1.48911917, 0.847954273, 1.29093385, 1.93435824, -0.0492398106]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for test in list_of_dicts:\n",
    "    response = deployed_query_model.predict(instances=[test])\n",
    "    \n",
    "    if count > 0 and count % INTERVAL == 0:\n",
    "        print(f\"{count} prediciton requests..\")\n",
    "        \n",
    "    count += 1\n",
    "    \n",
    "prediction = response[0]\n",
    "# print the prediction for the first instance\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4fe2e2-ff4f-4135-8e02-894c406975ab",
   "metadata": {},
   "source": [
    "### Save test instances to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "230b7816-94ba-432f-a54d-d246d5315bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "LOCAL_INSTANCE_FILE = 'test_instance_list.pkl'\n",
    "\n",
    "filehandler = open(LOCAL_INSTANCE_FILE, 'wb')\n",
    "pkl.dump(list_of_dicts, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d65169c-a9ae-4537-b6ee-38c4cdddc568",
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(LOCAL_INSTANCE_FILE, 'rb')\n",
    "LIST_OF_INSTANCES = pkl.load(filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a54b6c2-2a68-4e7e-b4fc-5bef6903c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST_OF_INSTANCES[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dcb203a9-8e92-431d-9a70-6ba922e11a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ndr-v1-hybrid-vertex-bucket/endpoint-tests/test_instance_list.pkl\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_TEST_SUBDIR = \"endpoint-tests\"\n",
    "\n",
    "!gsutil -q cp $LOCAL_INSTANCE_FILE $BUCKET_URI/$ENDPOINT_TEST_SUBDIR/$LOCAL_INSTANCE_FILE\n",
    "\n",
    "!gsutil ls $BUCKET_URI/$ENDPOINT_TEST_SUBDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f17525-d3d5-423a-8572-70f48fcc8bb5",
   "metadata": {},
   "source": [
    "# Test Index Recall\n",
    "\n",
    "* use query_model to convert test instance to embeddings\n",
    "* use embeddings to search for NN in ANN index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb088f54-d583-456b-b380-48210973338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_ANN_INDEX_ID: tfrs_128dim_v1_20230921202909\n",
      "DEPLOYED_BF_INDEX_ID: deployed_tfrs_128dim_v1_bf\n"
     ]
    }
   ],
   "source": [
    "DEPLOYED_ANN_INDEX_ID = deployed_ann_index.deployed_indexes[0].id\n",
    "DEPLOYED_BF_INDEX_ID = deployed_bf_index.deployed_indexes[0].id\n",
    "\n",
    "print(f\"DEPLOYED_ANN_INDEX_ID: {DEPLOYED_ANN_INDEX_ID}\")\n",
    "print(f\"DEPLOYED_BF_INDEX_ID: {DEPLOYED_BF_INDEX_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d7a9c51d-9fcc-4471-82c3-6679d644c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRACK_HISTORY == '5':\n",
    "#     TEST_INSTANCE = test_instances.TEST_INSTANCE_5\n",
    "# elif TRACK_HISTORY == '15':\n",
    "#     TEST_INSTANCE = test_instances.TEST_INSTANCE_15\n",
    "# else:\n",
    "#     TEST_INSTANCE = None\n",
    "#     print(\"Track History length not supported\")\n",
    "    \n",
    "# TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "85b1ffcd-941c-4a41-ab2d-323fa7501d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[-0.319549441, -0.736324608, -0.999139726, 0.936678231, 0.140084431, -0.413407475, 0.878894806, -0.970329106, -0.659263194, -1.60079765, 1.11298513, 0.534306586, 1.12248015, -0.79353, -0.221303761, 0.214388043, 0.851346672, -1.70991278, -0.428875, -0.796241462, -0.130663425, 0.679144442, 1.57031, -1.71820736, -0.0138283893, -0.696535349, 0.518329501, -1.51568925, -0.54820931, 0.00688769668, -1.16123128, 1.08391941, -0.113285184, 0.457706213, 0.0641227961, 0.416062444, -1.27625763, 0.214524657, -1.79184937, 0.368900865, -0.097617425, -2.05919147, -0.195343286, 0.136424914, -1.31718016, -0.237893417, 1.59560561, -0.966435671, 1.97090781, 0.787532568, -0.221562356, -0.302150905, 1.45196605, 0.0823364705, -1.3538276, 1.40799367, -1.17275703, 2.04082108, -0.43333602, 0.913677335, 0.126593262, -0.656877041, 0.239591926, 0.283293277, 0.875116467, -0.861238241, 0.537754834, 0.748203337, 0.236702815, -0.605949759, -0.857457638, -1.20023417, -1.0099895, -0.0130776241, -0.00597327948, -0.293667614, -0.201426148, 0.173060417, 1.38165593, 0.0985977352, 0.208134055, -0.716558337, 0.490972489, -0.158909678, 1.46330917, 0.303305387, 1.35440958, 0.503082812, 0.763622522, 0.78609848, -0.980907321, 1.18656552, -0.722483218, -0.131771222, 1.12935841, -0.390786767, -0.494330049, -1.45349109, -0.350742966, 0.60110724, 0.487943262, 0.336191267, -0.978412747, -0.0483992472, -0.642347634, 2.32962751, 0.705823898, -0.438072264, -0.999286592, -1.35016441, 0.641670406, 0.318202496, 1.40196693, 1.52482724, 1.30487597, 0.57906872, -1.29293466, 0.380096912, -0.184833914, -2.22611952, -0.370139569, -0.29136616, 0.132395029, -1.49185872, 0.849699259, 1.29289389, 1.93756354, -0.0493374951]], deployed_model_id='3605318418686803968', model_version_id='1', model_resource_name='projects/934903580331/locations/us-central1/models/2404541769992634368', explanations=None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_emb = deployed_query_model.predict([TEST_INSTANCE])\n",
    "playlist_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36253e-d9c9-4a05-9b9d-278da3b30224",
   "metadata": {},
   "source": [
    "### ANN search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e44646b-c7a9-4c7b-9d4e-2c793f49c44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN latency: 0.0102 seconds\n"
     ]
    }
   ],
   "source": [
    "# %%timeit \n",
    "start = time.time()\n",
    "\n",
    "ANN_response = deployed_ann_index.match(\n",
    "    deployed_index_id=DEPLOYED_ANN_INDEX_ID,\n",
    "    queries=playlist_emb.predictions,\n",
    "    num_neighbors=20\n",
    ")\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_ann_time = (end_time - start_time) / 60\n",
    "# print(f\"elapsed_ann_time: {elapsed_ann_time}\")\n",
    "elapsed_ann_time = time.time() - start\n",
    "elapsed_ann_time = round(elapsed_ann_time, 4)\n",
    "print(f'ANN latency: {elapsed_ann_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "147f3241-4651-478a-83b8-7c65f470dc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id=\"b'spotify:track:7opy2GAu6ni8snJvUUgj4M'\", distance=89.04745483398438),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1evFM5gO5L0aOw2l2wL88D'\", distance=89.03700256347656),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1FvVInbjQUHTnLo3wcEwEh'\", distance=89.02728271484375),\n",
       "  MatchNeighbor(id=\"b'spotify:track:25v6UWpnLnEH5hDdqrbhWE'\", distance=89.02726745605469),\n",
       "  MatchNeighbor(id=\"b'spotify:track:3AEt6lrKnKfc8H1Xq1mN1r'\", distance=89.0172119140625),\n",
       "  MatchNeighbor(id=\"b'spotify:track:5IEZ99PDHnKaAIeJ6EhS2J'\", distance=89.01597595214844),\n",
       "  MatchNeighbor(id=\"b'spotify:track:0IK0ej4joW9OORaJ8GasBn'\", distance=89.01570129394531),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1SejCUMSNYxnVC0vuRKzzy'\", distance=88.99887084960938),\n",
       "  MatchNeighbor(id=\"b'spotify:track:4mhSTVUnzCapQ02xwPXJrg'\", distance=88.99571228027344),\n",
       "  MatchNeighbor(id=\"b'spotify:track:3z9Qm5gfdCr4wklgMxAzFQ'\", distance=88.99554443359375),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1Ltgw2EXXngU8CZ8Fjvrmv'\", distance=88.99210357666016),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1WAcdfMjVbIju40ypX07vZ'\", distance=88.9920883178711),\n",
       "  MatchNeighbor(id=\"b'spotify:track:2dpMAvziCkoqqzhFMysWdS'\", distance=88.99075317382812),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1Alwh8Fy3NVzfN8IYbJjL2'\", distance=88.98953247070312),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1BLQaAtZzMaScRbd0aXJlt'\", distance=88.98500061035156),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1WHTqvsUVv8XaR09RnwQxb'\", distance=88.98454284667969),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1RnRMlOFte5F5FuvjzJNCc'\", distance=88.98088073730469),\n",
       "  MatchNeighbor(id=\"b'spotify:track:4QNDp0MrRoAz5JSs1MEuZx'\", distance=88.97848510742188),\n",
       "  MatchNeighbor(id=\"b'spotify:track:50Tqh6Bzww0YqkL7K8OXfH'\", distance=88.97413635253906),\n",
       "  MatchNeighbor(id=\"b'spotify:track:6V56AUegdLWT5cVnhJ54lc'\", distance=88.97021484375)]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb416a4-4f67-431b-8a61-2bee6b3797a4",
   "metadata": {},
   "source": [
    "### Brute-force search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95c0f506-9cad-4eac-9b49-bb690bca9f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruteforce latency: 0.3086 seconds\n"
     ]
    }
   ],
   "source": [
    "# %%timeit \n",
    "start = time.time()\n",
    "\n",
    "BF_response = deployed_bf_index.match(\n",
    "    deployed_index_id=DEPLOYED_BF_INDEX_ID,\n",
    "    queries=playlist_emb.predictions,\n",
    "    num_neighbors=20\n",
    ")\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_bf_time = (end_time - start_time) / 60\n",
    "# print(f\"elapsed_bf_time: {elapsed_bf_time}\")\n",
    "elapsed_bf_time = time.time() - start\n",
    "elapsed_bf_time = round(elapsed_bf_time, 4)\n",
    "print(f'Bruteforce latency: {elapsed_bf_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "920a5dd2-cda2-4db8-904f-a8d9b790a230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id=\"b'spotify:track:3ePcO8zbu6IznLKD5XBfV6'\", distance=89.0927963256836),\n",
       "  MatchNeighbor(id=\"b'spotify:track:6aYHi4SYZkn91EwrWxgGh3'\", distance=89.0899887084961),\n",
       "  MatchNeighbor(id=\"b'spotify:track:3aNwMNEmpns88B1wjpBGRl'\", distance=89.0806655883789),\n",
       "  MatchNeighbor(id=\"b'spotify:track:258m3BhXGYBk64QgYT1f6W'\", distance=89.06431579589844),\n",
       "  MatchNeighbor(id=\"b'spotify:track:0trwqplZTfQvrHM1FnVL8B'\", distance=89.06390380859375),\n",
       "  MatchNeighbor(id=\"b'spotify:track:11A88zUaDpXiput0IJ8C0P'\", distance=89.06157684326172),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1d5DGnrbtI0ZPhQtM9DQFw'\", distance=89.06036376953125),\n",
       "  MatchNeighbor(id=\"b'spotify:track:7EWX3ycwpuswKaivGITwIX'\", distance=89.06028747558594),\n",
       "  MatchNeighbor(id=\"b'spotify:track:4ohNTFZHEMfcE3DiN3Rh7Y'\", distance=89.05621337890625),\n",
       "  MatchNeighbor(id=\"b'spotify:track:6TukFfoYQmL0LIAP1SgjTX'\", distance=89.0560073852539),\n",
       "  MatchNeighbor(id=\"b'spotify:track:3xG6jYj6oeBEP4coZa0Cts'\", distance=89.05510711669922),\n",
       "  MatchNeighbor(id=\"b'spotify:track:19EQkfEzxqevVO7nSe4t9n'\", distance=89.0543212890625),\n",
       "  MatchNeighbor(id=\"b'spotify:track:7MMRoGvm7uhoUVhGvHJ3yW'\", distance=89.05406188964844),\n",
       "  MatchNeighbor(id=\"b'spotify:track:0V3OSpgJp5SC8FWtU6JlYO'\", distance=89.05403900146484),\n",
       "  MatchNeighbor(id=\"b'spotify:track:5LolNqlc9tMziNu9C6LsAN'\", distance=89.05300903320312),\n",
       "  MatchNeighbor(id=\"b'spotify:track:6JJCSIWkPe4yRZiesQ12bO'\", distance=89.04837799072266),\n",
       "  MatchNeighbor(id=\"b'spotify:track:7opy2GAu6ni8snJvUUgj4M'\", distance=89.04745483398438),\n",
       "  MatchNeighbor(id=\"b'spotify:track:7JJF9Ww6LfpEE2Rg5W2sdV'\", distance=89.04730224609375),\n",
       "  MatchNeighbor(id=\"b'spotify:track:3KeoqEUvaD3Ub4sf7fyO1K'\", distance=89.04721069335938),\n",
       "  MatchNeighbor(id=\"b'spotify:track:1qPpjstPj7ohEwWFuXRioc'\", distance=89.04647064208984)]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BF_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5dbc40-483f-4e6b-a7c0-71c9b8032c38",
   "metadata": {},
   "source": [
    "## Compute Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1df7ff3-7866-44ed-962f-8f0f3909c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
    "recalled_neighbors = 0\n",
    "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
    "    ANN_response, BF_response\n",
    "):\n",
    "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
    "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
    "\n",
    "    recalled_neighbors += len(\n",
    "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
    "    )\n",
    "\n",
    "recall = recalled_neighbors / len(\n",
    "    [neighbor for neighbors in BF_response for neighbor in neighbors]\n",
    ")\n",
    "\n",
    "print(\"Recall: {}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b97e18b4-7b4c-4766-88aa-d5aafb7e37b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduction in time         : 96.695%\n",
      "% increase in performance : 2925.49%\n",
      "how many times faster     : 30.255x faster\n"
     ]
    }
   ],
   "source": [
    "reduction = (elapsed_bf_time - elapsed_ann_time) / elapsed_bf_time*100.00\n",
    "increase  = (elapsed_bf_time - elapsed_ann_time)/elapsed_ann_time*100.00\n",
    "faster    = elapsed_bf_time / elapsed_ann_time\n",
    "\n",
    "print(f\"reduction in time         : {round(reduction, 3)}%\")\n",
    "print(f\"% increase in performance : {round(increase, 3)}%\")\n",
    "print(f\"how many times faster     : {round(faster, 3)}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd5a1d-4066-475b-acca-e0e32c2c07dc",
   "metadata": {},
   "source": [
    "# (Optional): Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943d3ad-91aa-479d-8375-02886d57ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitoring_job.pause()\n",
    "# monitoring_job.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d944ae-5be9-46b0-b842-2e3581d5a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_query_model.undeploy_all()\n",
    "# deployed_query_model.delete()\n",
    "# uploaded_query_model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e378f6d-8bd1-4093-ad8b-0f40b1862a20",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6905f32-d1f1-429a-9465-a23c6bfc0e97",
   "metadata": {},
   "source": [
    "## Model Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe643c8c-6fd8-4908-ac14-61db520275cd",
   "metadata": {},
   "source": [
    "### Cloud storage layout\n",
    "\n",
    "> Notice the following components in these Cloud Storage paths:\n",
    "\n",
    "* **cloud-ai-platform-** .. - This is a bucket created for you and assigned to capture your service's prediction data. Each monitoring job you create will trigger creation of a new folder in this bucket.\n",
    "* **`model_monitoring|instance_schemas`/job-** .. - This is your unique monitoring job number, which you can see above in both the response to your job creation requesst and the email notification.\n",
    "* **instance_schemas/job-** ../analysis - This is the monitoring jobs understanding and encoding of your training data's schema (field names, types, etc.).\n",
    "* **instance_schemas/job-** ../predict - This is the first prediction made to your model after the current monitoring job was enabled.\n",
    "* **model_monitoring/job-** ../serving - This folder is used to record data relevant to drift calculations. It contains measurement summaries for every hour your model serves traffic.\n",
    "* **model_monitoring/job-** ../training - This folder is used to record data relevant to training-serving skew calculations. It contains an ongoing summary of prediction data relative to training data.\n",
    "* **model_monitoring/job-** ../feature_attribution_score - This folder is used to record data relevant to feature attribution calculations. It contains an ongoing summary of feature attribution scores relative to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97cacb-e7e6-460e-bc03-abf25e72290f",
   "metadata": {},
   "source": [
    "### Interpret your results\n",
    "\n",
    "Vertex AI Model Monitoring detects an anomaly when the threshold set for a feature is exceeded. The following cells give you a sense of the alerting and reporting experience after model monitoring anomalies have been detected.\n",
    "\n",
    "Vertex AI Model Monitoring automatically notifies you of detected anomalies through email, but you can also [set up alerts through Cloud Logging](https://cloud.google.com/vertex-ai/docs/model-monitoring/using-model-monitoring#monitor-job)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376728a1-380e-4e44-b14e-66e20a1b9082",
   "metadata": {},
   "source": [
    "### Learn more about model monitoring\n",
    "\n",
    "**Congratulations!** You've now learned what model monitoring is, how to configure and enable it, and how to find and interpret the results. Check out the following resources to learn more about model monitoring and ML Ops.\n",
    "\n",
    "- [TensorFlow Data Validation](https://www.tensorflow.org/tfx/guide/tfdv)\n",
    "- [Data Understanding, Validation, and Monitoring At Scale](https://blog.tensorflow.org/2018/09/introducing-tensorflow-data-validation.html)\n",
    "- [Vertex Product Documentation](https://cloud.google.com/vertex-ai)\n",
    "- [Vertex AI Model Monitoring Reference Docs](https://cloud.google.com/vertex-ai/docs/reference)\n",
    "- [Vertex AI Model Monitoring blog article](https://cloud.google.com/blog/topics/developers-practitioners/monitor-models-training-serving-skew-vertex-ai)\n",
    "- [Explainable AI Whitepaper](https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
