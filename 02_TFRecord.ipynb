{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5383b2-071e-45b8-af2c-2421eb4f923a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Two - Tower Retreival Model\n",
    "\n",
    "### Key resources:\n",
    "* Many pages [here](https://www.tensorflow.org/recommenders/examples/deep_recommenders) include great techniques to build custom TFRS Models\n",
    "\n",
    "### Goals:\n",
    "* Show how to model off of most data types \n",
    "  * (String, Existing Embeddings (vectors), \n",
    "  * Floats (Normalized), \n",
    "  * Categorical with vocab, \n",
    "  * High Dim Categorical (Embed)\n",
    "* Leverage class templates to create custom 2 Tower Models quick/easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52e5f-a13b-46a7-849a-dc188b455a86",
   "metadata": {},
   "source": [
    "## SPOTIFY Create the tensorflow.io interface for the event and product table in Bigquery\n",
    "Best practices from Google are in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312070aa-00ae-467b-8747-0fefac329474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://spotify-tfrecords-blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3122eb-564b-46f9-9a50-851d19301521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "DROP_FIELDS = ['modified_at', 'row_number', 'seed_playlist_tracks']\n",
    "TF_RECORDS_DIR = 'gs://spotify-tfrecords-blog'\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c50a06-d69d-4d64-b254-26fb2a249fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick counts on training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1473-4a2d-4778-9f01-e2b76672a9f5",
   "metadata": {},
   "source": [
    "#### Quick counts on the training records for track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa56927-6722-43f9-88ac-ab638487164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 563.30query/s] \n",
      "Downloading: 100%|██████████| 1/1 [00:01<00:00,  1.02s/rows]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery TOTAL_PLAYLISTS\n",
    "select count(1) from hybrid-vertex.spotify_train_3.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418e5d8d-5410-4bca-a168-002d27ed95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65346428"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_PLAYLISTS = TOTAL_PLAYLISTS.values[0][0]\n",
    "TOTAL_PLAYLISTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4710f67-de96-401b-8a0c-abb05dd62c40",
   "metadata": {},
   "source": [
    "### Set the tf.io pipelines function from bigquery\n",
    "\n",
    "[Great blog post here on it](https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e985c505-1712-4d63-bc25-75df479fc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4349b880-9ecb-4ec3-ad4e-a8c35356208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U tensorflow-io==0.16.0 --user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db86c9f-5454-4629-80ba-c0273fca117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "import json\n",
    "import tensorflow as tf\n",
    "# import tensorflow_recommenders as tfrs\n",
    "import datetime\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.train import BytesList, Feature, FeatureList, Int64List, FloatList\n",
    "from tensorflow.train import SequenceExample, FeatureLists\n",
    "\n",
    "\n",
    "\n",
    "def bq_to_tfdata(client, row_restriction, table_id, col_names, dataset, batch_size=BATCH_SIZE):\n",
    "    TABLE_ID = table_id\n",
    "    COL_NAMES = col_names\n",
    "    DATASET = dataset\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, TABLE_ID, DATASET,\n",
    "        COL_NAMES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45e8d-3113-4528-9d71-8afdfd922d4f",
   "metadata": {},
   "source": [
    "## Get the song metadata\n",
    "\n",
    "To get a pipeline working we need the metadata for the table along with the table information. The following functions are helpers that give us the metadata into the proper types for `tf`\n",
    "\n",
    "\n",
    "For each table id, programatically get\n",
    "* Column names\n",
    "* Column types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e820-d1d7-48f9-902d-ad63be9b74fb",
   "metadata": {},
   "source": [
    "## Metadata dictionary to translate from BQ to tensorflow\n",
    "\n",
    "From the DDL we are going to get the types for use in a  to create a `BigQueryReadSession` from `tensorflow_io.bigquery` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b2013c-7896-4738-a174-79d9f2fbc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_2_tf_dict = \n",
    "\n",
    "{'name': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'collaborative': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'pid': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'description': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'duration_ms_playlist': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'pid_pos_id': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'pos': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'artist_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'track_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'artist_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'track_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'album_uri_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'duration_ms_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    " 'album_name_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'track_pop_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'artist_pop_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    " 'artist_genres_seed': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    " 'artist_followers_seed': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    " 'pos_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'artist_name_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'artist_uri_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'track_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'track_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'album_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'album_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    " 'duration_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    " 'duration_ms_seed_pl': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    " 'n_songs': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'num_artists': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    " 'num_albums': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    "'pos_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.int64},\n",
    "'track_uri_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "'track_name_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "'duration_ms_seed_songs_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.float64},\n",
    "'album_name_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "'artist_pop_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.float64},\n",
    "'artists_followers_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.float64},              \n",
    "'track_pop_seed_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.int64},  \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa17d16d-a645-43af-bab2-950085f90ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 15:52:51.163181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2299995000 Hz\n",
      "2022-06-27 15:52:51.164017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7e8008450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-06-27 15:52:51.164046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-06-27 15:52:51.164200: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "client = BigQueryClient()\n",
    "batch_size = 1\n",
    "bqsession = client.read_session(\n",
    "        \"projects/\" + PROJECT_ID,\n",
    "        PROJECT_ID, 'train_flatten', 'spotify_train_3',\n",
    "        bq_2_tf_dict,\n",
    "        requested_streams=2,)\n",
    "dataset = bqsession.parallel_read_rows()\n",
    "dataset = dataset.prefetch(1).shuffle(batch_size*10).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13d812a6-9d55-4c4a-b687-896e2ae54caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('album_name_seed', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'What Was I Thinking Of'], dtype=object)>), ('album_name_seed_pl', <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b'Use Your Illusion II', b'80s Songs from the Big Screen',\n",
      "        b'Different Light', b\"She's So Unusual\", b\"Surfin' USA\",\n",
      "        b'50 Big Ones: Greatest Hits',\n",
      "        b'Summer Days (And Summer Nights)',\n",
      "        b'Nursery Rhymes & Bible Songs for Kids - Childrens Music & Hymns & Sunday School Songs for Praise & Christian Worship',\n",
      "        b'Songs with the Greatest Piano Riffs in the World!',\n",
      "        b'The Savage Young Beatles Feat. Tony Sheridan']], dtype=object)>), ('album_name_seed_track', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'The Savage Young Beatles Feat. Tony Sheridan'], dtype=object)>), ('album_uri_seed', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:5UvwZF8MTWOpirUaZx6px9'], dtype=object)>), ('album_uri_seed_track', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:58Wthvmg2qEJT6sADb9sY1'], dtype=object)>), ('artist_followers_seed', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([9.])>), ('artist_genres_seed', <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'']], dtype=object)>), ('artist_name_seed', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'J.D.Beard'], dtype=object)>), ('artist_name_seed_track', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Tony Sheridan'], dtype=object)>), ('artist_pop_seed', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>), ('artist_pop_seed_pl', <tf.Tensor: shape=(1, 10), dtype=float64, numpy=array([[82.,  0., 65., 73., 75., 75., 75., 19., 35., 28.]])>), ('artist_uri_seed', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:6kOygcX15nEaQ8P0c62YXO'], dtype=object)>), ('artist_uri_seed_track', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:3muGwkg7cEbK52vzp76J38'], dtype=object)>), ('artists_followers_seed_pl', <tf.Tensor: shape=(1, 10), dtype=float64, numpy=\n",
      "array([[2.387000e+07, 2.800000e+01, 1.042487e+06, 1.918828e+06,\n",
      "        3.559951e+06, 3.559951e+06, 3.559951e+06, 6.550000e+02,\n",
      "        4.103000e+03, 4.964000e+03]])>), ('collaborative', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'false'], dtype=object)>), ('description', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b''], dtype=object)>), ('duration_ms_playlist', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([15350704])>), ('duration_ms_seed', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([170626.])>), ('duration_ms_seed_pl', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([2052879.])>), ('duration_ms_seed_songs_pl', <tf.Tensor: shape=(1, 10), dtype=float64, numpy=\n",
      "array([[336000., 237089., 204560., 238266., 149373., 217093., 160360.,\n",
      "        156000., 226605., 127533.]])>), ('duration_seed_track', <tf.Tensor: shape=(1,), dtype=float64, numpy=array([127533.])>), ('n_songs', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>), ('name', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Throwback'], dtype=object)>), ('num_albums', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>), ('num_artists', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([8])>), ('pid', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([11834])>), ('pid_pos_id', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'11834-10'], dtype=object)>), ('pos', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>), ('pos_seed_pl', <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])>), ('pos_seed_track', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([9])>), ('track_name_seed', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Johny and Janie'], dtype=object)>), ('track_name_seed_pl', <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b\"Knockin' On Heaven's Door\",\n",
      "        b'Karma Chameleon (from \"The Call\")', b'Walk Like an Egyptian',\n",
      "        b'Girls Just Want to Have Fun', b\"Surfin' U.S.A.\", b'Kokomo',\n",
      "        b'California Girls', b'Yellow Submarine', b'Let It Be',\n",
      "        b'Sweet Georgia Brown']], dtype=object)>), ('track_name_seed_track', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Sweet Georgia Brown'], dtype=object)>), ('track_pop_seed', <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>), ('track_pop_seed_pl', <tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[ 0,  0, 64, 81, 75,  0, 61,  8, 19,  0]])>), ('track_uri_seed', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:38zXwDM7r29fRYV761VtL1'], dtype=object)>), ('track_uri_seed_pl', <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b'spotify:track:7gXdAqJLCa5aYUeLVxosOz',\n",
      "        b'spotify:track:69qyiqGK60HLck0U5IlqGC',\n",
      "        b'spotify:track:3BGbqEDio3ocx1v4egIYr6',\n",
      "        b'spotify:track:4y1LsJpmMti1PfRQV9AWWe',\n",
      "        b'spotify:track:0wz1LjDb9ZNEYwOmDJ3Q4b',\n",
      "        b'spotify:track:0NqQmmLEN9rlnkh2JW0UIs',\n",
      "        b'spotify:track:6bJuuCtXYiwOcKT9s8uRh8',\n",
      "        b'spotify:track:4RYKhakKvfaawjX3HSqFAW',\n",
      "        b'spotify:track:6Hxg0aWE86cU1io3mibhT6',\n",
      "        b'spotify:track:3KQUZplafflXBkikZZKpWp']], dtype=object)>), ('track_uri_seed_track', <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:3KQUZplafflXBkikZZKpWp'], dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f532d8-d332-49c2-8fd2-43c09f79ebfa",
   "metadata": {},
   "source": [
    "### Confirm matching data and order for arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fb71dff-f103-483f-a315-123b5665b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 360.40query/s]                          \n",
      "Downloading: 100%|██████████| 1/1 [00:01<00:00,  1.14s/rows]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid_pos_id</th>\n",
       "      <th>name</th>\n",
       "      <th>collaborative</th>\n",
       "      <th>pid</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>num_albums</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>...</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>album_name</th>\n",
       "      <th>pos_seed</th>\n",
       "      <th>pos_artist_name</th>\n",
       "      <th>track_uri_seed</th>\n",
       "      <th>artist_uri_seed</th>\n",
       "      <th>track_name_seed</th>\n",
       "      <th>album_uri_seed</th>\n",
       "      <th>duration_ms_seed</th>\n",
       "      <th>album_name_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11834-10</td>\n",
       "      <td>Throwback</td>\n",
       "      <td>false</td>\n",
       "      <td>11834</td>\n",
       "      <td>1499126400</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>170626.0</td>\n",
       "      <td>What Was I Thinking Of</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[Guns N' Roses, Big Sounds Band, The Bangles, ...</td>\n",
       "      <td>[spotify:track:7gXdAqJLCa5aYUeLVxosOz, spotify...</td>\n",
       "      <td>[spotify:artist:3qm84nBOXUEQ2vnTfUTTFC, spotif...</td>\n",
       "      <td>[Knockin' On Heaven's Door, Karma Chameleon (f...</td>\n",
       "      <td>[spotify:album:5NL0MCTSbQtO13G62ofWAf, spotify...</td>\n",
       "      <td>[336000.0, 237089.0, 204560.0, 238266.0, 14937...</td>\n",
       "      <td>[Use Your Illusion II, 80s Songs from the Big ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pid_pos_id       name collaborative    pid  modified_at  num_tracks  \\\n",
       "0   11834-10  Throwback         false  11834   1499126400          75   \n",
       "\n",
       "   num_albums  num_followers  num_edits  num_artists  ... duration_ms  \\\n",
       "0          70              1          7           51  ...    170626.0   \n",
       "\n",
       "               album_name                        pos_seed  \\\n",
       "0  What Was I Thinking Of  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "\n",
       "                                     pos_artist_name  \\\n",
       "0  [Guns N' Roses, Big Sounds Band, The Bangles, ...   \n",
       "\n",
       "                                      track_uri_seed  \\\n",
       "0  [spotify:track:7gXdAqJLCa5aYUeLVxosOz, spotify...   \n",
       "\n",
       "                                     artist_uri_seed  \\\n",
       "0  [spotify:artist:3qm84nBOXUEQ2vnTfUTTFC, spotif...   \n",
       "\n",
       "                                     track_name_seed  \\\n",
       "0  [Knockin' On Heaven's Door, Karma Chameleon (f...   \n",
       "\n",
       "                                      album_uri_seed  \\\n",
       "0  [spotify:album:5NL0MCTSbQtO13G62ofWAf, spotify...   \n",
       "\n",
       "                                    duration_ms_seed  \\\n",
       "0  [336000.0, 237089.0, 204560.0, 238266.0, 14937...   \n",
       "\n",
       "                                     album_name_seed  \n",
       "0  [Use Your Illusion II, 80s Songs from the Big ...  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from `hybrid-vertex.spotify_mpd.ordered_position_training` where pid_pos_id = '11834-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae928c-beeb-4704-8b18-cd31bcb16d24",
   "metadata": {},
   "source": [
    "### Run adapts, and preprocess string lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5dcb463-5b0d-45c8-8c7a-16de7a6601a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "collaborative\n",
      "pid\n",
      "description\n",
      "duration_ms_playlist\n",
      "pid_pos_id\n",
      "pos\n",
      "artist_name_seed\n",
      "track_uri_seed\n",
      "artist_uri_seed\n",
      "track_name_seed\n",
      "album_uri_seed\n",
      "duration_ms_seed\n",
      "album_name_seed\n",
      "track_pop_seed\n",
      "artist_pop_seed\n",
      "artist_genres_seed\n",
      "artist_followers_seed\n",
      "pos_seed_track\n",
      "artist_name_seed_track\n",
      "artist_uri_seed_track\n",
      "track_name_seed_track\n",
      "track_uri_seed_track\n",
      "album_name_seed_track\n",
      "album_uri_seed_track\n",
      "duration_seed_track\n",
      "duration_ms_seed_pl\n",
      "n_songs\n",
      "num_artists\n",
      "num_albums\n",
      "pos_seed_pl\n",
      "track_uri_seed_pl\n",
      "track_name_seed_pl\n",
      "duration_ms_seed_songs_pl\n",
      "album_name_seed_pl\n",
      "artist_pop_seed_pl\n",
      "artists_followers_seed_pl\n",
      "track_pop_seed_pl\n"
     ]
    }
   ],
   "source": [
    "for k in bq_2_tf_dict:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952922f-5e2c-405b-8b44-4513afb64c89",
   "metadata": {},
   "source": [
    "# Organize fields by transforms\n",
    "\n",
    "## Stringlookup get vocab \n",
    "- track_uri_seed\n",
    "- artist_uri_seed\n",
    "- album_uri_seed\n",
    "- artist_uri_seed_track\n",
    "- track_uri_seed_track\n",
    "- album_uri_seed_track\n",
    "- track_uri_seed_pl\n",
    "\n",
    "## TextVectorization (NLPish)\n",
    "- name\n",
    "- description\n",
    "- artist_name_seed\n",
    "- artist_name_seed_track\n",
    "- track_name_seed_track\n",
    "- album_name_seed_track\n",
    "- track_name_seed_pl\n",
    "- album_name_seed_pl\n",
    "- album_name_seed\n",
    "- artist_genres_seed\n",
    "\n",
    "## Rich features\n",
    "- collaborative\n",
    "- duration_ms_playlist\n",
    "- track_name_seed\n",
    "- track_pop_seed\n",
    "- artist_pop_seed\n",
    "- duration_seed_track\n",
    "#### --- playlist features\n",
    "- n_songs\n",
    "- num_artists\n",
    "- num_albums\n",
    "- duration_ms_seed_pl\n",
    "- artist_pop_seed_pl\n",
    "- artists_followers_seed_pl\n",
    "- track_pop_seed_pl\n",
    "- artist_followers_seed\n",
    "- duration_ms_seed_songs_pl\n",
    "- duration_ms_seed\n",
    "\n",
    "#not used\n",
    "#pid\n",
    "##Identifier pid_pos_id\n",
    "##POS id not used, infering order in dataset pos_seed_track\n",
    "##No POS pos_seed_pl\n",
    "#pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1484e9-fe8b-459e-905d-a4284ba96ec6",
   "metadata": {},
   "source": [
    "#### Loop over values to find uniques to save to a vocab file\n",
    "\n",
    "We will save this in `gs://spotify-assets-blog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88cf1205-d5d8-4036-97a9-9943cafc241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "vocab_lookup_feats = [\n",
    "'track_uri_seed',\n",
    "'artist_uri_seed',\n",
    "'album_uri_seed',\n",
    "# 'artist_uri_seed_track',\n",
    "# 'track_uri_seed_track',\n",
    "# 'album_uri_seed_track',\n",
    "# 'track_uri_seed_pl', # ragged playlist\n",
    "]\n",
    "\n",
    "vocab_query = [f\"select distinct {field} from `hybrid-vertex.spotify_train_3.train_flatten`\" for field in vocab_lookup_feats]\n",
    "vocab_dict = {}\n",
    "for field, query in zip(vocab_lookup_feats, vocab_query):\n",
    "    data = client.query(query).result()\n",
    "    vocab_dict.update({field: list(d[0] for d in data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83a70287-19fa-470f-9fd3-89c23f4dd78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_uri_seed counts: 2249561\n",
      "artist_uri_seed counts: 294110\n",
      "album_uri_seed counts: 730377\n"
     ]
    }
   ],
   "source": [
    "### quick counts\n",
    "\n",
    "for k in vocab_dict:\n",
    "    print(f\"{k} counts: {len(vocab_dict[k])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097bce4-6cc1-4a2e-bb1d-660f3247c602",
   "metadata": {},
   "source": [
    "### Quick query to find the max length of repeated fields\n",
    "\n",
    "Find max counts to pad ragged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cae6340-e09c-4aae-b02b-d81fe161baab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 16/16 [00:00<00:00, 7311.13query/s]                       \n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  1.01rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  341"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "with counts as (select \tpid_pos_id, count(distinct x) as distinct_counts from `hybrid-vertex.spotify_train_3.train_flatten` inner join UNNEST(track_uri_seed_pl) x group by 1)\n",
    "select max(counts.distinct_counts) from counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155efa0-b4e9-40e1-930b-b30eb6783590",
   "metadata": {},
   "source": [
    "#### Recycling Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad63a5-184e-4b2c-9f20-5eab1b6e68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function ragged_unique_collection.<locals>.<lambda> at 0x7fa7586677a0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    for x in ds.map(lambda x: x[field]).batch(1):\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function ragged_unique_collection.<locals>.<lambda> at 0x7fa7586677a0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    for x in ds.map(lambda x: x[field]).batch(1):\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14418/2703635343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrack_uri_seed_pl_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mragged_unique_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'track_uri_seed_pl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#unique values =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14418/2703635343.py\u001b[0m in \u001b[0;36mragged_unique_collection\u001b[0;34m(ds, field)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ragged_unique_collection(ds, field):\n",
    "    data = np.array([''])\n",
    "    for x in ds.map(lambda x: x[field]).batch(1):\n",
    "        y = np.unique(np.concatenate(np.concatenate(x.numpy())))\n",
    "        data = np.concatenate([data, y])\n",
    "    data = np.unique(data)\n",
    "    return(data)\n",
    "\n",
    "track_uri_seed_pl_vocab = ragged_unique_collection(dataset, 'track_uri_seed_pl') #unique values = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8c498-1d8d-4ca8-b738-99e712a62bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55c77e-438a-433e-9fb4-fa15ea0da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ee8e5-d46a-4d62-94d2-5e2d60d6d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil mb -l us-central1 gs://spotify-assets-blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117d93f-7cfd-433b-84e0-f62955f98eb5",
   "metadata": {},
   "source": [
    "### Save the arrays to google storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f3594-50ec-423a-87c1-9ffa8387f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save above arrays - use naming convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8590b-6679-49f5-9473-428663ac9ac9",
   "metadata": {},
   "source": [
    "### Text Vectorization section\n",
    "Loop over and save the layers to a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c14332-b3cd-4de9-ab93-b0a2594ba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector_feats = ['name',\n",
    "'description',\n",
    "'artist_name_seed',\n",
    "'artist_name_seed_track',\n",
    "'track_name_seed_track',\n",
    "'album_name_seed_track',\n",
    "'track_name_seed_pl',\n",
    "'album_name_seed_pl',\n",
    "'album_name_seed',\n",
    "'artist_genres_seed',\n",
    "                    ]\n",
    "\n",
    "MAX_TOKENS = 100_000\n",
    "\n",
    "vectorizors = []\n",
    "\n",
    "def create_vectorizor_layers(ds, field, n_tokens, ngrams=3):\n",
    "    name = f\"{field}-{n_tokens}-{ngrams}\"\n",
    "    tv_layer = tf.keras.layers.TextVectorization(max_tokens=n_tokens, name=name, ngrams=ngrams)\n",
    "    return(tv_layer.adapt(ds.map(lambda x: x[field]).batch(1000))\n",
    "           \n",
    "for feat in text_vector_feats:\n",
    "           vectorizors.append(create_vectorizor_layers(dataset, feat, MAX_TOKENS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf39a187-9c37-490f-b12a-c263050ff247",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d16ec-9ee3-45de-8786-cac1bd1c8cd2",
   "metadata": {},
   "source": [
    "### Create a function to process data to new ds using map - then write DS to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1c5b6-1be6-4db7-b48b-d713559c355c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d43ba5-38d8-4ba6-8ad6-cf1e7950e296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14418/2223016346.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab_lookup_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0munique_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unique_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14418/2223016346.py\u001b[0m in \u001b[0;36mget_unique_np\u001b[0;34m(ds, field)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_unique_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2608\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ### Vocab to get string lookups\n",
    "# import numpy as np\n",
    "# import keras \n",
    "\n",
    "# vocab_lookup_feats = [\n",
    "# 'track_uri_seed',\n",
    "# 'artist_uri_seed',\n",
    "# 'album_uri_seed',\n",
    "# 'artist_uri_seed_track',\n",
    "# 'track_uri_seed_track',\n",
    "# 'album_uri_seed_track',\n",
    "# # 'track_uri_seed_pl', # ragged playlist\n",
    "# ]\n",
    "\n",
    "# def get_unique_np(ds, field) -> np.array:\n",
    "#     unique = np.unique(np.concatenate(list(ds.map(lambda x: x[field]).batch(1000))))\n",
    "#     return(unique)\n",
    "\n",
    "# unique_list = []\n",
    "# for feat in vocab_lookup_feats:\n",
    "#     unique_list.append(get_unique_np(dataset, feat))\n",
    "# text_vector_feats"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
