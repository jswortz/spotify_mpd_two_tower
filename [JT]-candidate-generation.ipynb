{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23dce37d-64a0-4acd-9601-7ddcf6c25c8f",
   "metadata": {},
   "source": [
    "# Candidate Generation\n",
    "\n",
    "After Two-Tower training, the `candidate_tower` is used to convert all candidate items into embeddings.\n",
    "\n",
    "The embeddings are indexed and deployed to an endpoint for serving.\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "* `TODO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e639d9d-b580-492f-9783-076da3f31827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ef9b81-a1ea-49d1-979f-d8ba3e55adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.storage.bucket import Bucket\n",
    "from google.cloud.storage.blob import Blob\n",
    "\n",
    "import google.cloud.aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485028ff-e7a1-463a-ae3a-9ea72c39ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANDIDATE_MODEL_DIR: gs://jt-tfrs-central/new-50e-full-jtv12/run-20230110-150417/model-dir/candidate_model\n"
     ]
    }
   ],
   "source": [
    "# gs://jt-tfrs-central/pipe-dev-2tower-tfrs-jtv10/run-20221228-210041/model-dir/candidate_model/saved_model.pb\n",
    "\n",
    "BUCKET = 'jt-tfrs-central' # -v2\n",
    "BUCKET_URI = f'gs://{BUCKET}'\n",
    "\n",
    "# stable\n",
    "# CANDIDATE_MODEL_GCS_PATH = 'pipe-dev-2tower-tfrs-jtv10/run-20221228-210041/model-dir/candidate_model'\n",
    "# CANDIDATE_MODEL_GCS_PATH = 'a50-epoch/run-20221230-160518/model-dir/candidate_model'\n",
    "\n",
    "# experimental paths\n",
    "# PATH_TO_INDEX_DIR = 'eval-jtv14-full-v6-jtv14/run-20230113-192032' # 30e-8m\n",
    "# EXPERIMENT_TAG = '30e-jtv14-v6-8m'\n",
    "\n",
    "PATH_TO_INDEX_DIR = 'new-50e-full-jtv12/run-20230110-150417' # 50e-65m\n",
    "EXPERIMENT_TAG = 'demo-50e-jtv12-65m'\n",
    "\n",
    "\n",
    "# full gcs path\n",
    "CANDIDATE_MODEL_GCS_PATH = f'{PATH_TO_INDEX_DIR}/model-dir/candidate_model'\n",
    "CANDIDATE_MODEL_DIR = f'{BUCKET_URI}/{CANDIDATE_MODEL_GCS_PATH}'\n",
    "\n",
    "print(f\"CANDIDATE_MODEL_DIR: {CANDIDATE_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4761374c-ec81-4be2-aa38-ba5751609aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-tfrs-central/new-50e-full-jtv12/run-20230110-150417/model-dir/candidate_model/\n",
      "gs://jt-tfrs-central/new-50e-full-jtv12/run-20230110-150417/model-dir/candidate_model/saved_model.pb\n",
      "gs://jt-tfrs-central/new-50e-full-jtv12/run-20230110-150417/model-dir/candidate_model/assets/\n",
      "gs://jt-tfrs-central/new-50e-full-jtv12/run-20230110-150417/model-dir/candidate_model/variables/\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $CANDIDATE_MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc2140-f27d-4eca-8164-63af2294f56f",
   "metadata": {},
   "source": [
    "## Load Candidate `SavedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3886b062-b146-4be1-8884-7621de96e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:01:16.126361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 19:01:16.789738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, artist_followers_can, duration_ms_can, track_mode_can, track_key_can, album_name_can, track_acousticness_can, track_danceability_can, track_name_can, track_uri_can, artist_pop_can, track_valence_can, track_tempo_can, time_signature_can, artist_genres_can, album_uri_can, track_speechiness_can, track_liveness_can, track_pop_can, track_energy_can, artist_uri_can, artist_name_can, track_instrumentalness_can, track_loudness_can) at 0x7FA10C291F90>})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_tower_uri = f'{CANDIDATE_MODEL_DIR}' # vertex trained\n",
    "\n",
    "loaded_candidate_model = tf.saved_model.load(candidate_tower_uri)\n",
    "\n",
    "loaded_candidate_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef25c58-eb42-4f4b-a4d2-5304d371aa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded_candidate_model.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a416aead-8da1-4845-bff9-56f5dedf93ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_1': TensorSpec(shape=(None, 32), dtype=tf.float32, name='output_1')}\n"
     ]
    }
   ],
   "source": [
    "candidate_predictor = loaded_candidate_model.signatures[\"serving_default\"]\n",
    "print(candidate_predictor.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2de03c0-4fea-448e-822e-be686ca53617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': TensorShape([None, 32])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_predictor.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f25833-95b6-48b2-bb4e-0f44870ac6de",
   "metadata": {},
   "source": [
    "## Candidate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f764b-2661-4bf3-8d8a-73e95252b7fc",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302f2b08-86e4-4519-a267-9b9783142b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40a571dd-c26c-4d06-81ca-6eea6713b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = {\n",
    "    \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "    \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "    \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "    \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "    \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # new\n",
    "    # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    \"time_signature_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3811ce05-c441-4e3e-9f91-a36b432ea3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_candidate_tfrecord_fn(example):\n",
    "    \"\"\"\n",
    "    Reads candidate serialized examples from gcs and converts to tfrecord\n",
    "    \"\"\"\n",
    "    # example = tf.io.parse_single_example(\n",
    "    example = tf.io.parse_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9122a86-1659-434d-8f88-a46dbdcc1623",
   "metadata": {},
   "source": [
    "## Candidate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6fd698b-f06e-40f1-81c8-7b1f266ce297",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_FILE_DIR = 'spotify-data-regimes'\n",
    "CANDIDATE_PREFIX = 'jtv14-8m/candidates' # jtv10 | jtv14-8m\n",
    "\n",
    "# SAMPLE_FILES = [\n",
    "#     \"gs://spotify-tfrecords-blog/tfrecords_v1/train/output-00000-of-00796.tfrecord\",\n",
    "#     \"gs://spotify-tfrecords-blog/tfrecords_v1/train/output-00002-of-00796.tfrecord\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871fdb33-cdd7-490d-91f0-2fcd33819b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_files = []\n",
    "for blob in storage_client.list_blobs(f\"{CANDIDATE_FILE_DIR}\", prefix=f'{CANDIDATE_PREFIX}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "candidate_dataset = tf.data.Dataset.from_tensor_slices(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.interleave(\n",
    "    # lambda x: tf.data.TFRecordDataset(x),\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False\n",
    ").map(parse_candidate_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE).with_options(options)\n",
    "\n",
    "parsed_candidate_dataset = parsed_candidate_dataset.cache() #400 MB on machine mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4948d822-f53b-4d7b-806a-716f092ea220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4U'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:4U91uJBtdsedXEuRMjgZRP'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=28450.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'edm', 'pop dance', 'progressive house', 'progressive trance', 'trance', 'uplifting trance'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Maor Levi'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=49.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:7iVuXpgNEl87BwdwV1L6he'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=420000.0>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.000864>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.615>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.697>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.624>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'0'>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0341>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-5.563>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4U - Original Mix'>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0358>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=127.985>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:3EK4rJ1JAcqpbNN2xG5hhR'>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.301>}\n",
      "_______________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 19:01:49.277958: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for features in parsed_candidate_dataset.take(1):\n",
    "    pprint(features)\n",
    "    print(\"_______________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "699ca0eb-efe5-42fd-9190-a9ce644f06eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c9be1e7-6f44-4a7f-be4f-047da40034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dataset = tf.data.TFRecordDataset(candidate_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f8003c0-f6a8-404a-adfb-645907c4320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4U'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:4U91uJBtdsedXEuRMjgZRP'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=28450.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'edm', 'pop dance', 'progressive house', 'progressive trance', 'trance', 'uplifting trance'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Maor Levi'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=49.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:7iVuXpgNEl87BwdwV1L6he'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=420000.0>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.000864>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.615>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.697>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.624>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'0'>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0341>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-5.563>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4U - Original Mix'>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0358>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=127.985>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:3EK4rJ1JAcqpbNN2xG5hhR'>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.301>}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "# parsed_candidate_dataset_v1 = raw_dataset.map(parse_candidate_tfrecord_fn)\n",
    "\n",
    "# for features in parsed_candidate_dataset_v1.take(1):\n",
    "#     pprint(features)\n",
    "#     print(\"_______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16012fa-f9e0-433f-9b2c-ff0affbb9a15",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "* use candidate_predictor to produce embeddings for each candidate item\n",
    "* store embeddings in list\n",
    "* zip candidate embeddings and candidate IDs together\n",
    "* write json or csv file for ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "328b63a3-ddf5-4c31-9fc5-25137c3270f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jt-tfrs-central/pipe-dev-2tower-tfrs-jtv10/run-20221228-210041/candidates/candidate_embeddings.json...\n",
      "- [1 files][882.4 MiB/882.4 MiB]   68.6 MiB/s                                   \n",
      "Operation completed over 1 objects/882.4 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# previously created embedding output\n",
    "# !gsutil cp gs://jt-tfrs-central/pipe-dev-2tower-tfrs-jtv10/run-20221228-210041/candidates/candidate_embeddings.json candidate_embs_20221228_210041.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5d1b5-cac0-4261-8974-eed5d576b4fc",
   "metadata": {},
   "source": [
    "### candidate embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "882e4240-183e-4025-9f75-2a403b723c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 1\n",
      "Length of embs: 2263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(1000, 32), dtype=float32, numpy=\n",
       " array([[-2.1645777 , -0.02569133,  1.1920751 , ...,  0.86502624,\n",
       "          0.8500546 , -0.95461535],\n",
       "        [-2.4586706 ,  0.18307656,  1.631067  , ...,  0.8345346 ,\n",
       "          1.6621102 ,  0.6864418 ],\n",
       "        [-0.40462023,  0.20384306,  1.3977935 , ...,  0.48818517,\n",
       "          1.202213  , -0.55006284],\n",
       "        ...,\n",
       "        [ 1.4562918 ,  0.09062123, -1.6182501 , ..., -0.15559816,\n",
       "         -1.3291026 ,  0.05066007],\n",
       "        [ 0.8157986 , -0.8581199 , -1.3720565 , ...,  0.43869933,\n",
       "          0.01423812,  0.78625923],\n",
       "        [ 1.8851609 , -0.46664304, -0.84363604, ...,  0.15309703,\n",
       "         -0.84201324, -0.55973303]], dtype=float32)>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# embs_iter = parsed_candidate_dataset_v1.batch(1000).map(\n",
    "#     lambda data: candidate_predictor(\n",
    "#         track_uri_can = data[\"track_uri_can\"],\n",
    "#         track_name_can = data['track_name_can'],\n",
    "#         artist_uri_can = data['artist_uri_can'],\n",
    "#         artist_name_can = data['artist_name_can'],\n",
    "#         album_uri_can = data['album_uri_can'],\n",
    "#         album_name_can = data['album_name_can'],\n",
    "#         duration_ms_can = data['duration_ms_can'],\n",
    "#         track_pop_can = data['track_pop_can'],\n",
    "#         artist_pop_can = data['artist_pop_can'],\n",
    "#         artist_genres_can = data['artist_genres_can'],\n",
    "#         artist_followers_can = data['artist_followers_can'],\n",
    "#         track_danceability_can = data['track_danceability_can'],\n",
    "#         track_energy_can = data['track_energy_can'],\n",
    "#         track_key_can = data['track_key_can'],\n",
    "#         track_loudness_can = data['track_loudness_can'],\n",
    "#         track_mode_can = data['track_mode_can'],\n",
    "#         track_speechiness_can = data['track_speechiness_can'],\n",
    "#         track_acousticness_can = data['track_acousticness_can'],\n",
    "#         track_instrumentalness_can = data['track_instrumentalness_can'],\n",
    "#         track_liveness_can = data['track_liveness_can'],\n",
    "#         track_valence_can = data['track_valence_can'],\n",
    "#         track_tempo_can = data['track_tempo_can'],\n",
    "#         time_signature_can = data['time_signature_can']\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# embs = []\n",
    "# for emb in embs_iter:\n",
    "#     embs.append(emb)\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = int((end_time - start_time) / 60)\n",
    "# print(f\"elapsed_time: {elapsed_time}\")\n",
    "\n",
    "# print(f\"Length of embs: {len(embs)}\")\n",
    "# embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52540283-930f-4d04-b26b-abba3df5184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 2\n",
      "Length of embs: 2263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(1000, 32), dtype=float32, numpy=\n",
       " array([[-18.286968,  17.23571 , -19.978462, ...,  18.750835, -15.788128,\n",
       "         -15.501454],\n",
       "        [-18.57132 ,  14.503975, -20.06953 , ...,  20.857546, -17.366013,\n",
       "         -13.32492 ],\n",
       "        [-19.951595,  18.043613, -19.234167, ...,  20.239983, -16.306307,\n",
       "         -13.712457],\n",
       "        ...,\n",
       "        [-21.273186,  17.025822, -20.385431, ...,  20.012783, -15.652888,\n",
       "         -15.942813],\n",
       "        [-20.724955,  16.600971, -20.99828 , ...,  18.18766 , -15.127804,\n",
       "         -15.904375],\n",
       "        [-21.274338,  17.190042, -20.05886 , ...,  18.788134, -16.438744,\n",
       "         -16.168468]], dtype=float32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "embs_iter = parsed_candidate_dataset.batch(1).map(\n",
    "    lambda data: candidate_predictor(\n",
    "        track_uri_can = data[\"track_uri_can\"],\n",
    "        track_name_can = data['track_name_can'],\n",
    "        artist_uri_can = data['artist_uri_can'],\n",
    "        artist_name_can = data['artist_name_can'],\n",
    "        album_uri_can = data['album_uri_can'],\n",
    "        album_name_can = data['album_name_can'],\n",
    "        duration_ms_can = data['duration_ms_can'],\n",
    "        track_pop_can = data['track_pop_can'],\n",
    "        artist_pop_can = data['artist_pop_can'],\n",
    "        artist_genres_can = data['artist_genres_can'],\n",
    "        artist_followers_can = data['artist_followers_can'],\n",
    "        track_danceability_can = data['track_danceability_can'],\n",
    "        track_energy_can = data['track_energy_can'],\n",
    "        track_key_can = data['track_key_can'],\n",
    "        track_loudness_can = data['track_loudness_can'],\n",
    "        track_mode_can = data['track_mode_can'],\n",
    "        track_speechiness_can = data['track_speechiness_can'],\n",
    "        track_acousticness_can = data['track_acousticness_can'],\n",
    "        track_instrumentalness_can = data['track_instrumentalness_can'],\n",
    "        track_liveness_can = data['track_liveness_can'],\n",
    "        track_valence_can = data['track_valence_can'],\n",
    "        track_tempo_can = data['track_tempo_can'],\n",
    "        time_signature_can = data['time_signature_can']\n",
    "    )\n",
    ")\n",
    "\n",
    "embs = []\n",
    "for emb in embs_iter:\n",
    "    embs.append(emb)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_time: {elapsed_time}\")\n",
    "\n",
    "print(f\"Length of embs: {len(embs)}\")\n",
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d2a511-25bb-4a8d-8406-6cdb5e3c7e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(1000, 32), dtype=float32, numpy=\n",
       " array([[-22.484255,  16.76609 , -20.048857, ...,  18.939014, -15.826862,\n",
       "         -14.891063],\n",
       "        [-21.822483,  16.105349, -21.608675, ...,  18.199999, -15.427704,\n",
       "         -18.101727],\n",
       "        [-22.031239,  16.899841, -19.461222, ...,  20.720133, -15.775556,\n",
       "         -15.618858],\n",
       "        ...,\n",
       "        [-22.87466 ,  16.337912, -19.301922, ...,  22.696274, -15.440932,\n",
       "         -15.426448],\n",
       "        [-23.492395,  15.230312, -20.434055, ...,  21.689314, -14.461754,\n",
       "         -15.414692],\n",
       "        [-23.185263,  15.206906, -21.171255, ...,  22.503517, -14.496807,\n",
       "         -15.805237]], dtype=float32)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140400e7-8252-4120-8411-8152a88180c0",
   "metadata": {},
   "source": [
    "Clean embedding output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6969996-dcb3-4db0-ab51-915b6b985e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cleaned_embs = [x['output_1'].numpy()[0] for x in embs] #clean up the output\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dc79e64-aca5-4058-8656-99eb11477854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cleaned_embs: 2262292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-18.544695 ,  17.253334 , -20.327787 ,  22.050714 , -18.613064 ,\n",
       "       -19.057636 , -22.897966 , -18.084929 ,  19.14662  ,  18.770685 ,\n",
       "        14.877865 , -18.66579  , -15.141766 , -16.15653  ,  21.366915 ,\n",
       "       -18.90796  ,  16.964298 ,  22.686796 , -20.013926 ,  15.816182 ,\n",
       "       -18.804203 , -22.604815 ,  19.63804  ,   0.8306754, -19.153149 ,\n",
       "        19.5806   ,  18.624025 ,  18.50726  ,  19.357174 ,  18.676226 ,\n",
       "       -16.975777 , -13.846929 ], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of cleaned_embs: {len(cleaned_embs)}\")\n",
    "cleaned_embs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15ee93-725a-49df-a056-9392799282bd",
   "metadata": {},
   "source": [
    "### candidate IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fde9926-d898-49a9-bcde-1a1854c8fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of track_uris: 2262292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'spotify:track:3EK4rJ1JAcqpbNN2xG5hhR'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean product IDs\n",
    "track_uris = [x['track_uri_can'].numpy() for x in parsed_candidate_dataset]\n",
    "\n",
    "print(f\"Length of track_uris: {len(track_uris)}\")\n",
    "\n",
    "track_uris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb203cb7-1254-4257-b6be-3624885eb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of track_uris_decoded: 2262292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spotify:track:3EK4rJ1JAcqpbNN2xG5hhR'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# track_uris_cleaned = [str(z).replace(\"b'\",\"\").replace(\"'\",\"\") for z in track_uris]\n",
    "track_uris_decoded = [z.decode(\"utf-8\") for z in track_uris]\n",
    "\n",
    "print(f\"Length of track_uris_decoded: {len(track_uris_decoded)}\")\n",
    "\n",
    "track_uris_decoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36a10d13-4a0a-4550-a78d-d92489be78ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of track_uris: 2262292\n",
      "Length of track_uris_cleaned: 2262292\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of track_uris: {len(track_uris)}\")\n",
    "print(f\"Length of track_uris_cleaned: {len(track_uris_decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270376ce-3d4a-452d-97d6-d54592aebe05",
   "metadata": {},
   "source": [
    "### Check for bad records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "758258ee-6a11-4fbd-8a48-b0fffc7b6b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.544695 ,  17.253334 , -20.327787 ,  22.050714 , -18.613064 ,\n",
       "       -19.057636 , -22.897966 , -18.084929 ,  19.14662  ,  18.770685 ,\n",
       "        14.877865 , -18.66579  , -15.141766 , -16.15653  ,  21.366915 ,\n",
       "       -18.90796  ,  16.964298 ,  22.686796 , -20.013926 ,  15.816182 ,\n",
       "       -18.804203 , -22.604815 ,  19.63804  ,   0.8306754, -19.153149 ,\n",
       "        19.5806   ,  18.624025 ,  18.50726  ,  19.357174 ,  18.676226 ,\n",
       "       -16.975777 , -13.846929 ], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fe1f6f2-d35e-4823-b4cd-035805c30ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_records: 0\n",
      "bad_record_filter: 0\n"
     ]
    }
   ],
   "source": [
    "bad_records = []\n",
    "\n",
    "for i, emb in enumerate(cleaned_embs):\n",
    "    bool_emb = np.isnan(emb)\n",
    "    for val in bool_emb:\n",
    "        if val:\n",
    "            bad_records.append(i)\n",
    "            \n",
    "bad_record_filter = np.unique(bad_records)\n",
    "\n",
    "print(f\"bad_records: {len(bad_records)}\")\n",
    "print(f\"bad_record_filter: {len(bad_record_filter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21e81ff0-7ce5-45d6-a197-5f7f4cccb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_record_filter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f44d09d-09a7-4acf-a0e2-3cca80e49c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_uris_valid = []\n",
    "emb_valid = []\n",
    "\n",
    "for i, pair in enumerate(zip(track_uris_decoded, cleaned_embs)):\n",
    "    if i in bad_record_filter:\n",
    "        pass\n",
    "    else:\n",
    "        t_uri, embed = pair\n",
    "        track_uris_valid.append(t_uri)\n",
    "        emb_valid.append(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0536b04-8337-49e2-8489-0463a3b95896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.544695 ,  17.253334 , -20.327787 ,  22.050714 , -18.613064 ,\n",
       "       -19.057636 , -22.897966 , -18.084929 ,  19.14662  ,  18.770685 ,\n",
       "        14.877865 , -18.66579  , -15.141766 , -16.15653  ,  21.366915 ,\n",
       "       -18.90796  ,  16.964298 ,  22.686796 , -20.013926 ,  15.816182 ,\n",
       "       -18.804203 , -22.604815 ,  19.63804  ,   0.8306754, -19.153149 ,\n",
       "        19.5806   ,  18.624025 ,  18.50726  ,  19.357174 ,  18.676226 ,\n",
       "       -16.975777 , -13.846929 ], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed856315-b86b-48e1-a72b-2f0c812b891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2262292"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d75969dd-b96c-4c3e-9e7d-ee793dcd4a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify:track:3EK4rJ1JAcqpbNN2xG5hhR'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_uris_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ded397c-197d-42ad-873c-8ad452f09cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2262292"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(track_uris_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f184b1-9f0c-4594-924b-45a4370c3c14",
   "metadata": {},
   "source": [
    "### tmp - dealing with bad track uris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc903e-674f-4610-ac30-985ecd7dfacb",
   "metadata": {},
   "source": [
    "## Write embedding vectors to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "692c6aa5-5e50-4283-bea5-924120c7ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'local_50e_small'\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "embeddings_index_filename = f'candidate_embs_{VERSION}_{TIMESTAMP}.json'\n",
    "\n",
    "with open(f'{embeddings_index_filename}', 'w') as f:\n",
    "    for prod, emb in zip(track_uris_valid, emb_valid):\n",
    "        f.write('{\"id\":\"' + str(prod) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c575e5-21c9-4244-a4b6-92c353f1c9f7",
   "metadata": {},
   "source": [
    "## Upload json to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "173ec51a-a6c2-4a30-848e-788a854e484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX_GCS_URI: gs://jt-tfrs-central/new-50e-full-jtv12/run-20230110-150417/candidates-index-local\n",
      "DESTINATION_BLOB_NAME: candidate_embs_local_v1_50e_20230116-154747.json\n",
      "SOURCE_FILE_NAME: candidate_embs_local_v1_50e_20230116-154747.json\n"
     ]
    }
   ],
   "source": [
    "# jt-tfrs-central/pipe-dev-2tower-tfrs-jtv10/run-20221228-210041\n",
    "\n",
    "# BUCKET = 'jt-tfrs-central'\n",
    "# PATH_TO_INDEX_DIR = 'a50-epoch/run-20221230-160518'\n",
    "INDEX_GCS_URI = f'gs://{BUCKET}/{PATH_TO_INDEX_DIR}/candidates-index-small-demo'\n",
    "\n",
    "print(f\"INDEX_GCS_URI: {INDEX_GCS_URI}\")\n",
    "\n",
    "DESTINATION_BLOB_NAME = embeddings_index_filename\n",
    "SOURCE_FILE_NAME = embeddings_index_filename\n",
    "\n",
    "print(f\"DESTINATION_BLOB_NAME: {DESTINATION_BLOB_NAME}\")\n",
    "print(f\"SOURCE_FILE_NAME: {SOURCE_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0340e8e7-c29f-4d91-b1d2-6a42e57f0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = Blob.from_string(os.path.join(INDEX_GCS_URI, DESTINATION_BLOB_NAME))\n",
    "blob.bucket._client = storage_client\n",
    "blob.upload_from_filename(SOURCE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a174-af0b-4b9e-bcec-98540f3b8edb",
   "metadata": {},
   "source": [
    "# Inspect track_uris\n",
    "\n",
    "* id in the track_uri should be 22 characters (total of 36 characters including `spotify:track:`)\n",
    "* some track_uris have an id that is 21 characters long\n",
    "* these are not present in the source data (BigQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4eab8276-512d-4d93-93e7-dd160106548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of track_uris_valid: 2262292\n",
      "\n",
      "ex: track_uris_valid[0]: spotify:track:3EK4rJ1JAcqpbNN2xG5hhR\n",
      "\n",
      "length of a track_uris_valid: 36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len(track_uris_valid)\n",
    "\n",
    "print(f\"count of track_uris_valid: {len(track_uris_valid)}\\n\")\n",
    "print(f\"ex: track_uris_valid[0]: {track_uris_valid[0]}\\n\")\n",
    "print(f\"length of a track_uris_valid: {len(track_uris_valid[0])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98deb670-cc10-418c-b77a-08ea5548bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short: 0\n",
      "normal: 2262292\n",
      "long: 0\n"
     ]
    }
   ],
   "source": [
    "short = []\n",
    "normal = []\n",
    "long = []\n",
    "\n",
    "for track_id in track_uris_valid:\n",
    "    if len(track_id)==36:\n",
    "        normal.append(track_id)\n",
    "    if len(track_id)<36:\n",
    "        short.append(track_id)\n",
    "    if len(track_id)>36:\n",
    "        long.append(track_id)\n",
    "        \n",
    "print(f\"short: {len(short)}\")\n",
    "print(f\"normal: {len(normal)}\")\n",
    "print(f\"long: {len(long)}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
