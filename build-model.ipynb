{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `./two_tower_src/` for the source code and model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders==0.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "# os.environ['TF_GPU_THREAD_COUNT']='1000'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 03:18:08.994863: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-07 03:18:09.684683: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-10-07 03:18:09.684941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38238 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "\n",
    "# limiting GPU growth\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logging.info(f'detected: {len(gpus)} GPUs')\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         logging.info(e)\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from two_tower_src import two_tower as tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 47000\n",
    "train_dir = 'spotify-beam-v3'\n",
    "train_dir_prefix = 'v6/train_last_5_v2/'\n",
    "\n",
    "valid_dir = 'spotify-beam-v3'\n",
    "valid_dir_prefix = 'v6/valid_last_5/'\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    " \n",
    "\n",
    "train_files = []\n",
    "for blob in client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}', delimiter=\"/\"):\n",
    "    train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "def full_parse(data):\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)\n",
    "\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[256,128]\n",
    "with tf.device('/GPU:0'):\n",
    "    model = tt.TheTwoTowers(layer_sizes)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_emb_model\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_track_uri_emb_model\n",
      "3 n_songs_pl_emb_model\n",
      "4 n_artists_pl_emb_model\n",
      "5 n_albums_pl_emb_model\n",
      "6 artist_name_pl_emb_model\n",
      "7 track_uri_pl_emb_model\n",
      "8 track_name_pl_emb_model\n",
      "9 duration_ms_songs_pl_emb_model\n",
      "10 album_name_pl_emb_model\n",
      "11 artist_pop_pl_emb_model\n",
      "12 artists_followers_pl_emb_model\n",
      "13 track_pop_pl_emb_model\n",
      "14 artist_genres_pl_emb_model\n",
      "15 pl_cross_layer\n",
      "16 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 artist_name_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 album_name_can_emb_model\n",
      "3 artist_uri_can_emb_model\n",
      "4 track_uri_can_emb_model\n",
      "5 album_uri_can_emb_model\n",
      "6 duration_ms_can_normalized\n",
      "7 track_pop_can_normalized\n",
      "8 artist_pop_can_normalized\n",
      "9 artist_followers_can_normalized\n",
      "10 artist_genres_can_emb_model\n",
      "11 can_cross_layer\n",
      "12 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {},
   "source": [
    "### Local training for one Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d7fa66-f527-4490-a559-4c20b074d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1294/1294 [==============================] - 1217s 940ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1325798.0766 - regularization_loss: 0.0000e+00 - total_loss: 1325798.0766\n",
      "Epoch 2/10\n",
      "1294/1294 [==============================] - 1225s 946ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 35933366.7038 - regularization_loss: 0.0000e+00 - total_loss: 35933366.7038\n",
      "Epoch 3/10\n",
      "1294/1294 [==============================] - 1213s 937ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 91775936.7326 - regularization_loss: 0.0000e+00 - total_loss: 91775936.7326\n",
      "Epoch 4/10\n",
      "1294/1294 [==============================] - 1235s 954ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 150101269.9938 - regularization_loss: 0.0000e+00 - total_loss: 150101269.9938\n",
      "Epoch 5/10\n",
      "1294/1294 [==============================] - 8982s 7s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 203203202.6538 - regularization_loss: 0.0000e+00 - total_loss: 203203202.6538 - val_factorized_top_k/top_1_categorical_accuracy: 0.3376 - val_factorized_top_k/top_5_categorical_accuracy: 0.7339 - val_factorized_top_k/top_10_categorical_accuracy: 0.7596 - val_factorized_top_k/top_50_categorical_accuracy: 0.8030 - val_factorized_top_k/top_100_categorical_accuracy: 0.8169 - val_loss: 27012130.0000 - val_regularization_loss: 0.0000e+00 - val_total_loss: 27012130.0000\n",
      "Epoch 6/10\n",
      "1294/1294 [==============================] - 1231s 951ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 286480126.4544 - regularization_loss: 0.0000e+00 - total_loss: 286480126.4544\n",
      "Epoch 7/10\n",
      "1294/1294 [==============================] - 1198s 925ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 305096985.7774 - regularization_loss: 0.0000e+00 - total_loss: 305096985.7774\n",
      "Epoch 8/10\n",
      " 970/1294 [=====================>........] - ETA: 5:28 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 372118025.0433 - regularization_loss: 0.0000e+00 - total_loss: 372118025.0433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294/1294 [==============================] - 1201s 928ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 472907449.0696 - regularization_loss: 0.0000e+00 - total_loss: 472907449.0696\n",
      "Epoch 10/10\n",
      " 566/1294 [============>.................] - ETA: 11:13 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 532624057.3428 - regularization_loss: 0.0000e+00 - total_loss: 532624057.3428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292/1294 [============================>.] - ETA: 1s - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 788383480.6687 - regularization_loss: 0.0000e+00 - total_loss: 788383480.6687"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "start_time = time.time()\n",
    "with tf.device('/GPU:0'):\n",
    "    layer_history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_freq=5,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        # steps_per_epoch=2,\n",
    "        # callbacks=tensorboard_cb,\n",
    "        # verbose=0\n",
    "    )\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training for {NUM_EPOCHS} epoch\")\n",
    "accuracy = layer_history.history['val_factorized_top_k/top_1_categorical_accuracy'][-1]\n",
    "print(f\"Top 100 categorical accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 462\n"
     ]
    }
   ],
   "source": [
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"Total runtime: {runtime_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('val_factorized_top_k/top_1_categorical_accuracy', [0.3375703990459442, 0.36303529143333435]), ('val_factorized_top_k/top_5_categorical_accuracy', [0.7338976860046387, 0.6722028255462646]), ('val_factorized_top_k/top_10_categorical_accuracy', [0.7596203088760376, 0.7091684937477112]), ('val_factorized_top_k/top_50_categorical_accuracy', [0.8029807209968567, 0.7852988839149475]), ('val_factorized_top_k/top_100_categorical_accuracy', [0.8168746829032898, 0.8088387846946716]), ('val_loss', [27012130.0, 315272576.0]), ('val_regularization_loss', [0, 0]), ('val_total_loss', [27012130.0, 315272576.0])]\n"
     ]
    }
   ],
   "source": [
    "val_keys = [v for v in layer_history.history.keys() if 'val' in v]\n",
    "print([(key, layer_history.history[key]) for key in val_keys])\n",
    "                      #'val_factorized_top_k/top_1_categorical_accuracy']]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
