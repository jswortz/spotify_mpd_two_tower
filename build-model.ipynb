{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {},
   "source": [
    "# Build baseline tfrs model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders==0.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {},
   "source": [
    "## Create Small Dataset for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93457c26-5e92-4ddd-81db-824922476d73",
   "metadata": {},
   "source": [
    "### features and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a94ba1a-db9e-4416-95f8-2e1f34575d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471a3a84-c965-407e-abbe-471fb846bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_name_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'name': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'collaborative': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'n_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_artists_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_albums_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'description_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "}\n",
    "    ###ragged\n",
    "\n",
    "seq_feats = {\n",
    "    'track_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'artist_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'album_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'track_uri_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'duration_ms_songs_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artist_pop_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artists_followers_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'track_pop_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artist_genres_pl': tf.io.RaggedFeature(tf.string),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {},
   "source": [
    "### Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c78641-4f19-4033-af80-cd841b4f009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 19:17:54.972779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-09-25 19:17:54.972866: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-25 19:17:54.972897: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (september-jsw): /proc/driver/nvidia/version does not exist\n",
      "2022-09-25 19:17:54.973355: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## testing output\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "# # gs://spotify-beam-v3/v3/candidates/*.tfrecords\n",
    "\n",
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/train/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "raw_dataset = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/valid/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "raw_dataset_valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_sequence_example(\n",
    "        example, \n",
    "        context_features=cont_feats,\n",
    "        sequence_features=seq_feats\n",
    "    )\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5023e7e2-b25f-4fa0-94db-af4901925d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parsed_dataset = raw_dataset.map(parse_tfrecord)\n",
    "parsed_dataset_valid = raw_dataset_valid.map(parse_tfrecord)\n",
    "\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 375\n",
    "MAX_TOKENS = 1_000_000\n",
    "\n",
    "# gives: \n",
    "# array([[ 1,  2, -1, -1],\n",
    "#       [ 3,  4, -1, -1]], dtype=int32)\n",
    "\n",
    "def pad_up_to(t, max_in_dims=[1 ,MAX_PLAYLIST_LENGTH], constant_value=''):\n",
    "    s = tf.shape(t)\n",
    "    paddings = [[0, m-s[i]] for (i,m) in enumerate(max_in_dims)]\n",
    "    return tf.pad(t, paddings, 'CONSTANT', constant_values=constant_value)\n",
    "\n",
    "def return_padded_tensors(context, data):\n",
    "    \n",
    "        a = data['track_name_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        b = data['artist_name_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        c = data['album_name_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        d = data['track_uri_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        e = data['duration_ms_songs_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        f = data['artist_pop_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        g = data['artists_followers_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        h = data['track_pop_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        i = data['artist_genres_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        \n",
    "        padded_data = context.copy()\n",
    "        padded_data['track_name_pl'] = a\n",
    "        padded_data['artist_name_pl'] = b\n",
    "        padded_data['album_name_pl'] = c\n",
    "        padded_data['track_uri_pl'] = d\n",
    "        padded_data['duration_ms_songs_pl'] = e\n",
    "        padded_data['artist_pop_pl'] = f\n",
    "        padded_data['artists_followers_pl'] = g\n",
    "        padded_data['track_pop_pl'] = h\n",
    "        padded_data['artist_genres_pl'] = i\n",
    "        \n",
    "        return padded_data\n",
    "parsed_dataset_padded = parsed_dataset.map(return_padded_tensors)   \n",
    "parsed_dataset_padded_valid = parsed_dataset_valid.map(return_padded_tensors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b420022-53c8-464e-8306-53b0faccbb20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for features in parsed_dataset_padded_valid.skip(3).take(1):\n",
    "#     pprint(features)\n",
    "#     print(\"_______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea17604-e4e9-45fe-9a6d-804b24c72acd",
   "metadata": {},
   "source": [
    "### Candidate Track dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53680f4f-9fa4-473b-91e6-b959fa5bfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/candidates/'\n",
    "\n",
    "candidate_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "def parse_candidate_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn, num_parallel_calls=-1)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn) ### THIS NEEDS TO BE FIXED SO THE UNIQUE PRODUCT DATASET HAS THE SAME FIELD NAMES (goes thru the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78a3917-06e5-4b9b-b6e8-62ce10ea2826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'The Sound of Everything Rmx'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:4a8tMD6qq6GUuUwNae38VI'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=277649.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'downtempo', 'electronica', 'funk', 'latin alternative', 'nu jazz', 'nu-cumbia', 'trip hop', 'world'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Quantic'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=64.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:5ZMwoAjeDtLJ0XRwRTgaK8'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=267130.0>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'The Sound of Everything - Watch TV & Se\\xc3\\xb1orlobo Remix'>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=53.0>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:27CDzo2P7Mf3dKoa76tNxb'>}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "for features in parsed_candidate_dataset.take(1):\n",
    "    pprint(features)\n",
    "    print(\"_______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f134d2e-aab7-45dd-a034-778acdc13c41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vocab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9208b3-af2a-439b-bca8-f05f1bb6f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'spotify-v1'\n",
    "FILE_PATH = 'vocabs/v2_string_vocabs'\n",
    "FILE_NAME = 'string_vocabs_v1_20220924-tokens.pkl'\n",
    "DESTINATION_FILE = 'downloaded_vocabs.txt'\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "with open(f'{DESTINATION_FILE}', 'wb') as file_obj:\n",
    "    client.download_blob_to_file(\n",
    "        f'gs://{BUCKET_NAME}/{FILE_PATH}/{FILE_NAME}', file_obj)\n",
    "\n",
    "    \n",
    "with open(f'{DESTINATION_FILE}', 'rb') as pickle_file:\n",
    "    vocab_dict_load = pkl.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54730095-0e82-4aa4-b71e-4e07a83ac27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'artist_name_can', 'track_uri_can', 'artist_uri_can', 'track_name_can', 'album_uri_can', 'album_name_can', 'artist_genres_can', 'unique_pids', 'artist_name_seed_track', 'artist_uri_seed_track', 'track_name_seed_track', 'track_uri_seed_track', 'album_name_seed_track', 'album_uri_seed_track', 'artist_genres_seed_track', 'description_pl', 'artist_name_pl', 'track_uri_pl', 'track_name_pl', 'album_name_pl', 'artist_genres_pl', 'min_duration_ms_seed_pl', 'max_duration_ms_seed_pl', 'min_n_songs_pl', 'max_n_songs_pl', 'min_n_artists_pl', 'max_n_artists_pl', 'min_n_albums_pl', 'max_n_albums_pl', 'min_artist_pop', 'max_artist_pop', 'min_duration_ms_songs_pl', 'max_duration_ms_songs_pl', 'min_artist_followers', 'max_artist_followers', 'min_track_pop', 'max_track_pop', 'avg_duration_ms_seed_pl', 'var_duration_ms_seed_pl', 'avg_n_songs_pl', 'var_n_songs_pl', 'avg_n_artists_pl', 'var_n_artists_pl', 'avg_n_albums_pl', 'var_n_albums_pl', 'avg_artist_pop', 'var_artist_pop', 'avg_duration_ms_songs_pl', 'var_duration_ms_songs_pl', 'avg_artist_followers', 'var_artist_followers', 'avg_track_pop', 'var_track_pop', '20000_tokens', '50000_tokens', '100000_tokens', '250000_tokens'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1cbcc2-f54e-44a6-a52f-7d9273bf8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict_load[\"unique_pids\"])\n",
    "\n",
    "avg_duration_ms_seed_pl = 13000151.68\n",
    "var_duration_ms_seed_pl = 133092900971233.58\n",
    "vocab_dict_load['avg_duration_ms_seed_pl']=avg_duration_ms_seed_pl\n",
    "vocab_dict_load['var_duration_ms_seed_pl']=var_duration_ms_seed_pl\n",
    "\n",
    "avg_n_songs_pl = 55.21\n",
    "var_n_songs_pl = 2317.54\n",
    "vocab_dict_load['avg_n_songs_pl']=avg_n_songs_pl\n",
    "vocab_dict_load['var_n_songs_pl']=var_n_songs_pl\n",
    "\n",
    "avg_n_artists_pl = 30.56\n",
    "var_n_artists_pl = 769.26\n",
    "vocab_dict_load['avg_n_artists_pl']=avg_n_artists_pl\n",
    "vocab_dict_load['var_n_artists_pl']=var_n_artists_pl\n",
    "\n",
    "avg_n_albums_pl = 40.25\n",
    "var_n_albums_pl = 1305.54\n",
    "vocab_dict_load['avg_n_albums_pl']=avg_n_albums_pl\n",
    "vocab_dict_load['var_n_albums_pl']=var_n_albums_pl\n",
    "\n",
    "avg_artist_pop = 16.08\n",
    "var_artist_pop = 300.64\n",
    "vocab_dict_load['avg_artist_pop']=avg_artist_pop\n",
    "vocab_dict_load['var_artist_pop']=var_artist_pop\n",
    "\n",
    "avg_duration_ms_songs_pl = 234823.14\n",
    "var_duration_ms_songs_pl = 5558806228.41\n",
    "vocab_dict_load['avg_duration_ms_songs_pl']=avg_duration_ms_songs_pl\n",
    "vocab_dict_load['var_duration_ms_songs_pl']=var_duration_ms_songs_pl\n",
    "\n",
    "avg_artist_followers = 43337.77\n",
    "var_artist_followers = 377777790193.57\n",
    "vocab_dict_load['avg_artist_followers']=avg_artist_followers\n",
    "vocab_dict_load['var_artist_followers']=var_artist_followers\n",
    "\n",
    "avg_track_pop = 10.85\n",
    "var_track_pop = 202.18\n",
    "vocab_dict_load['avg_track_pop']=avg_track_pop\n",
    "vocab_dict_load['var_track_pop']=var_track_pop\n",
    "# vocab_dict_load['unique_pids_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "186a4826-a4b1-4cc3-976e-8685cc4dbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUCKET='spotify-tfrecords-blog'\n",
    "# bucket=client.bucket(BUCKET)\n",
    "# blob = bucket.blob(f'vocabs_stats/vocab_dict_{VERSION}.txt')\n",
    "# pickle_out = pkl.dumps(vocab_dict_load)\n",
    "# blob.upload_from_string(pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef10ce3-1e76-41a3-a36e-16731139a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket=client.bucket(BUCKET)  \n",
    "# blob = bucket.blob('vocabs/string_vocabs')\n",
    "# blob.upload_from_filename('string_vocabs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4de4f-7b50-4ec5-bc1a-6eee6bde3e59",
   "metadata": {},
   "source": [
    "### Test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee785672-705b-4d7e-a2b3-1f3a6a529538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_test_instancet = {\n",
    "#     'name': np.asarray([b'Best Christmas']),\n",
    "#     'collaborative': np.asarray([b'false']),\n",
    "#     'pid': np.asarray([173671]),\n",
    "#     'description_pl': np.asarray([b'test description']),\n",
    "#     'duration_ms_seed_pl': np.asarray([5458995.]),\n",
    "#     'n_songs_pl': np.asarray([58.]),\n",
    "#     'num_artists_pl': np.asarray([19.]),\n",
    "#     'num_albums_pl': np.asarray([27.]),\n",
    "#     'artist_name_pl': np.asarray([[b'Juan Luis Guerra 4.40', b'Prince Royce', b'Luis Vargas']]),\n",
    "#     'track_uri_pl': np.asarray([[b'spotify:track:1g0IBPZTRP7VYkctJ4Qafg',b'spotify:track:43wUzbYxEFoXugYkgTzMWp']]),\n",
    "#     'track_name_pl': np.asarray([[b'Lover Come Back', b'White Lightning', b'Shake Me Down']]),\n",
    "#     'duration_ms_songs_pl': np.asarray([[245888., 195709., 283906., 271475., 300373., 275173., 236145.,]]),\n",
    "#     'album_name_pl': np.asarray([[b'Silsulim', b'Sara Shara', b'Muzika Vesheket', b'Ba La Lirkod']]),\n",
    "#     'artist_pop_pl': np.asarray([[81., 81., 70., 66., 66., 66., 46., 87.]]),\n",
    "#     'artists_followers_pl': np.asarray([[3.556710e+05, 8.200000e+02, 1.510000e+02, 1.098080e+05,]]),\n",
    "#     'artist_genres_pl': np.asarray([[b\"'israeli pop', 'jewish pop'\", b\"'israeli pop', 'jewish pop'\",]]),\n",
    "#     'track_pop_pl': np.asarray([[70, 77, 50, 44, 30, 28, 15, 26, 15, 18, 46, 38,]])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7be542-9aa4-4ddf-aa7f-5abd4cde18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_test_instance = {\n",
    "#     'artist_name': np.asarray([b'Hellogoodbye']),\n",
    "#     'track_name': np.asarray([b'When We First Met']),\n",
    "#     'album_name': np.asarray([b'Would It Kill You?']),\n",
    "#     'track_uri': np.asarray([b'Ba La Lirkod']),\n",
    "#     'artist_uri': np.asarray([b'spotify:artist:6GH0NzpthMGxu1mcfAkOde']),\n",
    "#     'album_uri': np.asarray([b'spotify:album:4dHXV7pJs6d8N9ACAMzhIw']),\n",
    "#     'duration_ms': np.asarray([154813.0]),\n",
    "#     'track_pop': np.asarray([45.0]),\n",
    "#     'artist_pop': np.asarray([51.0]),\n",
    "#     'artist_followers':np.asarray([205331.0]),\n",
    "#     'artist_genres': np.asarray([b\"'neon pop punk', 'pop punk'\"]),\n",
    "#     # 'test': np.asarray([b'test'])\n",
    "# }\n",
    "\n",
    "# # candidate_test_instance = {\n",
    "# #     'artist_name': np.asarray([b'Hellogoodbye']),\n",
    "# #     'track_name': np.asarray([b'When We First Met']),\n",
    "# #     'album_name': np.asarray([b'Would It Kill You?']),\n",
    "# #     'track_uri': np.asarray([b'Ba La Lirkod']),\n",
    "# #     'artist_uri': np.asarray([b'spotify:artist:6GH0NzpthMGxu1mcfAkOde']),\n",
    "# #     'album_uri': np.asarray([b'spotify:album:4dHXV7pJs6d8N9ACAMzhIw']),\n",
    "# #     'duration_ms': np.asarray([154813.0]),\n",
    "# #     'track_pop': np.asarray([45.0]),\n",
    "# #     'artist_pop': np.asarray([51.0]),\n",
    "# #     'artist_followers':np.asarray([205331.0]),\n",
    "# #     'artist_genres': np.asarray([b\"'neon pop punk', 'pop punk'\"]),\n",
    "# #     # 'test': np.asarray([b'test'])\n",
    "# # }\n",
    "# # pprint(can_test_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a87c3d-e54f-4e2e-93aa-b2d84c4d619f",
   "metadata": {},
   "source": [
    "# Two-Tower Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0387f3f-98be-464c-b080-ff08a8b6430e",
   "metadata": {},
   "source": [
    "## Playlist (query) Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586e5b73-71d2-455a-9b5d-99175e7463f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "TOKEN_DICT = '20000_tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74c47c08-b6f6-4afb-a213-c6234ff1a2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74028"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict_load[\"name\"]\n",
    "len(vocab_dict_load[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6553e994-0c3e-4a3c-be3b-852ff3d0a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Playlist_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "\n",
    "        # ========================================\n",
    "        # non-sequence playlist features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: playlist name\n",
    "        self.pl_name_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=MAX_TOKENS, # not needed if passing vocab\n",
    "                    vocabulary=vocab_dict[TOKEN_DICT]['name'], \n",
    "                    name=\"pl_name_txt_vectorizer\", \n",
    "                    ngrams=2\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[TOKEN_DICT]['name']) + 1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_name_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"pl_name_pooling\"),\n",
    "            ], name=\"pl_name_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: collaborative\n",
    "        collaborative_vocab = np.array([b'false', b'true'])\n",
    "        \n",
    "        self.pl_collaborative_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=collaborative_vocab, \n",
    "                    mask_token=None, \n",
    "                    name=\"pl_collaborative_lookup\", \n",
    "                    output_mode='int'\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(collaborative_vocab) + 1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_collaborative_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"pl_collaborative_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: pid\n",
    "        self.pl_track_uri_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=tf.constant(vocab_dict['track_uri_can']), \n",
    "                    mask_token=None, \n",
    "                    name=\"pl_track_uri_lookup\", \n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_can'])+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_track_uri_layer\",\n",
    "                ),\n",
    "            ], name=\"pl_track_uri_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: n_songs_pl\n",
    "        # TODO: Noramlize or Descritize?\n",
    "        n_songs_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_songs_pl'], \n",
    "            vocab_dict['max_n_songs_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.n_songs_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_songs_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_songs_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_songs_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_songs_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: num_artists_pl\n",
    "        # TODO: Noramlize or Descritize?\n",
    "        n_artists_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_artists_pl'], \n",
    "            vocab_dict['max_n_artists_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.n_artists_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_artists_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_artists_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_artists_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                )\n",
    "            ], name=\"n_artists_pl_emb_model\"\n",
    "        )\n",
    "\n",
    "        # Feature: num_albums_pl\n",
    "        n_albums_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_albums_pl'], \n",
    "            vocab_dict['max_n_albums_pl'],\n",
    "            num=100\n",
    "        )\n",
    "        self.n_albums_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_albums_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_albums_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_albums_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_albums_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # sequence playlist features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_pl\n",
    "        self.artist_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['artist_name_pl'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_name_pl']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_name_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_name_pl_1d\"),\n",
    "            ], name=\"artist_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_pl\n",
    "        # 2.2M unique\n",
    "        self.track_uri_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['track_uri_can'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_can']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_uri_1d\"),\n",
    "            ], name=\"track_uri_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_pl\n",
    "        self.track_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['track_name_pl'], \n",
    "                    name=\"track_name_pl_lookup\",\n",
    "                    output_mode='int',\n",
    "                    mask_token=''\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_name_pl']) + 2, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_name_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_name_pl_1d\"),\n",
    "            ], name=\"track_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        Feature: duration_ms_songs_pl\n",
    "        duration_ms_songs_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_duration_ms_songs_pl'], \n",
    "            vocab_dict['max_duration_ms_songs_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.duration_ms_songs_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Discretization(duration_ms_songs_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(duration_ms_songs_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"duration_ms_songs_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"duration_ms_songs_pl_emb_layer_pl_1d\"),\n",
    "            ], name=\"duration_ms_songs_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_pl\n",
    "        self.album_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=tf.constant(vocab_dict['album_name_pl']), \n",
    "                    mask_token=None, \n",
    "                    name=\"album_name_pl_lookup\"\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['album_name_pl']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_name_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"album_name_pl_emb_layer_1d\"),\n",
    "            ], name=\"album_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_pop_pl\n",
    "        artist_pop_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_artist_pop'], \n",
    "            vocab_dict['max_artist_pop'], \n",
    "            num=10\n",
    "        )\n",
    "        self.artist_pop_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Discretization(artist_pop_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(artist_pop_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_pop_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_pop_1d\"),\n",
    "            ], name=\"artist_pop_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artists_followers_pl\n",
    "        artists_followers_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_artist_followers'], \n",
    "            vocab_dict['max_artist_followers'], \n",
    "            num=10\n",
    "        )\n",
    "        self.artists_followers_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Discretization(artists_followers_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(artists_followers_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artists_followers_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artists_followers_pl_1d\"),\n",
    "            ], name=\"artists_followers_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_pl\n",
    "        track_pop_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_track_pop'], \n",
    "            vocab_dict['max_track_pop'], \n",
    "            num=10\n",
    "        )\n",
    "        self.track_pop_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(dtype=tf.float32),\n",
    "                tf.keras.layers.Discretization(track_pop_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(track_pop_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_pop_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_pop_pl_1d\"),\n",
    "            ], name=\"track_pop_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_pl\n",
    "        self.artist_genres_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['artist_genres_pl'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_genres_pl']) + 2, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_genres_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_genres_pl_1d\"),\n",
    "            ], name=\"artist_genres_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # dense and cross layers\n",
    "        # ========================================\n",
    "\n",
    "        # Cross Layers\n",
    "        if USE_CROSS_LAYER:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                projection_dim=PROJECTION_DIM,\n",
    "                kernel_initializer=\"glorot_uniform\", \n",
    "                name=\"pl_cross_layer\"\n",
    "            )\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "            \n",
    "        # Dense Layers\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"pl_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda x: tf.nn.l2_normalize(\n",
    "                    x, 1, epsilon=1e-12, name=\"normalize_dense\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # ========================================\n",
    "    # call\n",
    "    # ========================================\n",
    "    def call(self, data):\n",
    "        '''\n",
    "        The call method defines what happens when\n",
    "        the model is called\n",
    "        '''\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                self.pl_name_text_embedding(data['name']),\n",
    "                self.pl_collaborative_embedding(data['collaborative']),\n",
    "                self.pl_track_uri_embedding(data[\"track_uri_can\"]),\n",
    "                self.n_songs_pl_embedding(data[\"n_songs_pl\"]),\n",
    "                self.n_artists_pl_embedding(data['num_artists_pl']),\n",
    "                self.n_albums_pl_embedding(data[\"num_albums_pl\"]),\n",
    "                \n",
    "                # sequence features\n",
    "                self.artist_name_pl_embedding(tf.reshape(data[\"artist_name_pl\"], (-1, MAX_PLAYLIST_LENGTH))), #reshape to get [BATCH, MAX_SEQ_LEN]\n",
    "                self.track_uri_pl_embedding(tf.reshape(data[\"track_uri_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.track_name_pl_embedding(tf.reshape(data[\"track_name_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.duration_ms_songs_pl_embedding(tf.reshape(data[\"duration_ms_songs_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.album_name_pl_embedding(tf.reshape(data[\"album_name_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.artist_pop_pl_embedding(tf.reshape(data[\"artist_pop_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.artists_followers_pl_embedding(tf.reshape(data[\"artists_followers_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.track_pop_pl_embedding(tf.reshape(data[\"track_pop_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.artist_genres_pl_embedding(tf.reshape(data[\"artist_genres_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "            ], axis=1)\n",
    "        \n",
    "        # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            cross_embs = self._cross_layer(all_embs)\n",
    "            return self.dense_layers(cross_embs)\n",
    "        else:\n",
    "            return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bdd6e7-9b24-4093-86b0-a98f83b58eca",
   "metadata": {},
   "source": [
    "### test playlist tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1893e877-873c-4c2b-813e-ea924b096b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_playlist_model = Playlist_Model(layer_sizes,vocab_dict_load)\n",
    "\n",
    "# test_playlist_model.pl_name_text_embedding.layers[0].adapt(parsed_dataset_padded.map(lambda x: x['name']).batch(1000))\n",
    "\n",
    "# print(\"Adapts complete for name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e66fa-c949-4d66-ba28-b941fd6efcc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Some examples below of how to access an adapted vocabulary and set to a new key in the vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d020d381-738b-4d7e-80ff-3d56c5bb701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_playlist_model.pl_name_text_embedding.layers[0].get_vocabulary()\n",
    "# vocab_dict_load['name_voacb'] = test_playlist_model.pl_name_text_embedding.layers[0].get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b87363d4-64d9-4cca-9290-b26efdfe9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.24079734  0.1194577  -0.08142745 -0.03944536 -0.08887716  0.32795066\n",
      "   0.24494015 -0.15503904  0.02241188  0.03438294  0.20871319  0.09845296\n",
      "   0.23690431  0.20039856 -0.22924335 -0.2356256  -0.00522938 -0.16336669\n",
      "   0.2380808  -0.05811491 -0.3232733   0.15906623 -0.00424974  0.06915905\n",
      "  -0.24536668 -0.1391986   0.00075336  0.23227257  0.12719238 -0.18537754\n",
      "  -0.15481274  0.17707723]\n",
      " [-0.0170152   0.06694062 -0.04195818 -0.2600624  -0.03902358  0.2861531\n",
      "   0.1142315  -0.0443344  -0.03926488 -0.11029852  0.1830542  -0.00990605\n",
      "   0.17336099  0.3026132  -0.25378898 -0.24044695  0.08462902  0.00229012\n",
      "   0.1521645  -0.1697946  -0.25478396  0.07219823  0.08132857  0.25995997\n",
      "  -0.22344042 -0.22244564  0.15991941  0.24166773 -0.0466672  -0.01871636\n",
      "  -0.34021875  0.17639256]], shape=(2, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test with the source batched datset\n",
    "batched_dataset = parsed_dataset_padded.batch(2)\n",
    "for x in batched_dataset.take(1):\n",
    "    print(test_playlist_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0be2a2-af20-47e0-8759-94a48fa6d996",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"playlist__model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pl_name_emb_model (Sequenti  (None, 32)               2368928   \n",
      " al)                                                             \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| pl_name_txt_vectorizer (Tex  (None, None)           0         |\n",
      "| tVectorization)                                               |\n",
      "|                                                               |\n",
      "| pl_name_emb_layer (Embeddin  (None, None, 32)       2368928   |\n",
      "| g)                                                            |\n",
      "|                                                               |\n",
      "| pl_name_pooling (GlobalAver  (None, 32)             0         |\n",
      "| agePooling1D)                                                 |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_collaborative_emb_model   (10, 32)                 96        \n",
      " (Sequential)                                                    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| pl_collaborative_lookup (St  (10,)                  0         |\n",
      "| ringLookup)                                                   |\n",
      "|                                                               |\n",
      "| pl_collaborative_emb_layer   (10, 32)               96        |\n",
      "| (Embedding)                                                   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_track_uri_emb_model (Seq  (10, 32)                 72393376  \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| pl_track_uri_lookup (String  (10,)                  0         |\n",
      "| Lookup)                                                       |\n",
      "|                                                               |\n",
      "| pl_track_uri_layer (Embeddi  (10, 32)               72393376  |\n",
      "| ng)                                                           |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " n_songs_pl_emb_model (Seque  (10, 32)                 3232      \n",
      " ntial)                                                          \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization (Discretizat  (10,)                  0         |\n",
      "| ion)                                                          |\n",
      "|                                                               |\n",
      "| n_songs_pl_emb_layer (Embed  (10, 32)               3232      |\n",
      "| ding)                                                         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " n_artists_pl_emb_model (Seq  (10, 32)                 3232      \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_1 (Discretiz  (10,)                  0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| n_artists_pl_emb_layer (Emb  (10, 32)               3232      |\n",
      "| edding)                                                       |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " n_albums_pl_emb_model (Sequ  (10, 32)                 3232      \n",
      " ential)                                                         \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_2 (Discretiz  (10,)                  0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| n_albums_pl_emb_layer (Embe  (10, 32)               3232      |\n",
      "| dding)                                                        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_name_pl_emb_model (S  (10, 32)                 9206752   \n",
      " equential)                                                      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| string_lookup_1 (StringLook  (10, 375)              0         |\n",
      "| up)                                                           |\n",
      "|                                                               |\n",
      "| artist_name_pl_emb_layer (E  (10, 375, 32)          9206752   |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| artist_name_pl_1d (GlobalAv  (10, 32)               0         |\n",
      "| eragePooling1D)                                               |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_uri_pl_emb_model (Seq  (10, 32)                 72393376  \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| string_lookup_2 (StringLook  (10, 375)              0         |\n",
      "| up)                                                           |\n",
      "|                                                               |\n",
      "| track_uri_pl_emb_layer (Emb  (10, 375, 32)          72393376  |\n",
      "| edding)                                                       |\n",
      "|                                                               |\n",
      "| track_uri_1d (GlobalAverage  (10, 32)               0         |\n",
      "| Pooling1D)                                                    |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_name_pl_emb_model (Se  (10, 32)                 47480160  \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| track_name_pl_lookup (Strin  (10, 375)              0         |\n",
      "| gLookup)                                                      |\n",
      "|                                                               |\n",
      "| track_name_pl_emb_layer (Em  (10, 375, 32)          47480160  |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| track_name_pl_1d (GlobalAve  (10, 32)               0         |\n",
      "| ragePooling1D)                                                |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " duration_ms_songs_pl_emb_mo  (10, 32)                 3232      \n",
      " del (Sequential)                                                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_3 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| duration_ms_songs_pl_emb_la  (10, 375, 32)          3232      |\n",
      "| yer (Embedding)                                               |\n",
      "|                                                               |\n",
      "| duration_ms_songs_pl_emb_la  (10, 32)               0         |\n",
      "| yer_pl_1d (GlobalAveragePoo                                   |\n",
      "| ling1D)                                                       |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " album_name_pl_emb_model (Se  (10, 32)                 18292032  \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| album_name_pl_lookup (Strin  (10, 375)              0         |\n",
      "| gLookup)                                                      |\n",
      "|                                                               |\n",
      "| album_name_pl_emb_layer (Em  (10, 375, 32)          18292032  |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| album_name_pl_emb_layer_1d   (10, 32)               0         |\n",
      "| (GlobalAveragePooling1D)                                      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_pop_pl_emb_model (Se  (10, 32)                 352       \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_4 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| artist_pop_pl_emb_layer (Em  (10, 375, 32)          352       |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| artist_pop_1d (GlobalAverag  (10, 32)               0         |\n",
      "| ePooling1D)                                                   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artists_followers_pl_emb_mo  (10, 32)                 352       \n",
      " del (Sequential)                                                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_5 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| artists_followers_pl_emb_la  (10, 375, 32)          352       |\n",
      "| yer (Embedding)                                               |\n",
      "|                                                               |\n",
      "| artists_followers_pl_1d (Gl  (10, 32)               0         |\n",
      "| obalAveragePooling1D)                                         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_pop_pl_emb_model (Seq  (10, 32)                 352       \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_6 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| track_pop_pl_emb_layer (Emb  (10, 375, 32)          352       |\n",
      "| edding)                                                       |\n",
      "|                                                               |\n",
      "| track_pop_pl_1d (GlobalAver  (10, 32)               0         |\n",
      "| agePooling1D)                                                 |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_genres_pl_emb_model   (10, 32)                 1260768   \n",
      " (Sequential)                                                    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| flatten (Flatten)         (10, 375)                 0         |\n",
      "|                                                               |\n",
      "| string_lookup_3 (StringLook  (10, 375)              0         |\n",
      "| up)                                                           |\n",
      "|                                                               |\n",
      "| artist_genres_pl_emb_layer   (10, 375, 32)          1260768   |\n",
      "| (Embedding)                                                   |\n",
      "|                                                               |\n",
      "| artist_genres_pl_1d (Global  (10, 32)               0         |\n",
      "| AveragePooling1D)                                             |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_cross_layer (Cross)      multiple                  5280      \n",
      "                                                                 \n",
      " pl_dense_layers (Sequential  (10, 32)                 32864     \n",
      " )                                                               \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| dense (Dense)             (10, 64)                  30784     |\n",
      "|                                                               |\n",
      "| dropout (Dropout)         (10, 64)                  0         |\n",
      "|                                                               |\n",
      "| dense_1 (Dense)           (10, 32)                  2080      |\n",
      "|                                                               |\n",
      "| lambda (Lambda)           (10, 32)                  0         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 223,447,616\n",
      "Trainable params: 223,447,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_playlist_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede145f9-1973-4261-8d98-c2429857b125",
   "metadata": {},
   "source": [
    "## Track (candidate) Tower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f92c564e-e5e4-43b0-a011-fd4355555c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "\n",
    "# candidate_test_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9345cb95-f44f-4437-8ffa-d1670b30da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidate_Track_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ========================================\n",
    "        # Candidate features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_can\n",
    "        self.artist_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=MAX_TOKENS,\n",
    "                    vocabulary=vocab_dict[TOKEN_DICT][\"artist_name_can\"],\n",
    "                    name=\"artist_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[TOKEN_DICT][\"artist_name_can\"])+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_name_can_pooling\"),\n",
    "            ], name=\"artist_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_can\n",
    "        self.track_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=MAX_TOKENS,\n",
    "                    vocabulary=vocab_dict[TOKEN_DICT][\"track_name_can\"],\n",
    "                    name=\"track_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[TOKEN_DICT][\"track_name_can\"])+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"track_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_name_can_pooling\"),\n",
    "            ], name=\"track_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_can\n",
    "        self.album_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=MAX_TOKENS,\n",
    "                    vocabulary=vocab_dict[TOKEN_DICT][\"album_name_can\"],\n",
    "                    name=\"album_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[TOKEN_DICT][\"album_name_can\"])+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"album_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"album_name_can_pooling\"),\n",
    "            ], name=\"album_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_uri_can\n",
    "        self.artist_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=200_000+1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"artist_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_can\n",
    "        self.track_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=200_000+1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"track_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_uri_can\n",
    "        self.album_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=200_000+1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"album_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: duration_ms_can\n",
    "        self.duration_ms_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_duration_ms_songs_pl'],\n",
    "            variance=vocab_dict['var_duration_ms_songs_pl'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_can\n",
    "        self.track_pop_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_track_pop'],\n",
    "            variance=vocab_dict['var_track_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_pop_can\n",
    "        self.artist_pop_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_pop'],\n",
    "            variance=vocab_dict['var_artist_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_followers_can\n",
    "        self.artist_followers_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_followers'],\n",
    "            variance=vocab_dict['var_artist_followers'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_can\n",
    "        self.artist_genres_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=MAX_TOKENS,\n",
    "                    vocabulary=vocab_dict[TOKEN_DICT][\"artist_genres_can\"],\n",
    "                    name=\"artist_genres_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[TOKEN_DICT][\"artist_genres_can\"])+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_genres_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_genres_can_pooling\"),\n",
    "            ], name=\"artist_genres_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # Dense & Cross Layers\n",
    "        # ========================================\n",
    "        \n",
    "        # Cross Layers\n",
    "        if USE_CROSS_LAYER:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                projection_dim=PROJECTION_DIM,\n",
    "                kernel_initializer=\"glorot_uniform\", \n",
    "                name=\"can_cross_layer\"\n",
    "            )\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "        \n",
    "        # Dense Layer\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"candidate_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    # ========================================\n",
    "    # Call Function\n",
    "    # ========================================\n",
    "            \n",
    "    def call(self, data):\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                self.artist_name_can_text_embedding(data['artist_name_can']),  \n",
    "                self.track_name_can_text_embedding(data['track_name_can']),  \n",
    "                self.album_name_can_text_embedding(data['album_name_can']),  \n",
    "                self.artist_uri_can_embedding(data['artist_uri_can']),  \n",
    "                self.track_uri_can_embedding(data['track_uri_can']),  \n",
    "                self.album_uri_can_embedding(data['album_uri_can']),  \n",
    "                tf.reshape(self.duration_ms_can_normalized(data[\"duration_ms_can\"]), (-1, 1)), \n",
    "                tf.reshape(self.track_pop_can_normalized(data[\"track_pop_can\"]), (-1, 1)),  \n",
    "                tf.reshape(self.artist_pop_can_normalized(data[\"artist_pop_can\"]), (-1, 1)),  \n",
    "                tf.reshape(self.artist_followers_can_normalized(data[\"artist_followers_can\"]), (-1, 1)),  \n",
    "                self.artist_genres_can_text_embedding(data['album_uri_can']),  \n",
    "            ], axis=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # return self.dense_layers(all_embs)\n",
    "                # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            cross_embs = self._cross_layer(all_embs)\n",
    "            return self.dense_layers(cross_embs)\n",
    "        else:\n",
    "            return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545f0aa-ffe7-4f7b-85fd-890aa596aae8",
   "metadata": {},
   "source": [
    "### Candidate model\n",
    "Note adapts are done on the unique candidate dataset to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01b52944-7db2-4a41-95ff-602b97f35345",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_can_track_model = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "\n",
    "#adapts\n",
    "# test_can_track_model.artist_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_name_can']).batch(1000))\n",
    "# test_can_track_model.track_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['track_name_can']).batch(1000))\n",
    "# test_can_track_model.album_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['album_name_can']).batch(1000))\n",
    "# test_can_track_model.artist_genres_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_genres_can']).batch(1000))\n",
    "\n",
    "# can_result = test_can_track_model([candidate_test_instance])\n",
    "\n",
    "# print(f\"Shape of can_result: {can_result.shape}\")\n",
    "# can_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7295b620-60aa-42e5-a46d-fc497e15c5c6",
   "metadata": {},
   "source": [
    "## Validate the output in a small batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02d1c46d-a143-4269-828d-04df1f9d1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0964616e-01 -2.0273963e-01 -1.6171724e-01  4.1036580e-02\n",
      "   2.2482567e-02 -3.8034260e-01 -1.2404062e-01  1.8046717e-01\n",
      "  -5.7641275e-02  3.4220837e-02  3.6167437e-01  2.3731464e-01\n",
      "  -1.6525175e-01 -2.0938483e-01 -2.0903079e-01 -2.3419552e-01\n",
      "   4.7581303e-01  6.9526576e-02  8.9940511e-02 -4.5503274e-01\n",
      "   2.7845639e-01 -4.5115960e-01  2.6341677e-03  4.0934753e-01\n",
      "  -4.0826166e-01 -4.3676198e-02  7.9480290e-02  4.9368612e-02\n",
      "  -5.0574541e-04  3.0065373e-02  7.9911485e-02 -2.4642922e-01]\n",
      " [ 8.6540654e-02 -2.6987299e-01 -2.1784680e-01  8.6919129e-02\n",
      "   6.7914426e-02  1.3308555e-02  1.9345397e-01  8.5098863e-02\n",
      "   9.7315006e-02  2.4139276e-01  3.7444821e-01 -7.1457073e-02\n",
      "  -6.0909495e-02 -4.6696588e-03  3.8654145e-02 -2.3778360e-01\n",
      "  -9.1306038e-02 -4.4441041e-02  2.1198118e-01 -1.7389628e-01\n",
      "  -3.7855703e-01 -4.9127266e-01 -2.6902246e-01  2.6790175e-01\n",
      "  -2.9841387e-01 -6.1379880e-02 -3.1172809e-01 -1.7677441e-02\n",
      "  -2.4390560e-01  2.2383888e-01  7.3229986e-01  4.4219978e-02]], shape=(2, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test with the source batched datset and candidate dataset\n",
    "batched_dataset = parsed_candidate_dataset.batch(2)\n",
    "for x in batched_dataset.take(1):\n",
    "    print(test_can_track_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7e41a-88f2-4fd5-9d14-910f3f611dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_can_track_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4634b4-5fc8-4bb2-9257-6ab6d5651359",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e03ddde4-dd1c-402d-a5ff-d7907b1ed3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class TheTwoTowers(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, layer_sizes, vocab_dict_load):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.query_tower = Playlist_Model(layer_sizes, vocab_dict_load)\n",
    "        \n",
    "        self.candidate_tower = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "        \n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=parsed_candidate_dataset.batch(128).cache().map(self.candidate_tower)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, data, training=False):\n",
    "        query_embeddings = self.query_tower(data)\n",
    "        candidate_embeddings = self.candidate_tower(data)\n",
    "\n",
    "        return self.task(\n",
    "            query_embeddings, \n",
    "            candidate_embeddings, \n",
    "            compute_metrics=not training\n",
    "        ) # turn off metrics to save time on training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b73c7d-dd79-45f1-b6cf-5af1338bcd23",
   "metadata": {},
   "source": [
    "### This section is used to adapt the data over multiple max-token configs\n",
    "Only run this once then save the adapted vocabularies to gcs so the model trains faster and adapts no lonter are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "356a6481-42d2-4a75-a135-951e5ed40ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_tokens) -> TheTwoTowers: \n",
    "    layer_sizes=[64,32]\n",
    "    global MAX_TOKENS #set global for the init \n",
    "    MAX_TOKENS = max_tokens\n",
    "    model = TheTwoTowers(layer_sizes, vocab_dict_load)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))\n",
    "    mt_confirm = model.query_tower.pl_name_text_embedding.layers[0].get_config()['max_tokens'] #confirm the setting takes place\n",
    "    assert mt_confirm == max_tokens\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292317b4-fb6b-471e-87a6-bf0d7b47d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test it out\n",
    "model = create_model(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d05a9a9a-e09f-49b1-923b-046d3d5e9c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate max tokens are set properly in the layer config\n",
    "model.query_tower.pl_name_text_embedding.layers[0].get_config()['max_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "383fd640-739d-477c-a452-3cc4934987db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in place function to adapt the text vectorizors. This will set the vocabulary in the layer as a list of tokens\n",
    "def adapt_text_vectorizors(model) -> None:\n",
    "    #do the adapts\n",
    "    model.query_tower.pl_name_text_embedding.layers[0].adapt(parsed_dataset_padded.map(lambda x: x['name']).batch(10_000))\n",
    "    print(\"Adapts for name complete\")\n",
    "    model.candidate_tower.artist_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_name_can']).batch(10_000))\n",
    "    print(\"Adapts for artist_name_can complete\")\n",
    "    model.candidate_tower.track_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['track_name_can']).batch(10_000))\n",
    "    print(\"Adapts for track_name_can complete\")\n",
    "    model.candidate_tower.album_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['album_name_can']).batch(10_000))\n",
    "    print(\"Adapts for album_name_can complete\")\n",
    "    model.candidate_tower.artist_genres_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_genres_can']).batch(10_000))\n",
    "    print(\"Adapts for artist_genres_can complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1db9af19-9d67-420f-8c9f-2055c48acd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vocab_dict(model) -> dict:\n",
    "    #get the dictionaries from the adapted layers\n",
    "    pl_name_text_vocab = model.query_tower.pl_name_text_embedding.layers[0].get_vocabulary()\n",
    "    artist_name_can_vocab = model.candidate_tower.artist_name_can_text_embedding.layers[0].get_vocabulary()\n",
    "    album_name_can_vocab = model.candidate_tower.album_name_can_text_embedding.layers[0].get_vocabulary()\n",
    "    artist_genres_can_vocab = model.candidate_tower.artist_genres_can_text_embedding.layers[0].get_vocabulary()\n",
    "    track_name_can_vocab = model.candidate_tower.track_name_can_text_embedding.layers[0].get_vocabulary()\n",
    "    #create a new dictionary for the adapted vocabularies\n",
    "    vocab_dict = {}\n",
    "    vocab_dict[f\"{MAX_TOKENS}_tokens\"] = {'name':[], 'artist_name_can': [], 'album_name_can': [], 'artist_genres_can': []}\n",
    "    vocab_dict[f\"{MAX_TOKENS}_tokens\"].update({\"name\": pl_name_text_vocab})\n",
    "    vocab_dict[f\"{MAX_TOKENS}_tokens\"].update({\"artist_name_can\": artist_name_can_vocab})\n",
    "    vocab_dict[f\"{MAX_TOKENS}_tokens\"].update({\"album_name_can\": album_name_can_vocab})\n",
    "    vocab_dict[f\"{MAX_TOKENS}_tokens\"].update({\"artist_genres_can\": artist_genres_can_vocab})\n",
    "    vocab_dict[f\"{MAX_TOKENS}_tokens\"].update({\"track_name_can\": track_name_can_vocab})\n",
    "    return(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66839355-043d-41ae-a51a-d10cce4b4d7c",
   "metadata": {},
   "source": [
    "### Now call all of the functions in a loop of desired n_tokens \n",
    "This is all to compute only one time and subsequently leverage the vocabularies generated\n",
    "\n",
    "Note it may be good practice to `.pop` undesired keys from the dictionary to preserve memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "660de637-1376-43a7-8593-3b7e02c371df",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_list = [20_000, 50_000, 100_000, 250_000]\n",
    "\n",
    "def adapt_loop(mt) -> dict:\n",
    "    model = create_model(max_tokens=mt)\n",
    "    adapt_text_vectorizors(model)\n",
    "    vocab_dict = update_vocab_dict(model)\n",
    "    return(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359aba4c-dde7-4ce8-b4fa-a6420c78eef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapts for name complete\n",
      "Adapts for artist_name_can complete\n",
      "Adapts for track_name_can complete\n",
      "Adapts for album_name_can complete\n",
      "Adapts for artist_genres_can complete\n",
      "Adapts for name complete\n",
      "Adapts for artist_name_can complete\n",
      "Adapts for track_name_can complete\n",
      "Adapts for album_name_can complete\n",
      "Adapts for artist_genres_can complete\n",
      "Adapts for track_name_can complete\n",
      "Adapts for album_name_can complete\n",
      "Adapts for artist_genres_can complete\n"
     ]
    }
   ],
   "source": [
    "#run thru the loop and do the adapts, re-creating the model each time - research todo - subsetting larger adapts??\n",
    "for max_token in max_token_list:\n",
    "    incremental_vocab = adapt_loop(max_token)\n",
    "    vocab_dict_load.update(incremental_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ec44804-2750-44f9-bd96-c51bd60c22ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'artist_name_can', 'track_uri_can', 'artist_uri_can', 'track_name_can', 'album_uri_can', 'album_name_can', 'artist_genres_can', 'unique_pids', 'artist_name_seed_track', 'artist_uri_seed_track', 'track_name_seed_track', 'track_uri_seed_track', 'album_name_seed_track', 'album_uri_seed_track', 'artist_genres_seed_track', 'description_pl', 'artist_name_pl', 'track_uri_pl', 'track_name_pl', 'album_name_pl', 'artist_genres_pl', 'min_duration_ms_seed_pl', 'max_duration_ms_seed_pl', 'min_n_songs_pl', 'max_n_songs_pl', 'min_n_artists_pl', 'max_n_artists_pl', 'min_n_albums_pl', 'max_n_albums_pl', 'min_artist_pop', 'max_artist_pop', 'min_duration_ms_songs_pl', 'max_duration_ms_songs_pl', 'min_artist_followers', 'max_artist_followers', 'min_track_pop', 'max_track_pop', 'avg_duration_ms_seed_pl', 'var_duration_ms_seed_pl', 'avg_n_songs_pl', 'var_n_songs_pl', 'avg_n_artists_pl', 'var_n_artists_pl', 'avg_n_albums_pl', 'var_n_albums_pl', 'avg_artist_pop', 'var_artist_pop', 'avg_duration_ms_songs_pl', 'var_duration_ms_songs_pl', 'avg_artist_followers', 'var_artist_followers', 'avg_track_pop', 'var_track_pop', '20000_tokens', '50000_tokens', '100000_tokens', '250000_tokens'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3852a-ccf0-4c7b-ab1d-66d133bd051e",
   "metadata": {},
   "source": [
    "## Upload new adapts for use in training\n",
    "\n",
    "Notice the new keys `20000_tokens`, `50000_tokens`, `100000_tokens`, `250000_tokens` tokens. Each one of these dictionaries inside the original dictionary are available and should be used as vocabularies based on the number of tokens. Note each used `ngrams=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3baa2eeb-eff4-470b-a2f1-7c2b77292c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'of', 'a']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"][\"album_name_can\"][:5] #example access and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a1d91c-8634-4a75-949f-7190f00152f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional - update vocab files after adapts\n",
    "\n",
    "BUCKET_NAME = 'spotify-v1'\n",
    "FILE_PATH = 'vocabs/v2_string_vocabs'\n",
    "FILE_NAME = 'string_vocabs_v1_20220924-tokens21.pkl'\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "with open(f'{FILE_NAME}', 'wb') as pickle_file:\n",
    "    pkl.dump(vocab_dict_load, pickle_file, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e88a4-d989-4e74-82bb-780ad8c9b346",
   "metadata": {},
   "source": [
    "### Upload the new vocabulary to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "939085d7-7aa4-4065-b736-278d89c8d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string_vocabs_v1_20220924-tokens.pkl uploaded to gs://vocabs/v2_string_vocabs/string_vocabs_v1_20220924-tokens.pkl/vocabs/v2_string_vocabs\n"
     ]
    }
   ],
   "source": [
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(FILE_PATH + \"/\" + FILE_NAME)\n",
    "blob.upload_from_filename(FILE_NAME)\n",
    "\n",
    "print(f\"{FILE_NAME} uploaded to gs://{blob.name}/{FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca457e4-9cad-4463-8209-29f81781b1d1",
   "metadata": {},
   "source": [
    "#### End of Adapt Section\n",
    "\n",
    "## Training Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheTwoTowers(layer_sizes, vocab_dict_load)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_emb_model\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_track_uri_emb_model\n",
      "3 n_songs_pl_emb_model\n",
      "4 n_artists_pl_emb_model\n",
      "5 n_albums_pl_emb_model\n",
      "6 artist_name_pl_emb_model\n",
      "7 track_uri_pl_emb_model\n",
      "8 track_name_pl_emb_model\n",
      "9 duration_ms_songs_pl_emb_model\n",
      "10 album_name_pl_emb_model\n",
      "11 artist_pop_pl_emb_model\n",
      "12 artists_followers_pl_emb_model\n",
      "13 track_pop_pl_emb_model\n",
      "14 artist_genres_pl_emb_model\n",
      "15 pl_cross_layer\n",
      "16 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 artist_name_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 album_name_can_emb_model\n",
      "3 artist_uri_can_emb_model\n",
      "4 track_uri_can_emb_model\n",
      "5 album_uri_can_emb_model\n",
      "6 normalization_4\n",
      "7 normalization_5\n",
      "8 normalization_6\n",
      "9 normalization_7\n",
      "10 artist_genres_can_emb_model\n",
      "11 can_cross_layer\n",
      "12 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {},
   "source": [
    "# Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "864281ee-f760-4b20-aacc-0b6f0e0ea5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffle_train = parsed_dataset_padded.shuffle(10_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "TRAIN = shuffle_train.batch(128)\n",
    "VALID = parsed_dataset_padded_valid.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d2320-28ac-4292-83fd-503191830179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 46s 215ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 625.1274 - regularization_loss: 0.0000e+00 - total_loss: 625.1274"
     ]
    }
   ],
   "source": [
    "import time    \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "layer_history = model.fit(\n",
    "    TRAIN,\n",
    "    validation_data=VALID,\n",
    "    # validation_freq=5,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # callbacks=tensorboard_cb,\n",
    "    # verbose=1\n",
    ")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training for {NUM_EPOCHS} epoch, ran for: {train_time:.0} seconds\")\n",
    "accuracy = layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top 100 categorical accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a280c-998a-4d8f-801e-33a7baa8192c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Local Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86789b-1a89-4944-8075-3c08eae90def",
   "metadata": {},
   "source": [
    "## Loading SavedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "2d344efa-cf6f-42dc-a336-34d6f36c740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_tower_uri = 'gs://spotify-tfrs-dir/v2/run-20220920-210334/candidate_tower'\n",
    "loaded_candidate_model = tf.saved_model.load(candidate_tower_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412c459-2203-42f3-b2e4-8da74ba01e64",
   "metadata": {},
   "source": [
    "### Candidate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c50049b0-5c34-49ff-8e94-d8569b0c5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded_candidate_model.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "3a667320-922d-4120-bdbf-9bec2c84ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_1': TensorSpec(shape=(None, 32), dtype=tf.float32, name='output_1')}\n"
     ]
    }
   ],
   "source": [
    "infer = loaded_candidate_model.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "39c74e86-8f4b-46f5-8309-30861a824975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, album_name_can, album_uri_can, artist_followers_can, artist_genres_can, artist_name_can, artist_pop_can, artist_uri_can, duration_ms_can, track_name_can, track_pop_can, track_uri_can) at 0x7F1A85BA2C10>})\n"
     ]
    }
   ],
   "source": [
    "loaded_candidate_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "8e58f5f2-4c8a-4d51-8651-1d3956f13825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': TensorShape([None, 32])}"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 = loaded_candidate_model.signatures['serving_default']\n",
    "predict2.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "953a9df6-39c6-4399-832e-2b629371f8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "2680e5fd-63f4-4b44-8004-6a5020d28120",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_iter = parsed_candidate_dataset.batch(1).map(\n",
    "    lambda data: predict2(\n",
    "        artist_name_can = data[\"artist_name_can\"],\n",
    "        track_name_can = data['track_name_can'],\n",
    "        album_name_can = data['album_name_can'],\n",
    "        track_uri_can = data['track_uri_can'],\n",
    "        artist_uri_can = data['artist_uri_can'],\n",
    "        album_uri_can = data['album_uri_can'],\n",
    "        duration_ms_can = data['duration_ms_can'],\n",
    "        track_pop_can = data['track_pop_can'],\n",
    "        artist_pop_can = data['artist_pop_can'],\n",
    "        artist_followers_can = data['artist_followers_can'],\n",
    "        artist_genres_can = data['artist_genres_can']\n",
    "    )\n",
    ")\n",
    "\n",
    "embs = []\n",
    "for emb in embs_iter:\n",
    "    embs.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "9094ab59-3c1c-4d7b-8a27-6f4bf1964816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embs: 166827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[ 0.32745814,  0.15835902, -0.62232316, -0.18282643,  0.05425396,\n",
       "          0.08093273, -0.36878368, -0.6777717 , -0.28926852, -0.44578883,\n",
       "          0.03769037,  0.2013096 ,  0.01650199, -0.38547963, -0.2734376 ,\n",
       "          0.16123655,  0.12652676, -0.09455037,  0.3709236 , -0.04336764,\n",
       "         -0.20310198,  0.21418957, -0.44912496, -0.16798183, -0.21492694,\n",
       "          0.04033846,  0.14083184,  0.25597924,  0.20490994,  0.18837534,\n",
       "         -0.15261272,  0.06471566]], dtype=float32)>}"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of embs: {len(embs)}\")\n",
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "48a0b07d-182b-46f6-af30-649a40930d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cleaned_embs: 166827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.32745814,  0.15835902, -0.62232316, -0.18282643,  0.05425396,\n",
       "        0.08093273, -0.36878368, -0.6777717 , -0.28926852, -0.44578883,\n",
       "        0.03769037,  0.2013096 ,  0.01650199, -0.38547963, -0.2734376 ,\n",
       "        0.16123655,  0.12652676, -0.09455037,  0.3709236 , -0.04336764,\n",
       "       -0.20310198,  0.21418957, -0.44912496, -0.16798183, -0.21492694,\n",
       "        0.04033846,  0.14083184,  0.25597924,  0.20490994,  0.18837534,\n",
       "       -0.15261272,  0.06471566], dtype=float32)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_embs = [x['output_1'].numpy()[0] for x in embs] #clean up the output\n",
    "\n",
    "print(f\"Length of cleaned_embs: {len(cleaned_embs)}\")\n",
    "cleaned_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "27178db5-2a2c-4e86-9be2-97b2265ac114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'spotify:track:6KhJeYLg1AimCQjH6ii1Al'"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean product IDs\n",
    "track_uris = [x['track_uri_can'].numpy() for x in parsed_candidate_dataset]\n",
    "track_uris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1df48335-27d6-4c6a-969a-2df1412ac466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'spotify:track:6KhJeYLg1AimCQjH6ii1Al'"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_uris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "5b43b165-8992-4e9e-96a3-5753d860d661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify:track:6KhJeYLg1AimCQjH6ii1Al'"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_uris_cleaned = [str(z).replace(\"b'\",\"\").replace(\"'\",\"\") for z in track_uris]\n",
    "track_uris_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "3b6d3cf5-4a4d-4295-a371-d34bc0fef9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of track_uris: 166827\n",
      "Length of track_uris_cleaned: 166827\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of track_uris: {len(track_uris)}\")\n",
    "print(f\"Length of track_uris_cleaned: {len(track_uris_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677bd2b-d8d6-4697-a1b0-62c68749f63d",
   "metadata": {},
   "source": [
    "### Write Index Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "61178306-29e1-4d70-90b9-669e0a7a476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'local-v1'\n",
    "TIMESTAMP = '092022'\n",
    "\n",
    "embeddings_index_filename = f'candidate_embeddings_{VERSION}_{TIMESTAMP}.json'\n",
    "\n",
    "with open(f'{embeddings_index_filename}', 'w') as f:\n",
    "    for prod, emb in zip(track_uris_cleaned, cleaned_embs):\n",
    "        f.write('{\"id\":\"' + str(prod) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "1a772d6a-000b-468a-a7ad-5cacebf31889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('candidate_embeddings_local-v1_092022.json', 'r') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5e34d-8bdf-46af-b39f-63f6d5caa695",
   "metadata": {},
   "source": [
    "### Query Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "b3eb27dd-a85f-4970-be5b-2971607afdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tower_uri = 'gs://spotify-tfrs-dir/v2/run-20220920-210334/query_tower'\n",
    "loaded_query_model = tf.saved_model.load(query_tower_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "4c85d98c-cb52-48e8-8c72-69d46a1b0c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, album_name_can, album_name_pl, album_name_seed_track, album_uri_can, album_uri_seed_track, artist_followers_can, artist_followers_seed_track, artist_genres_can, artist_genres_pl, artist_genres_seed_track, artist_name_can, artist_name_pl, artist_name_seed_track, artist_pop_can, artist_pop_pl, artist_pop_seed_track, artist_uri_can, artist_uri_seed_track, artists_followers_pl, collaborative, description_pl, duration_ms_can, duration_ms_seed_pl, duration_ms_songs_pl, duration_seed_track, n_songs_pl, name, num_albums_pl, num_artists_pl, pid, pos_seed_track, track_name_can, track_name_pl, track_name_seed_track, track_pop_can, track_pop_pl, track_pop_seed_track, track_uri_can, track_uri_pl, track_uri_seed_track) at 0x7F1935582D50>})"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_query_model.signatures"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
