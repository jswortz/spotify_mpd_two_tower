{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {},
   "source": [
    "# Build baseline tfrs model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders==0.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {},
   "source": [
    "## Create Small Dataset for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93457c26-5e92-4ddd-81db-824922476d73",
   "metadata": {},
   "source": [
    "### features and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a94ba1a-db9e-4416-95f8-2e1f34575d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_features = {\n",
    "        'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471a3a84-c965-407e-abbe-471fb846bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # 'pos_seed_track': tf.io.FixedLenFeature(dtype=tf.int64, shape=()),\n",
    "    'track_name_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_seed_track': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_seed_track': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    # 'pid': tf.io.FixedLenFeature(dtype=tf.int64, shape=()),\n",
    "    'name': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'collaborative': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    # 'duration_ms_seed_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'n_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_artists_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_albums_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'description_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "}\n",
    "    ###ragged\n",
    "\n",
    "seq_feats = {\n",
    "    'track_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'artist_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'album_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'track_uri_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'duration_ms_songs_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artist_pop_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artists_followers_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'track_pop_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artist_genres_pl': tf.io.RaggedFeature(tf.string),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {},
   "source": [
    "### Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10c78641-4f19-4033-af80-cd841b4f009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing output\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "# # gs://spotify-beam-v3/v3/candidates/*.tfrecords\n",
    "\n",
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/train/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "raw_dataset = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/valid/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "raw_dataset_valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_sequence_example(\n",
    "        example, \n",
    "        context_features=cont_feats,\n",
    "        sequence_features=seq_feats\n",
    "    )\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5023e7e2-b25f-4fa0-94db-af4901925d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parsed_dataset = raw_dataset.map(parse_tfrecord)\n",
    "parsed_dataset_valid = raw_dataset_valid.map(parse_tfrecord)\n",
    "\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 375\n",
    "MAX_TOKENS = 1_000_000\n",
    "\n",
    "# gives: \n",
    "# array([[ 1,  2, -1, -1],\n",
    "#       [ 3,  4, -1, -1]], dtype=int32)\n",
    "\n",
    "def pad_up_to(t, max_in_dims=[1 ,MAX_PLAYLIST_LENGTH], constant_value=''):\n",
    "    s = tf.shape(t)\n",
    "    paddings = [[0, m-s[i]] for (i,m) in enumerate(max_in_dims)]\n",
    "    return tf.pad(t, paddings, 'CONSTANT', constant_values=constant_value)\n",
    "\n",
    "def return_padded_tensors(context, data):\n",
    "    \n",
    "        a = data['track_name_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        b = data['artist_name_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        c = data['album_name_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        d = data['track_uri_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        e = data['duration_ms_songs_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        f = data['artist_pop_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        g = data['artists_followers_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        h = data['track_pop_pl'].to_tensor(default_value=-1., shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        i = data['artist_genres_pl'].to_tensor(default_value='', shape=[None, MAX_PLAYLIST_LENGTH]), \n",
    "        \n",
    "        padded_data = context.copy()\n",
    "        padded_data['track_name_pl'] = a\n",
    "        padded_data['artist_name_pl'] = b\n",
    "        padded_data['album_name_pl'] = c\n",
    "        padded_data['track_uri_pl'] = d\n",
    "        padded_data['duration_ms_songs_pl'] = e\n",
    "        padded_data['artist_pop_pl'] = f\n",
    "        padded_data['artists_followers_pl'] = g\n",
    "        padded_data['track_pop_pl'] = h\n",
    "        padded_data['artist_genres_pl'] = i\n",
    "        \n",
    "        return padded_data\n",
    "parsed_dataset_padded = parsed_dataset.map(return_padded_tensors)   \n",
    "parsed_dataset_padded_valid = parsed_dataset_valid.map(return_padded_tensors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b420022-53c8-464e-8306-53b0faccbb20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Word Of Mouth'>,\n",
      " 'album_name_pl': (<tf.Tensor: shape=(1, 375), dtype=string, numpy=\n",
      "array([[b'Stranglehold', b'Roadhouse 01', b'A Song For Every Moon',\n",
      "        b'Uncomfortable - Single', b'A Song For Every Moon', b'Freudian',\n",
      "        b'Michl', b'Salt', b'blkswn', b'blkswn', b'blkswn', b'blkswn',\n",
      "        b'Blonde', b'Chanel', b'Kiddo', b'I Learnt Some Jazz Today',\n",
      "        b\"Say It Here, While It's Safe\",\n",
      "        b'Piece of Cake (feat. Harrison Sands and Shota)',\n",
      "        b'Land of Lights', b'Blonde', b'Nat Love', b'Pine & Ginger',\n",
      "        b'She Say', b'S!ck S!ck S!ck', b'Telefone', b'Nocturnal',\n",
      "        b'Hotel Allan', b'alarm (prod. no sentences)',\n",
      "        b'Buttermilk - EP', b'Restoration of an American Idol',\n",
      "        b'Into the Flame', b'The Thirst (feat. Shiz)', b'Urban Flora',\n",
      "        b'A Song For Every Moon', b\"Sex n' Drugs\", b'Thoughts of You',\n",
      "        b\"Searchin'\", b'Tell Me Why', b'Kiddo', b'Por Vida', b'grey',\n",
      "        b'Lotto (feat. Cousin Neighbor)', b'Fading', b'Lemons',\n",
      "        b'Midnight Moonlight EP', b'Waste?', b'Afterglow', b'Afterglow',\n",
      "        b'Black Girl Magic', b'digital druglord', b'Changed',\n",
      "        b'Open Arms', b'This Is What It\\xe2\\x80\\x99s Like',\n",
      "        b'Something To Believe In', b'DAMN.', b'Coloring Book', b'Riot',\n",
      "        b'Dead', b'Uzutrap', b'LANY', b'Under the Influence',\n",
      "        b'About Me', b'Good For You', b'By Myself', b'The Afterglow',\n",
      "        b'In The Lonely Hour', b\"When It's Dark Out\", b'130 Mood : TRBL',\n",
      "        b'Been Calling', b'Whose Mans Is This_', b'Sound of Sinning',\n",
      "        b'Menu (SINGLE)', b'Mornings (See You Again)', b'Real Love',\n",
      "        b'Provider', b'Summer Daze - EP', b'Found', b'H.E.R.', b'92',\n",
      "        b'North', b'Belong To U', b'Indigo', b'SEPT 5TH', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'']], dtype=object)>,),\n",
      " 'album_name_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b'SEPT 5TH'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:1urOknNCkViW2SDrfWOXo5'>,\n",
      " 'album_uri_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:0jLynoED1FbV2Ky7vU6Pjc'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=144490.0>,\n",
      " 'artist_followers_seed_track': <tf.Tensor: shape=(), dtype=float32, numpy=1051451.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'canadian contemporary r&b', 'modern alternative rock'\">,\n",
      " 'artist_genres_pl': (<tf.Tensor: shape=(1, 375), dtype=string, numpy=\n",
      "array([[b\"'alternative r&b', 'electropop', 'nyc pop', 'pittsburgh indie'\",\n",
      "        b\"'canadian contemporary r&b', 'modern alternative rock'\",\n",
      "        b\"'pop'\", b'NONE', b\"'pop'\",\n",
      "        b\"'canadian contemporary r&b', 'pop', 'r&b'\", b'NONE',\n",
      "        b\"'alternative r&b', 'portland hip hop'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'lgbtq+ hip hop', 'neo soul', 'pop'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'lgbtq+ hip hop', 'neo soul', 'pop'\",\n",
      "        b\"'canadian contemporary r&b', 'canadian pop', 'dance pop', 'pop', 'r&b'\",\n",
      "        b\"'modern reggae'\", b'NONE',\n",
      "        b\"'desi hip hop', 'lo-fi rap', 'pop rap'\", b'NONE',\n",
      "        b\"'alternative r&b', 'hip hop', 'lgbtq+ hip hop', 'neo soul', 'pop'\",\n",
      "        b'NONE', b'NONE', b\"'modern reggae'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'alternative r&b', 'chicago rap', 'escape room', 'hip hop', 'indie soul', 'underground hip hop'\",\n",
      "        b\"'canadian contemporary r&b', 'canadian hip hop', 'pop rap', 'r&b', 'trap', 'trap soul'\",\n",
      "        b\"'canadian contemporary r&b', 'modern alternative rock'\",\n",
      "        b\"'lo-fi rap'\", b\"'lo-fi rap'\",\n",
      "        b\"'atl hip hop', 'pop rap', 'rap', 'southern hip hop', 'trap', 'underground hip hop'\",\n",
      "        b'NONE', b'NONE',\n",
      "        b\"'alternative r&b', 'electropop', 'etherpop', 'pop', 'r&b'\",\n",
      "        b\"'pop'\", b\"'desi hip hop', 'lo-fi rap', 'pop rap'\", b'NONE',\n",
      "        b\"'modern reggae'\", b\"'vapor twitch'\",\n",
      "        b\"'canadian contemporary r&b', 'canadian pop', 'dance pop', 'pop', 'r&b'\",\n",
      "        b\"'colombian pop', 'dance pop', 'pop', 'r&b'\", b'NONE',\n",
      "        b\"'christian hip hop', 'christian trap'\",\n",
      "        b\"'christian hip hop', 'christian trap'\", b'NONE',\n",
      "        b\"'alternative r&b', 'chill r&b', 'escape room', 'indie r&b', 'indie soul', 'neo soul', 'r&b'\",\n",
      "        b'NONE',\n",
      "        b\"'icelandic folk', 'icelandic indie', 'icelandic pop', 'indie folk'\",\n",
      "        b\"'icelandic folk', 'icelandic indie', 'icelandic pop', 'indie folk'\",\n",
      "        b\"'uk alternative hip hop'\", b\"'electropop', 'pop', 'pop rap'\",\n",
      "        b\"'alt z', 'canadian contemporary r&b', 'pop'\",\n",
      "        b\"'alternative r&b', 'electropop', 'indie electropop', 'indie poptimism', 'indie soul', 'vapor soul', 'vapor twitch'\",\n",
      "        b\"'alt z', 'electropop', 'indie electropop', 'indie poptimism', 'metropopolis'\",\n",
      "        b\"'modern alternative rock', 'modern rock', 'pop rock', 'rock', 'stomp and holler'\",\n",
      "        b\"'conscious hip hop', 'hip hop', 'rap', 'west coast rap'\",\n",
      "        b\"'chicago rap', 'conscious hip hop', 'hip hop', 'pop rap', 'rap'\",\n",
      "        b\"'memphis hip hop'\",\n",
      "        b\"'alt z', 'dance pop', 'electropop', 'pop', 'post-teen pop'\",\n",
      "        b'NONE', b\"'la pop', 'pop'\", b'NONE', b\"'indie electropop'\",\n",
      "        b\"'hip hop', 'pop', 'portland hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'alt z', 'electropop', 'pop'\",\n",
      "        b\"'electropop', 'pop', 'pop rap'\",\n",
      "        b\"'dance pop', 'pop', 'uk pop'\",\n",
      "        b\"'indie pop rap', 'oakland hip hop', 'pop', 'pop rap', 'rap'\",\n",
      "        b\"'k-pop', 'korean r&b'\",\n",
      "        b\"'afro dancehall', 'afropop', 'azontobeats', 'nigerian pop', 'swedish dancehall', 'uk dancehall'\",\n",
      "        b'NONE',\n",
      "        b\"'afrobeat', 'bay area indie', 'funk', 'instrumental funk', 'psychedelic soul', 'soul'\",\n",
      "        b\"'alternative r&b', 'hip hop', 'rap', 'underground hip hop'\",\n",
      "        b\"'chill r&b'\", b'NONE',\n",
      "        b\"'alternative r&b', 'hip hop', 'lgbtq+ hip hop', 'neo soul', 'pop'\",\n",
      "        b\"'vapor soul'\", b\"'uk contemporary r&b'\",\n",
      "        b\"'alternative r&b', 'dance pop', 'pop', 'r&b'\",\n",
      "        b\"'dutch hip hop', 'dutch rap pop'\",\n",
      "        b\"'abstract beats', 'alternative r&b', 'indie r&b', 'indie soul', 'vapor twitch'\",\n",
      "        b\"'pop edm', 'progressive electro house'\",\n",
      "        b\"'alternative r&b', 'indie r&b', 'indie soul'\",\n",
      "        b\"'alternative r&b', 'canadian contemporary r&b', 'indie r&b', 'pop', 'pop r&b', 'pop rap', 'r&b', 'trap soul'\",\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'']], dtype=object)>,),\n",
      " 'artist_genres_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b\"'alternative r&b', 'canadian contemporary r&b', 'indie r&b', 'pop', 'pop r&b', 'pop rap', 'r&b', 'trap soul'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Allan Rayman'>,\n",
      " 'artist_name_pl': (<tf.Tensor: shape=(1, 375), dtype=string, numpy=\n",
      "array([[b'Kevin Garrett', b'Allan Rayman', b'Bruno Major', b'Mansa',\n",
      "        b'Bruno Major', b'Daniel Caesar', b'Michl', b'Shy Girls',\n",
      "        b'Smino', b'Smino', b'Smino', b'Smino', b'Frank Ocean',\n",
      "        b'Frank Ocean', b'Jessie Reyez', b'Tessellated',\n",
      "        b'Kweku Collins', b'Abhi The Nomad', b'Eventide', b'Frank Ocean',\n",
      "        b'Kweku Collins', b'Amindi K. Fro$t', b'Tessellated', b'Smino',\n",
      "        b'Noname', b'Roy Woods', b'Allan Rayman', b'atlas', b'Biskwiq',\n",
      "        b'Mike WiLL Made-It', b'Tay', b'Tay', b'Alina Baraz',\n",
      "        b'Bruno Major', b'Abhi The Nomad', b'William Bolton',\n",
      "        b'Tessellated', b'vbnd', b'Jessie Reyez', b'Kali Uchis',\n",
      "        b'Kweku Collins', b'JGivens', b'Tragic Hero', b'dylAn',\n",
      "        b'Ravyn Lenae', b'Michl', b'\\xc3\\x81sgeir', b'\\xc3\\x81sgeir',\n",
      "        b'Che Lingo', b'blackbear', b'JP Saxe', b'RKCB', b'Glades',\n",
      "        b'Young the Giant', b'Kendrick Lamar', b'Chance The Rapper',\n",
      "        b'Jon Waltz', b'Madison Beer', b'J. Han', b'LANY', b'Majik',\n",
      "        b'Elias Abid', b'Amin\\xc3\\xa9', b'Christian French',\n",
      "        b'blackbear', b'Sam Smith', b'G-Eazy', b'DEAN', b'Maleek Berry',\n",
      "        b'Charlie Powers', b'Monophonics', b'Smino', b'Alextbh',\n",
      "        b'Cortes', b'Frank Ocean', b'Cool Company', b'Seramic',\n",
      "        b'H.E.R.', b'SRNO', b'Sango', b'Fancy Cars', b'River Tiber',\n",
      "        b'dvsn', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'']], dtype=object)>,),\n",
      " 'artist_name_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b'dvsn'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=57.0>,\n",
      " 'artist_pop_pl': (<tf.Tensor: shape=(1, 375), dtype=float32, numpy=\n",
      "array([[56., 57., 76., 49., 76., 82., 53., 46., 73., 73., 73., 73., 87.,\n",
      "        87., 72., 42., 42., 61., 32., 87., 42.,  0., 42., 73., 61., 67.,\n",
      "        57., 55., 59., 71.,  4.,  4., 70., 76., 61., 47., 42., 46., 72.,\n",
      "        85., 42., 31., 26., 30., 59., 53., 58., 58., 50., 85., 73., 58.,\n",
      "        51., 70., 91., 80., 41., 78., 20., 79., 34., 25., 76., 65., 85.,\n",
      "        86., 81., 67., 60., 31., 51., 73., 47.,  0., 87., 51., 26., 81.,\n",
      "        69., 55., 43., 51., 65., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]],\n",
      "      dtype=float32)>,),\n",
      " 'artist_pop_seed_track': <tf.Tensor: shape=(), dtype=float32, numpy=65.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:6Yv6OBXD6ZQakEljaGaDAk'>,\n",
      " 'artist_uri_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:7e1ICztHM2Sc4JNLxeMXYl'>,\n",
      " 'artists_followers_pl': (<tf.Tensor: shape=(1, 375), dtype=float32, numpy=\n",
      "array([[ 1.2562500e+05,  1.4449000e+05,  8.2950100e+05,  8.6620000e+03,\n",
      "         8.2950100e+05,  3.1571950e+06,  1.5782400e+05,  5.8059000e+04,\n",
      "         6.2357700e+05,  6.2357700e+05,  6.2357700e+05,  6.2357700e+05,\n",
      "         9.1429110e+06,  9.1429110e+06,  1.0747770e+06,  1.7105000e+04,\n",
      "         4.9978000e+04,  1.0601400e+05,  7.9240000e+03,  9.1429110e+06,\n",
      "         4.9978000e+04,  2.8700000e+02,  1.7105000e+04,  6.2357700e+05,\n",
      "         6.0877000e+05,  8.4721000e+05,  1.4449000e+05,  1.6107500e+05,\n",
      "         5.6810000e+04,  1.3711760e+06,  5.2000000e+02,  5.2000000e+02,\n",
      "         1.0617970e+06,  8.2950100e+05,  1.0601400e+05,  1.9342000e+04,\n",
      "         1.7105000e+04,  3.2877000e+04,  1.0747770e+06,  2.7112680e+06,\n",
      "         4.9978000e+04,  2.2799000e+04,  7.1650000e+03,  4.6300000e+03,\n",
      "         2.8826700e+05,  1.5782400e+05,  2.7211500e+05,  2.7211500e+05,\n",
      "         1.8223000e+04,  4.6268480e+06,  3.3516400e+05,  1.0685900e+05,\n",
      "         8.1725000e+04,  1.3825310e+06,  1.9595648e+07,  5.5914660e+06,\n",
      "         9.4470000e+03,  4.6326380e+06,  3.1460000e+03,  4.4885300e+06,\n",
      "         1.2757000e+04,  8.9200000e+02,  1.7566430e+06,  2.4156600e+05,\n",
      "         4.6268480e+06,  1.9080876e+07,  5.0360250e+06,  1.2394940e+06,\n",
      "         3.3200000e+05,  3.2060000e+03,  7.8842000e+04,  6.2357700e+05,\n",
      "         7.8490000e+04,  1.2800000e+02,  9.1429110e+06,  3.1248000e+04,\n",
      "         9.3470000e+03,  4.9476360e+06,  1.6605000e+04,  1.7391700e+05,\n",
      "         9.3180000e+03,  4.5205000e+04,  1.0514510e+06, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00,\n",
      "        -1.0000000e+00, -1.0000000e+00, -1.0000000e+00]], dtype=float32)>,),\n",
      " 'collaborative': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'description_pl': <tf.Tensor: shape=(), dtype=string, numpy=b''>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=179533.0>,\n",
      " 'duration_ms_songs_pl': (<tf.Tensor: shape=(1, 375), dtype=float32, numpy=\n",
      "array([[ 2.01360e+05,  2.25880e+05,  2.10240e+05,  4.00615e+05,\n",
      "         1.74167e+05,  2.78179e+05,  2.08214e+05,  2.30720e+05,\n",
      "         1.88209e+05,  1.69319e+05,  2.05199e+05,  1.74805e+05,\n",
      "         3.07151e+05,  2.10285e+05,  2.40906e+05,  1.06909e+05,\n",
      "         2.05984e+05,  2.16923e+05,  2.77590e+05,  1.84516e+05,\n",
      "         2.38546e+05,  1.89230e+05,  2.16000e+05,  2.64125e+05,\n",
      "         2.18627e+05,  2.01290e+05,  1.58186e+05,  1.38239e+05,\n",
      "         1.05600e+05,  2.34022e+05,  1.71000e+05,  1.93142e+05,\n",
      "         2.76436e+05,  1.55616e+05,  2.17777e+05,  2.09970e+05,\n",
      "         1.50000e+05,  1.31677e+05,  1.85240e+05,  2.12000e+05,\n",
      "         2.61955e+05,  2.12371e+05,  2.44500e+05,  1.05128e+05,\n",
      "         2.19648e+05,  1.97323e+05,  2.47120e+05,  3.07826e+05,\n",
      "         2.10000e+05,  1.68428e+05,  2.79269e+05,  2.28965e+05,\n",
      "         1.84425e+05,  2.24400e+05,  2.75253e+05,  2.90316e+05,\n",
      "         2.14153e+05,  1.94826e+05,  2.33532e+05,  2.34818e+05,\n",
      "         2.14727e+05,  2.25207e+05,  2.20160e+05,  1.84624e+05,\n",
      "         2.17026e+05,  1.84748e+05,  2.22466e+05,  2.29359e+05,\n",
      "         1.96800e+05,  1.96946e+05,  2.00600e+05,  1.99040e+05,\n",
      "         2.13097e+05,  1.89048e+05,  2.43238e+05,  1.52500e+05,\n",
      "         1.86195e+05,  2.09400e+05,  1.72042e+05,  2.22000e+05,\n",
      "         2.02574e+05,  1.52250e+05,  2.46293e+05, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,\n",
      "        -1.00000e+00, -1.00000e+00, -1.00000e+00]], dtype=float32)>,),\n",
      " 'duration_seed_track': <tf.Tensor: shape=(), dtype=float32, numpy=246293.0>,\n",
      " 'n_songs_pl': <tf.Tensor: shape=(), dtype=float32, numpy=83.0>,\n",
      " 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Vibezz'>,\n",
      " 'num_albums_pl': <tf.Tensor: shape=(), dtype=float32, numpy=75.0>,\n",
      " 'num_artists_pl': <tf.Tensor: shape=(), dtype=float32, numpy=62.0>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Word Of Mouth'>,\n",
      " 'track_name_pl': (<tf.Tensor: shape=(1, 375), dtype=string, numpy=\n",
      "array([[b'Stranglehold', b'Repeat', b'Easily', b'Uncomfortable',\n",
      "        b\"Wouldn't Mean A Thing\", b'Get You (feat. Kali Uchis)',\n",
      "        b'Die Trying', b'What If I Can', b'Glass Flows',\n",
      "        b'Wild Irish Roses', b'Maraca', b'Ricky Millions', b'Nights',\n",
      "        b'Chanel', b'Figures', b'I Learnt Some Jazz Today',\n",
      "        b'Lonely Lullabies',\n",
      "        b'Piece of Cake (feat. Harrison Sands and Shota)',\n",
      "        b'Land of Lights', b'Pink + White', b'Stupid Rose',\n",
      "        b'Pine & Ginger', b'She Say', b'Ruby Red',\n",
      "        b'Forever (feat. Joseph Chilliams & Ravyn Lenae)', b'Dangerous',\n",
      "        b'Song 512', b'alarm (prod. no sentences)',\n",
      "        b'Faucets (feat. Healy)',\n",
      "        b'Grown up Fairy Tales (feat. Chance the Rapper & Jeremih)',\n",
      "        b'Into the Flame', b'The Thirst (feat. Shiz)',\n",
      "        b'Pretty Thoughts - FKJ Remix', b'Second Time', b\"Sex n' Drugs\",\n",
      "        b'Thoughts of You', b\"Searchin'\", b'Tell Me Why', b'Fuck It',\n",
      "        b'Loner', b'Jump.i', b'Lotto (feat. Cousin Neighbor)', b'Fading',\n",
      "        b'Lemons', b'Spice', b'Waste?', b'Unbound', b'Fennir yfir',\n",
      "        b'Black Girl Magic',\n",
      "        b'hell is where i dreamt of u and woke up alone', b'Changed',\n",
      "        b'Open Arms', b'Drive // Stripped',\n",
      "        b'Something To Believe In - Live Acoustic', b'PRIDE.',\n",
      "        b'Summer Friends (feat. Jeremih & Francis & The Lights)',\n",
      "        b'Riot', b'Dead', b'Uzutrap', b'13', b'27', b'About Me',\n",
      "        b'Heebiejeebies - Bonus', b'By Myself', b'Califormula',\n",
      "        b'Safe With Me', b'Some Kind Of Drug', b'D (Half Moon)',\n",
      "        b'Been Calling', b'Whose Mans Is This_', b'La La La Love Me',\n",
      "        b'Menu', b'Lead The Way', b'Real Love', b'Provider',\n",
      "        b'Beneath the Lights', b'Found', b'Best Part', b'One Dance',\n",
      "        b'Middle of Things, Beautiful Wife (feat. Xavier Om\\xc3\\xa4r))',\n",
      "        b'Belong To U', b'West', b'Hallucinations', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'']], dtype=object)>,),\n",
      " 'track_name_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b'Hallucinations'>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_pop_pl': (<tf.Tensor: shape=(1, 375), dtype=float32, numpy=\n",
      "array([[ 0., 48., 81., 32., 57., 84., 41.,  0., 54., 71., 47., 45., 83.,\n",
      "        84., 69.,  0.,  0.,  0., 16., 84.,  0., 50.,  0., 47., 48., 47.,\n",
      "        35.,  0., 41., 49.,  0.,  0., 29., 63., 44.,  0.,  0.,  0., 50.,\n",
      "        68.,  0., 11.,  0.,  0., 52., 34., 28., 13., 22.,  1.,  0.,  0.,\n",
      "         0., 38., 81., 61.,  0., 55.,  0.,  0., 31., 13., 69., 64., 47.,\n",
      "        22., 68., 68.,  0.,  0., 49., 36.,  0.,  0., 68.,  0.,  0., 79.,\n",
      "         0., 50.,  0.,  0., 63., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]],\n",
      "      dtype=float32)>,),\n",
      " 'track_pop_seed_track': <tf.Tensor: shape=(), dtype=float32, numpy=63.0>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:0aVQHaVi4hnNwS7ka194QT'>,\n",
      " 'track_uri_pl': (<tf.Tensor: shape=(1, 375), dtype=string, numpy=\n",
      "array([[b'spotify:track:5wYbTyBlqYiCN5vfp0JACL',\n",
      "        b'spotify:track:7tLWymW3ieb60ZI0aFa4lv',\n",
      "        b'spotify:track:2k9N4caeCIJLOWwWwssrEM',\n",
      "        b'spotify:track:7qdfQMpIUOwsIKTM69XVyW',\n",
      "        b'spotify:track:2My7DsxhZodhsguIHCqAGm',\n",
      "        b'spotify:track:7zFXmv6vqI4qOt4yGf3jYZ',\n",
      "        b'spotify:track:5O06nbk5wDRr1WR3Tyo0Af',\n",
      "        b'spotify:track:6x59xGENjPKBfBbFaJrx6w',\n",
      "        b'spotify:track:06BLANboqUEnvBHJH0aViQ',\n",
      "        b'spotify:track:6efkcs2aUBMFKxl0cl2JWQ',\n",
      "        b'spotify:track:4TtKJMwpf4Df6vacawP1k3',\n",
      "        b'spotify:track:4RcIM9FCaFFlAfC6pMMb59',\n",
      "        b'spotify:track:7eqoqGkKwgOaWNNHx90uEZ',\n",
      "        b'spotify:track:6Nle9hKrkL1wQpwNfEkxjh',\n",
      "        b'spotify:track:3U3J5v3rkx89WnFEQvAJD5',\n",
      "        b'spotify:track:5OsIEsKYHmARpNvVFkWjKB',\n",
      "        b'spotify:track:7BLBIXwIOXPSpTOh1YnKSA',\n",
      "        b'spotify:track:3aLKqv7FPLxC1CXWLKx8e5',\n",
      "        b'spotify:track:0JmzkMiu7ARjNLetSVICMY',\n",
      "        b'spotify:track:3xKsf9qdS1CyvXSMEid6g8',\n",
      "        b'spotify:track:5UO7PbqKIVIijPgEBNPEd1',\n",
      "        b'spotify:track:7iHsUPZjmTqzog933uh5lU',\n",
      "        b'spotify:track:32sxMJ44j8DDD5KiDXVn0J',\n",
      "        b'spotify:track:0E6GxVs1NLV9FxK9rK4K1G',\n",
      "        b'spotify:track:3cFqaY74NyS6rcitujSx2g',\n",
      "        b'spotify:track:313cdthw8naSCqGDNON7XB',\n",
      "        b'spotify:track:6AaBcAy4Bq9o9OdQ3WOWgG',\n",
      "        b'spotify:track:1UeaZu60NUVnJVK6ONpyPe',\n",
      "        b'spotify:track:5WJ3Py8BuLkt0RaDrN8U2X',\n",
      "        b'spotify:track:2w7CXqA8SonrkEC74zuBVM',\n",
      "        b'spotify:track:6EwkuhiNG7AdBP8afmFtO1',\n",
      "        b'spotify:track:0hYr8J9hFQmt7SFFUUT8c8',\n",
      "        b'spotify:track:3WrIsXM196pQz95nZyxSDD',\n",
      "        b'spotify:track:6Ub9ro6DKs0u0J0zIBw5Of',\n",
      "        b'spotify:track:6cvRSOoJKvQwS0oDt0TePP',\n",
      "        b'spotify:track:7lIIdjDhVx5l8kDbTqmWdk',\n",
      "        b'spotify:track:5u1jV3NN4lR1O0YyCqCphr',\n",
      "        b'spotify:track:65cwAfq5FM5UBEyD1w5oWY',\n",
      "        b'spotify:track:2iPo6qr1P0xQDWgbLCAJ7t',\n",
      "        b'spotify:track:6m6R6O2BOZDCNymhJ45spI',\n",
      "        b'spotify:track:171awMjY0IamtiXWfNnIus',\n",
      "        b'spotify:track:74tSdQK9QvmBlXlxAIxxrA',\n",
      "        b'spotify:track:55qULu9m5js4KPcshHAdyH',\n",
      "        b'spotify:track:68YAZg1HzCaDjTeEXlqkP7',\n",
      "        b'spotify:track:2QmU4B8fsyWcTQLVDl06Pk',\n",
      "        b'spotify:track:2NHBZioRzyMG6VTsyqqrLB',\n",
      "        b'spotify:track:2R3cKxBdjqpmeINbNpELOs',\n",
      "        b'spotify:track:1fsPtW8ff8iuK3vF5rR88R',\n",
      "        b'spotify:track:3v1ERynrK48XDoeTtav83V',\n",
      "        b'spotify:track:7mmf56XtAneYnuomOuvySJ',\n",
      "        b'spotify:track:0d9PbHaIlNHYqnizRF1odR',\n",
      "        b'spotify:track:5jQQDwJosT89Wy5vOLCafm',\n",
      "        b'spotify:track:7EpsAOwJU61tXSaT2xCk7z',\n",
      "        b'spotify:track:6j0OqIhUxvOgGPTXxNj124',\n",
      "        b'spotify:track:6IZvVAP7VPPnsGX6bvgkqg',\n",
      "        b'spotify:track:2fl0B0OaXjWbjHCQFx2O8W',\n",
      "        b'spotify:track:3WpA2qsihqFtTcuNzBlEYI',\n",
      "        b'spotify:track:5kApwSRDqF5CKclVLw1FBM',\n",
      "        b'spotify:track:7tZsT7e40yJ5rv729j2NrU',\n",
      "        b'spotify:track:3zgs1f6Tj0mn29qTXJuhSY',\n",
      "        b'spotify:track:3Gl6bd4gJog9CQmqS1H7ke',\n",
      "        b'spotify:track:4lvs8f2BwirfIe5hB04Rwi',\n",
      "        b'spotify:track:32xx0fAv3CIeGmNaWTHvEF',\n",
      "        b'spotify:track:6iRTYLWbxXtUz00KQIWiTN',\n",
      "        b'spotify:track:6eH0vTMo40p9Jbp67ZmUmC',\n",
      "        b'spotify:track:4Xy46vKRLab0hfzFlcI5fb',\n",
      "        b'spotify:track:1Bqxj0aH5KewYHKUg1IdrF',\n",
      "        b'spotify:track:3uA8SjMyDtwtt0jLPMQbVD',\n",
      "        b'spotify:track:6AtJkbqi8D9V7em7swWLR0',\n",
      "        b'spotify:track:0XUOcGbyiR2iiN8DsuJW5l',\n",
      "        b'spotify:track:1wlPuhYpOJRPHVUeizRdx2',\n",
      "        b'spotify:track:4y9uFK5dLF9aX423q7hHp0',\n",
      "        b'spotify:track:6900N5IPVHzAaYJDA99Ac6',\n",
      "        b'spotify:track:1LeotL0lJvp7DFQd5wj5DJ',\n",
      "        b'spotify:track:6R6ihJhRbgu7JxJKIbW57w',\n",
      "        b'spotify:track:668wD7a3RNNX4BlwOTHQCX',\n",
      "        b'spotify:track:3InoZulaW9jwR9992k8dnf',\n",
      "        b'spotify:track:4OBZT9EnhYIV17t4pGw7ig',\n",
      "        b'spotify:track:5bkIN5gDuV9Y9P3JjbTfI8',\n",
      "        b'spotify:track:1OjmLuc3Kf34WcEAasCjsO',\n",
      "        b'spotify:track:711J1I0VfLoAqKX3d2b7PE',\n",
      "        b'spotify:track:26oTYFTOdLZxDwfoHTGvmj',\n",
      "        b'spotify:track:0UE0RhnRaEYsiYgXpyLoZc', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'', b'',\n",
      "        b'']], dtype=object)>,),\n",
      " 'track_uri_seed_track': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:0UE0RhnRaEYsiYgXpyLoZc'>}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "for features in parsed_dataset_padded_valid.skip(3).take(1):\n",
    "    pprint(features)\n",
    "    print(\"_______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea17604-e4e9-45fe-9a6d-804b24c72acd",
   "metadata": {},
   "source": [
    "### Candidate Track dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53680f4f-9fa4-473b-91e6-b959fa5bfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/candidates/'\n",
    "\n",
    "candidate_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "def parse_candidate_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn, num_parallel_calls=-1)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn) ### THIS NEEDS TO BE FIXED SO THE UNIQUE PRODUCT DATASET HAS THE SAME FIELD NAMES (goes thru the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78a3917-06e5-4b9b-b6e8-62ce10ea2826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'The Sound of Everything Rmx'>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:4a8tMD6qq6GUuUwNae38VI'>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=277649.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'downtempo', 'electronica', 'funk', 'latin alternative', 'nu jazz', 'nu-cumbia', 'trip hop', 'world'\">,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Quantic'>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=64.0>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:5ZMwoAjeDtLJ0XRwRTgaK8'>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=267130.0>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'The Sound of Everything - Watch TV & Se\\xc3\\xb1orlobo Remix'>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=53.0>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:27CDzo2P7Mf3dKoa76tNxb'>}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "for features in parsed_candidate_dataset.take(1):\n",
    "    pprint(features)\n",
    "    print(\"_______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f134d2e-aab7-45dd-a034-778acdc13c41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vocab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9208b3-af2a-439b-bca8-f05f1bb6f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'spotify-v1'\n",
    "FILE_PATH = 'vocabs/v1_string_vocabs'\n",
    "FILE_NAME = 'string_vocabs_v1_20220705-202905.txt'\n",
    "DESTINATION_FILE = 'downloaded_vocabs.txt'\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "with open(f'{DESTINATION_FILE}', 'wb') as file_obj:\n",
    "    client.download_blob_to_file(\n",
    "        f'gs://{BUCKET_NAME}/{FILE_PATH}/{FILE_NAME}', file_obj)\n",
    "\n",
    "    \n",
    "with open(f'{DESTINATION_FILE}', 'rb') as pickle_file:\n",
    "    vocab_dict_load = pkl.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1cbcc2-f54e-44a6-a52f-7d9273bf8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab_dict_load[\"unique_pids\"])\n",
    "\n",
    "avg_duration_ms_seed_pl = 13000151.68\n",
    "var_duration_ms_seed_pl = 133092900971233.58\n",
    "vocab_dict_load['avg_duration_ms_seed_pl']=avg_duration_ms_seed_pl\n",
    "vocab_dict_load['var_duration_ms_seed_pl']=var_duration_ms_seed_pl\n",
    "\n",
    "avg_n_songs_pl = 55.21\n",
    "var_n_songs_pl = 2317.54\n",
    "vocab_dict_load['avg_n_songs_pl']=avg_n_songs_pl\n",
    "vocab_dict_load['var_n_songs_pl']=var_n_songs_pl\n",
    "\n",
    "avg_n_artists_pl = 30.56\n",
    "var_n_artists_pl = 769.26\n",
    "vocab_dict_load['avg_n_artists_pl']=avg_n_artists_pl\n",
    "vocab_dict_load['var_n_artists_pl']=var_n_artists_pl\n",
    "\n",
    "avg_n_albums_pl = 40.25\n",
    "var_n_albums_pl = 1305.54\n",
    "vocab_dict_load['avg_n_albums_pl']=avg_n_albums_pl\n",
    "vocab_dict_load['var_n_albums_pl']=var_n_albums_pl\n",
    "\n",
    "avg_artist_pop = 16.08\n",
    "var_artist_pop = 300.64\n",
    "vocab_dict_load['avg_artist_pop']=avg_artist_pop\n",
    "vocab_dict_load['var_artist_pop']=var_artist_pop\n",
    "\n",
    "avg_duration_ms_songs_pl = 234823.14\n",
    "var_duration_ms_songs_pl = 5558806228.41\n",
    "vocab_dict_load['avg_duration_ms_songs_pl']=avg_duration_ms_songs_pl\n",
    "vocab_dict_load['var_duration_ms_songs_pl']=var_duration_ms_songs_pl\n",
    "\n",
    "avg_artist_followers = 43337.77\n",
    "var_artist_followers = 377777790193.57\n",
    "vocab_dict_load['avg_artist_followers']=avg_artist_followers\n",
    "vocab_dict_load['var_artist_followers']=var_artist_followers\n",
    "\n",
    "avg_track_pop = 10.85\n",
    "var_track_pop = 202.18\n",
    "vocab_dict_load['avg_track_pop']=avg_track_pop\n",
    "vocab_dict_load['var_track_pop']=var_track_pop\n",
    "# vocab_dict_load['unique_pids_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae5c9f6-0328-4faa-9817-b90992bfde3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 999997, 999998, 999999])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load['unique_pids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b10d7b1c-1e5c-4fb4-a078-ba01b03c9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION='test-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186a4826-a4b1-4cc3-976e-8685cc4dbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET='spotify-tfrecords-blog'\n",
    "bucket=client.bucket(BUCKET)\n",
    "blob = bucket.blob(f'vocabs_stats/vocab_dict_{VERSION}.txt')\n",
    "pickle_out = pkl.dumps(vocab_dict_load)\n",
    "blob.upload_from_string(pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ef10ce3-1e76-41a3-a36e-16731139a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket=client.bucket(BUCKET)  \n",
    "# blob = bucket.blob('vocabs/string_vocabs')\n",
    "# blob.upload_from_filename('string_vocabs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4de4f-7b50-4ec5-bc1a-6eee6bde3e59",
   "metadata": {},
   "source": [
    "### Test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee785672-705b-4d7e-a2b3-1f3a6a529538",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_test_instancet = {\n",
    "    'name': np.asarray([b'Best Christmas']),\n",
    "    'collaborative': np.asarray([b'false']),\n",
    "    'pid': np.asarray([173671]),\n",
    "    'description_pl': np.asarray([b'test description']),\n",
    "    'duration_ms_seed_pl': np.asarray([5458995.]),\n",
    "    'n_songs_pl': np.asarray([58.]),\n",
    "    'num_artists_pl': np.asarray([19.]),\n",
    "    'num_albums_pl': np.asarray([27.]),\n",
    "    'artist_name_pl': np.asarray([[b'Juan Luis Guerra 4.40', b'Prince Royce', b'Luis Vargas']]),\n",
    "    'track_uri_pl': np.asarray([[b'spotify:track:1g0IBPZTRP7VYkctJ4Qafg',b'spotify:track:43wUzbYxEFoXugYkgTzMWp']]),\n",
    "    'track_name_pl': np.asarray([[b'Lover Come Back', b'White Lightning', b'Shake Me Down']]),\n",
    "    'duration_ms_songs_pl': np.asarray([[245888., 195709., 283906., 271475., 300373., 275173., 236145.,]]),\n",
    "    'album_name_pl': np.asarray([[b'Silsulim', b'Sara Shara', b'Muzika Vesheket', b'Ba La Lirkod']]),\n",
    "    'artist_pop_pl': np.asarray([[81., 81., 70., 66., 66., 66., 46., 87.]]),\n",
    "    'artists_followers_pl': np.asarray([[3.556710e+05, 8.200000e+02, 1.510000e+02, 1.098080e+05,]]),\n",
    "    'artist_genres_pl': np.asarray([[b\"'israeli pop', 'jewish pop'\", b\"'israeli pop', 'jewish pop'\",]]),\n",
    "    'track_pop_pl': np.asarray([[70, 77, 50, 44, 30, 28, 15, 26, 15, 18, 46, 38,]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7be542-9aa4-4ddf-aa7f-5abd4cde18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_test_instance = {\n",
    "    'artist_name': np.asarray([b'Hellogoodbye']),\n",
    "    'track_name': np.asarray([b'When We First Met']),\n",
    "    'album_name': np.asarray([b'Would It Kill You?']),\n",
    "    'track_uri': np.asarray([b'Ba La Lirkod']),\n",
    "    'artist_uri': np.asarray([b'spotify:artist:6GH0NzpthMGxu1mcfAkOde']),\n",
    "    'album_uri': np.asarray([b'spotify:album:4dHXV7pJs6d8N9ACAMzhIw']),\n",
    "    'duration_ms': np.asarray([154813.0]),\n",
    "    'track_pop': np.asarray([45.0]),\n",
    "    'artist_pop': np.asarray([51.0]),\n",
    "    'artist_followers':np.asarray([205331.0]),\n",
    "    'artist_genres': np.asarray([b\"'neon pop punk', 'pop punk'\"]),\n",
    "    # 'test': np.asarray([b'test'])\n",
    "}\n",
    "\n",
    "# candidate_test_instance = {\n",
    "#     'artist_name': np.asarray([b'Hellogoodbye']),\n",
    "#     'track_name': np.asarray([b'When We First Met']),\n",
    "#     'album_name': np.asarray([b'Would It Kill You?']),\n",
    "#     'track_uri': np.asarray([b'Ba La Lirkod']),\n",
    "#     'artist_uri': np.asarray([b'spotify:artist:6GH0NzpthMGxu1mcfAkOde']),\n",
    "#     'album_uri': np.asarray([b'spotify:album:4dHXV7pJs6d8N9ACAMzhIw']),\n",
    "#     'duration_ms': np.asarray([154813.0]),\n",
    "#     'track_pop': np.asarray([45.0]),\n",
    "#     'artist_pop': np.asarray([51.0]),\n",
    "#     'artist_followers':np.asarray([205331.0]),\n",
    "#     'artist_genres': np.asarray([b\"'neon pop punk', 'pop punk'\"]),\n",
    "#     # 'test': np.asarray([b'test'])\n",
    "# }\n",
    "# pprint(can_test_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a87c3d-e54f-4e2e-93aa-b2d84c4d619f",
   "metadata": {},
   "source": [
    "# Two-Tower Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0387f3f-98be-464c-b080-ff08a8b6430e",
   "metadata": {},
   "source": [
    "## Playlist (query) Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "586e5b73-71d2-455a-9b5d-99175e7463f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c47c08-b6f6-4afb-a213-c6234ff1a2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74028"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict_load[\"name\"]\n",
    "len(vocab_dict_load[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1122ba98-978b-4bfe-8d82-835e9c2f2689",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': array([b'! 2017 Songs', b'! <3', b'! DJ', ...,\n",
       "        b'\\xf0\\x9f\\xa6\\x84\\xf0\\x9f\\xa6\\x84',\n",
       "        b'\\xf0\\x9f\\xa6\\x84\\xf0\\x9f\\xa6\\x84\\xf0\\x9f\\xa6\\x84',\n",
       "        b'\\xf0\\x9f\\xa6\\x8b\\xf0\\x9f\\xa6\\x8b\\xf0\\x9f\\xa6\\x8b'], dtype=object),\n",
       " 'artist_name_can': array([b'!!!', b'!Dela Dap', b'!Distain', ..., b'\\xed\\x9b\\x88 Hun',\n",
       "        b'\\xef\\xbc\\x92\\xef\\xbc\\x98\\xef\\xbc\\x91\\xef\\xbc\\x94',\n",
       "        b'\\xef\\xbc\\xad\\xef\\xbc\\xa9\\xef\\xbc\\xb9\\xef\\xbc\\xa1\\xef\\xbc\\xb6\\xef\\xbc\\xa9'],\n",
       "       dtype=object),\n",
       " 'track_uri_can': array([b'spotify:track:0000uJA4xCdxThagdLkkLR',\n",
       "        b'spotify:track:0002yNGLtYSYtc0X6ZnFvp',\n",
       "        b'spotify:track:00039MgrmLoIzSpuYKurn9', ...,\n",
       "        b'spotify:track:7zzwsf6tmZETUV26kR7D5z',\n",
       "        b'spotify:track:7zzxEH0xUl5k3p6IxUfgAO',\n",
       "        b'spotify:track:7zzyrYnZIfvYAGwl7lRb7X'], dtype=object),\n",
       " 'artist_uri_can': array([b'spotify:artist:0001ZVMPt41Vwzt1zsmuzp',\n",
       "        b'spotify:artist:0001cekkfdEBoMlwVQvpLg',\n",
       "        b'spotify:artist:0001wHqxbF2YYRQxGdbyER', ...,\n",
       "        b'spotify:artist:7zzVVpR5daxXjgmXNj5nfI',\n",
       "        b'spotify:artist:7zzZtvkqJ7GnXfCte5z3gm',\n",
       "        b'spotify:artist:7zzsdcNemyhcNk2wpNsXZt'], dtype=object),\n",
       " 'track_name_can': array([b'!', b'! (Foreword)', b'! (The Song Formerly Known As)', ...,\n",
       "        b'\\xef\\xbb\\xbfThe Right Move',\n",
       "        b'\\xef\\xbf\\xbc9 Fruitless Years of Total Fucking Agony',\n",
       "        b'\\xef\\xbf\\xbd\\xc3\\xa4k\\xc3\\xa4skero'], dtype=object),\n",
       " 'album_uri_can': array([b'spotify:album:00010fh2pSk7f1mGIhgorB',\n",
       "        b'spotify:album:00045VFusrXwCSietfmspc',\n",
       "        b'spotify:album:0005lpYtyKk9B3e0mWjdem', ...,\n",
       "        b'spotify:album:7zzZUxOJ7fnNz2McXzH8wz',\n",
       "        b'spotify:album:7zzu2Xa7v5lAlzSjGzjrBa',\n",
       "        b'spotify:album:7zzuO4Kbud2YPyGsacVA3h'], dtype=object),\n",
       " 'album_name_can': array([b'!', b'!! Going Places !!', b'!!! Chk Chik Chick', ...,\n",
       "        b'\\xed\\x9b\\x84\\xec\\x95\\x84\\xec\\x9c\\xa0-\\xed\\x95\\x99\\xea\\xb5\\x90 2015 (Original Television Soundtrack), Pt.3',\n",
       "        b'\\xed\\x9e\\x88\\xec\\x96\\xb4\\xeb\\xa1\\x9c - Single',\n",
       "        b'\\xef\\xbb\\xbfBPitch Control - Best of 2014'], dtype=object),\n",
       " 'artist_genres_can': array([b'', b'\"australian children\\'s music\"',\n",
       "        b'\"australian children\\'s music\", \"children\\'s folk\", \"children\\'s music\"',\n",
       "        ..., b\"'zouk', 'zouk riddim'\", b\"'zouk', 'zouk riddim' 'zouk'\",\n",
       "        b\"'zydeco'\"], dtype=object),\n",
       " 'unique_pids': array([     0,      1,      2, ..., 999997, 999998, 999999]),\n",
       " 'artist_name_seed_track': array([b'!!!', b'!Dela Dap', b'!Distain', ..., b'\\xed\\x9b\\x88 Hun',\n",
       "        b'\\xef\\xbc\\x92\\xef\\xbc\\x98\\xef\\xbc\\x91\\xef\\xbc\\x94',\n",
       "        b'\\xef\\xbc\\xad\\xef\\xbc\\xa9\\xef\\xbc\\xb9\\xef\\xbc\\xa1\\xef\\xbc\\xb6\\xef\\xbc\\xa9'],\n",
       "       dtype=object),\n",
       " 'artist_uri_seed_track': array([b'spotify:artist:0001ZVMPt41Vwzt1zsmuzp',\n",
       "        b'spotify:artist:0001cekkfdEBoMlwVQvpLg',\n",
       "        b'spotify:artist:0001wHqxbF2YYRQxGdbyER', ...,\n",
       "        b'spotify:artist:7zzVVpR5daxXjgmXNj5nfI',\n",
       "        b'spotify:artist:7zzZtvkqJ7GnXfCte5z3gm',\n",
       "        b'spotify:artist:7zzsdcNemyhcNk2wpNsXZt'], dtype=object),\n",
       " 'track_name_seed_track': array([b'!', b'! (Foreword)', b'! (The Song Formerly Known As)', ...,\n",
       "        b'\\xef\\xbb\\xbfThe Right Move',\n",
       "        b'\\xef\\xbf\\xbc9 Fruitless Years of Total Fucking Agony',\n",
       "        b'\\xef\\xbf\\xbd\\xc3\\xa4k\\xc3\\xa4skero'], dtype=object),\n",
       " 'track_uri_seed_track': array([b'spotify:track:0000uJA4xCdxThagdLkkLR',\n",
       "        b'spotify:track:0002yNGLtYSYtc0X6ZnFvp',\n",
       "        b'spotify:track:00039MgrmLoIzSpuYKurn9', ...,\n",
       "        b'spotify:track:7zzwsf6tmZETUV26kR7D5z',\n",
       "        b'spotify:track:7zzxEH0xUl5k3p6IxUfgAO',\n",
       "        b'spotify:track:7zzyrYnZIfvYAGwl7lRb7X'], dtype=object),\n",
       " 'album_name_seed_track': array([b'!', b'!! Going Places !!', b'!!! Chk Chik Chick', ...,\n",
       "        b'\\xed\\x9b\\x84\\xec\\x95\\x84\\xec\\x9c\\xa0-\\xed\\x95\\x99\\xea\\xb5\\x90 2015 (Original Television Soundtrack), Pt.3',\n",
       "        b'\\xed\\x9e\\x88\\xec\\x96\\xb4\\xeb\\xa1\\x9c - Single',\n",
       "        b'\\xef\\xbb\\xbfBPitch Control - Best of 2014'], dtype=object),\n",
       " 'album_uri_seed_track': array([b'spotify:album:00010fh2pSk7f1mGIhgorB',\n",
       "        b'spotify:album:00045VFusrXwCSietfmspc',\n",
       "        b'spotify:album:0005lpYtyKk9B3e0mWjdem', ...,\n",
       "        b'spotify:album:7zzZUxOJ7fnNz2McXzH8wz',\n",
       "        b'spotify:album:7zzu2Xa7v5lAlzSjGzjrBa',\n",
       "        b'spotify:album:7zzuO4Kbud2YPyGsacVA3h'], dtype=object),\n",
       " 'artist_genres_seed_track': array([b'', b'\"australian children\\'s music\"',\n",
       "        b'\"australian children\\'s music\", \"children\\'s folk\", \"children\\'s music\"',\n",
       "        ..., b\"'zouk', 'zouk riddim'\", b\"'zouk', 'zouk riddim' 'zouk'\",\n",
       "        b\"'zydeco'\"], dtype=object),\n",
       " 'description_pl': array([b'', b'!', b'! english&#x2F;spanish !', ..., b'\\xf0\\x9f\\x9a\\xa8',\n",
       "        b'\\xf0\\x9f\\xa4\\x91',\n",
       "        b'\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98\\xf0\\x9f\\xa4\\x98'],\n",
       "       dtype=object),\n",
       " 'artist_name_pl': array([b'!!!', b'!Dela Dap', b'!Distain', ..., b'\\xed\\x9b\\x88 Hun',\n",
       "        b'\\xef\\xbc\\x92\\xef\\xbc\\x98\\xef\\xbc\\x91\\xef\\xbc\\x94',\n",
       "        b'\\xef\\xbc\\xad\\xef\\xbc\\xa9\\xef\\xbc\\xb9\\xef\\xbc\\xa1\\xef\\xbc\\xb6\\xef\\xbc\\xa9'],\n",
       "       dtype=object),\n",
       " 'track_uri_pl': array([b'spotify:track:0000uJA4xCdxThagdLkkLR',\n",
       "        b'spotify:track:0002yNGLtYSYtc0X6ZnFvp',\n",
       "        b'spotify:track:00039MgrmLoIzSpuYKurn9', ...,\n",
       "        b'spotify:track:7zzwsf6tmZETUV26kR7D5z',\n",
       "        b'spotify:track:7zzxEH0xUl5k3p6IxUfgAO',\n",
       "        b'spotify:track:7zzyrYnZIfvYAGwl7lRb7X'], dtype=object),\n",
       " 'track_name_pl': array([b'!', b'! (Foreword)', b'! (The Song Formerly Known As)', ...,\n",
       "        b'\\xef\\xbb\\xbfThe Right Move',\n",
       "        b'\\xef\\xbf\\xbc9 Fruitless Years of Total Fucking Agony',\n",
       "        b'\\xef\\xbf\\xbd\\xc3\\xa4k\\xc3\\xa4skero'], dtype=object),\n",
       " 'album_name_pl': array([b'!', b'!! Going Places !!', b'!!! Chk Chik Chick', ...,\n",
       "        b'\\xed\\x9b\\x84\\xec\\x95\\x84\\xec\\x9c\\xa0-\\xed\\x95\\x99\\xea\\xb5\\x90 2015 (Original Television Soundtrack), Pt.3',\n",
       "        b'\\xed\\x9e\\x88\\xec\\x96\\xb4\\xeb\\xa1\\x9c - Single',\n",
       "        b'\\xef\\xbb\\xbfBPitch Control - Best of 2014'], dtype=object),\n",
       " 'artist_genres_pl': array([b'', b'\"australian children\\'s music\"',\n",
       "        b'\"australian children\\'s music\", \"children\\'s folk\", \"children\\'s music\"',\n",
       "        ..., b\"'zouk', 'zouk riddim'\", b\"'zouk', 'zouk riddim' 'zouk'\",\n",
       "        b\"'zydeco'\"], dtype=object),\n",
       " 'min_duration_ms_seed_pl': 0,\n",
       " 'max_duration_ms_seed_pl': 629322792,\n",
       " 'min_n_songs_pl': 1,\n",
       " 'max_n_songs_pl': 375,\n",
       " 'min_n_artists_pl': 1,\n",
       " 'max_n_artists_pl': 237,\n",
       " 'min_n_albums_pl': 1,\n",
       " 'max_n_albums_pl': 244,\n",
       " 'min_artist_pop': 0,\n",
       " 'max_artist_pop': 100,\n",
       " 'min_duration_ms_songs_pl': -1,\n",
       " 'max_duration_ms_songs_pl': 20744575,\n",
       " 'min_artist_followers': 0,\n",
       " 'max_artist_followers': 94437255,\n",
       " 'min_track_pop': 0,\n",
       " 'max_track_pop': 96,\n",
       " 'avg_duration_ms_seed_pl': 13000151.68,\n",
       " 'var_duration_ms_seed_pl': 133092900971233.58,\n",
       " 'avg_n_songs_pl': 55.21,\n",
       " 'var_n_songs_pl': 2317.54,\n",
       " 'avg_n_artists_pl': 30.56,\n",
       " 'var_n_artists_pl': 769.26,\n",
       " 'avg_n_albums_pl': 40.25,\n",
       " 'var_n_albums_pl': 1305.54,\n",
       " 'avg_artist_pop': 16.08,\n",
       " 'var_artist_pop': 300.64,\n",
       " 'avg_duration_ms_songs_pl': 234823.14,\n",
       " 'var_duration_ms_songs_pl': 5558806228.41,\n",
       " 'avg_artist_followers': 43337.77,\n",
       " 'var_artist_followers': 377777790193.57,\n",
       " 'avg_track_pop': 10.85,\n",
       " 'var_track_pop': 202.18}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6553e994-0c3e-4a3c-be3b-852ff3d0a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Playlist_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "\n",
    "        # ========================================\n",
    "        # non-sequence playlist features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: playlist name\n",
    "        self.pl_name_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    max_tokens=MAX_TOKENS, # not needed if passing vocab\n",
    "                    # vocabulary=vocab_dict['name'], \n",
    "                    name=\"pl_name_txt_vectorizer\", \n",
    "                    ngrams=2\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=MAX_TOKENS + 1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_name_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"pl_name_pooling\"),\n",
    "            ], name=\"pl_name_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: collaborative\n",
    "        collaborative_vocab = np.array([b'false', b'true'])\n",
    "        \n",
    "        self.pl_collaborative_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=collaborative_vocab, \n",
    "                    mask_token=None, \n",
    "                    name=\"pl_collaborative_lookup\", \n",
    "                    output_mode='int'\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(collaborative_vocab) + 1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_collaborative_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"pl_collaborative_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: pid\n",
    "        self.pl_track_uri_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=tf.constant(vocab_dict['track_uri_can']), \n",
    "                    mask_token=None, \n",
    "                    name=\"pl_track_uri_lookup\", \n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_can'])+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_track_uri_layer\",\n",
    "                ),\n",
    "            ], name=\"pl_track_uri_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: n_songs_pl\n",
    "        # TODO: Noramlize or Descritize?\n",
    "        n_songs_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_songs_pl'], \n",
    "            vocab_dict['max_n_songs_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.n_songs_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_songs_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_songs_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_songs_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_songs_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: num_artists_pl\n",
    "        # TODO: Noramlize or Descritize?\n",
    "        n_artists_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_artists_pl'], \n",
    "            vocab_dict['max_n_artists_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.n_artists_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_artists_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_artists_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_artists_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                )\n",
    "            ], name=\"n_artists_pl_emb_model\"\n",
    "        )\n",
    "\n",
    "        # Feature: num_albums_pl\n",
    "        n_albums_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_albums_pl'], \n",
    "            vocab_dict['max_n_albums_pl'],\n",
    "            num=100\n",
    "        )\n",
    "        self.n_albums_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_albums_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_albums_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_albums_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_albums_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # sequence playlist features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_pl\n",
    "        self.artist_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['artist_name_pl'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_name_pl']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_name_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_name_pl_1d\"),\n",
    "            ], name=\"artist_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_pl\n",
    "        # 2.2M unique\n",
    "        self.track_uri_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['track_uri_can'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_can']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_uri_1d\"),\n",
    "            ], name=\"track_uri_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_pl\n",
    "        self.track_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['track_name_pl'], \n",
    "                    name=\"track_name_pl_lookup\",\n",
    "                    output_mode='int',\n",
    "                    mask_token=''\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_name_pl']) + 2, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_name_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_name_pl_1d\"),\n",
    "            ], name=\"track_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        Feature: duration_ms_songs_pl\n",
    "        duration_ms_songs_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_duration_ms_songs_pl'], \n",
    "            vocab_dict['max_duration_ms_songs_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.duration_ms_songs_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Discretization(duration_ms_songs_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(duration_ms_songs_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"duration_ms_songs_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"duration_ms_songs_pl_emb_layer_pl_1d\"),\n",
    "            ], name=\"duration_ms_songs_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_pl\n",
    "        self.album_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=tf.constant(vocab_dict['album_name_pl']), \n",
    "                    mask_token=None, \n",
    "                    name=\"album_name_pl_lookup\"\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['album_name_pl']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_name_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"album_name_pl_emb_layer_1d\"),\n",
    "            ], name=\"album_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_pop_pl\n",
    "        artist_pop_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_artist_pop'], \n",
    "            vocab_dict['max_artist_pop'], \n",
    "            num=10\n",
    "        )\n",
    "        self.artist_pop_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Discretization(artist_pop_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(artist_pop_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_pop_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_pop_1d\"),\n",
    "            ], name=\"artist_pop_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artists_followers_pl\n",
    "        artists_followers_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_artist_followers'], \n",
    "            vocab_dict['max_artist_followers'], \n",
    "            num=10\n",
    "        )\n",
    "        self.artists_followers_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Discretization(artists_followers_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(artists_followers_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artists_followers_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artists_followers_pl_1d\"),\n",
    "            ], name=\"artists_followers_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_pl\n",
    "        track_pop_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_track_pop'], \n",
    "            vocab_dict['max_track_pop'], \n",
    "            num=10\n",
    "        )\n",
    "        self.track_pop_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                # tf.keras.layers.Flatten(dtype=tf.float32),\n",
    "                tf.keras.layers.Discretization(track_pop_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(track_pop_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_pop_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_pop_pl_1d\"),\n",
    "            ], name=\"track_pop_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_pl\n",
    "        self.artist_genres_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['artist_genres_pl'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_genres_pl']) + 2, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_genres_pl_emb_layer\",\n",
    "                    mask_zero=False\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_genres_pl_1d\"),\n",
    "            ], name=\"artist_genres_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # dense and cross layers\n",
    "        # ========================================\n",
    "\n",
    "        # Cross Layers\n",
    "        if USE_CROSS_LAYER:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                projection_dim=PROJECTION_DIM,\n",
    "                kernel_initializer=\"glorot_uniform\", \n",
    "                name=\"pl_cross_layer\"\n",
    "            )\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "            \n",
    "        # Dense Layers\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"pl_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda x: tf.nn.l2_normalize(\n",
    "                    x, 1, epsilon=1e-12, name=\"normalize_dense\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # ========================================\n",
    "    # call\n",
    "    # ========================================\n",
    "    def call(self, data):\n",
    "        '''\n",
    "        The call method defines what happens when\n",
    "        the model is called\n",
    "        '''\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                self.pl_name_text_embedding(data['name']),\n",
    "                self.pl_collaborative_embedding(data['collaborative']),\n",
    "                self.pl_track_uri_embedding(data[\"track_uri_can\"]),\n",
    "                self.n_songs_pl_embedding(data[\"n_songs_pl\"]),\n",
    "                self.n_artists_pl_embedding(data['num_artists_pl']),\n",
    "                self.n_albums_pl_embedding(data[\"num_albums_pl\"]),\n",
    "                \n",
    "                # sequence features\n",
    "                self.artist_name_pl_embedding(tf.reshape(data[\"artist_name_pl\"], (-1, MAX_PLAYLIST_LENGTH))), #reshape to get [BATCH, MAX_SEQ_LEN]\n",
    "                self.track_uri_pl_embedding(tf.reshape(data[\"track_uri_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.track_name_pl_embedding(tf.reshape(data[\"track_name_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.duration_ms_songs_pl_embedding(tf.reshape(data[\"duration_ms_songs_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.album_name_pl_embedding(tf.reshape(data[\"album_name_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.artist_pop_pl_embedding(tf.reshape(data[\"artist_pop_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.artists_followers_pl_embedding(tf.reshape(data[\"artists_followers_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.track_pop_pl_embedding(tf.reshape(data[\"track_pop_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "                self.artist_genres_pl_embedding(tf.reshape(data[\"artist_genres_pl\"], (-1, MAX_PLAYLIST_LENGTH))),\n",
    "            ], axis=1)\n",
    "        \n",
    "        # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            cross_embs = self._cross_layer(all_embs)\n",
    "            return self.dense_layers(cross_embs)\n",
    "        else:\n",
    "            return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bdd6e7-9b24-4093-86b0-a98f83b58eca",
   "metadata": {},
   "source": [
    "### test playlist tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1893e877-873c-4c2b-813e-ea924b096b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapts complete for name\n"
     ]
    }
   ],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_playlist_model = Playlist_Model(layer_sizes,vocab_dict_load)\n",
    "\n",
    "test_playlist_model.pl_name_text_embedding.layers[0].adapt(parsed_dataset_padded.map(lambda x: x['name']).batch(1000))\n",
    "\n",
    "print(\"Adapts complete for name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38ae8e37-e44f-4352-88cc-bad1c8c21971",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'music',\n",
       " 'country',\n",
       " 'party',\n",
       " 'summer',\n",
       " 'chill',\n",
       " 'good',\n",
       " 'jams',\n",
       " 'songs',\n",
       " 'rock',\n",
       " 'playlist',\n",
       " 'rap',\n",
       " 'new',\n",
       " 'the',\n",
       " '2017',\n",
       " 'my',\n",
       " 'mix',\n",
       " 'oldies',\n",
       " 'vibes',\n",
       " 'workout',\n",
       " 'old',\n",
       " 'throwback',\n",
       " '2016',\n",
       " 'work',\n",
       " 'car',\n",
       " 'christmas',\n",
       " 'up',\n",
       " 'dance',\n",
       " 'wedding',\n",
       " 'road',\n",
       " '90s',\n",
       " '2015',\n",
       " 'feels',\n",
       " 'classic',\n",
       " 'stuff',\n",
       " 'lit',\n",
       " 'love',\n",
       " 'worship',\n",
       " '80s',\n",
       " 'edm',\n",
       " 'it',\n",
       " 'school',\n",
       " 'out',\n",
       " 'hop',\n",
       " 'time',\n",
       " 'trip',\n",
       " 'throwbacks',\n",
       " 'pop',\n",
       " 'hip',\n",
       " 'best',\n",
       " 'happy',\n",
       " 'gym',\n",
       " 'classics',\n",
       " 'hip hop',\n",
       " 'spring',\n",
       " 'running',\n",
       " 'road trip',\n",
       " 'jamz',\n",
       " '17',\n",
       " 'slow',\n",
       " 'of',\n",
       " 'all',\n",
       " 'tunes',\n",
       " 'fall',\n",
       " 'run',\n",
       " 'classic rock',\n",
       " 'random',\n",
       " 'disney',\n",
       " 'feel',\n",
       " 'alternative',\n",
       " 'old school',\n",
       " 'driving',\n",
       " '16',\n",
       " 'me',\n",
       " 'for',\n",
       " 'day',\n",
       " 'feel good',\n",
       " 'rb',\n",
       " 'hype',\n",
       " 'but',\n",
       " 'i',\n",
       " 'pregame',\n",
       " 'indie',\n",
       " 'goodies',\n",
       " 'house',\n",
       " 'spanish',\n",
       " 'christian',\n",
       " 'fun',\n",
       " '2',\n",
       " 'beach',\n",
       " 'hits',\n",
       " 'back',\n",
       " '2014',\n",
       " 'good vibes',\n",
       " 'favorites',\n",
       " '3',\n",
       " 'shower',\n",
       " 'oldies but',\n",
       " 'mellow',\n",
       " 'in',\n",
       " 'get',\n",
       " 'chillin',\n",
       " 'turn',\n",
       " 'sad',\n",
       " 'mood',\n",
       " 'you',\n",
       " 'roadtrip',\n",
       " 'but goodies',\n",
       " 'good stuff',\n",
       " 'a',\n",
       " 'summer 17',\n",
       " 'halloween',\n",
       " 'top',\n",
       " 'jazz',\n",
       " 'jam',\n",
       " 'favorite',\n",
       " 'study',\n",
       " 'my music',\n",
       " 'beats',\n",
       " 'tbt',\n",
       " 'morning',\n",
       " 'alt',\n",
       " 'winter',\n",
       " 'drive',\n",
       " 'turn up',\n",
       " 'trap',\n",
       " 'soul',\n",
       " 'relax',\n",
       " 'to',\n",
       " 'sleep',\n",
       " 'pump',\n",
       " 'work out',\n",
       " 'summer 2017',\n",
       " 'fire',\n",
       " 'down',\n",
       " 'cool',\n",
       " 'bangers',\n",
       " 'reggaeton',\n",
       " 'favs',\n",
       " 'everything',\n",
       " 'life',\n",
       " 'good music',\n",
       " 'best of',\n",
       " 'and',\n",
       " 'current',\n",
       " 'reggae',\n",
       " 'just',\n",
       " 'idk',\n",
       " 'classical',\n",
       " '1',\n",
       " 'summer 16',\n",
       " 'ride',\n",
       " 'on',\n",
       " 'like',\n",
       " '2013',\n",
       " '2000s',\n",
       " 'the feels',\n",
       " 'car jams',\n",
       " 'vibe',\n",
       " 'pump up',\n",
       " 'gospel',\n",
       " 'dinner',\n",
       " 'jesus',\n",
       " 'chill music',\n",
       " 'acoustic',\n",
       " 'sunday',\n",
       " 'litty',\n",
       " 'vibin',\n",
       " 'good songs',\n",
       " 'easy',\n",
       " 'dope',\n",
       " 'calm',\n",
       " 'march',\n",
       " 'dad',\n",
       " 'the best',\n",
       " 'reception',\n",
       " 'punk',\n",
       " 'pool',\n",
       " 'october',\n",
       " 'la',\n",
       " 'hiphop',\n",
       " 'game',\n",
       " 'summer 2016',\n",
       " 'party playlist',\n",
       " 'days',\n",
       " 'the good',\n",
       " 'soft',\n",
       " 'metal',\n",
       " 'its',\n",
       " 'party mix',\n",
       " 'one',\n",
       " 'in the',\n",
       " 'go',\n",
       " 'girl',\n",
       " 'chill vibes',\n",
       " 'summer 2015',\n",
       " 'gold',\n",
       " 'august',\n",
       " 'april',\n",
       " 'vibez',\n",
       " 'turnt',\n",
       " 'sing',\n",
       " 'jammin',\n",
       " 'home',\n",
       " 'guilty',\n",
       " '15',\n",
       " 'rainy',\n",
       " 'my songs',\n",
       " 'may',\n",
       " 'june',\n",
       " 'july',\n",
       " 'grad',\n",
       " 'favorite songs',\n",
       " 'year',\n",
       " 'this',\n",
       " 'tb',\n",
       " 'smooth',\n",
       " 'now',\n",
       " 'love songs',\n",
       " 'bumpin',\n",
       " 'tracks',\n",
       " 'list',\n",
       " 'grad party',\n",
       " 'fresh',\n",
       " 'faves',\n",
       " 'electronic',\n",
       " '20',\n",
       " 'years',\n",
       " 'that',\n",
       " 'sweet',\n",
       " 'summer vibes',\n",
       " 'slow jams',\n",
       " 'november',\n",
       " 'nostalgia',\n",
       " 'mom',\n",
       " 'i like',\n",
       " 'all time',\n",
       " '2k17',\n",
       " '',\n",
       " 'texas',\n",
       " 'september',\n",
       " 'rides',\n",
       " 'praise',\n",
       " 'new music',\n",
       " 'mine',\n",
       " 'hour',\n",
       " 'fav',\n",
       " 'espaol',\n",
       " 'dubstep',\n",
       " 'childhood',\n",
       " 'car rides',\n",
       " 'break',\n",
       " 'awesome',\n",
       " '',\n",
       " 'is',\n",
       " 'clean',\n",
       " 'chill out',\n",
       " 'banda',\n",
       " 'af',\n",
       " 'yeah',\n",
       " 'nye',\n",
       " 'my jams',\n",
       " 'covers',\n",
       " 'boat',\n",
       " 'baby',\n",
       " '70s',\n",
       " 'top tracks',\n",
       " 'throw',\n",
       " 'other',\n",
       " 'new new',\n",
       " 'lovin',\n",
       " 'kpop',\n",
       " 'good good',\n",
       " 'deep',\n",
       " 'corridos',\n",
       " 'college',\n",
       " '2015 top',\n",
       " 'white',\n",
       " 'upbeat',\n",
       " 'power',\n",
       " 'party music',\n",
       " 'musica',\n",
       " 'latin',\n",
       " 'its lit',\n",
       " 'instrumental',\n",
       " 'high',\n",
       " 'good country',\n",
       " 'electro',\n",
       " 'birthday',\n",
       " 'wedding reception',\n",
       " 'wedding playlist',\n",
       " 'trance',\n",
       " 'play',\n",
       " 'of the',\n",
       " 'new country',\n",
       " 'musicals',\n",
       " 'lets',\n",
       " 'groovy',\n",
       " 'daily',\n",
       " 'cocktail',\n",
       " 'car ride',\n",
       " 'blues',\n",
       " 'yes',\n",
       " 'xmas',\n",
       " 'work work',\n",
       " 'summer jams',\n",
       " 'salsa',\n",
       " 'pumped',\n",
       " 'pre',\n",
       " 'pleasures',\n",
       " 'mixtape',\n",
       " 'january',\n",
       " 'it back',\n",
       " 'guilty pleasures',\n",
       " 'girls',\n",
       " 'gang',\n",
       " 'feelings',\n",
       " 'feeling',\n",
       " 'everyday',\n",
       " 'e',\n",
       " 'dance party',\n",
       " 'bump',\n",
       " 'trippin',\n",
       " 'soundtracks',\n",
       " 'old country',\n",
       " 'oh',\n",
       " 'new years',\n",
       " 'listening',\n",
       " 'hot',\n",
       " 'flow',\n",
       " 'feelin',\n",
       " 'fall 2016',\n",
       " 'christian music',\n",
       " 'camp',\n",
       " 'bangerz',\n",
       " 'bad',\n",
       " '100',\n",
       " 'yup',\n",
       " 'times',\n",
       " 'summa',\n",
       " 'spring 2017',\n",
       " 'sleepy',\n",
       " 'sexy',\n",
       " 'sad songs',\n",
       " 'roll',\n",
       " 'on the',\n",
       " 'ok',\n",
       " 'lake',\n",
       " 'kids',\n",
       " 'hard',\n",
       " 'golden',\n",
       " 'february',\n",
       " 'fall 2017',\n",
       " 'cruisin',\n",
       " 'cocktail hour',\n",
       " 'coachella',\n",
       " 'breathe',\n",
       " 'bops',\n",
       " '',\n",
       " 'yoga',\n",
       " 'what',\n",
       " 'werk',\n",
       " 'song',\n",
       " 'sixteen',\n",
       " 'sex',\n",
       " 'red',\n",
       " 'r',\n",
       " 'quiet',\n",
       " 'pre game',\n",
       " 'not',\n",
       " 'marathon',\n",
       " 'latino',\n",
       " 'l',\n",
       " 'it out',\n",
       " 'in my',\n",
       " 'funk',\n",
       " 'friday',\n",
       " 'english',\n",
       " 'en',\n",
       " 'easy listening',\n",
       " 'cruise',\n",
       " 'autumn',\n",
       " 'the road',\n",
       " 'texas country',\n",
       " 'techno',\n",
       " 'take',\n",
       " 'summer country',\n",
       " 'slow jamz',\n",
       " 'road trippin',\n",
       " 'ready',\n",
       " 'prom',\n",
       " 'pool party',\n",
       " 'old songs',\n",
       " 'main',\n",
       " 'i love',\n",
       " 'homework',\n",
       " 'holiday',\n",
       " 'groove',\n",
       " 'graduation',\n",
       " 'classic country',\n",
       " 'angst',\n",
       " 'yo',\n",
       " 'work it',\n",
       " 'warm',\n",
       " 'summertime',\n",
       " 'rage',\n",
       " 'party time',\n",
       " 'nice',\n",
       " 'listen',\n",
       " 'jesus jams',\n",
       " 'gaming',\n",
       " 'fave',\n",
       " 'fav songs',\n",
       " 'december',\n",
       " 'country music',\n",
       " 'church',\n",
       " 'bus',\n",
       " 'aux',\n",
       " 'yeet',\n",
       " 'yee',\n",
       " 'xxx',\n",
       " 'windows down',\n",
       " 'windows',\n",
       " 'weekend',\n",
       " 'wedding dinner',\n",
       " 'sunday morning',\n",
       " 'summer17',\n",
       " 'summer 2014',\n",
       " 'spring break',\n",
       " 'spring 2015',\n",
       " 'senior',\n",
       " 's',\n",
       " 'run run',\n",
       " 'real',\n",
       " 'ratchet',\n",
       " 'okay',\n",
       " 'of everything',\n",
       " 'no',\n",
       " 'n',\n",
       " 'myself',\n",
       " 'my country',\n",
       " 'happy happy',\n",
       " 'daily mix',\n",
       " 'country jams',\n",
       " 'cardio',\n",
       " 'blah',\n",
       " 'bang',\n",
       " 'b',\n",
       " 'all the',\n",
       " 'workout playlist',\n",
       " 'whatever',\n",
       " 'wake',\n",
       " 'untitled',\n",
       " 'teen',\n",
       " 'summer sixteen',\n",
       " 'spring 2016',\n",
       " 'sounds',\n",
       " 'songs i',\n",
       " 'sauce',\n",
       " 'new stuff',\n",
       " 'mornings',\n",
       " 'mixed',\n",
       " 'long',\n",
       " 'lifting',\n",
       " 'la la',\n",
       " 'know',\n",
       " 'island',\n",
       " 'gameday',\n",
       " 'funky',\n",
       " 'for you',\n",
       " 'for the',\n",
       " 'focus',\n",
       " 'fall 2015',\n",
       " 'en espaol',\n",
       " 'emo',\n",
       " 'dance music',\n",
       " 'country lovin',\n",
       " 'cleaning',\n",
       " 'chilling',\n",
       " 'blue',\n",
       " 'best songs',\n",
       " 'all songs',\n",
       " 'again',\n",
       " '2k16',\n",
       " '',\n",
       " 'zone',\n",
       " 'your',\n",
       " 'yas',\n",
       " 'travel',\n",
       " 'throwback jams',\n",
       " 'summer 2k17',\n",
       " 'spanish music',\n",
       " 'something',\n",
       " 'simp',\n",
       " 'rock n',\n",
       " 'riding',\n",
       " 'rainy days',\n",
       " 'rainy day',\n",
       " 'o',\n",
       " 'n roll',\n",
       " 'my mix',\n",
       " 'middle school',\n",
       " 'middle',\n",
       " 'march 2017',\n",
       " 'love you',\n",
       " 'jan',\n",
       " 'it up',\n",
       " 'heavy',\n",
       " 'goods',\n",
       " 'goldies',\n",
       " 'first',\n",
       " 'fiesta',\n",
       " 'do',\n",
       " 'country favs',\n",
       " 'coffee',\n",
       " 'class',\n",
       " 'chill mix',\n",
       " 'bit of',\n",
       " 'bit',\n",
       " 'bbq',\n",
       " 'bass',\n",
       " 'basketball',\n",
       " '90s alternative',\n",
       " 'workout music',\n",
       " 'wake up',\n",
       " 'vegas',\n",
       " 'ultimate',\n",
       " 'titty',\n",
       " 'throw back',\n",
       " 'thoughts',\n",
       " 't',\n",
       " 'swing',\n",
       " 'sunny',\n",
       " 'some',\n",
       " 'snowboarding',\n",
       " 'school hip',\n",
       " 'rnb',\n",
       " 'party bus',\n",
       " 'old jams',\n",
       " 'og',\n",
       " 'new songs',\n",
       " 'my favs',\n",
       " 'my favorites',\n",
       " 'motown',\n",
       " 'misc',\n",
       " 'low',\n",
       " 'litty titty',\n",
       " 'house party',\n",
       " 'hood',\n",
       " 'hippity',\n",
       " 'hi',\n",
       " 'good times',\n",
       " 'good morning',\n",
       " 'getting ready',\n",
       " 'getting',\n",
       " 'forever',\n",
       " 'folk',\n",
       " 'family',\n",
       " 'discover',\n",
       " 'disco',\n",
       " 'dirt',\n",
       " 'dancing',\n",
       " 'dance dance',\n",
       " 'dad music',\n",
       " 'christmas music',\n",
       " 'chillout',\n",
       " 'car playlist',\n",
       " 'california',\n",
       " 'boy',\n",
       " 'bday',\n",
       " 'bands',\n",
       " 'aye',\n",
       " 'a1',\n",
       " '90s rock',\n",
       " '60s',\n",
       " 'yuh',\n",
       " 'young',\n",
       " 'winter 2016',\n",
       " 'wedding dance',\n",
       " 'time favorites',\n",
       " 'things',\n",
       " 'the playlist',\n",
       " 'tailgate',\n",
       " 'swag',\n",
       " 'sundays',\n",
       " 'summer 2013',\n",
       " 'sprang',\n",
       " 'spotify',\n",
       " 'soundtrack',\n",
       " 'soundhound',\n",
       " 'songs to',\n",
       " 'school rap',\n",
       " 'school jams',\n",
       " 'roadtrippin',\n",
       " 'right',\n",
       " 'relaxing',\n",
       " 'plane',\n",
       " 'only',\n",
       " 'oldie',\n",
       " 'old but',\n",
       " 'october 2017',\n",
       " 'movie',\n",
       " 'moms',\n",
       " 'memories',\n",
       " 'little',\n",
       " 'junior',\n",
       " 'ish',\n",
       " 'high school',\n",
       " 'hannah',\n",
       " 'going',\n",
       " 'get pumped',\n",
       " 'falling',\n",
       " 'eve',\n",
       " 'electric',\n",
       " 'driving music',\n",
       " 'dont',\n",
       " 'disney songs',\n",
       " 'chris',\n",
       " 'chillaxin',\n",
       " 'beautiful',\n",
       " 'bachata',\n",
       " '2000',\n",
       " 'youth',\n",
       " 'yellow',\n",
       " 'yacht',\n",
       " 'worship music',\n",
       " 'working',\n",
       " 'with',\n",
       " 'west',\n",
       " 'waves',\n",
       " 'warm up',\n",
       " 'trips',\n",
       " 'today',\n",
       " 'throwback songs',\n",
       " 'throw it',\n",
       " 'this is',\n",
       " 'the goods',\n",
       " 'the classics',\n",
       " 'summer playlist',\n",
       " 'straight',\n",
       " 'sprung',\n",
       " 'spring 17',\n",
       " 'sorry',\n",
       " 'ski',\n",
       " 'saturday',\n",
       " 'room',\n",
       " 'romantic',\n",
       " 'roads',\n",
       " 'roadie',\n",
       " 'relaxation',\n",
       " 'red bull',\n",
       " 'random songs',\n",
       " 'pretty',\n",
       " 'praise worship',\n",
       " 'party party',\n",
       " 'our',\n",
       " 'opm',\n",
       " 'old stuff',\n",
       " 'my stuff',\n",
       " 'my jam',\n",
       " 'my favorite',\n",
       " 'moms playlist',\n",
       " 'modern',\n",
       " 'miami',\n",
       " 'meh',\n",
       " 'm',\n",
       " 'lounge',\n",
       " 'laid back',\n",
       " 'laid',\n",
       " 'kickback',\n",
       " 'hipster',\n",
       " 'her',\n",
       " 'guitar',\n",
       " 'great',\n",
       " 'goes',\n",
       " 'get it',\n",
       " 'game day',\n",
       " 'freshman',\n",
       " 'fall 17',\n",
       " 'fall 16',\n",
       " 'espanol',\n",
       " 'electronica',\n",
       " 'eh',\n",
       " 'editions',\n",
       " 'dnb',\n",
       " 'discovered',\n",
       " 'daze',\n",
       " 'cumbias',\n",
       " 'country mix',\n",
       " 'commute',\n",
       " 'christmas time',\n",
       " 'chill edm',\n",
       " 'chill af',\n",
       " 'chicago',\n",
       " 'bull editions',\n",
       " 'bull',\n",
       " 'be',\n",
       " 'bb',\n",
       " 'america',\n",
       " '14',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'years eve',\n",
       " 'yacht rock',\n",
       " 'y',\n",
       " 'writing',\n",
       " 'wrap',\n",
       " 'world',\n",
       " 'workout mix',\n",
       " 'winter 2017',\n",
       " 'white girl',\n",
       " 'wedding songs',\n",
       " 'vroom',\n",
       " 'vacation',\n",
       " 'u',\n",
       " 'tropical',\n",
       " 'tree',\n",
       " 'top 100',\n",
       " 'todays hits',\n",
       " 'todays',\n",
       " 'thursday',\n",
       " 'thinking',\n",
       " 'the soul',\n",
       " 'that good',\n",
       " 'sunshine',\n",
       " 'sun',\n",
       " 'summer 15',\n",
       " 'study music',\n",
       " 'spirit',\n",
       " 'soft rock',\n",
       " 'so',\n",
       " 'slaps',\n",
       " 'skool',\n",
       " 'shuffle',\n",
       " 'sexy time',\n",
       " 'right now',\n",
       " 'reggeton',\n",
       " 'reggeaton',\n",
       " 'queen',\n",
       " 'popular',\n",
       " 'playlist 2',\n",
       " 'piano',\n",
       " 'perfect',\n",
       " 'old rock',\n",
       " 'old rap',\n",
       " 'of july',\n",
       " 'my top',\n",
       " 'mix it',\n",
       " 'mix 1',\n",
       " 'mi',\n",
       " 'meow',\n",
       " 'may 2017',\n",
       " 'loud',\n",
       " 'live',\n",
       " 'latina',\n",
       " 'kuntry',\n",
       " 'jazzy',\n",
       " 'in love',\n",
       " 'idek',\n",
       " 'him',\n",
       " 'hey',\n",
       " 'heat',\n",
       " 'heart',\n",
       " 'halloween party',\n",
       " 'half',\n",
       " 'h',\n",
       " 'gym time',\n",
       " 'gym jams',\n",
       " 'groovin',\n",
       " 'grind',\n",
       " 'grade',\n",
       " 'get lit',\n",
       " 'gang gang',\n",
       " 'fuego',\n",
       " 'food',\n",
       " 'feeling myself',\n",
       " 'drivin',\n",
       " 'dj',\n",
       " 'dark',\n",
       " 'dank',\n",
       " 'damn',\n",
       " 'country hits',\n",
       " 'christmas favorites',\n",
       " 'cant',\n",
       " 'canciones',\n",
       " 'c',\n",
       " 'butter',\n",
       " 'brown',\n",
       " 'bounce',\n",
       " 'bluegrass',\n",
       " 'big',\n",
       " 'best playlist',\n",
       " 'beatz',\n",
       " 'beat',\n",
       " 'beast',\n",
       " 'ballads',\n",
       " 'back in',\n",
       " 'awesome mix',\n",
       " 'alt rock',\n",
       " 'alex',\n",
       " 'afternoon',\n",
       " 'acl',\n",
       " '90s rb',\n",
       " '90s hip',\n",
       " '4th',\n",
       " '420',\n",
       " '2012',\n",
       " '00s',\n",
       " '0',\n",
       " '',\n",
       " 'yay',\n",
       " 'xx',\n",
       " 'work mix',\n",
       " 'wild',\n",
       " 'why',\n",
       " 'wedding music',\n",
       " 'want',\n",
       " 'volleyball',\n",
       " 'under',\n",
       " 'turnip',\n",
       " 'to sing',\n",
       " 'timeless',\n",
       " 'throwback thursday',\n",
       " 'the day',\n",
       " 'teen angst',\n",
       " 'summer time',\n",
       " 'summer party',\n",
       " 'summer lovin',\n",
       " 'summer jamz',\n",
       " 'straight fire',\n",
       " 'spin',\n",
       " 'southern',\n",
       " 'softball',\n",
       " 'snow',\n",
       " 'smoke',\n",
       " 'skiing',\n",
       " 'seventeen',\n",
       " 'senior year',\n",
       " 'scores',\n",
       " 'running mix',\n",
       " 'rock en',\n",
       " 'rewind',\n",
       " 'raphiphop',\n",
       " 'playlist1',\n",
       " 'peaceful',\n",
       " 'pch',\n",
       " 'party list',\n",
       " 'party jams',\n",
       " 'partay',\n",
       " 'part',\n",
       " 'old skool',\n",
       " 'old music',\n",
       " 'offline',\n",
       " 'newnew',\n",
       " 'new rap',\n",
       " 'new playlist',\n",
       " 'nashville',\n",
       " 'my life',\n",
       " 'my faves',\n",
       " 'my childhood',\n",
       " 'move',\n",
       " 'more',\n",
       " 'monster',\n",
       " 'molly',\n",
       " 'mode',\n",
       " 'mm',\n",
       " 'michael',\n",
       " 'mexico',\n",
       " 'lol',\n",
       " 'lit songs',\n",
       " 'light',\n",
       " 'lazy',\n",
       " 'katie',\n",
       " 'karaoke',\n",
       " 'jesus music',\n",
       " 'jamzzz',\n",
       " 'jake',\n",
       " 'irish',\n",
       " 'inspiration',\n",
       " 'im',\n",
       " 'hit',\n",
       " 'hindi',\n",
       " 'here',\n",
       " 'hawaii',\n",
       " 'happy vibes',\n",
       " 'graduation party',\n",
       " 'good rap',\n",
       " 'go to',\n",
       " 'girl power',\n",
       " 'get turnt',\n",
       " 'friendsgiving',\n",
       " 'free',\n",
       " 'for mom',\n",
       " 'football',\n",
       " 'feelz',\n",
       " 'feelin it',\n",
       " 'feb',\n",
       " 'ever',\n",
       " 'energy',\n",
       " 'dub',\n",
       " 'drinking',\n",
       " 'drake',\n",
       " 'dirty',\n",
       " 'deep house',\n",
       " 'de',\n",
       " 'dat',\n",
       " 'dancehall',\n",
       " 'dads',\n",
       " 'country tunes',\n",
       " 'country playlist',\n",
       " 'country gold',\n",
       " 'country faves',\n",
       " 'chinese',\n",
       " 'chillstep',\n",
       " 'chilll',\n",
       " 'chill playlist',\n",
       " 'chill 20',\n",
       " 'car music',\n",
       " 'bye',\n",
       " 'bruh',\n",
       " 'boi',\n",
       " 'black',\n",
       " 'better',\n",
       " 'best country',\n",
       " 'beans',\n",
       " 'bachelorette',\n",
       " 'art',\n",
       " 'another',\n",
       " 'ambient',\n",
       " 'alone',\n",
       " 'airplane',\n",
       " 'after',\n",
       " 'adventure',\n",
       " '90s country',\n",
       " '80s hits',\n",
       " '80',\n",
       " '30',\n",
       " '21',\n",
       " '131',\n",
       " '12',\n",
       " 'yeehaw',\n",
       " 'ya',\n",
       " 'workout 2',\n",
       " 'work playlist',\n",
       " 'why not',\n",
       " 'vibing',\n",
       " 'valentines day',\n",
       " 'valentines',\n",
       " 'v',\n",
       " 'under the',\n",
       " 'uh',\n",
       " 'trash',\n",
       " 'training',\n",
       " 'to the',\n",
       " 'throwin it',\n",
       " 'throwin',\n",
       " 'the list',\n",
       " 'take it',\n",
       " 'summer16',\n",
       " 'summer tunes',\n",
       " 'summer 2k16',\n",
       " 'studying',\n",
       " 'squad',\n",
       " 'spring 2014',\n",
       " 'south',\n",
       " 'soul food',\n",
       " 'something new',\n",
       " 'sleepy time',\n",
       " 'sky',\n",
       " 'skrt',\n",
       " 'sing along',\n",
       " 'school dance',\n",
       " 'school country',\n",
       " 'sarah',\n",
       " 'sadness',\n",
       " 'ryan',\n",
       " 'running playlist',\n",
       " 'running 2',\n",
       " 'roots',\n",
       " 'road again',\n",
       " 'reception playlist',\n",
       " 'raw',\n",
       " 'rap playlist',\n",
       " 'rap mix',\n",
       " 'rap hip',\n",
       " 'randomness',\n",
       " 'rain',\n",
       " 'punk goes',\n",
       " 'pleasure',\n",
       " 'play it',\n",
       " 'pill',\n",
       " 'people',\n",
       " 'peanut butter',\n",
       " 'peanut',\n",
       " 'past',\n",
       " 'para',\n",
       " 'ones',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_playlist_model.pl_name_text_embedding.layers[0].get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d020d381-738b-4d7e-80ff-3d56c5bb701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict_load['name_voacb'] = test_playlist_model.pl_name_text_embedding.layers[0].get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b87363d4-64d9-4cca-9290-b26efdfe9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.12191597 -0.02955313  0.26741976 -0.19543947 -0.08209568  0.38031173\n",
      "   0.22954062  0.11182079  0.14448637 -0.01198089 -0.03505188  0.2502452\n",
      "   0.10176286 -0.00109097  0.05177378 -0.1142177   0.01734834 -0.26544943\n",
      "   0.2931487   0.09069694 -0.15994911  0.44579393  0.04805622 -0.1678858\n",
      "  -0.0100677  -0.07310402 -0.07062502  0.11664435  0.0698021  -0.02859749\n",
      "   0.27798328 -0.14243548]\n",
      " [-0.41296196 -0.02142718  0.17761382  0.15274735 -0.04896091  0.5102782\n",
      "   0.08266084 -0.03581357  0.20971023 -0.09563252  0.03559438  0.1491059\n",
      "   0.04533963 -0.11260843 -0.09356883 -0.099608   -0.16720319 -0.3448041\n",
      "   0.14887866  0.04505316 -0.0779938   0.19867907 -0.25701636 -0.1361999\n",
      "   0.04184773 -0.1288359   0.04295938  0.0744244   0.1968722   0.03109774\n",
      "   0.02927961 -0.16021407]], shape=(2, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test with the source batched datset\n",
    "batched_dataset = parsed_dataset_padded.batch(2)\n",
    "for x in batched_dataset.take(1):\n",
    "    print(test_playlist_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0be2a2-af20-47e0-8759-94a48fa6d996",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"playlist__model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pl_name_emb_model (Sequenti  (None, 32)               2368928   \n",
      " al)                                                             \n",
      "||\n",
      "| pl_name_txt_vectorizer (Tex  (None, None)           0         |\n",
      "| tVectorization)                                               |\n",
      "|                                                               |\n",
      "| pl_name_emb_layer (Embeddin  (None, None, 32)       2368928   |\n",
      "| g)                                                            |\n",
      "|                                                               |\n",
      "| pl_name_pooling (GlobalAver  (None, 32)             0         |\n",
      "| agePooling1D)                                                 |\n",
      "\n",
      " pl_collaborative_emb_model   (10, 32)                 96        \n",
      " (Sequential)                                                    \n",
      "||\n",
      "| pl_collaborative_lookup (St  (10,)                  0         |\n",
      "| ringLookup)                                                   |\n",
      "|                                                               |\n",
      "| pl_collaborative_emb_layer   (10, 32)               96        |\n",
      "| (Embedding)                                                   |\n",
      "\n",
      " pl_track_uri_emb_model (Seq  (10, 32)                 72393376  \n",
      " uential)                                                        \n",
      "||\n",
      "| pl_track_uri_lookup (String  (10,)                  0         |\n",
      "| Lookup)                                                       |\n",
      "|                                                               |\n",
      "| pl_track_uri_layer (Embeddi  (10, 32)               72393376  |\n",
      "| ng)                                                           |\n",
      "\n",
      " n_songs_pl_emb_model (Seque  (10, 32)                 3232      \n",
      " ntial)                                                          \n",
      "||\n",
      "| discretization (Discretizat  (10,)                  0         |\n",
      "| ion)                                                          |\n",
      "|                                                               |\n",
      "| n_songs_pl_emb_layer (Embed  (10, 32)               3232      |\n",
      "| ding)                                                         |\n",
      "\n",
      " n_artists_pl_emb_model (Seq  (10, 32)                 3232      \n",
      " uential)                                                        \n",
      "||\n",
      "| discretization_1 (Discretiz  (10,)                  0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| n_artists_pl_emb_layer (Emb  (10, 32)               3232      |\n",
      "| edding)                                                       |\n",
      "\n",
      " n_albums_pl_emb_model (Sequ  (10, 32)                 3232      \n",
      " ential)                                                         \n",
      "||\n",
      "| discretization_2 (Discretiz  (10,)                  0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| n_albums_pl_emb_layer (Embe  (10, 32)               3232      |\n",
      "| dding)                                                        |\n",
      "\n",
      " artist_name_pl_emb_model (S  (10, 32)                 9206752   \n",
      " equential)                                                      \n",
      "||\n",
      "| string_lookup_1 (StringLook  (10, 375)              0         |\n",
      "| up)                                                           |\n",
      "|                                                               |\n",
      "| artist_name_pl_emb_layer (E  (10, 375, 32)          9206752   |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| artist_name_pl_1d (GlobalAv  (10, 32)               0         |\n",
      "| eragePooling1D)                                               |\n",
      "\n",
      " track_uri_pl_emb_model (Seq  (10, 32)                 72393376  \n",
      " uential)                                                        \n",
      "||\n",
      "| string_lookup_2 (StringLook  (10, 375)              0         |\n",
      "| up)                                                           |\n",
      "|                                                               |\n",
      "| track_uri_pl_emb_layer (Emb  (10, 375, 32)          72393376  |\n",
      "| edding)                                                       |\n",
      "|                                                               |\n",
      "| track_uri_1d (GlobalAverage  (10, 32)               0         |\n",
      "| Pooling1D)                                                    |\n",
      "\n",
      " track_name_pl_emb_model (Se  (10, 32)                 47480160  \n",
      " quential)                                                       \n",
      "||\n",
      "| track_name_pl_lookup (Strin  (10, 375)              0         |\n",
      "| gLookup)                                                      |\n",
      "|                                                               |\n",
      "| track_name_pl_emb_layer (Em  (10, 375, 32)          47480160  |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| track_name_pl_1d (GlobalAve  (10, 32)               0         |\n",
      "| ragePooling1D)                                                |\n",
      "\n",
      " duration_ms_songs_pl_emb_mo  (10, 32)                 3232      \n",
      " del (Sequential)                                                \n",
      "||\n",
      "| discretization_3 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| duration_ms_songs_pl_emb_la  (10, 375, 32)          3232      |\n",
      "| yer (Embedding)                                               |\n",
      "|                                                               |\n",
      "| duration_ms_songs_pl_emb_la  (10, 32)               0         |\n",
      "| yer_pl_1d (GlobalAveragePoo                                   |\n",
      "| ling1D)                                                       |\n",
      "\n",
      " album_name_pl_emb_model (Se  (10, 32)                 18292032  \n",
      " quential)                                                       \n",
      "||\n",
      "| album_name_pl_lookup (Strin  (10, 375)              0         |\n",
      "| gLookup)                                                      |\n",
      "|                                                               |\n",
      "| album_name_pl_emb_layer (Em  (10, 375, 32)          18292032  |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| album_name_pl_emb_layer_1d   (10, 32)               0         |\n",
      "| (GlobalAveragePooling1D)                                      |\n",
      "\n",
      " artist_pop_pl_emb_model (Se  (10, 32)                 352       \n",
      " quential)                                                       \n",
      "||\n",
      "| discretization_4 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| artist_pop_pl_emb_layer (Em  (10, 375, 32)          352       |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| artist_pop_1d (GlobalAverag  (10, 32)               0         |\n",
      "| ePooling1D)                                                   |\n",
      "\n",
      " artists_followers_pl_emb_mo  (10, 32)                 352       \n",
      " del (Sequential)                                                \n",
      "||\n",
      "| discretization_5 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| artists_followers_pl_emb_la  (10, 375, 32)          352       |\n",
      "| yer (Embedding)                                               |\n",
      "|                                                               |\n",
      "| artists_followers_pl_1d (Gl  (10, 32)               0         |\n",
      "| obalAveragePooling1D)                                         |\n",
      "\n",
      " track_pop_pl_emb_model (Seq  (10, 32)                 352       \n",
      " uential)                                                        \n",
      "||\n",
      "| discretization_6 (Discretiz  (10, 375)              0         |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| track_pop_pl_emb_layer (Emb  (10, 375, 32)          352       |\n",
      "| edding)                                                       |\n",
      "|                                                               |\n",
      "| track_pop_pl_1d (GlobalAver  (10, 32)               0         |\n",
      "| agePooling1D)                                                 |\n",
      "\n",
      " artist_genres_pl_emb_model   (10, 32)                 1260768   \n",
      " (Sequential)                                                    \n",
      "||\n",
      "| flatten (Flatten)         (10, 375)                 0         |\n",
      "|                                                               |\n",
      "| string_lookup_3 (StringLook  (10, 375)              0         |\n",
      "| up)                                                           |\n",
      "|                                                               |\n",
      "| artist_genres_pl_emb_layer   (10, 375, 32)          1260768   |\n",
      "| (Embedding)                                                   |\n",
      "|                                                               |\n",
      "| artist_genres_pl_1d (Global  (10, 32)               0         |\n",
      "| AveragePooling1D)                                             |\n",
      "\n",
      " pl_cross_layer (Cross)      multiple                  5280      \n",
      "                                                                 \n",
      " pl_dense_layers (Sequential  (10, 32)                 32864     \n",
      " )                                                               \n",
      "||\n",
      "| dense (Dense)             (10, 64)                  30784     |\n",
      "|                                                               |\n",
      "| dropout (Dropout)         (10, 64)                  0         |\n",
      "|                                                               |\n",
      "| dense_1 (Dense)           (10, 32)                  2080      |\n",
      "|                                                               |\n",
      "| lambda (Lambda)           (10, 32)                  0         |\n",
      "\n",
      "=================================================================\n",
      "Total params: 223,447,616\n",
      "Trainable params: 223,447,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_playlist_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede145f9-1973-4261-8d98-c2429857b125",
   "metadata": {},
   "source": [
    "## Track (candidate) Tower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f92c564e-e5e4-43b0-a011-fd4355555c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "\n",
    "# candidate_test_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9345cb95-f44f-4437-8ffa-d1670b30da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidate_Track_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ========================================\n",
    "        # Candidate features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_can\n",
    "        self.artist_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    max_tokens=MAX_TOKENS,\n",
    "                    # vocabulary=vocab_dict[\"artist_name_can\"],\n",
    "                    name=\"artist_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=MAX_TOKENS+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_name_can_pooling\"),\n",
    "            ], name=\"artist_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_can\n",
    "        self.track_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    max_tokens=MAX_TOKENS,\n",
    "                    # vocabulary=vocab_dict[\"track_name_can\"],\n",
    "                    name=\"track_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=MAX_TOKENS+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"track_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_name_can_pooling\"),\n",
    "            ], name=\"track_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_can\n",
    "        self.album_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    max_tokens=MAX_TOKENS,\n",
    "                    # vocabulary=vocab_dict[\"album_name_can\"],\n",
    "                    name=\"album_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=MAX_TOKENS+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"album_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"album_name_can_pooling\"),\n",
    "            ], name=\"album_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_uri_can\n",
    "        self.artist_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=200_000+1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"artist_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_can\n",
    "        self.track_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=200_000+1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"track_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_uri_can\n",
    "        self.album_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=200_000+1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"album_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: duration_ms_can\n",
    "        self.duration_ms_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_duration_ms_songs_pl'],\n",
    "            variance=vocab_dict['var_duration_ms_songs_pl'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_can\n",
    "        self.track_pop_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_track_pop'],\n",
    "            variance=vocab_dict['var_track_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_pop_can\n",
    "        self.artist_pop_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_pop'],\n",
    "            variance=vocab_dict['var_artist_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_followers_can\n",
    "        self.artist_followers_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_followers'],\n",
    "            variance=vocab_dict['var_artist_followers'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_can\n",
    "        self.artist_genres_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    max_tokens=MAX_TOKENS,\n",
    "                    # vocabulary=vocab_dict[\"artist_genres_can\"],\n",
    "                    name=\"artist_genres_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=MAX_TOKENS+1,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_genres_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_genres_can_pooling\"),\n",
    "            ], name=\"artist_genres_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # Dense & Cross Layers\n",
    "        # ========================================\n",
    "        \n",
    "        # Cross Layers\n",
    "        if USE_CROSS_LAYER:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                projection_dim=PROJECTION_DIM,\n",
    "                kernel_initializer=\"glorot_uniform\", \n",
    "                name=\"can_cross_layer\"\n",
    "            )\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "        \n",
    "        # Dense Layer\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"candidate_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    # ========================================\n",
    "    # Call Function\n",
    "    # ========================================\n",
    "            \n",
    "    def call(self, data):\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                self.artist_name_can_text_embedding(data['artist_name_can']),  \n",
    "                self.track_name_can_text_embedding(data['track_name_can']),  \n",
    "                self.album_name_can_text_embedding(data['album_name_can']),  \n",
    "                self.artist_uri_can_embedding(data['artist_uri_can']),  \n",
    "                self.track_uri_can_embedding(data['track_uri_can']),  \n",
    "                self.album_uri_can_embedding(data['album_uri_can']),  \n",
    "                tf.reshape(self.duration_ms_can_normalized(data[\"duration_ms_can\"]), (-1, 1)), \n",
    "                tf.reshape(self.track_pop_can_normalized(data[\"track_pop_can\"]), (-1, 1)),  \n",
    "                tf.reshape(self.artist_pop_can_normalized(data[\"artist_pop_can\"]), (-1, 1)),  \n",
    "                tf.reshape(self.artist_followers_can_normalized(data[\"artist_followers_can\"]), (-1, 1)),  \n",
    "                self.artist_genres_can_text_embedding(data['album_uri_can']),  \n",
    "            ], axis=1\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # return self.dense_layers(all_embs)\n",
    "                # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            cross_embs = self._cross_layer(all_embs)\n",
    "            return self.dense_layers(cross_embs)\n",
    "        else:\n",
    "            return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545f0aa-ffe7-4f7b-85fd-890aa596aae8",
   "metadata": {},
   "source": [
    "### Candidate model\n",
    "Note adapts are done on the unique candidate dataset to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01b52944-7db2-4a41-95ff-602b97f35345",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_can_track_model = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "\n",
    "#adapts\n",
    "test_can_track_model.artist_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_name_can']).batch(1000))\n",
    "test_can_track_model.track_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['track_name_can']).batch(1000))\n",
    "test_can_track_model.album_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['album_name_can']).batch(1000))\n",
    "test_can_track_model.artist_genres_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_genres_can']).batch(1000))\n",
    "\n",
    "# can_result = test_can_track_model([candidate_test_instance])\n",
    "\n",
    "# print(f\"Shape of can_result: {can_result.shape}\")\n",
    "# can_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7295b620-60aa-42e5-a46d-fc497e15c5c6",
   "metadata": {},
   "source": [
    "## Validate the output in a small batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d1c46d-a143-4269-828d-04df1f9d1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.16611138e-01 -2.04020873e-01 -1.16053328e-01  5.32517061e-02\n",
      "   7.53906071e-02 -4.25571978e-01 -1.39279783e-01  1.57434329e-01\n",
      "  -7.10058585e-02 -2.85662040e-02  5.31206608e-01  2.83476382e-01\n",
      "  -1.90265477e-01 -2.14888752e-01 -1.26938522e-01 -2.40889877e-01\n",
      "   5.10127246e-01  4.57332358e-02  1.68353155e-01 -4.51710194e-01\n",
      "   1.78325117e-01 -4.95814562e-01  2.49489173e-02  4.06476349e-01\n",
      "  -4.88519043e-01  7.03144372e-02  1.10611647e-01  1.93128213e-02\n",
      "  -2.63601542e-04  2.42397189e-02  2.28524953e-02 -2.54099429e-01]\n",
      " [ 6.88601732e-02 -2.39342123e-01 -1.45322546e-01  3.65444720e-02\n",
      "   1.55565798e-01  8.12748075e-03  1.65407032e-01  1.02503739e-01\n",
      "  -3.88229489e-02  2.07624465e-01  3.07005078e-01 -1.08786941e-01\n",
      "  -6.59863651e-02  1.67001560e-02  8.75131488e-02 -1.87251627e-01\n",
      "  -5.65811470e-02 -7.63903707e-02  1.17914274e-01 -1.65222943e-01\n",
      "  -4.16381299e-01 -4.63461429e-01 -2.26131201e-01  1.44475937e-01\n",
      "  -2.54403561e-01 -5.76799661e-02 -2.67308056e-01  1.24412328e-02\n",
      "  -2.05820337e-01  2.80421019e-01  7.07858682e-01  7.75220767e-02]], shape=(2, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test with the source batched datset and candidate dataset\n",
    "batched_dataset = parsed_candidate_dataset.batch(2)\n",
    "for x in batched_dataset.take(1):\n",
    "    print(test_can_track_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13a7e41a-88f2-4fd5-9d14-910f3f611dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"candidate__track__model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " artist_name_can_emb_model (  (None, 32)               9206752   \n",
      " Sequential)                                                     \n",
      "||\n",
      "| artist_name_can_txt_vectori  (None, None)           0         |\n",
      "| zer (TextVectorization)                                       |\n",
      "|                                                               |\n",
      "| artist_name_can_emb_layer (  (None, None, 32)       9206752   |\n",
      "| Embedding)                                                    |\n",
      "|                                                               |\n",
      "| artist_name_can_pooling (Gl  (None, 32)             0         |\n",
      "| obalAveragePooling1D)                                         |\n",
      "\n",
      " track_name_can_emb_model (S  (None, 32)               47480128  \n",
      " equential)                                                      \n",
      "||\n",
      "| track_name_can_txt_vectoriz  (None, None)           0         |\n",
      "| er (TextVectorization)                                        |\n",
      "|                                                               |\n",
      "| track_name_can_emb_layer (E  (None, None, 32)       47480128  |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| track_name_can_pooling (Glo  (None, 32)             0         |\n",
      "| balAveragePooling1D)                                          |\n",
      "\n",
      " album_name_can_emb_model (S  (None, 32)               18292032  \n",
      " equential)                                                      \n",
      "||\n",
      "| album_name_can_txt_vectoriz  (None, None)           0         |\n",
      "| er (TextVectorization)                                        |\n",
      "|                                                               |\n",
      "| album_name_can_emb_layer (E  (None, None, 32)       18292032  |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| album_name_can_pooling (Glo  (None, 32)             0         |\n",
      "| balAveragePooling1D)                                          |\n",
      "\n",
      " artist_uri_can_emb_model (S  (2, 32)                  6400032   \n",
      " equential)                                                      \n",
      "||\n",
      "| hashing (Hashing)         (2,)                      0         |\n",
      "|                                                               |\n",
      "| artist_uri_can_emb_layer (E  (2, 32)                6400032   |\n",
      "| mbedding)                                                     |\n",
      "\n",
      " track_uri_can_emb_model (Se  (2, 32)                  6400032   \n",
      " quential)                                                       \n",
      "||\n",
      "| hashing_1 (Hashing)       (2,)                      0         |\n",
      "|                                                               |\n",
      "| track_uri_can_emb_layer (Em  (2, 32)                6400032   |\n",
      "| bedding)                                                      |\n",
      "\n",
      " album_uri_can_emb_model (Se  (2, 32)                  6400032   \n",
      " quential)                                                       \n",
      "||\n",
      "| hashing_2 (Hashing)       (2,)                      0         |\n",
      "|                                                               |\n",
      "| album_uri_can_emb_layer (Em  (2, 32)                6400032   |\n",
      "| bedding)                                                      |\n",
      "\n",
      " normalization (Normalizatio  multiple                 0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " normalization_1 (Normalizat  multiple                 0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " normalization_2 (Normalizat  multiple                 0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " normalization_3 (Normalizat  multiple                 0         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " artist_genres_can_emb_model  (None, 32)               1260736   \n",
      "  (Sequential)                                                   \n",
      "||\n",
      "| artist_genres_can_txt_vecto  (None, None)           0         |\n",
      "| rizer (TextVectorization)                                     |\n",
      "|                                                               |\n",
      "| artist_genres_can_emb_layer  (None, None, 32)       1260736   |\n",
      "|  (Embedding)                                                  |\n",
      "|                                                               |\n",
      "| artist_genres_can_pooling (  (None, 32)             0         |\n",
      "| GlobalAveragePooling1D)                                       |\n",
      "\n",
      " can_cross_layer (Cross)     multiple                  2508      \n",
      "                                                                 \n",
      " candidate_dense_layers (Seq  (2, 32)                  16736     \n",
      " uential)                                                        \n",
      "||\n",
      "| dense_6 (Dense)           (2, 64)                   14656     |\n",
      "|                                                               |\n",
      "| dropout_2 (Dropout)       (2, 64)                   0         |\n",
      "|                                                               |\n",
      "| dense_7 (Dense)           (2, 32)                   2080      |\n",
      "\n",
      "=================================================================\n",
      "Total params: 95,458,988\n",
      "Trainable params: 95,458,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_can_track_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4634b4-5fc8-4bb2-9257-6ab6d5651359",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e03ddde4-dd1c-402d-a5ff-d7907b1ed3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a vertex_train/trainer/task.py\n",
    "\n",
    "class TheTwoTowers(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, layer_sizes, vocab_dict_load):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.query_tower = Playlist_Model(layer_sizes, vocab_dict_load)\n",
    "        \n",
    "        self.candidate_tower = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "        \n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=parsed_candidate_dataset.batch(128).cache().map(self.candidate_tower)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, data, training=False):\n",
    "        query_embeddings = self.query_tower(data)\n",
    "        candidate_embeddings = self.candidate_tower(data)\n",
    "\n",
    "        return self.task(\n",
    "            query_embeddings, \n",
    "            candidate_embeddings, \n",
    "            compute_metrics=not training\n",
    "        ) # turn off metrics to save time on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "356a6481-42d2-4a75-a135-951e5ed40ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "model = TheTwoTowers(layer_sizes, vocab_dict_load)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fd640-739d-477c-a452-3cc4934987db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the adapts\n",
    "model.query_tower.pl_name_text_embedding.layers[0].adapt(parsed_dataset_padded.map(lambda x: x['name']).batch(10_000))\n",
    "print(\"Adapts for name complete\")\n",
    "model.candidate_tower.artist_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_name_can']).batch(10_000))\n",
    "print(\"Adapts for artist_name_can complete\")\n",
    "model.candidate_tower.track_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['track_name_can']).batch(10_000))\n",
    "print(\"Adapts for track_name_can complete\")\n",
    "model.candidate_tower.album_name_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['album_name_can']).batch(10_000))\n",
    "print(\"Adapts for album_name_can complete\")\n",
    "model.candidate_tower.artist_genres_can_text_embedding.layers[0].adapt(parsed_candidate_dataset.map(lambda x: x['artist_genres_can']).batch(10_000))\n",
    "print(\"Adapts for artist_genres_can complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1db9af19-9d67-420f-8c9f-2055c48acd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_name_text_vocab = model.query_tower.pl_name_text_embedding.layers[0].get_vocabulary()\n",
    "artist_name_can_vocab = model.candidate_tower.artist_name_can_text_embedding.layers[0].get_vocabulary()\n",
    "album_name_can_vocab = model.candidate_tower.album_name_can_text_embedding.layers[0].get_vocabulary()\n",
    "artist_genres_can_vocab = model.candidate_tower.artist_genres_can_text_embedding.layers[0].get_vocabulary()\n",
    "track_name_can_vocab = model.candidate_tower.track_name_can_text_embedding.layers[0].get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5abadc8-7561-44cf-88ae-2d893f06cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"] = {'name':[], 'artist_name_can': [], 'album_name_can': [], 'artist_genres_can': []}\n",
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"].update({\"name\": pl_name_text_vocab})\n",
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"].update({\"artist_name_can\": artist_name_can_vocab})\n",
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"].update({\"album_name_can\": album_name_can_vocab})\n",
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"].update({\"artist_genres_can\": artist_genres_can_vocab})\n",
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"].update({\"track_name_can\": track_name_can_vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ec44804-2750-44f9-bd96-c51bd60c22ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'artist_name_can', 'track_uri_can', 'artist_uri_can', 'track_name_can', 'album_uri_can', 'album_name_can', 'artist_genres_can', 'unique_pids', 'artist_name_seed_track', 'artist_uri_seed_track', 'track_name_seed_track', 'track_uri_seed_track', 'album_name_seed_track', 'album_uri_seed_track', 'artist_genres_seed_track', 'description_pl', 'artist_name_pl', 'track_uri_pl', 'track_name_pl', 'album_name_pl', 'artist_genres_pl', 'min_duration_ms_seed_pl', 'max_duration_ms_seed_pl', 'min_n_songs_pl', 'max_n_songs_pl', 'min_n_artists_pl', 'max_n_artists_pl', 'min_n_albums_pl', 'max_n_albums_pl', 'min_artist_pop', 'max_artist_pop', 'min_duration_ms_songs_pl', 'max_duration_ms_songs_pl', 'min_artist_followers', 'max_artist_followers', 'min_track_pop', 'max_track_pop', 'avg_duration_ms_seed_pl', 'var_duration_ms_seed_pl', 'avg_n_songs_pl', 'var_n_songs_pl', 'avg_n_artists_pl', 'var_n_artists_pl', 'avg_n_albums_pl', 'var_n_albums_pl', 'avg_artist_pop', 'var_artist_pop', 'avg_duration_ms_songs_pl', 'var_duration_ms_songs_pl', 'avg_artist_followers', 'var_artist_followers', 'avg_track_pop', 'var_track_pop', 'name_voacb', '20000_tokens', '100000_tokens', '1000000_tokens'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3852a-ccf0-4c7b-ab1d-66d133bd051e",
   "metadata": {},
   "source": [
    "## Upload new adapts for use in training\n",
    "\n",
    "Notice the new keys `20000_tokens`, `50000_tokens`, and `1000000_tokens`. Each one of these dictionaries inside the original dictionary are available and should be used as vocabularies based on the number of tokens. Note each used `ngrams=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3baa2eeb-eff4-470b-a2f1-7c2b77292c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load[f\"{MAX_TOKENS}_tokens\"][\"album_name_can\"][:3] #example access and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07a1d91c-8634-4a75-949f-7190f00152f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional - update vocab files after adapts\n",
    "\n",
    "BUCKET_NAME = 'spotify-v1'\n",
    "FILE_PATH = 'vocabs/v2_string_vocabs'\n",
    "FILE_NAME = 'string_vocabs_v1_20220924-tokens.pkl'\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "with open(f'{FILE_NAME}', 'wb') as pickle_file:\n",
    "    pkl.dump(vocab_dict_load, pickle_file, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3ac91-bbfc-40b2-aeea-216e5f5cc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Upload the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "939085d7-7aa4-4065-b736-278d89c8d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string_vocabs_v1_20220924-tokens.pkl uploaded to gs://spotify-v1/vocabs/v2_string_vocabs\n"
     ]
    }
   ],
   "source": [
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(FILE_PATH)\n",
    "blob.upload_from_filename(FILE_NAME)\n",
    "\n",
    "print(f\"{FILE_NAME} uploaded to gs://{BUCKET_NAME}/{FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_emb_model\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_track_uri_emb_model\n",
      "3 n_songs_pl_emb_model\n",
      "4 n_artists_pl_emb_model\n",
      "5 n_albums_pl_emb_model\n",
      "6 artist_name_pl_emb_model\n",
      "7 track_uri_pl_emb_model\n",
      "8 track_name_pl_emb_model\n",
      "9 duration_ms_songs_pl_emb_model\n",
      "10 album_name_pl_emb_model\n",
      "11 artist_pop_pl_emb_model\n",
      "12 artists_followers_pl_emb_model\n",
      "13 track_pop_pl_emb_model\n",
      "14 artist_genres_pl_emb_model\n",
      "15 pl_cross_layer\n",
      "16 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7ae02-0350-45c9-a9c7-2c62af0438a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 artist_name_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 album_name_can_emb_model\n",
      "3 artist_uri_can_emb_model\n",
      "4 track_uri_can_emb_model\n",
      "5 album_uri_can_emb_model\n",
      "6 normalization_20\n",
      "7 normalization_21\n",
      "8 normalization_22\n",
      "9 normalization_23\n",
      "10 artist_genres_can_emb_model\n",
      "11 can_cross_layer\n",
      "12 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {},
   "source": [
    "# Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "864281ee-f760-4b20-aacc-0b6f0e0ea5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffle_train = parsed_dataset_padded.shuffle(10_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "TRAIN = shuffle_train.batch(128)\n",
    "VALID = parsed_dataset_padded_valid.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d2320-28ac-4292-83fd-503191830179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time    \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "layer_history = model.fit(\n",
    "    TRAIN,\n",
    "    validation_data=VALID,\n",
    "    # validation_freq=5,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # callbacks=tensorboard_cb,\n",
    "    # verbose=1\n",
    ")\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training for {NUM_EPOCHS} epoch, ran for: {train_time:.0} seconds\")\n",
    "accuracy = layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top 100 categorical accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a280c-998a-4d8f-801e-33a7baa8192c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Local Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86789b-1a89-4944-8075-3c08eae90def",
   "metadata": {},
   "source": [
    "## Loading SavedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "2d344efa-cf6f-42dc-a336-34d6f36c740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_tower_uri = 'gs://spotify-tfrs-dir/v2/run-20220920-210334/candidate_tower'\n",
    "loaded_candidate_model = tf.saved_model.load(candidate_tower_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412c459-2203-42f3-b2e4-8da74ba01e64",
   "metadata": {},
   "source": [
    "### Candidate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c50049b0-5c34-49ff-8e94-d8569b0c5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded_candidate_model.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "3a667320-922d-4120-bdbf-9bec2c84ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_1': TensorSpec(shape=(None, 32), dtype=tf.float32, name='output_1')}\n"
     ]
    }
   ],
   "source": [
    "infer = loaded_candidate_model.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "39c74e86-8f4b-46f5-8309-30861a824975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, album_name_can, album_uri_can, artist_followers_can, artist_genres_can, artist_name_can, artist_pop_can, artist_uri_can, duration_ms_can, track_name_can, track_pop_can, track_uri_can) at 0x7F1A85BA2C10>})\n"
     ]
    }
   ],
   "source": [
    "loaded_candidate_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "8e58f5f2-4c8a-4d51-8651-1d3956f13825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': TensorShape([None, 32])}"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2 = loaded_candidate_model.signatures['serving_default']\n",
    "predict2.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "953a9df6-39c6-4399-832e-2b629371f8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "2680e5fd-63f4-4b44-8004-6a5020d28120",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_iter = parsed_candidate_dataset.batch(1).map(\n",
    "    lambda data: predict2(\n",
    "        artist_name_can = data[\"artist_name_can\"],\n",
    "        track_name_can = data['track_name_can'],\n",
    "        album_name_can = data['album_name_can'],\n",
    "        track_uri_can = data['track_uri_can'],\n",
    "        artist_uri_can = data['artist_uri_can'],\n",
    "        album_uri_can = data['album_uri_can'],\n",
    "        duration_ms_can = data['duration_ms_can'],\n",
    "        track_pop_can = data['track_pop_can'],\n",
    "        artist_pop_can = data['artist_pop_can'],\n",
    "        artist_followers_can = data['artist_followers_can'],\n",
    "        artist_genres_can = data['artist_genres_can']\n",
    "    )\n",
    ")\n",
    "\n",
    "embs = []\n",
    "for emb in embs_iter:\n",
    "    embs.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "9094ab59-3c1c-4d7b-8a27-6f4bf1964816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embs: 166827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[ 0.32745814,  0.15835902, -0.62232316, -0.18282643,  0.05425396,\n",
       "          0.08093273, -0.36878368, -0.6777717 , -0.28926852, -0.44578883,\n",
       "          0.03769037,  0.2013096 ,  0.01650199, -0.38547963, -0.2734376 ,\n",
       "          0.16123655,  0.12652676, -0.09455037,  0.3709236 , -0.04336764,\n",
       "         -0.20310198,  0.21418957, -0.44912496, -0.16798183, -0.21492694,\n",
       "          0.04033846,  0.14083184,  0.25597924,  0.20490994,  0.18837534,\n",
       "         -0.15261272,  0.06471566]], dtype=float32)>}"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of embs: {len(embs)}\")\n",
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "48a0b07d-182b-46f6-af30-649a40930d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cleaned_embs: 166827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.32745814,  0.15835902, -0.62232316, -0.18282643,  0.05425396,\n",
       "        0.08093273, -0.36878368, -0.6777717 , -0.28926852, -0.44578883,\n",
       "        0.03769037,  0.2013096 ,  0.01650199, -0.38547963, -0.2734376 ,\n",
       "        0.16123655,  0.12652676, -0.09455037,  0.3709236 , -0.04336764,\n",
       "       -0.20310198,  0.21418957, -0.44912496, -0.16798183, -0.21492694,\n",
       "        0.04033846,  0.14083184,  0.25597924,  0.20490994,  0.18837534,\n",
       "       -0.15261272,  0.06471566], dtype=float32)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_embs = [x['output_1'].numpy()[0] for x in embs] #clean up the output\n",
    "\n",
    "print(f\"Length of cleaned_embs: {len(cleaned_embs)}\")\n",
    "cleaned_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "27178db5-2a2c-4e86-9be2-97b2265ac114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'spotify:track:6KhJeYLg1AimCQjH6ii1Al'"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean product IDs\n",
    "track_uris = [x['track_uri_can'].numpy() for x in parsed_candidate_dataset]\n",
    "track_uris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1df48335-27d6-4c6a-969a-2df1412ac466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'spotify:track:6KhJeYLg1AimCQjH6ii1Al'"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_uris[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "5b43b165-8992-4e9e-96a3-5753d860d661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify:track:6KhJeYLg1AimCQjH6ii1Al'"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_uris_cleaned = [str(z).replace(\"b'\",\"\").replace(\"'\",\"\") for z in track_uris]\n",
    "track_uris_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "3b6d3cf5-4a4d-4295-a371-d34bc0fef9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of track_uris: 166827\n",
      "Length of track_uris_cleaned: 166827\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of track_uris: {len(track_uris)}\")\n",
    "print(f\"Length of track_uris_cleaned: {len(track_uris_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677bd2b-d8d6-4697-a1b0-62c68749f63d",
   "metadata": {},
   "source": [
    "### Write Index Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "61178306-29e1-4d70-90b9-669e0a7a476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'local-v1'\n",
    "TIMESTAMP = '092022'\n",
    "\n",
    "embeddings_index_filename = f'candidate_embeddings_{VERSION}_{TIMESTAMP}.json'\n",
    "\n",
    "with open(f'{embeddings_index_filename}', 'w') as f:\n",
    "    for prod, emb in zip(track_uris_cleaned, cleaned_embs):\n",
    "        f.write('{\"id\":\"' + str(prod) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "1a772d6a-000b-468a-a7ad-5cacebf31889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('candidate_embeddings_local-v1_092022.json', 'r') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5e34d-8bdf-46af-b39f-63f6d5caa695",
   "metadata": {},
   "source": [
    "### Query Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "b3eb27dd-a85f-4970-be5b-2971607afdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tower_uri = 'gs://spotify-tfrs-dir/v2/run-20220920-210334/query_tower'\n",
    "loaded_query_model = tf.saved_model.load(query_tower_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "4c85d98c-cb52-48e8-8c72-69d46a1b0c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, album_name_can, album_name_pl, album_name_seed_track, album_uri_can, album_uri_seed_track, artist_followers_can, artist_followers_seed_track, artist_genres_can, artist_genres_pl, artist_genres_seed_track, artist_name_can, artist_name_pl, artist_name_seed_track, artist_pop_can, artist_pop_pl, artist_pop_seed_track, artist_uri_can, artist_uri_seed_track, artists_followers_pl, collaborative, description_pl, duration_ms_can, duration_ms_seed_pl, duration_ms_songs_pl, duration_seed_track, n_songs_pl, name, num_albums_pl, num_artists_pl, pid, pos_seed_track, track_name_can, track_name_pl, track_name_seed_track, track_pop_can, track_pop_pl, track_pop_seed_track, track_uri_can, track_uri_pl, track_uri_seed_track) at 0x7F1935582D50>})"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_query_model.signatures"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
