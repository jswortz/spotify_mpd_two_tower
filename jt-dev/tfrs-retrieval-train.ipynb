{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b950b35-cba2-4469-ba8c-05557a73c6d3",
   "metadata": {},
   "source": [
    "# Multi-Tower Encoders with TFRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb22515-5157-406b-a810-046ab13afaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "SEED = 41781897\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "BQ_LOCATION='us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0133923-e691-4897-8586-064b9e466d64",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pip\n",
    "\n",
    "> check package versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e419bcb3-7734-421d-aea6-3faf2a7b7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.8.2\n",
      "tensorflow-cloud==0.1.16\n",
      "tensorflow-datasets==4.4.0\n",
      "tensorflow-estimator==2.8.0\n",
      "tensorflow-hub==0.12.0\n",
      "tensorflow-io==0.23.0\n",
      "tensorflow-io-gcs-filesystem==0.23.0\n",
      "tensorflow-metadata==1.8.0\n",
      "tensorflow-probability==0.14.1\n",
      "tensorflow-recommenders==0.6.0\n",
      "tensorflow-serving-api==2.8.0\n",
      "tensorflow-transform==1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e6eec-c9c6-4af8-a787-3be40d4b8c9b",
   "metadata": {},
   "source": [
    "#### JT package versions (7/7)\n",
    "```\n",
    "tensorflow==2.9.1\n",
    "tensorflow-cloud==0.1.16\n",
    "tensorflow-data-validation==0.26.1\n",
    "tensorflow-datasets==4.4.0\n",
    "tensorflow-estimator==2.9.0\n",
    "tensorflow-hub==0.12.0\n",
    "tensorflow-io==0.26.0\n",
    "tensorflow-io-gcs-filesystem==0.26.0\n",
    "tensorflow-metadata==1.8.0\n",
    "tensorflow-model-analysis==0.26.1\n",
    "tensorflow-probability==0.14.1\n",
    "tensorflow-recommenders==0.6.0\n",
    "tensorflow-serving-api==2.9.0\n",
    "tensorflow-transform==1.9.0\n",
    "```\n",
    "produces error:\n",
    "> `UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95b680-d39d-44dd-a312-0e3857c187f7",
   "metadata": {},
   "source": [
    "#### JT package versions (7/6)\n",
    "\n",
    "```\n",
    "tensorflow==2.9.1\n",
    "tensorflow-cloud==0.1.13\n",
    "tensorflow-data-validation==0.26.1\n",
    "tensorflow-datasets==3.0.0\n",
    "tensorflow-estimator==2.9.0\n",
    "tensorflow-hub==0.9.0\n",
    "tensorflow-io==0.26.0\n",
    "tensorflow-io-gcs-filesystem==0.26.0\n",
    "tensorflow-metadata==0.26.0\n",
    "tensorflow-model-analysis==0.26.1\n",
    "tensorflow-probability==0.11.0\n",
    "tensorflow-recommenders==0.6.0\n",
    "tensorflow-serving-api==2.3.0\n",
    "tensorflow-transform==0.26.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60fade-86df-4f5b-ba5a-e0a79b29eb7c",
   "metadata": {},
   "source": [
    "#### JW package versions \n",
    "```\n",
    "tensorflow==2.3.1\n",
    "tensorflow-cloud==0.1.16\n",
    "tensorflow-datasets==4.4.0\n",
    "tensorflow-estimator==2.3.0\n",
    "tensorflow-hub==0.12.0\n",
    "tensorflow-io==0.15.0\n",
    "tensorflow-io-gcs-filesystem==0.26.0\n",
    "tensorflow-metadata==1.8.0\n",
    "tensorflow-probability==0.14.1\n",
    "tensorflow-recommenders==0.6.0\n",
    "tensorflow-serving-api==2.8.0\n",
    "tensorflow-transform==1.8.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f56cc-ec19-4a94-aec3-c403fb2cdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders==0.6.0 --user\n",
    "# !pip install -U tensorflow-io==0.26.0 --user\n",
    "# pip install tensorflow-cloud==0.1.16\n",
    "# pip install tensorflow-datasets==4.4.0\n",
    "# pip install tensorflow-hub==0.12.0\n",
    "# pip install tensorflow-metadata==1.8.0\n",
    "# pip install tensorflow-probability==0.14.1\n",
    "# pip install tensorflow-serving-api==2.9.0\n",
    "# pip install tensorflow-transform==1.9.1\n",
    "\n",
    "# pip uninstall tensorflow\n",
    "# pip uninstall tensorflow-cloud\n",
    "# pip uninstall tensorflow-data-validation\n",
    "# pip uninstall tensorflow-datasets\n",
    "# pip uninstall tensorflow-estimator\n",
    "# pip uninstall tensorflow-hub\n",
    "# pip uninstall tensorflow-io\n",
    "# pip uninstall tensorflow-io-gcs-filesystem\n",
    "# pip uninstall tensorflow-metadata\n",
    "# pip uninstall tensorflow-model-analysis\n",
    "# pip uninstall tensorflow-probability\n",
    "# pip uninstall tensorflow-recommenders\n",
    "# pip uninstall tensorflow-serving-api\n",
    "# pip uninstall tensorflow-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89fdc03-2386-47c6-92c0-a9400958b829",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd388f39-e54a-4d41-ad74-834f7077a6c8",
   "metadata": {},
   "source": [
    "> With TF 2.3, Autotune was experimental and was in nightly build but in TF 2.5, it is in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cff2c99-3c3c-42ea-8e63-65e987f3404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18266/3881075686.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBigQueryClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBigQueryReadSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"tensorflow_io\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GENERATING_TF_DOCS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/api/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_dataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIOLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/experimental/io_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_io_layer_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkafka_io_layer_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/experimental/text_io_layer_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTextIOLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"\"\"TextIOLayer\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrictVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranspose_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpy_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #do this b/c there's an info-level bug that can safely be ignored\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import datetime\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.train import BytesList, Feature, FeatureList, Int64List, FloatList\n",
    "from tensorflow.train import SequenceExample, FeatureLists\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ba121c-7ea9-418d-b5e2-537452d1f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6353d90-bca2-46f3-9c83-53984611aed4",
   "metadata": {},
   "source": [
    "## Prep Train Data\n",
    "\n",
    "* Use tensorflow-io to import from BigQuery\n",
    "* Creates a [TF Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#methods_2) object \n",
    "* Vocab files for `TextVectorization` and `StringLookup` layers pre-computed and saved to GCS\n",
    "\n",
    "\n",
    "See [end-to-end guide BQ -> TF Dataset](https://www.tensorflow.org/io/tutorials/bigquery#load_census_data_in_tensorflow_dataset_using_bigquery_reader) for tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355b7091-facd-4d5e-adbb-66b39120b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf data_prep\n",
    "# ! mkdir data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b91bbd-c765-4f96-b58a-daf944f1c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_2_tf_dict = {\n",
    "    'name': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'collaborative': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    # 'pid': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    "    # 'duration_ms_playlist': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    "    # 'pid_pos_id': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    # candidate features\n",
    "    'pos_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    "    'artist_name_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'track_uri_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'artist_uri_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'track_name_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'album_uri_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'duration_ms_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'album_name_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'track_pop_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'artist_pop_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'artist_genres_can': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'artist_followers_can': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    # seed track features\n",
    "    'pos_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    "    'artist_name_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'artist_uri_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'track_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'track_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'album_name_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'album_uri_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'duration_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'track_pop_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'artist_pop_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'artist_genres_seed_track': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    'artist_followers_seed_track': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    ### playlist features\n",
    "    'duration_ms_seed_pl': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'n_songs_pl': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'num_artists_pl': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'num_albums_pl': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.float64},\n",
    "    'description_pl': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    # 'pos_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.int64},\n",
    "    'artist_name_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "    'track_uri_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "    'track_name_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "    'duration_ms_songs_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.float64},\n",
    "    'album_name_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "    'artist_pop_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.float64},\n",
    "    'artists_followers_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.float64},              \n",
    "    'track_pop_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.int64},\n",
    "    'artist_genres_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.string},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014e8c7c-8af0-40d1-ae94-460fe3a781df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:55:39.814109: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2022-07-07 04:55:39.814450: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-07-07 04:55:39.962800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-07 04:55:39.962858: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-07 04:55:39.962885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (spotify-tf-2-3-jt): /proc/driver/nvidia/version does not exist\n",
      "2022-07-07 04:55:39.963314: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "BQ_TABLE_TRAIN = 'train_flatten'\n",
    "BQ_DATASET_TRAIN = 'spotify_train_3'\n",
    "io_batch_size = 1\n",
    "\n",
    "bq_client = BigQueryClient()\n",
    "\n",
    "bqsession = bq_client.read_session(\n",
    "    \"projects/\" + PROJECT_ID,\n",
    "    PROJECT_ID, \n",
    "    f'{BQ_TABLE_TRAIN}', \n",
    "    f'{BQ_DATASET_TRAIN}',\n",
    "    bq_2_tf_dict,\n",
    "    requested_streams=2,\n",
    ")\n",
    "\n",
    "dataset = bqsession.parallel_read_rows()\n",
    "dataset = dataset.prefetch(1).shuffle(io_batch_size*10).batch(io_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a6f47-33b6-40fc-beab-6f018f530e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:55:45.550130: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 04:55:45.550196: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 04:55:45.550754: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 04:55:45.550802: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    }
   ],
   "source": [
    "# pprint(dataset.take(1))\n",
    "for x in dataset.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fea41c-c18d-456f-97c5-d44cd2e718ee",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "* ` 'repeated', 'nullable' or 'required'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "f9c4d78e-4b32-446c-b161-cee518685d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq_3_tf_dict = {\n",
    "    'name': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'collaborative': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'pid': {\"mode\": \"nullable\", \"output_type\": dtypes.int64},\n",
    "    # 'duration_ms_playlist': {'mode': BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.int64},\n",
    "    # 'pid_pos_id': {'mode':BigQueryClient.FieldMode.NULLABLE, 'output_type': dtypes.string},\n",
    "    # candidate features\n",
    "    'pos_can': {\"mode\":\"nullable\", \"output_type\": dtypes.int64},\n",
    "    'artist_name_can': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'track_uri_can': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'artist_uri_can': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'track_name_can': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'album_uri_can': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'duration_ms_can': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    'album_name_can': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'track_pop_can': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    'artist_pop_can': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    'artist_genres_can': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'artist_followers_can': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    # seed track features\n",
    "    'pos_seed_track': {\"mode\":\"nullable\", \"output_type\": dtypes.int64},\n",
    "    'artist_name_seed_track': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'artist_uri_seed_track': {\"mode\":\"nullable\", \"output_type\": dtypes.string},\n",
    "    'track_name_seed_track': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'track_uri_seed_track': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'album_name_seed_track': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'album_uri_seed_track': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'duration_seed_track': {\"mode\": \"nullable\", \"output_type\": dtypes.float64},\n",
    "    'track_pop_seed_track': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    'artist_pop_seed_track': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    'artist_genres_seed_track': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    'artist_followers_seed_track': {\"mode\":\"nullable\", \"output_type\": dtypes.float64},\n",
    "    ### playlist features\n",
    "    'duration_ms_seed_pl': {\"mode\": \"nullable\", \"output_type\": dtypes.float64},\n",
    "    'n_songs_pl': {\"mode\": \"nullable\", \"output_type\": dtypes.float64},\n",
    "    'num_artists_pl': {\"mode\": \"nullable\", \"output_type\": dtypes.float64},\n",
    "    'num_albums_pl': {\"mode\": \"nullable\", \"output_type\": dtypes.float64},\n",
    "    'description_pl': {\"mode\": \"nullable\", \"output_type\": dtypes.string},\n",
    "    # 'pos_pl': {'mode': BigQueryClient.FieldMode.REPEATED, 'output_type': dtypes.int64},\n",
    "    'artist_name_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.string},\n",
    "    'track_uri_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.string},\n",
    "    'track_name_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.string},\n",
    "    'duration_ms_songs_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.float64},\n",
    "    'album_name_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.string},\n",
    "    'artist_pop_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.float64},\n",
    "    'artists_followers_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.float64},              \n",
    "    'track_pop_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.int64},\n",
    "    'artist_genres_pl': {\"mode\": \"repeated\", \"output_type\": dtypes.string},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "06004d36-29c2-46fd-81c7-eb7cb834e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_TABLE_TRAIN = 'train_flatten'\n",
    "BQ_DATASET_TRAIN = 'spotify_train_3'\n",
    "io_batch_size = 1\n",
    "\n",
    "bq_client = BigQueryClient()\n",
    "\n",
    "bqsession_2 = bq_client.read_session(\n",
    "    parent = \"projects/\" + PROJECT_ID,\n",
    "    project_id=PROJECT_ID, \n",
    "    table_id = f'{BQ_TABLE_TRAIN}', \n",
    "    dataset_id = f'{BQ_DATASET_TRAIN}',\n",
    "    selected_fields = bq_2_tf_dict,\n",
    "    requested_streams = 2,\n",
    ")\n",
    "\n",
    "dataset_2 = bqsession_2.parallel_read_rows()\n",
    "dataset_2 = dataset_2.prefetch(1).shuffle(io_batch_size*10).batch(io_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4073d7-2f07-4268-a48d-51ba31ae50e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6213/3972787848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_2' is not defined"
     ]
    }
   ],
   "source": [
    "for x in dataset_2.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdbd10-0975-4fd3-8fe1-5bf8ed01d9ee",
   "metadata": {},
   "source": [
    "# Multi-Tower Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab908ab-590e-4bc1-a011-df278b974f0f",
   "metadata": {},
   "source": [
    "Create a DNN nominator based on a 3-tower architecture, with `playlist`, `seed_track`, and `candidate_track` towers (TODO: insert diagram)\n",
    "\n",
    "* In this model, we have **two** kinds of query embeddings: `playlist` and `seed_track`\n",
    "* Within `playlist`, we include the sequence of tracks in each playlist\n",
    "* We propose an attention-based playlist model to summarize the track sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb63b5d1-79a8-4724-b643-ed33766fe55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from google.cloud import storage\n",
    "\n",
    "BUCKET_NAME = 'spotify-v1'\n",
    "FILE_PATH = 'vocabs/v1_string_vocabs'\n",
    "FILE_NAME = 'string_vocabs_v1_20220705-202905.txt'\n",
    "DESTINATION_FILE = 'downloaded_vocabs.txt'\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "with open(f'{DESTINATION_FILE}', 'wb') as file_obj:\n",
    "    client.download_blob_to_file(\n",
    "        f'gs://{BUCKET_NAME}/{FILE_PATH}/{FILE_NAME}', file_obj)\n",
    "\n",
    "    \n",
    "with open(f'{DESTINATION_FILE}', 'rb') as pickle_file:\n",
    "    vocab_dict_load = pkl.load(pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "18dd4367-f76e-407d-982d-5b5c539e958e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(vocab_dict_load[\"unique_pids\"])\n",
    "\n",
    "avg_duration_ms_seed_pl = 13000151.68\n",
    "var_duration_ms_seed_pl = 133092900971233.58\n",
    "vocab_dict_load['avg_duration_ms_seed_pl']=avg_duration_ms_seed_pl\n",
    "vocab_dict_load['var_duration_ms_seed_pl']=var_duration_ms_seed_pl\n",
    "\n",
    "avg_n_songs_pl = 55.21\n",
    "var_n_songs_pl = 2317.54\n",
    "vocab_dict_load['avg_n_songs_pl']=avg_n_songs_pl\n",
    "vocab_dict_load['var_n_songs_pl']=var_n_songs_pl\n",
    "\n",
    "avg_n_artists_pl = 30.56\n",
    "var_n_artists_pl = 769.26\n",
    "vocab_dict_load['avg_n_artists_pl']=avg_n_artists_pl\n",
    "vocab_dict_load['var_n_artists_pl']=var_n_artists_pl\n",
    "\n",
    "avg_n_albums_pl = 40.25\n",
    "var_n_albums_pl = 1305.54\n",
    "vocab_dict_load['avg_n_albums_pl']=avg_n_albums_pl\n",
    "vocab_dict_load['var_n_albums_pl']=var_n_albums_pl\n",
    "\n",
    "avg_artist_pop = 16.08\n",
    "var_artist_pop = 300.64\n",
    "vocab_dict_load['avg_artist_pop']=avg_artist_pop\n",
    "vocab_dict_load['var_artist_pop']=var_artist_pop\n",
    "\n",
    "avg_duration_ms_songs_pl = 234823.14\n",
    "var_duration_ms_songs_pl = 5558806228.41\n",
    "vocab_dict_load['avg_duration_ms_songs_pl']=avg_duration_ms_songs_pl\n",
    "vocab_dict_load['var_duration_ms_songs_pl']=var_duration_ms_songs_pl\n",
    "\n",
    "avg_artist_followers = 43337.77\n",
    "var_artist_followers = 377777790193.57\n",
    "vocab_dict_load['avg_artist_followers']=avg_artist_followers\n",
    "vocab_dict_load['var_artist_followers']=var_artist_followers\n",
    "\n",
    "avg_track_pop = 10.85\n",
    "var_track_pop = 202.18\n",
    "vocab_dict_load['avg_track_pop']=avg_track_pop\n",
    "vocab_dict_load['var_track_pop']=var_track_pop\n",
    "# vocab_dict_load['unique_pids_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "93765ecd-93e3-4b4e-ade4-87632cd812a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 999997, 999998, 999999])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict_load['unique_pids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "184e6d85-365b-4964-9cb1-c44c1594ae11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 03:12:27.135176: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 03:12:27.135233: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 03:12:27.135958: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 03:12:27.136003: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1).as_numpy_iterator():\n",
    "    print(x.shape)\n",
    "  # pprint(x['track_pop_pl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c0f340f5-e639-435e-8e0c-b26f0dc3099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = {\n",
    "    'name': np.asarray([b'Best Christmas']),\n",
    "    'collaborative': np.asarray([b'false']),\n",
    "    'pid': np.asarray([173671]),\n",
    "    'description_pl': np.asarray([b'test description']),\n",
    "    'duration_ms_seed_pl': np.asarray([5458995.]),\n",
    "    'n_songs_pl': np.asarray([58.]),\n",
    "    'num_artists_pl': np.asarray([19.]),\n",
    "    'num_albums_pl': np.asarray([27.]),\n",
    "    'artist_name_pl': np.asarray([[b'Juan Luis Guerra 4.40', b'Prince Royce', b'Luis Vargas']]),\n",
    "    'track_uri_pl': np.asarray([[b'spotify:track:1g0IBPZTRP7VYkctJ4Qafg',b'spotify:track:43wUzbYxEFoXugYkgTzMWp']]),\n",
    "    'track_name_pl': np.asarray([[b'Lover Come Back', b'White Lightning', b'Shake Me Down']]),\n",
    "    'duration_ms_songs_pl': np.asarray([[245888., 195709., 283906., 271475., 300373., 275173., 236145.,]]),\n",
    "    'album_name_pl': np.asarray([[b'Silsulim', b'Sara Shara', b'Muzika Vesheket', b'Ba La Lirkod']]),\n",
    "    'artist_pop_pl': np.asarray([[81., 81., 70., 66., 66., 66., 46., 87.]]),\n",
    "    'artists_followers_pl': np.asarray([[3.556710e+05, 8.200000e+02, 1.510000e+02, 1.098080e+05,]]),\n",
    "    'artist_genres_pl': np.asarray([[b\"'israeli pop', 'jewish pop'\", b\"'israeli pop', 'jewish pop'\",]]),\n",
    "    'track_pop_pl': np.asarray([[70, 77, 50, 44, 30, 28, 15, 26, 15, 18, 46, 38,]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "5810d605-4caa-448a-b205-7ce2d1843101",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19751/4135868879.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pprint(test_instance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# pprint(test_instance)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bccf90-2f88-4546-bffe-0e4bf8e8da50",
   "metadata": {},
   "source": [
    "## Playlist Tower\n",
    "\n",
    "TODO \n",
    "* For playlist sequence features: \n",
    "> * vectorize text features as sequence (`TextVectorization`)? or `StringLookup`? If vectorize, last dimension in shape needs to be 1\n",
    "> * Use both `track_uri` and `track_name`? or just one?\n",
    "> * Should numerical features (followers, popularity) just be an aggregated feature at the playlist-level? Or keep as sequence feature? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "3b8ca7a4-a6e4-4f21-a6aa-d854b5e7a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "\n",
    "class Playlist_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "\n",
    "        # ========================================\n",
    "        # non-sequence playlist features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: playlist name\n",
    "        self.pl_name_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=len(vocab_dict[\"name\"]), # not needed if passing vocab\n",
    "                    vocabulary=vocab_dict['name'], \n",
    "                    name=\"pl_name_txt_vectorizer\", \n",
    "                    ngrams=2\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"name\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_name_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"pl_name_pooling\"),\n",
    "            ], name=\"pl_name_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: collaborative\n",
    "        collaborative_vocab = np.array([b'false', b'true'])\n",
    "        \n",
    "        self.pl_collaborative_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=collaborative_vocab, \n",
    "                    mask_token=None, \n",
    "                    name=\"pl_collaborative_lookup\", \n",
    "                    output_mode='int'\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(collaborative_vocab),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_collaborative_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"pl_collaborative_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: pid\n",
    "        self.pl_pid_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.IntegerLookup(\n",
    "                    vocabulary=vocab_dict['unique_pids'], \n",
    "                    mask_token=None, \n",
    "                    name=\"pl_pid_lookup\", \n",
    "                    # output_mode='int'\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['unique_pids']),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"pl_pid_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"pl_pid_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: description_pl\n",
    "        self.pl_description_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    # max_tokens=len(vocab_dict[\"description_pl\"]), # not needed if passing vocab\n",
    "                    vocabulary=vocab_dict['description_pl'], \n",
    "                    name=\"description_pl_vectorizer\", \n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"description_pl\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"description_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"description_pl_pooling\"),\n",
    "            ], name=\"pl_description_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: duration_ms_seed_pl                      \n",
    "        # TODO: Noramlize or Descritize?\n",
    "        duration_ms_seed_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_duration_ms_seed_pl'], \n",
    "            vocab_dict['max_duration_ms_seed_pl'], \n",
    "            num=1000\n",
    "        )\n",
    "        self.duration_ms_seed_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(duration_ms_seed_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(duration_ms_seed_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"duration_ms_seed_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"duration_ms_seed_pl_emb_model\"\n",
    "        )\n",
    "        # self.duration_ms_seed_pl_normalization = tf.keras.layers.Normalization(\n",
    "        #     mean=vocab_dict['avg_duration_ms_seed_pl'],\n",
    "        #     variance=vocab_dict['var_duration_ms_seed_pl'],\n",
    "        #     axis=None\n",
    "        # )\n",
    "        \n",
    "        # Feature: n_songs_pl\n",
    "        # TODO: Noramlize or Descritize?\n",
    "        n_songs_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_songs_pl'], \n",
    "            vocab_dict['max_n_songs_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.n_songs_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_songs_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_songs_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_songs_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_songs_pl_emb_model\"\n",
    "        )\n",
    "        # self.n_songs_pl_normalization = tf.keras.layers.Normalization(\n",
    "        #     mean=vocab_dict['avg_n_songs_pl'],\n",
    "        #     variance=vocab_dict['var_n_songs_pl'],\n",
    "        #     axis=None\n",
    "        # )\n",
    "        \n",
    "        # Feature: num_artists_pl\n",
    "        # TODO: Noramlize or Descritize?\n",
    "        n_artists_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_artists_pl'], \n",
    "            vocab_dict['max_n_artists_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.n_artists_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_artists_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_artists_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_artists_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_artists_pl_emb_model\"\n",
    "        )\n",
    "        # self.n_artists_pl_normalization = tf.keras.layers.Normalization(\n",
    "        #     mean=vocab_dict['avg_n_artists_pl'],\n",
    "        #     variance=vocab_dict['var_n_artists_pl'],\n",
    "        #     axis=None\n",
    "        # )\n",
    "        \n",
    "        # Feature: num_albums_pl\n",
    "        n_albums_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_n_albums_pl'], \n",
    "            vocab_dict['max_n_albums_pl'],\n",
    "            num=100\n",
    "        )\n",
    "        self.n_albums_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(n_albums_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(n_albums_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    name=\"n_albums_pl_emb_layer\",\n",
    "                )\n",
    "            ], name=\"n_albums_pl_emb_model\"\n",
    "        )\n",
    "        # self.n_albums_pl_normalization = tf.keras.layers.Normalization(\n",
    "        #     mean=vocab_dict['avg_n_albums_pl'],\n",
    "        #     variance=vocab_dict['var_n_albums_pl'],\n",
    "        #     axis=None\n",
    "        # )\n",
    "        \n",
    "        # ========================================\n",
    "        # sequence playlist features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_pl\n",
    "        self.artist_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['artist_name_pl'], mask_token=''),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_name_pl']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_name_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"artist_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_pl\n",
    "        # 2.2M unique\n",
    "        self.track_uri_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_pl']) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"track_uri_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_pl\n",
    "        self.track_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['track_name_pl'], \n",
    "                    name=\"track_name_pl_lookup\",\n",
    "                    output_mode='int',\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_name_pl']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_name_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"track_name_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: duration_ms_songs_pl\n",
    "        duration_ms_songs_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_duration_ms_songs_pl'], \n",
    "            vocab_dict['max_duration_ms_songs_pl'], \n",
    "            num=100\n",
    "        )\n",
    "        self.duration_ms_songs_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(duration_ms_songs_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(duration_ms_songs_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"duration_ms_songs_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"duration_ms_songs_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_pl\n",
    "        self.album_name_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['album_name_pl'], mask_token=None),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['album_name_pl']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_name_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"album_name_pl_emb_model\"\n",
    "        )\n",
    "\n",
    "        # Feature: artist_pop_pl\n",
    "        artist_pop_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_artist_pop'], \n",
    "            vocab_dict['max_artist_pop'], \n",
    "            num=10\n",
    "        )\n",
    "        self.artist_pop_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(artist_pop_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(artist_pop_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_pop_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"artist_pop_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artists_followers_pl\n",
    "        artists_followers_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_artist_followers'], \n",
    "            vocab_dict['max_artist_followers'], \n",
    "            num=10\n",
    "        )\n",
    "        self.artists_followers_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(artists_followers_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(artists_followers_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artists_followers_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"artists_followers_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_pl\n",
    "        track_pop_pl_buckets = np.linspace(\n",
    "            vocab_dict['min_track_pop'], \n",
    "            vocab_dict['max_track_pop'], \n",
    "            num=10\n",
    "        )\n",
    "        self.track_pop_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Discretization(track_pop_pl_buckets.tolist()),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(track_pop_pl_buckets) + 1, \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_pop_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"track_pop_pl_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_pl\n",
    "        self.artist_genres_pl_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.StringLookup(\n",
    "                    vocabulary=vocab_dict['artist_genres_pl'], mask_token=None),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_genres_pl']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_genres_pl_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GRU(EMBEDDING_DIM),\n",
    "            ], name=\"artist_genres_pl_emb_model\"\n",
    "        )\n",
    "\n",
    "        # ========================================\n",
    "        # dense and cross layers\n",
    "        # ========================================\n",
    "\n",
    "        # Cross Layers\n",
    "        if USE_CROSS_LAYER:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                projection_dim=PROJECTION_DIM,\n",
    "                kernel_initializer=\"glorot_uniform\", \n",
    "                name=\"pl_cross_layer\"\n",
    "            )\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "            \n",
    "        # Dense Layers\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"pl_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda x: tf.nn.l2_normalize(\n",
    "                    x, 1, epsilon=1e-12, name=\"normalize_dense\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    # ========================================\n",
    "    # call\n",
    "    # ========================================\n",
    "    def call(self, data):\n",
    "        '''\n",
    "        The call method defines what happens when\n",
    "        the model is called\n",
    "        '''\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                self.pl_name_text_embedding(data['name']),\n",
    "                self.pl_collaborative_embedding(data['collaborative']),\n",
    "                self.pl_pid_embedding(data[\"pid\"]),\n",
    "                self.pl_description_text_embedding(data['description_pl']),\n",
    "                self.duration_ms_seed_pl_embedding(data[\"duration_ms_seed_pl\"]),\n",
    "                # tf.reshape(self.duration_ms_seed_pl_normalization(data[\"duration_ms_seed_pl\"]), (-1, 1))      # Normalize or Discretize?\n",
    "                self.n_songs_pl_embedding(data[\"n_songs_pl\"]),\n",
    "                # tf.reshape(self.n_songs_pl_normalization(data[\"n_songs_pl\"]), (-1, 1))                        # Normalize or Discretize?\n",
    "                self.n_artists_pl_embedding(data['num_artists_pl']),\n",
    "                # tf.reshape(self.n_artists_pl_normalization(data[\"num_artists_pl\"]), (-1, 1))                  # Normalize or Discretize?\n",
    "                self.n_albums_pl_embedding(data[\"num_albums_pl\"]),\n",
    "                # tf.reshape(self.n_albums_pl_normalization(data[\"num_albums_pl\"]), (-1, 1))                    # Normalize or Discretize?\n",
    "                \n",
    "                # sequence features\n",
    "                # data[\"pos_pl\"],\n",
    "                self.artist_name_pl_embedding(data[\"artist_name_pl\"]),\n",
    "                self.track_uri_pl_embedding(data[\"track_uri_pl\"]),\n",
    "                self.track_name_pl_embedding(data[\"track_name_pl\"]),\n",
    "                self.duration_ms_songs_pl_embedding(data[\"duration_ms_songs_pl\"]),\n",
    "                self.album_name_pl_embedding(data[\"album_name_pl\"]),\n",
    "                self.artist_pop_pl_embedding(data[\"artist_pop_pl\"]),\n",
    "                self.artists_followers_pl_embedding(data[\"artists_followers_pl\"]),\n",
    "                self.track_pop_pl_embedding(data[\"track_pop_pl\"]),\n",
    "                self.artist_genres_pl_embedding(data[\"artist_genres_pl\"]),\n",
    "            ], axis=1)\n",
    "        \n",
    "        # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            cross_embs = self._cross_layer(all_embs)\n",
    "            return self.dense_layers(cross_embs)\n",
    "        else:\n",
    "            return self.dense_layers(all_embs)\n",
    "    \n",
    "    # For visualizing model graph only # todo: remove\n",
    "    # def build_graph(self,):\n",
    "    #     x = tf.keras.layers.Input(shape=(32,32))\n",
    "    #     return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "4a1ea41b-f457-43bb-8595-1c46c5c3fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pl_result: (1, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.05321983, -0.04084665,  0.11637767,  0.3411542 ,  0.09852977,\n",
       "        -0.06006141,  0.14619492,  0.24855876, -0.12215702, -0.15610446,\n",
       "        -0.08795111, -0.27013752, -0.04377728, -0.12331408,  0.09523007,\n",
       "        -0.13910483,  0.09044929, -0.19123396,  0.14647555, -0.3671819 ,\n",
       "         0.19767866,  0.03310812,  0.12395252,  0.14589746,  0.18691422,\n",
       "        -0.23982897,  0.08464528, -0.00168197,  0.38199148,  0.10042445,\n",
       "        -0.2411324 , -0.1092459 ]], dtype=float32)>"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_playlist_model = Playlist_Model(layer_sizes,vocab_dict_load)\n",
    "\n",
    "pl_result = test_playlist_model(test_instance)\n",
    "\n",
    "print(f\"Shape of pl_result: {pl_result.shape}\")\n",
    "pl_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "dfb87b17-517e-4205-b645-3a2c25f67865",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"playlist__model_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pl_name_emb_model (Sequenti  (None, 32)               2368896   \n",
      " al)                                                             \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| pl_name_txt_vectorizer (Tex  (None, None)           0         |\n",
      "| tVectorization)                                               |\n",
      "|                                                               |\n",
      "| pl_name_emb_layer (Embeddin  (None, None, 32)       2368896   |\n",
      "| g)                                                            |\n",
      "|                                                               |\n",
      "| pl_name_pooling (GlobalAver  (None, 32)             0         |\n",
      "| agePooling1D)                                                 |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_collaborative_emb_model   (1, 32)                  64        \n",
      " (Sequential)                                                    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| pl_collaborative_lookup (St  (1,)                   0         |\n",
      "| ringLookup)                                                   |\n",
      "|                                                               |\n",
      "| pl_collaborative_emb_layer   (1, 32)                64        |\n",
      "| (Embedding)                                                   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_pid_emb_model (Sequentia  (1, 32)                  32000000  \n",
      " l)                                                              \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| pl_pid_lookup (IntegerLooku  (1,)                   0         |\n",
      "| p)                                                            |\n",
      "|                                                               |\n",
      "| pl_pid_emb_layer (Embedding  (1, 32)                32000000  |\n",
      "| )                                                             |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_description_emb_model (S  (None, 32)               580416    \n",
      " equential)                                                      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| description_pl_vectorizer (  (None, None)           0         |\n",
      "| TextVectorization)                                            |\n",
      "|                                                               |\n",
      "| description_pl_emb_layer (E  (None, None, 32)       580416    |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| description_pl_pooling (Glo  (None, 32)             0         |\n",
      "| balAveragePooling1D)                                          |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " duration_ms_seed_pl_emb_mod  (1, 32)                  32032     \n",
      " el (Sequential)                                                 \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_102 (Discret  (1,)                   0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| duration_ms_seed_pl_emb_lay  (1, 32)                32032     |\n",
      "| er (Embedding)                                                |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " n_songs_pl_emb_model (Seque  (1, 32)                  3232      \n",
      " ntial)                                                          \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_103 (Discret  (1,)                   0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| n_songs_pl_emb_layer (Embed  (1, 32)                3232      |\n",
      "| ding)                                                         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " n_artists_pl_emb_model (Seq  (1, 32)                  3232      \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_104 (Discret  (1,)                   0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| n_artists_pl_emb_layer (Emb  (1, 32)                3232      |\n",
      "| edding)                                                       |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " n_albums_pl_emb_model (Sequ  (1, 32)                  3232      \n",
      " ential)                                                         \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_105 (Discret  (1,)                   0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| n_albums_pl_emb_layer (Embe  (1, 32)                3232      |\n",
      "| dding)                                                        |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_name_pl_emb_model (S  (1, 32)                  9213088   \n",
      " equential)                                                      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| string_lookup_139 (StringLo  (1, 3)                 0         |\n",
      "| okup)                                                         |\n",
      "|                                                               |\n",
      "| artist_name_pl_emb_layer (E  (1, 3, 32)             9206752   |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| gru_79 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_uri_pl_emb_model (Seq  (1, 32)                  72399712  \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_15 (Hashing)      (1, 2)                    0         |\n",
      "|                                                               |\n",
      "| track_uri_pl_emb_layer (Emb  (1, 2, 32)             72393376  |\n",
      "| edding)                                                       |\n",
      "|                                                               |\n",
      "| gru_80 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_name_pl_emb_model (Se  (1, 32)                  47486432  \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| track_name_pl_lookup (Strin  (1, 3)                 0         |\n",
      "| gLookup)                                                      |\n",
      "|                                                               |\n",
      "| track_name_pl_emb_layer (Em  (1, 3, 32)             47480096  |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| gru_81 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " duration_ms_songs_pl_emb_mo  (1, 32)                  9568      \n",
      " del (Sequential)                                                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_106 (Discret  (1, 7)                 0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| duration_ms_songs_pl_emb_la  (1, 7, 32)             3232      |\n",
      "| yer (Embedding)                                               |\n",
      "|                                                               |\n",
      "| gru_82 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " album_name_pl_emb_model (Se  (1, 32)                  18298336  \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| string_lookup_140 (StringLo  (1, 4)                 0         |\n",
      "| okup)                                                         |\n",
      "|                                                               |\n",
      "| album_name_pl_emb_layer (Em  (1, 4, 32)             18292000  |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| gru_83 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_pop_pl_emb_model (Se  (1, 32)                  6688      \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_107 (Discret  (1, 8)                 0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| artist_pop_pl_emb_layer (Em  (1, 8, 32)             352       |\n",
      "| bedding)                                                      |\n",
      "|                                                               |\n",
      "| gru_84 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artists_followers_pl_emb_mo  (1, 32)                  6688      \n",
      " del (Sequential)                                                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_108 (Discret  (1, 4)                 0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| artists_followers_pl_emb_la  (1, 4, 32)             352       |\n",
      "| yer (Embedding)                                               |\n",
      "|                                                               |\n",
      "| gru_85 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_pop_pl_emb_model (Seq  (1, 32)                  6688      \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| discretization_109 (Discret  (1, 12)                0         |\n",
      "| ization)                                                      |\n",
      "|                                                               |\n",
      "| track_pop_pl_emb_layer (Emb  (1, 12, 32)            352       |\n",
      "| edding)                                                       |\n",
      "|                                                               |\n",
      "| gru_86 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_genres_pl_emb_model   (1, 32)                  1267040   \n",
      " (Sequential)                                                    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| string_lookup_141 (StringLo  (1, 2)                 0         |\n",
      "| okup)                                                         |\n",
      "|                                                               |\n",
      "| artist_genres_pl_emb_layer   (1, 2, 32)             1260704   |\n",
      "| (Embedding)                                                   |\n",
      "|                                                               |\n",
      "| gru_87 (GRU)              (1, 32)                   6336      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " pl_cross_layer (Cross)      multiple                  0 (unused)\n",
      "                                                                 \n",
      " pl_dense_layers (Sequential  (1, 32)                  36960     \n",
      " )                                                               \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| dense_58 (Dense)          (1, 64)                   34880     |\n",
      "|                                                               |\n",
      "| dropout (Dropout)         (1, 64)                   0         |\n",
      "|                                                               |\n",
      "| dense_59 (Dense)          (1, 32)                   2080      |\n",
      "|                                                               |\n",
      "| lambda (Lambda)           (1, 32)                   0         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 183,722,304\n",
      "Trainable params: 183,722,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_playlist_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "dfd401b4-59a0-40f9-9a54-43c0922bc028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 03:18:36.468809: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 03:18:36.468871: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 03:18:36.469407: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-07 03:18:36.469435: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19751/2945118074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this = next(it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "it = iter(dataset)\n",
    "print(next(it).numpy())\n",
    "\n",
    "# this = next(it)\n",
    "\n",
    "# print(f\"Shape of this: {this.shape} \\n\")\n",
    "# print(this.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "0d751e4b-847a-491b-bf01-b0e5dd5d4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_playlist_model.layers\n",
    "# test_playlist_model.compile()\n",
    "test_playlist_model.build((None,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "699c3a64-5d73-4b82-ae14-f498b5d30d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(\n",
    "#     test_playlist_model.build(), \n",
    "#     show_shapes=True,\n",
    "#     show_dtype=True,\n",
    "#     show_layer_names=True,\n",
    "#     # rankdir='TB',\n",
    "#     expand_nested=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab5a01-14cf-4bcc-874c-b8c965e69661",
   "metadata": {},
   "source": [
    "## Seed Track Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "2c4cfeda-cffb-46e4-93a4-b866e6dbd82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 19:01:55.773449: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-06 19:01:55.773506: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-06 19:01:55.773928: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-06 19:01:55.773956: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1).as_numpy_iterator():\n",
    "    pprint(x['duration_seed_track'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d1884c52-575f-42ce-a3c0-531600cb4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_seed_track': array([b'Kaththi (Original Motion Picture Soundtrack)'], dtype='|S44'),\n",
      " 'album_uri_seed_track': array([b'spotify:album:2qFqhre2weJ6I4kcVMomtH'], dtype='|S36'),\n",
      " 'artist_followers_seed_track': array([29.]),\n",
      " 'artist_genres_seed_track': array([b\"'neon pop punk', 'pop punk'\"], dtype='|S27'),\n",
      " 'artist_name_seed_track': array([b'The Shadowboxers'], dtype='|S16'),\n",
      " 'artist_pop_seed_track': array([51.]),\n",
      " 'artist_uri_seed_track': array([b'spotify:artist:1zO48bXRrBLAZIxDsMe80S'], dtype='|S37'),\n",
      " 'duration_seed_track': array([291002.]),\n",
      " 'pos_seed_track': array([45]),\n",
      " 'track_name_seed_track': array([b'Ba La Lirkod'], dtype='|S12'),\n",
      " 'track_pop_seed_track': array([27.]),\n",
      " 'track_uri_seed_track': array([b'spotify:track:2JuWEcRAVurR3ySo62OEfN'], dtype='|S36')}\n"
     ]
    }
   ],
   "source": [
    "seed_test_instance = {\n",
    "    'pos_seed_track': np.asarray([45], dtype=np.int64),\n",
    "    'artist_name_seed_track': np.asarray([b'The Shadowboxers']),\n",
    "    'artist_uri_seed_track': np.asarray([b'spotify:artist:1zO48bXRrBLAZIxDsMe80S']),\n",
    "    'track_name_seed_track': np.asarray([b'Ba La Lirkod']),\n",
    "    'track_uri_seed_track': np.asarray([b'spotify:track:2JuWEcRAVurR3ySo62OEfN']),\n",
    "    'album_name_seed_track': np.asarray([b'Kaththi (Original Motion Picture Soundtrack)']),\n",
    "    'album_uri_seed_track': np.asarray([b'spotify:album:2qFqhre2weJ6I4kcVMomtH']),\n",
    "    'duration_seed_track': np.asarray([291002.0]),\n",
    "    'track_pop_seed_track': np.asarray([27.0]),\n",
    "    'artist_pop_seed_track': np.asarray([51.0]),\n",
    "    'artist_followers_seed_track':np.asarray([29.0]),\n",
    "    'artist_genres_seed_track': np.asarray([b\"'neon pop punk', 'pop punk'\"]),\n",
    "}\n",
    "\n",
    "pprint(seed_test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "070ba217-a567-4aaf-8dfa-4cf9ba302f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "\n",
    "class Seed_Track_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ========================================\n",
    "        # seed track features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_seed_track\n",
    "        self.artist_name_seed_track_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"artist_name_seed_track\"],\n",
    "                    name=\"artist_name_seed_track_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"artist_name_seed_track\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_name_seed_track_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_name_seed_track_pooling\"),\n",
    "            ], name=\"artist_name_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_uri_seed_track\n",
    "        # self.artist_uri_seed_track_embedding = tf.keras.layers.CategoryEncoding(num_tokens=64, output_mode=\"int\")\n",
    "        self.artist_uri_seed_track_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_uri_seed_track']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_uri_seed_track_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"artist_uri_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_seed_track\n",
    "        self.track_name_seed_track_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"track_name_seed_track\"],\n",
    "                    name=\"track_name_seed_track_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"track_name_seed_track\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"track_name_seed_track_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_name_seed_track_pooling\"),\n",
    "            ], name=\"track_name_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_seed_track\n",
    "        self.track_uri_seed_track_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_seed_track']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_seed_track_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"track_uri_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_seed_track\n",
    "        self.album_name_seed_track_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"album_name_seed_track\"],\n",
    "                    name=\"album_name_seed_track_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"album_name_seed_track\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"album_name_seed_track_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"album_name_seed_track_pooling\"),\n",
    "            ], name=\"album_name_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_uri_seed_track\n",
    "        self.album_uri_seed_track_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['album_uri_seed_track']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_uri_seed_track_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"album_uri_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: duration_seed_track\n",
    "        self.duration_seed_track_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_duration_ms_songs_pl'],\n",
    "            variance=vocab_dict['var_duration_ms_songs_pl'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_seed_track\n",
    "        self.track_pop_seed_track_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_track_pop'],\n",
    "            variance=vocab_dict['var_track_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_pop_seed_track\n",
    "        self.artist_pop_seed_track_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_pop'],\n",
    "            variance=vocab_dict['var_artist_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_followers_seed_track\n",
    "        self.artist_followers_seed_track_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_followers'],\n",
    "            variance=vocab_dict['var_artist_followers'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_seed_track\n",
    "        self.artist_genres_seed_track_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"artist_genres_seed_track\"],\n",
    "                    name=\"artist_genres_seed_track_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"artist_genres_seed_track\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_genres_seed_track_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_genres_seed_track_pooling\"),\n",
    "            ], name=\"artist_genres_seed_track_emb_model\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # ========================================\n",
    "        # dense and cross layers\n",
    "        # ========================================\n",
    "\n",
    "        # Cross Layers\n",
    "        if USE_CROSS_LAYER:\n",
    "            self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "                projection_dim=PROJECTION_DIM,\n",
    "                kernel_initializer=\"glorot_uniform\", \n",
    "                name=\"seed_track_cross_layer\"\n",
    "            )\n",
    "        else:\n",
    "            self._cross_layer = None\n",
    "            \n",
    "        # Dense Layer\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"seed_track_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "        ### ADDING L2 NORM AT THE END\n",
    "        self.dense_layers.add(\n",
    "            tf.keras.layers.Lambda(\n",
    "                lambda x: tf.nn.l2_normalize(\n",
    "                    x, 1, epsilon=1e-12, name=\"normalize_dense\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # ========================================\n",
    "    # call\n",
    "    # ========================================\n",
    "    def call(self, data):\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                # data['pos_seed_track']\n",
    "                self.artist_name_seed_track_text_embedding(data['artist_name_seed_track']),\n",
    "                self.artist_uri_seed_track_embedding(data['artist_uri_seed_track']),\n",
    "                self.track_name_seed_track_text_embedding(data['track_name_seed_track']),\n",
    "                self.track_uri_seed_track_embedding(data[\"track_uri_seed_track\"]),\n",
    "                self.album_name_seed_track_text_embedding(data[\"album_name_seed_track\"]),\n",
    "                self.album_uri_seed_track_embedding(data[\"album_uri_seed_track\"]),\n",
    "                tf.reshape(self.duration_seed_track_normalized(data[\"duration_seed_track\"]), (-1, 1)),\n",
    "                tf.reshape(self.duration_seed_track_normalized(data[\"track_pop_seed_track\"]), (-1, 1)),\n",
    "                tf.reshape(self.duration_seed_track_normalized(data[\"artist_pop_seed_track\"]), (-1, 1)),\n",
    "                tf.reshape(self.artist_followers_seed_track_normalized(data[\"artist_followers_seed_track\"]), (-1, 1)),\n",
    "                self.artist_genres_seed_track_text_embedding(data[\"artist_genres_seed_track\"]),\n",
    "            ], axis=1)\n",
    "        \n",
    "        # Build Cross Network\n",
    "        if self._cross_layer is not None:\n",
    "            cross_embs = self._cross_layer(all_embs)\n",
    "            return self.dense_layers(cross_embs)\n",
    "        else:\n",
    "            return self.dense_layers(all_embs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "4e414778-5b4f-4d0f-b500-3bd223daca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of seed_result: (1, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.4738885 , -0.6975312 , -0.5645372 , -0.30292508,  0.28519604,\n",
       "         0.27546224, -0.30110165,  1.0748749 ,  0.55002886, -0.15349019,\n",
       "         0.15894473,  0.00926473, -0.03872087, -0.6707542 , -0.45568797,\n",
       "        -0.03077737,  0.12979181, -0.08829829,  0.08990557, -0.87537277,\n",
       "         0.27182013,  0.05736695,  0.36312905, -0.85142   , -0.3251322 ,\n",
       "         0.21681169, -0.13190483,  0.6076351 ,  0.37525287,  0.5584176 ,\n",
       "         0.09826156, -0.00232439]], dtype=float32)>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_seed_track_model = Seed_Track_Model(layer_sizes, vocab_dict_load)\n",
    "\n",
    "seed_result = test_seed_track_model(seed_test_instance)\n",
    "\n",
    "print(f\"Shape of seed_result: {seed_result.shape}\")\n",
    "seed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d65c7-23b5-43a5-9eac-d9b5d4698fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_can_track_model = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "\n",
    "can_result = test_can_track_model(can_test_instance)\n",
    "\n",
    "print(f\"Shape of can_result: {can_result.shape}\")\n",
    "can_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "19b6feaa-66de-473b-91b3-148102f0d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seed__track__model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " artist_name_seed_track_emb_  (None, 32)               9206720   \n",
      " model (Sequential)                                              \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| artist_name_seed_track_txt_  (None, None)           0         |\n",
      "| vectorizer (TextVectorizati                                   |\n",
      "| on)                                                           |\n",
      "|                                                               |\n",
      "| artist_name_seed_track_emb_  (None, None, 32)       9206720   |\n",
      "| layer (Embedding)                                             |\n",
      "|                                                               |\n",
      "| artist_name_seed_track_pool  (None, 32)             0         |\n",
      "| ing (GlobalAveragePooling1D                                   |\n",
      "| )                                                             |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_uri_seed_track_emb_m  (1, 32)                  9467520   \n",
      " odel (Sequential)                                               \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_41 (Hashing)      (1,)                      0         |\n",
      "|                                                               |\n",
      "| artist_uri_seed_track_emb_l  (1, 32)                9467520   |\n",
      "| ayer (Embedding)                                              |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_name_seed_track_emb_m  (None, 32)               47480096  \n",
      " odel (Sequential)                                               \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| track_name_seed_track_txt_v  (None, None)           0         |\n",
      "| ectorizer (TextVectorizatio                                   |\n",
      "| n)                                                            |\n",
      "|                                                               |\n",
      "| track_name_seed_track_emb_l  (None, None, 32)       47480096  |\n",
      "| ayer (Embedding)                                              |\n",
      "|                                                               |\n",
      "| track_name_seed_track_pooli  (None, 32)             0         |\n",
      "| ng (GlobalAveragePooling1D)                                   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_uri_seed_track_emb_mo  (1, 32)                  72393344  \n",
      " del (Sequential)                                                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_42 (Hashing)      (1,)                      0         |\n",
      "|                                                               |\n",
      "| track_uri_seed_track_emb_la  (1, 32)                72393344  |\n",
      "| yer (Embedding)                                               |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " album_name_seed_track_emb_m  (None, 32)               18292000  \n",
      " odel (Sequential)                                               \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| album_name_seed_track_txt_v  (None, None)           0         |\n",
      "| ectorizer (TextVectorizatio                                   |\n",
      "| n)                                                            |\n",
      "|                                                               |\n",
      "| album_name_seed_track_emb_l  (None, None, 32)       18292000  |\n",
      "| ayer (Embedding)                                              |\n",
      "|                                                               |\n",
      "| album_name_seed_track_pooli  (None, 32)             0         |\n",
      "| ng (GlobalAveragePooling1D)                                   |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " album_uri_seed_track_emb_mo  (1, 32)                  23509888  \n",
      " del (Sequential)                                                \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_43 (Hashing)      (1,)                      0         |\n",
      "|                                                               |\n",
      "| album_uri_seed_track_emb_la  (1, 32)                23509888  |\n",
      "| yer (Embedding)                                               |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " normalization_21 (Normaliza  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " normalization_22 (Normaliza  multiple                 0 (unused)\n",
      " tion)                                                           \n",
      "                                                                 \n",
      " normalization_23 (Normaliza  multiple                 0 (unused)\n",
      " tion)                                                           \n",
      "                                                                 \n",
      " normalization_24 (Normaliza  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " artist_genres_seed_track_em  (None, 32)               1260704   \n",
      " b_model (Sequential)                                            \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| artist_genres_seed_track_tx  (None, None)           0         |\n",
      "| t_vectorizer (TextVectoriza                                   |\n",
      "| tion)                                                         |\n",
      "|                                                               |\n",
      "| artist_genres_seed_track_em  (None, None, 32)       1260704   |\n",
      "| b_layer (Embedding)                                           |\n",
      "|                                                               |\n",
      "| artist_genres_seed_track_po  (None, 32)             0         |\n",
      "| oling (GlobalAveragePooling                                   |\n",
      "| 1D)                                                           |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " seed_track_dense_layers (Se  (1, 32)                  16736     \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| dense_96 (Dense)          (1, 64)                   14656     |\n",
      "|                                                               |\n",
      "| dense_97 (Dense)          (1, 32)                   2080      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 181,627,008\n",
      "Trainable params: 181,627,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_seed_track_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a5958-afc8-4671-af48-618eb2ed4374",
   "metadata": {},
   "source": [
    "## Candidate Track Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "aa56f901-fca0-4b1a-8f19-fbc8c714688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 19:20:49.049023: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-06 19:20:49.049080: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-06 19:20:49.049666: E tensorflow/core/framework/dataset.cc:580] UNIMPLEMENTED: Cannot compute input sources for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n",
      "2022-07-06 19:20:49.049713: E tensorflow/core/framework/dataset.cc:584] UNIMPLEMENTED: Cannot merge options for dataset of type IO>BigQueryDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.take(1).as_numpy_iterator():\n",
    "    pprint(x['artist_name_can'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "9047d76a-fa58-451f-ac5c-97817bb8b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': array([b'Would It Kill You?'], dtype='|S18'),\n",
      " 'album_uri_can': array([b'spotify:album:4dHXV7pJs6d8N9ACAMzhIw'], dtype='|S36'),\n",
      " 'artist_followers_can': array([205331.]),\n",
      " 'artist_genres_can': array([b\"'neon pop punk', 'pop punk'\"], dtype='|S27'),\n",
      " 'artist_name_can': array([b'Hellogoodbye'], dtype='|S12'),\n",
      " 'artist_pop_can': array([51.]),\n",
      " 'artist_uri_can': array([b'spotify:artist:6GH0NzpthMGxu1mcfAkOde'], dtype='|S37'),\n",
      " 'duration_ms_can': array([154813.]),\n",
      " 'test': array([b'test'], dtype='|S4'),\n",
      " 'track_name_can': array([b'When We First Met'], dtype='|S17'),\n",
      " 'track_pop_can': array([45.]),\n",
      " 'track_uri_can': array([b'Ba La Lirkod'], dtype='|S12')}\n"
     ]
    }
   ],
   "source": [
    "can_test_instance = {\n",
    "    'artist_name_can': np.asarray([b'Hellogoodbye']),\n",
    "    'track_name_can': np.asarray([b'When We First Met']),\n",
    "    'album_name_can': np.asarray([b'Would It Kill You?']),\n",
    "    'track_uri_can': np.asarray([b'Ba La Lirkod']),\n",
    "    'artist_uri_can': np.asarray([b'spotify:artist:6GH0NzpthMGxu1mcfAkOde']),\n",
    "    'album_uri_can': np.asarray([b'spotify:album:4dHXV7pJs6d8N9ACAMzhIw']),\n",
    "    'duration_ms_can': np.asarray([154813.0]),\n",
    "    'track_pop_can': np.asarray([45.0]),\n",
    "    'artist_pop_can': np.asarray([51.0]),\n",
    "    'artist_followers_can':np.asarray([205331.0]),\n",
    "    'artist_genres_can': np.asarray([b\"'neon pop punk', 'pop punk'\"]),\n",
    "    'test': np.asarray([b'test'])\n",
    "}\n",
    "\n",
    "pprint(can_test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "6f4a59c7-2ee5-4882-9a1a-336b03aef988",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=True\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "\n",
    "class Candidate_Track_Model(tf.keras.Model):\n",
    "    def __init__(self, layer_sizes, vocab_dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ========================================\n",
    "        # Candidate features\n",
    "        # ========================================\n",
    "        \n",
    "        # Feature: artist_name_can\n",
    "        self.artist_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"artist_name_can\"],\n",
    "                    name=\"artist_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"artist_name_can\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_name_can_pooling\"),\n",
    "            ], name=\"artist_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_name_can\n",
    "        self.track_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"track_name_can\"],\n",
    "                    name=\"track_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"track_name_can\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"track_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"track_name_can_pooling\"),\n",
    "            ], name=\"track_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_name_can\n",
    "        self.album_name_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"album_name_can\"],\n",
    "                    name=\"album_name_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"album_name_can\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"album_name_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"album_name_can_pooling\"),\n",
    "            ], name=\"album_name_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_uri_can\n",
    "        self.artist_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['artist_uri_can']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"artist_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"artist_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: track_uri_can\n",
    "        self.track_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['track_uri_can']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"track_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"track_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: album_uri_can\n",
    "        self.album_uri_can_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Hashing(num_bins=200_000),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict['album_uri_can']), \n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    name=\"album_uri_can_emb_layer\",\n",
    "                ),\n",
    "            ], name=\"album_uri_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # Feature: duration_ms_can\n",
    "        self.duration_ms_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_duration_ms_songs_pl'],\n",
    "            variance=vocab_dict['var_duration_ms_songs_pl'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: track_pop_can\n",
    "        self.track_pop_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_track_pop'],\n",
    "            variance=vocab_dict['var_track_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_pop_can\n",
    "        self.artist_pop_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_pop'],\n",
    "            variance=vocab_dict['var_artist_pop'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_followers_can\n",
    "        self.artist_followers_can_normalized = tf.keras.layers.Normalization(\n",
    "            mean=vocab_dict['avg_artist_followers'],\n",
    "            variance=vocab_dict['var_artist_followers'],\n",
    "            axis=None\n",
    "        )\n",
    "        \n",
    "        # Feature: artist_genres_can\n",
    "        self.artist_genres_can_text_embedding = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.TextVectorization(\n",
    "                    vocabulary=vocab_dict[\"artist_genres_can\"],\n",
    "                    name=\"artist_genres_can_txt_vectorizer\",\n",
    "                    ngrams=2,\n",
    "                ),\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim=len(vocab_dict[\"artist_genres_can\"]),\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    mask_zero=False,\n",
    "                    name=\"artist_genres_can_emb_layer\",\n",
    "                ),\n",
    "                tf.keras.layers.GlobalAveragePooling1D(name=\"artist_genres_can_pooling\"),\n",
    "            ], name=\"artist_genres_can_emb_model\"\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # Dense & Cross Layers\n",
    "        # ========================================\n",
    "        \n",
    "        # Cross Layers\n",
    "        \n",
    "        # Dense Layer\n",
    "        self.dense_layers = tf.keras.Sequential(name=\"candidate_dense_layers\")\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.dense_layers.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.dense_layers.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    # ========================================\n",
    "    # Call Function\n",
    "    # ========================================\n",
    "            \n",
    "    def call(self, data):\n",
    "        \n",
    "        all_embs = tf.concat(\n",
    "            [\n",
    "                self.artist_name_can_text_embedding(data['artist_name_can']),\n",
    "                self.track_name_can_text_embedding(data['track_name_can']),\n",
    "                self.album_name_can_text_embedding(data['album_name_can']),\n",
    "                self.artist_uri_can_embedding(data['artist_uri_can']),\n",
    "                self.track_uri_can_embedding(data['track_uri_can']),\n",
    "                self.album_uri_can_embedding(data['album_uri_can']),\n",
    "                tf.reshape(self.duration_ms_can_normalized(data[\"duration_ms_can\"]), (-1, 1)),\n",
    "                tf.reshape(self.track_pop_can_normalized(data[\"track_pop_can\"]), (-1, 1)),\n",
    "                tf.reshape(self.artist_pop_can_normalized(data[\"artist_pop_can\"]), (-1, 1)),\n",
    "                tf.reshape(self.artist_followers_can_normalized(data[\"artist_followers_can\"]), (-1, 1)),\n",
    "                self.artist_genres_can_text_embedding(data['album_uri_can']),\n",
    "            ], axis=1\n",
    "        )\n",
    "        \n",
    "        return self.dense_layers(all_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "ed9b58d1-9875-4f51-9a1b-2a19fc3b9b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of can_result: (1, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[-0.64103854,  0.17936414, -0.1597794 , -0.23482801,  0.04011448,\n",
       "         0.06539779, -0.07605655, -0.17988613,  0.06396451,  0.28101248,\n",
       "        -0.43454924,  0.06150659, -0.1915848 , -0.11559332,  0.00649117,\n",
       "         0.04989069,  0.18501326, -0.01549801, -0.16110197,  0.15586206,\n",
       "         0.16208774,  0.26024503,  0.16025694,  0.12186014, -0.04252896,\n",
       "        -0.01786662,  0.06143963, -0.39211723, -0.15657601,  0.29838738,\n",
       "         0.02947132, -0.07277929]], dtype=float32)>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes=[64,32]\n",
    "\n",
    "test_can_track_model = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "\n",
    "can_result = test_can_track_model(can_test_instance)\n",
    "\n",
    "print(f\"Shape of can_result: {can_result.shape}\")\n",
    "can_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "ee1b015e-811e-4e0e-a00a-f8724c05e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"candidate__track__model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " artist_name_can_emb_model (  (None, 32)               9206720   \n",
      " Sequential)                                                     \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| artist_name_can_txt_vectori  (None, None)           0         |\n",
      "| zer (TextVectorization)                                       |\n",
      "|                                                               |\n",
      "| artist_name_can_emb_layer (  (None, None, 32)       9206720   |\n",
      "| Embedding)                                                    |\n",
      "|                                                               |\n",
      "| artist_name_can_pooling (Gl  (None, 32)             0         |\n",
      "| obalAveragePooling1D)                                         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_name_can_emb_model (S  (None, 32)               47480096  \n",
      " equential)                                                      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| track_name_can_txt_vectoriz  (None, None)           0         |\n",
      "| er (TextVectorization)                                        |\n",
      "|                                                               |\n",
      "| track_name_can_emb_layer (E  (None, None, 32)       47480096  |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| track_name_can_pooling (Glo  (None, 32)             0         |\n",
      "| balAveragePooling1D)                                          |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " album_name_can_emb_model (S  (None, 32)               18292000  \n",
      " equential)                                                      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| album_name_can_txt_vectoriz  (None, None)           0         |\n",
      "| er (TextVectorization)                                        |\n",
      "|                                                               |\n",
      "| album_name_can_emb_layer (E  (None, None, 32)       18292000  |\n",
      "| mbedding)                                                     |\n",
      "|                                                               |\n",
      "| album_name_can_pooling (Glo  (None, 32)             0         |\n",
      "| balAveragePooling1D)                                          |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " artist_uri_can_emb_model (S  (1, 32)                  9467520   \n",
      " equential)                                                      \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_56 (Hashing)      (1,)                      0         |\n",
      "|                                                               |\n",
      "| artist_uri_can_emb_layer (E  (1, 32)                9467520   |\n",
      "| mbedding)                                                     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " track_uri_can_emb_model (Se  (1, 32)                  72393344  \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_57 (Hashing)      (1,)                      0         |\n",
      "|                                                               |\n",
      "| track_uri_can_emb_layer (Em  (1, 32)                72393344  |\n",
      "| bedding)                                                      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " album_uri_can_emb_model (Se  (1, 32)                  23509888  \n",
      " quential)                                                       \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| hashing_58 (Hashing)      (1,)                      0         |\n",
      "|                                                               |\n",
      "| album_uri_can_emb_layer (Em  (1, 32)                23509888  |\n",
      "| bedding)                                                      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " normalization_34 (Normaliza  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " normalization_35 (Normaliza  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " normalization_36 (Normaliza  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " normalization_37 (Normaliza  multiple                 0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " artist_genres_can_emb_model  (None, 32)               1260704   \n",
      "  (Sequential)                                                   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| artist_genres_can_txt_vecto  (None, None)           0         |\n",
      "| rizer (TextVectorization)                                     |\n",
      "|                                                               |\n",
      "| artist_genres_can_emb_layer  (None, None, 32)       1260704   |\n",
      "|  (Embedding)                                                  |\n",
      "|                                                               |\n",
      "| artist_genres_can_pooling (  (None, 32)             0         |\n",
      "| GlobalAveragePooling1D)                                       |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " candidate_dense_layers (Seq  (1, 32)                  16736     \n",
      " uential)                                                        \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| dense_112 (Dense)         (1, 64)                   14656     |\n",
      "|                                                               |\n",
      "| dropout_9 (Dropout)       (1, 64)                   0         |\n",
      "|                                                               |\n",
      "| dense_113 (Dense)         (1, 32)                   2080      |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 181,627,008\n",
      "Trainable params: 181,627,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_can_track_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d410a94-92cc-4097-94f3-ed24578ebae0",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "c2458bbc-1214-4ac7-8a9f-7548701b92db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pl_can_concat: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.05321983, -0.04084665,  0.11637767,  0.3411542 ,  0.09852977,\n",
       "        -0.06006141,  0.14619492,  0.24855876, -0.12215702, -0.15610446,\n",
       "        -0.08795111, -0.27013752, -0.04377728, -0.12331408,  0.09523007,\n",
       "        -0.13910483,  0.09044929, -0.19123396,  0.14647555, -0.3671819 ,\n",
       "         0.19767866,  0.03310812,  0.12395252,  0.14589746,  0.18691422,\n",
       "        -0.23982897,  0.08464528, -0.00168197,  0.38199148,  0.10042445,\n",
       "        -0.2411324 , -0.1092459 , -0.64103854,  0.17936414, -0.1597794 ,\n",
       "        -0.23482801,  0.04011448,  0.06539779, -0.07605655, -0.17988613,\n",
       "         0.06396451,  0.28101248, -0.43454924,  0.06150659, -0.1915848 ,\n",
       "        -0.11559332,  0.00649117,  0.04989069,  0.18501326, -0.01549801,\n",
       "        -0.16110197,  0.15586206,  0.16208774,  0.26024503,  0.16025694,\n",
       "         0.12186014, -0.04252896, -0.01786662,  0.06143963, -0.39211723,\n",
       "        -0.15657601,  0.29838738,  0.02947132, -0.07277929]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pl_result\n",
    "# seed_result\n",
    "# can_result\n",
    "\n",
    "pl_can_concat = tf.concat([pl_result,can_result], axis=1)\n",
    "\n",
    "print(f\"Shape of pl_can_concat: {pl_can_concat.shape[1]}\")\n",
    "pl_can_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "ce04e315-532f-4909-b5c9-4e2c103ebc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sd_can_concat: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
       "array([[ 0.4738885 , -0.6975312 , -0.5645372 , -0.30292508,  0.28519604,\n",
       "         0.27546224, -0.30110165,  1.0748749 ,  0.55002886, -0.15349019,\n",
       "         0.15894473,  0.00926473, -0.03872087, -0.6707542 , -0.45568797,\n",
       "        -0.03077737,  0.12979181, -0.08829829,  0.08990557, -0.87537277,\n",
       "         0.27182013,  0.05736695,  0.36312905, -0.85142   , -0.3251322 ,\n",
       "         0.21681169, -0.13190483,  0.6076351 ,  0.37525287,  0.5584176 ,\n",
       "         0.09826156, -0.00232439, -0.64103854,  0.17936414, -0.1597794 ,\n",
       "        -0.23482801,  0.04011448,  0.06539779, -0.07605655, -0.17988613,\n",
       "         0.06396451,  0.28101248, -0.43454924,  0.06150659, -0.1915848 ,\n",
       "        -0.11559332,  0.00649117,  0.04989069,  0.18501326, -0.01549801,\n",
       "        -0.16110197,  0.15586206,  0.16208774,  0.26024503,  0.16025694,\n",
       "         0.12186014, -0.04252896, -0.01786662,  0.06143963, -0.39211723,\n",
       "        -0.15657601,  0.29838738,  0.02947132, -0.07277929]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_can_concat = tf.concat([seed_result,can_result], axis=1)\n",
    "\n",
    "print(f\"Shape of sd_can_concat: {sd_can_concat.shape[1]}\")\n",
    "sd_can_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "8d0add47-89c8-408c-bb47-bf76f47391c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTowerModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, layer_sizes, vocab_dict_load, Seed_Candidate_Weight: float, Playlist_Candidate_Weight: float):\n",
    "        super().__init__()\n",
    "        self.playlist_tower = Playlist_Model(layer_sizes, vocab_dict_load)\n",
    "        self.seed_track_tower = Seed_Track_Model(layer_sizes, vocab_dict_load)\n",
    "        self.shared_candidate_tower = Candidate_Track_Model(layer_sizes, vocab_dict_load)\n",
    "        \n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "        \n",
    "        # =============================\n",
    "        # Playlist-Candidate subtower\n",
    "        # =============================\n",
    "        '''\n",
    "        a sub-model to take (1) Playlist and (2) Candidate features\n",
    "        and retrieve \n",
    "        '''\n",
    "        \n",
    "        self.Playlist_Candidate_Subtower = tf.keras.Sequential(name=\"playlist-candidate-subtower\")\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.Playlist_Candidate_Subtower.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.Playlist_Candidate_Subtower.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.Playlist_Candidate_Subtower.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # =============================\n",
    "        # Seed-Candidate subtower\n",
    "        # =============================\n",
    "        \n",
    "        self.Seed_Candidate_Subtower = tf.keras.Sequential(name=\"seed-candidate-subtower\")\n",
    "        # Use the ReLU activation for all but the last layer.\n",
    "        for layer_size in layer_sizes[:-1]:\n",
    "            self.Seed_Candidate_Subtower.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    activation=\"relu\", \n",
    "                    kernel_initializer=initializer,\n",
    "                )\n",
    "            )\n",
    "            if DROPOUT:\n",
    "                self.Seed_Candidate_Subtower.add(tf.keras.layers.Dropout(DROPOUT_RATE))\n",
    "                \n",
    "        # No activation for the last layer\n",
    "        for layer_size in layer_sizes[-1:]:\n",
    "            self.Seed_Candidate_Subtower.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    layer_size, \n",
    "                    kernel_initializer=initializer\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # =============================\n",
    "        # Retrieval Tasks\n",
    "        # =============================\n",
    "              \n",
    "        self.Playlist_Candidate_Task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=dataset.batch(128).cache().map(self.Playlist_Candidate_Subtower)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.Seed_Candidate_Task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=dataset.batch(128).cache().map(self.Seed_Candidate_Subtower)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # =============================\n",
    "        # Loss Weights\n",
    "        # =============================\n",
    "        self.Playlist_Candidate_Weight = Playlist_Candidate_Weight\n",
    "        self.Seed_Candidate_Weight = Seed_Candidate_Weight\n",
    "        \n",
    "    # Call\n",
    "    def call(self, data):\n",
    "        # get all embeddings\n",
    "        playlist_embeddings = self.playlist_tower(data)\n",
    "        seed_track_embeddings = self.seed_track_tower(data)\n",
    "        candidate_embeddings= self.shared_candidate_tower(data)\n",
    "        \n",
    "        # Apply the multi-layered DNN model to a concat of \n",
    "        # Playlist and Candidate features\n",
    "        Playlist_Candidate_Embeddings = self.Playlist_Candidate_Subtower(\n",
    "            tf.concat([playlist_embeddings, candidate_embeddings], axis=1)\n",
    "        )\n",
    "       \n",
    "        # Apply the multi-layered DNN model to a concat of \n",
    "        # Seed_Track and Candidate features\n",
    "        Seed_Candidate_Embeddings = self.Seed_Candidate_Subtower(\n",
    "            tf.concat([seed_track_embeddings, candidate_embeddings], axis=1)\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            playlist_embeddings,\n",
    "            seed_track_embeddings,\n",
    "            candidate_embeddings,\n",
    "            Playlist_Candidate_Embeddings,\n",
    "            Seed_Candidate_Embeddings,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, data, training=False):\n",
    "        \n",
    "        playlist_embeddings, seed_track_embeddings, candidate_embeddings, _, _ = self(data)\n",
    "        \n",
    "        playlist_candidate_loss = self.Playlist_Candidate_Task(\n",
    "            playlist_embeddings, candidate_embeddings, compute_metrics=not training)\n",
    "        \n",
    "        seed_candidate_loss = self.Seed_Candidate_Task(\n",
    "            seed_track_embeddings, candidate_embeddings, compute_metrics=not training)\n",
    "\n",
    "        return (\n",
    "            self.Playlist_Candidate_Weight * playlist_candidate_loss \n",
    "            + self.Seed_Candidate_Weight * seed_candidate_loss\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "63406535-cd99-4f17-81bb-d911c5c4474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.playlist_tower = Playlist_Model(layer_sizes, vocab_dict_load)\n",
    "# self.seed_track_tower = Seed_Track_Model(layer_sizes, vocab_dict_load)\n",
    "# self.shared_candidate_tower = Candidate_Track_Model(layer_sizes, vocab_dict_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "d0add962-3697-4ad6-9bf5-dcbec216d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('album_name_can', <tf.Tensor 'args_0:0' shape=(None, None) dtype=string>), ('album_name_pl', <tf.Tensor 'args_1:0' shape=(None, None, None) dtype=string>), ('album_name_seed_track', <tf.Tensor 'args_2:0' shape=(None, None) dtype=string>), ('album_uri_can', <tf.Tensor 'args_3:0' shape=(None, None) dtype=string>), ('album_uri_seed_track', <tf.Tensor 'args_4:0' shape=(None, None) dtype=string>), ('artist_followers_can', <tf.Tensor 'args_5:0' shape=(None, None) dtype=float64>), ('artist_followers_seed_track', <tf.Tensor 'args_6:0' shape=(None, None) dtype=float64>), ('artist_genres_can', <tf.Tensor 'args_7:0' shape=(None, None) dtype=string>), ('artist_genres_pl', <tf.Tensor 'args_8:0' shape=(None, None, None) dtype=string>), ('artist_genres_seed_track', <tf.Tensor 'args_9:0' shape=(None, None) dtype=string>), ('artist_name_can', <tf.Tensor 'args_10:0' shape=(None, None) dtype=string>), ('artist_name_pl', <tf.Tensor 'args_11:0' shape=(None, None, None) dtype=string>), ('artist_name_seed_track', <tf.Tensor 'args_12:0' shape=(None, None) dtype=string>), ('artist_pop_can', <tf.Tensor 'args_13:0' shape=(None, None) dtype=float64>), ('artist_pop_pl', <tf.Tensor 'args_14:0' shape=(None, None, None) dtype=float64>), ('artist_pop_seed_track', <tf.Tensor 'args_15:0' shape=(None, None) dtype=float64>), ('artist_uri_can', <tf.Tensor 'args_16:0' shape=(None, None) dtype=string>), ('artist_uri_seed_track', <tf.Tensor 'args_17:0' shape=(None, None) dtype=string>), ('artists_followers_pl', <tf.Tensor 'args_18:0' shape=(None, None, None) dtype=float64>), ('collaborative', <tf.Tensor 'args_19:0' shape=(None, None) dtype=string>), ('description_pl', <tf.Tensor 'args_20:0' shape=(None, None) dtype=string>), ('duration_ms_can', <tf.Tensor 'args_21:0' shape=(None, None) dtype=float64>), ('duration_ms_seed_pl', <tf.Tensor 'args_22:0' shape=(None, None) dtype=float64>), ('duration_ms_songs_pl', <tf.Tensor 'args_23:0' shape=(None, None, None) dtype=float64>), ('duration_seed_track', <tf.Tensor 'args_24:0' shape=(None, None) dtype=float64>), ('n_songs_pl', <tf.Tensor 'args_25:0' shape=(None, None) dtype=float64>), ('name', <tf.Tensor 'args_26:0' shape=(None, None) dtype=string>), ('num_albums_pl', <tf.Tensor 'args_27:0' shape=(None, None) dtype=float64>), ('num_artists_pl', <tf.Tensor 'args_28:0' shape=(None, None) dtype=float64>), ('pid', <tf.Tensor 'args_29:0' shape=(None, None) dtype=int64>), ('pos_can', <tf.Tensor 'args_30:0' shape=(None, None) dtype=int64>), ('pos_seed_track', <tf.Tensor 'args_31:0' shape=(None, None) dtype=int64>), ('track_name_can', <tf.Tensor 'args_32:0' shape=(None, None) dtype=string>), ('track_name_pl', <tf.Tensor 'args_33:0' shape=(None, None, None) dtype=string>), ('track_name_seed_track', <tf.Tensor 'args_34:0' shape=(None, None) dtype=string>), ('track_pop_can', <tf.Tensor 'args_35:0' shape=(None, None) dtype=float64>), ('track_pop_pl', <tf.Tensor 'args_36:0' shape=(None, None, None) dtype=int64>), ('track_pop_seed_track', <tf.Tensor 'args_37:0' shape=(None, None) dtype=float64>), ('track_uri_can', <tf.Tensor 'args_38:0' shape=(None, None) dtype=string>), ('track_uri_pl', <tf.Tensor 'args_39:0' shape=(None, None, None) dtype=string>), ('track_uri_seed_track', <tf.Tensor 'args_40:0' shape=(None, None) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"playlist-candidate-subtower\" (type Sequential).\n\nLayer \"dense_152\" expects 1 input(s), but it received 41 input tensors. Inputs received: [<tf.Tensor 'args_0:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_1:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_2:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_3:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_4:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_5:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_6:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_7:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_8:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_9:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_10:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_11:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_12:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_13:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_14:0' shape=(None, None, None) dtype=float64>, <tf.Tensor 'args_15:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_16:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_17:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_18:0' shape=(None, None, None) dtype=float64>, <tf.Tensor 'args_19:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_20:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_21:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_22:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_23:0' shape=(None, None, None) dtype=float64>, <tf.Tensor 'args_24:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_25:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_26:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_27:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_28:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_29:0' shape=(None, None) dtype=int64>, <tf.Tensor 'args_30:0' shape=(None, None) dtype=int64>, <tf.Tensor 'args_31:0' shape=(None, None) dtype=int64>, <tf.Tensor 'args_32:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_33:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_34:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_35:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_36:0' shape=(None, None, None) dtype=int64>, <tf.Tensor 'args_37:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_38:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_39:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_40:0' shape=(None, None) dtype=string>]\n\nCall arguments received by layer \"playlist-candidate-subtower\" (type Sequential):\n  • inputs=OrderedDict([('album_name_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('album_name_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('album_name_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('album_uri_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('album_uri_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_followers_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_followers_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_genres_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_genres_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('artist_genres_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_name_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_name_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('artist_name_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_pop_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_pop_pl', 'tf.Tensor(shape=(None, None, None), dtype=float64)'), ('artist_pop_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_uri_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_uri_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artists_followers_pl', 'tf.Tensor(shape=(None, None, None), dtype=float64)'), ('collaborative', 'tf.Tensor(shape=(None, None), dtype=string)'), ('description_pl', 'tf.Tensor(shape=(None, None), dtype=string)'), ('duration_ms_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('duration_ms_seed_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('duration_ms_songs_pl', 'tf.Tensor(shape=(None, None, None), dtype=float64)'), ('duration_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('n_songs_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('name', 'tf.Tensor(shape=(None, None), dtype=string)'), ('num_albums_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('num_artists_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('pid', 'tf.Tensor(shape=(None, None), dtype=int64)'), ('pos_can', 'tf.Tensor(shape=(None, None), dtype=int64)'), ('pos_seed_track', 'tf.Tensor(shape=(None, None), dtype=int64)'), ('track_name_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('track_name_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('track_name_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('track_pop_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('track_pop_pl', 'tf.Tensor(shape=(None, None, None), dtype=int64)'), ('track_pop_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('track_uri_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('track_uri_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('track_uri_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)')])\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19751/1060540243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvocab_dict_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mSeed_Candidate_Weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mPlaylist_Candidate_Weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19751/801857325.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer_sizes, vocab_dict_load, Seed_Candidate_Weight, Playlist_Candidate_Weight)\u001b[0m\n\u001b[1;32m     71\u001b[0m         self.Playlist_Candidate_Task = tfrs.tasks.Retrieval(\n\u001b[1;32m     72\u001b[0m             metrics=tfrs.metrics.FactorizedTopK(\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mcandidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlaylist_Candidate_Subtower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2046\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   2047\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 2048\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5246\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5247\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5248\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5249\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2566\u001b[0m     \"\"\"\n\u001b[1;32m   2567\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2568\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2569\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mautograph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\u001b[0m\u001b[1;32m    201\u001b[0m                      \u001b[0;34mf' but it received {len(inputs)} input tensors. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                      f'Inputs received: {inputs}')\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"playlist-candidate-subtower\" (type Sequential).\n\nLayer \"dense_152\" expects 1 input(s), but it received 41 input tensors. Inputs received: [<tf.Tensor 'args_0:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_1:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_2:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_3:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_4:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_5:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_6:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_7:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_8:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_9:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_10:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_11:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_12:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_13:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_14:0' shape=(None, None, None) dtype=float64>, <tf.Tensor 'args_15:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_16:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_17:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_18:0' shape=(None, None, None) dtype=float64>, <tf.Tensor 'args_19:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_20:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_21:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_22:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_23:0' shape=(None, None, None) dtype=float64>, <tf.Tensor 'args_24:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_25:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_26:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_27:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_28:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_29:0' shape=(None, None) dtype=int64>, <tf.Tensor 'args_30:0' shape=(None, None) dtype=int64>, <tf.Tensor 'args_31:0' shape=(None, None) dtype=int64>, <tf.Tensor 'args_32:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_33:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_34:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_35:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_36:0' shape=(None, None, None) dtype=int64>, <tf.Tensor 'args_37:0' shape=(None, None) dtype=float64>, <tf.Tensor 'args_38:0' shape=(None, None) dtype=string>, <tf.Tensor 'args_39:0' shape=(None, None, None) dtype=string>, <tf.Tensor 'args_40:0' shape=(None, None) dtype=string>]\n\nCall arguments received by layer \"playlist-candidate-subtower\" (type Sequential):\n  • inputs=OrderedDict([('album_name_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('album_name_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('album_name_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('album_uri_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('album_uri_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_followers_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_followers_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_genres_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_genres_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('artist_genres_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_name_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_name_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('artist_name_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_pop_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_pop_pl', 'tf.Tensor(shape=(None, None, None), dtype=float64)'), ('artist_pop_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('artist_uri_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artist_uri_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('artists_followers_pl', 'tf.Tensor(shape=(None, None, None), dtype=float64)'), ('collaborative', 'tf.Tensor(shape=(None, None), dtype=string)'), ('description_pl', 'tf.Tensor(shape=(None, None), dtype=string)'), ('duration_ms_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('duration_ms_seed_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('duration_ms_songs_pl', 'tf.Tensor(shape=(None, None, None), dtype=float64)'), ('duration_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('n_songs_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('name', 'tf.Tensor(shape=(None, None), dtype=string)'), ('num_albums_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('num_artists_pl', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('pid', 'tf.Tensor(shape=(None, None), dtype=int64)'), ('pos_can', 'tf.Tensor(shape=(None, None), dtype=int64)'), ('pos_seed_track', 'tf.Tensor(shape=(None, None), dtype=int64)'), ('track_name_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('track_name_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('track_name_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)'), ('track_pop_can', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('track_pop_pl', 'tf.Tensor(shape=(None, None, None), dtype=int64)'), ('track_pop_seed_track', 'tf.Tensor(shape=(None, None), dtype=float64)'), ('track_uri_can', 'tf.Tensor(shape=(None, None), dtype=string)'), ('track_uri_pl', 'tf.Tensor(shape=(None, None, None), dtype=string)'), ('track_uri_seed_track', 'tf.Tensor(shape=(None, None), dtype=string)')])\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "layer_sizes=[64,32]\n",
    "seed_playlist_weight = 1.0\n",
    "playlist_candidate_weight = 1.0\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "PROJECTION_DIM = 5\n",
    "SEED = 1234\n",
    "USE_CROSS_LAYER=False\n",
    "DROPOUT='False'\n",
    "DROPOUT_RATE='0.33'\n",
    "\n",
    "model = MultiTowerModel(\n",
    "    layer_sizes, \n",
    "    vocab_dict_load,\n",
    "    Seed_Candidate_Weight = 1.0, \n",
    "    Playlist_Candidate_Weight = 1.0,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ba282-3a5d-4b01-8e0e-c543f7f2982e",
   "metadata": {},
   "source": [
    "#### References\n",
    "* [multi-head_and torso: Dugtrio code](https://source.corp.google.com/piper///depot/google3/learning/brain/models/recommendations/dugtrio/torso/multi_head_torso.py)\n",
    "* [CPU-optimized sparse implementation of attention](https://source.corp.google.com/piper///depot/google3/ads/ubaq/brain_embeddings/tensorflow/layers.py;l=1234;rcl=202730546?q=layers.py%20f:brain_embeddings&dr=)\n",
    "\n",
    "#### Notes\n",
    "* `tf.feature_column.sequence_categorical_column_with_identity` - \"Pass this to embedding_column or indicator_column to convert sequence categorical data into dense representation for input to sequence NN, such as RN\" [docs](https://www.tensorflow.org/api_docs/python/tf/feature_column/sequence_categorical_column_with_identity)\n",
    "* Implementing a sequential model with Two Tower [docs](https://www.tensorflow.org/recommenders/examples/sequential_retrieval#implementing_a_sequential_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9bdfd1-ee59-474e-9f2b-1f24a0ca4594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
