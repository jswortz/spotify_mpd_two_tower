{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0158045e-a522-4c23-8c11-c67139f1ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "042f2033-b755-4c3d-bff4-595e36194fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.train import BytesList, Feature, FeatureList, Int64List, FloatList\n",
    "from tensorflow.train import SequenceExample, FeatureLists, Example\n",
    "\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "# import tensorflow_recommenders as tfrs\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceaaa220-fe9d-4c17-b4d4-c2aabfb9575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_array(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[v.encode('utf-8') for v in value]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[float(v) for v in value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[int(v) for v in value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c0b55-4255-4b81-8d59-bacd2dc13816",
   "metadata": {},
   "source": [
    "## Test - small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c78a8e66-e5ae-41bd-a1bf-2d0b6b5a321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(ln):\n",
    "    q_ln = ln['query'] #grabs the query stuff in the json\n",
    "    c_ln = ln['candidate']\n",
    "    \n",
    "    # ===============================\n",
    "    # Ragged Features - Query\n",
    "    # ===============================\n",
    "    ragged_key_list = [\n",
    "        'track_name_pl',\n",
    "        'artist_name_pl',\n",
    "        'album_name_pl',\n",
    "        # 'track_uri_pl',\n",
    "        'duration_ms_songs_pl',\n",
    "        'artist_pop_pl',\n",
    "        'artists_followers_pl',\n",
    "        'track_pop_pl',\n",
    "        'artist_genres_pl',\n",
    "    ]\n",
    "    \n",
    "    ragged_dict = {}\n",
    "    \n",
    "    for _ in ragged_key_list:\n",
    "        ragged_dict[_] = []\n",
    "        \n",
    "    for x in q_ln['track_name_pl']:\n",
    "        ragged_dict['track_name_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    for x in q_ln['artist_name_pl']:\n",
    "        ragged_dict['artist_name_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    for x in q_ln['album_name_pl']:\n",
    "        ragged_dict['album_name_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    # for x in q_ln['track_uri_pl']:\n",
    "    #     ragged_dict['track_uri_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    for x in q_ln['duration_ms_songs_pl']:\n",
    "        ragged_dict['duration_ms_songs_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['artist_pop_pl']:\n",
    "        ragged_dict['artist_pop_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['artists_followers_pl']:\n",
    "        ragged_dict['artists_followers_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['track_pop_pl']:\n",
    "        ragged_dict['track_pop_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['artist_genres_pl']:\n",
    "        ragged_dict['artist_genres_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    # Set List Types\n",
    "    # Bytes\n",
    "    track_name_pl = BytesList(value=ragged_dict['track_name_pl'])\n",
    "    artist_name_pl = BytesList(value=ragged_dict['artist_name_pl'])\n",
    "    album_name_pl = BytesList(value=ragged_dict['album_name_pl'])\n",
    "    # track_uri_pl = BytesList(value=ragged_dict['track_uri_pl'])\n",
    "    artist_genres_pl = BytesList(value=ragged_dict['artist_genres_pl'])\n",
    "    \n",
    "    # Float List\n",
    "    duration_ms_songs_pl = FloatList(value=ragged_dict['duration_ms_songs_pl'])\n",
    "    artist_pop_pl = FloatList(value=ragged_dict['artist_pop_pl'])\n",
    "    artists_followers_pl = FloatList(value=ragged_dict['artists_followers_pl'])\n",
    "    track_pop_pl = FloatList(value=ragged_dict['track_pop_pl'])\n",
    "    \n",
    "    # Set FeatureLists\n",
    "    # Bytes\n",
    "    track_name_pl = FeatureList(feature=[Feature(bytes_list=track_name_pl)])\n",
    "    artist_name_pl = FeatureList(feature=[Feature(bytes_list=artist_name_pl)])\n",
    "    album_name_pl = FeatureList(feature=[Feature(bytes_list=album_name_pl)])\n",
    "    # track_uri_pl = FeatureList(feature=[Feature(bytes_list=track_uri_pl)])\n",
    "    artist_genres_pl = FeatureList(feature=[Feature(bytes_list=artist_genres_pl)])\n",
    "    \n",
    "    # Float Lists\n",
    "    duration_ms_songs_pl = FeatureList(feature=[Feature(float_list=duration_ms_songs_pl)])\n",
    "    artist_pop_pl = FeatureList(feature=[Feature(float_list=artist_pop_pl)])\n",
    "    artists_followers_pl = FeatureList(feature=[Feature(float_list=artists_followers_pl)])\n",
    "    track_pop_pl = FeatureList(feature=[Feature(float_list=track_pop_pl)])\n",
    "    \n",
    "    # ===============================\n",
    "    # Create Context Features\n",
    "    # ===============================\n",
    "    context_features = {\n",
    "        # playlist - context features\n",
    "        \"name\": string_array(q_ln['name']),\n",
    "        'collaborative' : string_array(q_ln['collaborative']),\n",
    "        # 'duration_ms_seed_pl' : float_feature(q_ln['duration_ms_seed_pl']),\n",
    "        'n_songs_pl' : float_feature(q_ln['n_songs_pl']),\n",
    "        'num_artists_pl' : float_feature(q_ln['num_artists_pl']),\n",
    "        'num_albums_pl' : float_feature(q_ln['num_albums_pl']),\n",
    "        'description_pl' : string_array(q_ln['description_pl']),\n",
    "        \n",
    "        # seed track - context features\n",
    "        # 'track_name_seed_track' : string_array(q_ln['track_name_seed_track']),\n",
    "        # 'artist_name_seed_track' : string_array(q_ln['artist_name_seed_track']),\n",
    "        # 'album_name_seed_track' : string_array(q_ln['album_name_seed_track']),\n",
    "        # 'track_uri_seed_track' : string_array(q_ln['track_uri_seed_track']),\n",
    "        # 'artist_uri_seed_track' : string_array(q_ln['artist_uri_seed_track']),\n",
    "        # 'album_uri_seed_track' : string_array(q_ln['album_uri_seed_track']),\n",
    "        # 'duration_seed_track' : float_feature(q_ln['duration_seed_track']),\n",
    "        # 'track_pop_seed_track' : float_feature(q_ln['track_pop_seed_track']),\n",
    "        # 'artist_pop_seed_track' : float_feature(q_ln['artist_pop_seed_track']),\n",
    "        # 'artist_genres_seed_track' : string_array(q_ln['artist_genres_seed_track']),\n",
    "        # 'artist_followers_seed_track' : float_feature(q_ln['artist_followers_seed_track']),\n",
    "        \n",
    "        #candidate features\n",
    "        \"track_name_can\": string_array(c_ln['track_name_can']), \n",
    "        \"artist_name_can\": string_array(c_ln['artist_name_can']),\n",
    "        \"album_name_can\": string_array(c_ln['album_name_can']),\n",
    "        \"track_uri_can\": string_array(c_ln['track_uri_can']),\n",
    "        # \"artist_uri_can\": string_array(c_ln['artist_uri_can']),\n",
    "        # \"album_uri_can\": string_array(c_ln['album_uri_can']),\n",
    "        \"duration_ms_can\": float_feature(c_ln['duration_ms_can']),\n",
    "        \"track_pop_can\": float_feature(c_ln['track_pop_can']), \n",
    "        \"artist_pop_can\": float_feature(c_ln['artist_pop_can']),\n",
    "        \"artist_genres_can\": string_array(c_ln['artist_genres_can']),\n",
    "        \"artist_followers_can\": float_feature(c_ln['artist_followers_can']),\n",
    "    }\n",
    "    \n",
    "    # ===============================\n",
    "    # Create Sequence\n",
    "    # ===============================\n",
    "    seq = SequenceExample(\n",
    "        context=tf.train.Features(\n",
    "            feature=context_features\n",
    "        ),\n",
    "        feature_lists=FeatureLists(\n",
    "            feature_list={\n",
    "                \"track_name_pl\": track_name_pl,\n",
    "                \"artist_name_pl\": artist_name_pl,\n",
    "                \"album_name_pl\": album_name_pl,\n",
    "                # \"track_uri_pl\": track_uri_pl,\n",
    "                \"duration_ms_songs_pl\": duration_ms_songs_pl,\n",
    "                \"artist_pop_pl\": artist_pop_pl,\n",
    "                \"artists_followers_pl\": artists_followers_pl,\n",
    "                \"track_pop_pl\": track_pop_pl,\n",
    "                \"artist_genres_pl\": artist_genres_pl\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "363d2cdf-5808-4355-bad9-f72747b6d98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 32930\n",
      "Number of Expected TFRecords: 3\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'gs://spotify-builtin-2t'\n",
    "small_SCHEMA_JSON = f'{BUCKET}/schema_small.json'\n",
    "small_sample_TRAIN_JSON = f'{BUCKET}/train_data_small/000000000000.jsonl'\n",
    "SMALL_TRAIN_DS = f'{BUCKET}/train_data_small/*.jsonl'\n",
    "\n",
    "SMALL_DEST = 'gs://spotify-tfrecords-blog/small_data/train'\n",
    "\n",
    "# Calculate records per file\n",
    "num_records = sum(1 for _ in file_io.FileIO(small_sample_TRAIN_JSON, 'rb')) #CHANGE THIS TO LARGE DATASET WHEN READY\n",
    "print(\"Total number of records: {}\".format(num_records))\n",
    "\n",
    "num_samples = 12228\n",
    "num_tfrecords = num_records // num_samples \n",
    "if num_records % num_samples:\n",
    "    num_tfrecords += 1\n",
    "\n",
    "print(\"Number of Expected TFRecords: {}\".format(num_tfrecords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a707d-2d8b-4aa3-adfa-4724f2038818",
   "metadata": {},
   "source": [
    "### write the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd074d21-8d84-4691-91ea-15269a857ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32930it [00:33, 985.31it/s] \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "BUCKET = 'gs://spotify-builtin-2t'\n",
    "# TRAIN_JSON = f'{BUCKET}/train_data_small/*.jsonl'\n",
    "TRAIN_JSON = f'{BUCKET}/train_data_small/000000000000.jsonl'\n",
    "\n",
    "GCS_DESTINATION = 'gs://spotify-tfrecords-blog/small_data/train'\n",
    "\n",
    "\n",
    "record_counter = 0\n",
    "lns = [] \n",
    "tfrec_counter = 0\n",
    "\n",
    "# quick function to write the data as we read through it\n",
    "def write_a_tfrec(lns):\n",
    "    #next write to a tfrecord\n",
    "    with tf.io.TFRecordWriter(\n",
    "        GCS_DESTINATION + \"/spotify-%.6i-%i.tfrec\" % (tfrec_counter, len(lns))\n",
    "    ) as writer:\n",
    "        for ln in lns:\n",
    "            example = parse_line(ln)\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "            \n",
    "#record counter makes sure we are batching every `num_samples` and end of list\n",
    "\n",
    "with file_io.FileIO(TRAIN_JSON, 'r') as reader:\n",
    "    \n",
    "    for line in tqdm(reader):\n",
    "        record_counter += 1\n",
    "        if record_counter % num_samples == 0 or record_counter == num_records: \n",
    "            write_a_tfrec(lns) #write out a batch\n",
    "            lns = [] #reset to a new batch\n",
    "            tfrec_counter += 1\n",
    "        else:\n",
    "            lns.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cda7bfe3-f9e1-4532-8d1a-d999a1a9e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://spotify-tfrecords-blog/small_data/train/spotify_00-12227.tfrec\n",
      "gs://spotify-tfrecords-blog/small_data/train/spotify_01-12227.tfrec\n",
      "gs://spotify-tfrecords-blog/small_data/train/spotify_02-8473.tfrec\n"
     ]
    }
   ],
   "source": [
    "#verify records\n",
    "!gsutil ls $GCS_DESTINATION | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86263a48-92e0-4b1e-a1ad-997c8d4e220c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### confirm the records (read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4404a16d-758a-4fc4-b189-096dde88d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "context_features = {\n",
    "    # playlist - context features\n",
    "    'name': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'collaborative': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'n_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'num_artists_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'num_albums_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'description_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "\n",
    "    #candidate features\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "}\n",
    "train_sequence_features = {\n",
    "    'track_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'artist_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'album_name_pl': tf.io.RaggedFeature(tf.string),\n",
    "    # 'track_uri_pl': tf.io.RaggedFeature(tf.string),\n",
    "    'duration_ms_songs_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artist_pop_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artists_followers_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'track_pop_pl': tf.io.RaggedFeature(tf.float32),\n",
    "    'artist_genres_pl': tf.io.RaggedFeature(tf.string),\n",
    "}\n",
    "def parse_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_sequence_example(\n",
    "        example, \n",
    "        sequence_features=train_sequence_features, \n",
    "        context_features=context_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "train_files= []\n",
    "\n",
    "BUCKET_NAME_TRAIN = 'spotify-tfrecords-blog'\n",
    "OBJ_PATH_TRAIN = 'small_data/train'\n",
    "\n",
    "for blob in client.list_blobs(f'{BUCKET_NAME_TRAIN}', prefix=f'{OBJ_PATH_TRAIN}/', delimiter='/'):\n",
    "    train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "raw_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "parsed_dataset = raw_dataset.map(\n",
    "        parse_tfrecord_fn,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4da39a24-7d05-441f-a49c-f3b0a7e780db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset element_spec=({'album_name_can': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'collaborative': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'description_pl': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'duration_ms_can': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'n_songs_pl': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'name': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'num_albums_pl': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'num_artists_pl': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'track_name_can': TensorSpec(shape=(1,), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'track_uri_can': TensorSpec(shape=(1,), dtype=tf.string, name=None)}, {'album_name_pl': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32), 'artist_genres_pl': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32), 'artist_name_pl': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32), 'artist_pop_pl': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'artists_followers_pl': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'duration_ms_songs_pl': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32), 'track_name_pl': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int32), 'track_pop_pl': RaggedTensorSpec(TensorShape([None, None]), tf.float32, 1, tf.int32)})>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d57ca605-69c4-4add-81f1-eabe447c2584",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'album_name_can': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b\"Some Things Don't Come Easy\"]], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b\"'yacht rock'\"]], dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'England Dan Seals']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[25.]], dtype=float32)>, 'collaborative': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'false']], dtype=object)>, 'description_pl': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'NONE']], dtype=object)>, 'duration_ms_can': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[172240.]], dtype=float32)>, 'n_songs_pl': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[50.]], dtype=float32)>, 'name': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'Yacht Rock']], dtype=object)>, 'num_albums_pl': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[45.]], dtype=float32)>, 'num_artists_pl': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[38.]], dtype=float32)>, 'track_name_can': <tf.Tensor: shape=(1, 1), dtype=string, numpy=\n",
      "array([[b\"We'll Never Have To Say Goodbye Again - Single Version\"]],\n",
      "      dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[58.]], dtype=float32)>, 'track_uri_can': <tf.Tensor: shape=(1, 1), dtype=string, numpy=array([[b'spotify:track:7gfF9nA0mUeaRCPE5ezZLj']], dtype=object)>}, {'album_name_pl': <tf.RaggedTensor [[[b'Keep The Fire', b'Robbie Dupree', b'Minute By Minute',\n",
      "   b'What Were Once Vices Are Now Habits', b\"If That's What It Takes\",\n",
      "   b'Christopher Cross', b'Player', b'Toto IV', b'One Eighty',\n",
      "   b\"Seals & Crofts' Greatest Hits\", b'Nights Are Forever',\n",
      "   b'Five-A-Side', b'City To City', b'Christopher Cross',\n",
      "   b'Looking Glass', b'Dance With Me: The Best Of Orleans',\n",
      "   b'The Original Soundtrack', b'Daryl Hall & John Oates',\n",
      "   b'Partners In Crime', b'Worlds Away',\n",
      "   b\"Seals & Crofts' Greatest Hits\", b'Abandoned Luncheonette',\n",
      "   b'The Dream Weaver', b'Deceptive Bends', b'Hearts',\n",
      "   b'Bread On The Waters', b'Nightwatch',\n",
      "   b'Singer of Songs, Teller of Tales', b'Firefall', b'Legend',\n",
      "   b'The Essential Playlist', b'Phoenix', b'Thunder Island',\n",
      "   b'If You Could Read My Mind', b\"Struttin' My Stuff\",\n",
      "   b'Starland Vocal Band', b'First Under The Wire', b'Goodbye Girl',\n",
      "   b'Street Talk', b'Mixed Emotions', b\"Seals & Crofts' Greatest Hits\",\n",
      "   b'Sweet Baby James', b'Back to Front', b'Dr. Heckle & Mr. Jive',\n",
      "   b'JT', b'Fleetwood Mac', b'Toto', b'Waking & Dreaming',\n",
      "   b'City To City', b'Nights Are Forever']]]>, 'artist_genres_pl': <tf.RaggedTensor [[[b\"'album rock', 'classic rock', 'mellow gold', 'new wave pop', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'art rock', 'blues rock', 'classic rock', 'country rock', 'folk rock', 'hard rock', 'heartland rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'art rock', 'blues rock', 'classic rock', 'country rock', 'folk rock', 'hard rock', 'heartland rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'mellow gold', 'quiet storm', 'soft rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'album rock', 'disco', 'folk rock', 'mellow gold', 'new wave pop', 'quiet storm', 'soft rock', 'yacht rock'\",\n",
      "   b\"'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'classic rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'album rock', 'art rock', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'symphonic rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'album rock', 'bubblegum pop', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'yacht rock'\", b\"'classic uk pop'\",\n",
      "   b\"'album rock', 'art rock', 'classic rock', 'classic uk pop', 'country rock', 'folk rock', 'mellow gold', 'soft rock'\",\n",
      "   b\"'adult standards', 'album rock', 'disco', 'folk rock', 'mellow gold', 'new wave pop', 'quiet storm', 'soft rock', 'yacht rock'\",\n",
      "   b\"'soft rock', 'sunshine pop'\",\n",
      "   b\"'bubblegum pop', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'art rock', 'classic rock', 'classic uk pop', 'folk rock', 'glam rock', 'mellow gold', 'rock', 'soft rock', 'symphonic rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'classic rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'soft rock', 'yacht rock'\",\n",
      "   b\"'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'album rock', 'bubblegum pop', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'classic rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'classic rock', 'country rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'art rock', 'classic rock', 'classic uk pop', 'folk rock', 'glam rock', 'mellow gold', 'rock', 'soft rock', 'symphonic rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'art rock', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'rock', 'soft rock'\",\n",
      "   b\"'adult standards', 'folk rock', 'mellow gold', 'soft rock'\",\n",
      "   b\"'album rock', 'classic rock', 'mellow gold', 'new wave pop', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'bubblegum pop', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'bubblegum pop', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock'\",\n",
      "   b\"'album rock', 'classic rock', 'classic uk pop', 'country rock', 'folk', 'folk rock', 'heartland rock', 'mellow gold', 'roots rock', 'singer-songwriter', 'soft rock'\",\n",
      "   b\"'soft rock'\",\n",
      "   b\"'adult standards', 'classic rock', 'country rock', 'folk', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'yacht rock'\",\n",
      "   b\"'album rock', 'canadian country', 'canadian singer-songwriter', 'classic rock', 'country rock', 'folk', 'folk rock', 'mellow gold', 'rock', 'roots rock', 'singer-songwriter', 'soft rock'\",\n",
      "   b\"'blues rock', 'classic rock', 'country rock', 'electric blues', 'southern rock'\",\n",
      "   b\"'soft rock'\",\n",
      "   b\"'album rock', 'art rock', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'classic uk pop', 'mellow gold', 'soft rock'\",\n",
      "   b\"'album rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'yacht rock'\",\n",
      "   b\"'adult standards', 'album rock', 'bubblegum pop', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'adult standards', 'classic rock', 'folk', 'folk rock', 'mellow gold', 'rock', 'singer-songwriter', 'soft rock'\",\n",
      "   b\"'adult standards', 'brill building pop', 'classic rock', 'classic uk pop', 'folk rock', 'mellow gold', 'soft rock'\",\n",
      "   b\"'yacht rock'\",\n",
      "   b\"'adult standards', 'classic rock', 'folk', 'folk rock', 'mellow gold', 'rock', 'singer-songwriter', 'soft rock'\",\n",
      "   b\"'album rock', 'classic rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'classic rock', 'mellow gold', 'rock', 'soft rock', 'yacht rock'\",\n",
      "   b\"'bubblegum pop', 'classic rock', 'country rock', 'folk rock', 'mellow gold', 'soft rock', 'yacht rock'\",\n",
      "   b\"'album rock', 'art rock', 'classic rock', 'classic uk pop', 'country rock', 'folk rock', 'mellow gold', 'soft rock'\",\n",
      "   b\"'yacht rock'\"]]]>, 'artist_name_pl': <tf.RaggedTensor [[[b'Kenny Loggins', b'Robbie Dupree', b'The Doobie Brothers',\n",
      "   b'The Doobie Brothers', b'Michael McDonald', b'Christopher Cross',\n",
      "   b'Player', b'Toto', b'Ambrosia', b'Seals and Crofts',\n",
      "   b'England Dan Seals', b'Ace', b'Gerry Rafferty', b'Christopher Cross',\n",
      "   b'Looking Glass', b'Orleans', b'10cc', b'Daryl Hall & John Oates',\n",
      "   b'Rupert Holmes', b'Pablo Cruise', b'Seals and Crofts',\n",
      "   b'Daryl Hall & John Oates', b'Gary Wright', b'10cc', b'America',\n",
      "   b'Bread', b'Kenny Loggins', b'Paul Davis', b'Firefall', b'Poco',\n",
      "   b'Bertie Higgins', b'Dan Fogelberg', b'Jay Ferguson',\n",
      "   b'Gordon Lightfoot', b'Elvin Bishop', b'Starland Vocal Band',\n",
      "   b'Little River Band', b'David Gates', b'Steve Perry', b'Exile',\n",
      "   b'Seals and Crofts', b'James Taylor', b\"Gilbert O'Sullivan\",\n",
      "   b'England Dan', b'James Taylor', b'Fleetwood Mac', b'Toto',\n",
      "   b'Orleans', b'Gerry Rafferty', b'England Dan Seals']]]>, 'artist_pop_pl': <tf.RaggedTensor [[[69.0, 48.0, 70.0, 70.0, 60.0, 66.0, 58.0, 75.0, 56.0, 59.0, 25.0,\n",
      "   48.0, 67.0, 66.0, 60.0, 57.0, 64.0, 74.0, 62.0, 45.0, 59.0, 74.0,\n",
      "   49.0, 64.0, 69.0, 67.0, 69.0, 49.0, 48.0, 51.0, 46.0, 58.0, 41.0,\n",
      "   64.0, 53.0, 48.0, 64.0, 49.0, 57.0, 48.0, 59.0, 71.0, 60.0, 25.0,\n",
      "   71.0, 83.0, 75.0, 57.0, 67.0, 25.0]]]>, 'artists_followers_pl': <tf.RaggedTensor [[[819212.0, 41296.0, 1864729.0, 1864729.0, 382466.0, 737191.0, 98426.0,\n",
      "   2205253.0, 286184.0, 541811.0, 0.0, 9535.0, 249174.0, 737191.0,\n",
      "   62771.0, 125774.0, 545731.0, 1746472.0, 70108.0, 120132.0, 541811.0,\n",
      "   1746472.0, 112136.0, 545731.0, 1325511.0, 1190961.0, 819212.0,\n",
      "   103423.0, 160239.0, 189459.0, 14190.0, 577466.0, 5167.0, 605181.0,\n",
      "   76296.0, 9736.0, 883587.0, 138321.0, 467812.0, 14348.0, 541811.0,\n",
      "   1962327.0, 267784.0, 63018.0, 1962327.0, 8006117.0, 2205253.0,\n",
      "   125774.0, 249174.0, 0.0]]]>, 'duration_ms_songs_pl': <tf.RaggedTensor [[[236733.0, 206733.0, 223866.0, 255266.0, 222280.0, 256146.0, 253204.0,\n",
      "   331200.0, 324040.0, 203966.0, 159106.0, 204226.0, 365626.0, 275506.0,\n",
      "   186946.0, 180479.0, 366640.0, 185293.0, 276493.0, 251426.0, 247813.0,\n",
      "   313373.0, 256173.0, 209266.0, 199573.0, 192200.0, 237826.0, 233893.0,\n",
      "   164440.0, 176800.0, 198946.0, 195066.0, 240693.0, 228840.0, 276000.0,\n",
      "   193040.0, 313320.0, 168866.0, 218066.0, 296826.0, 254253.0, 200579.0,\n",
      "   217728.0, 284720.0, 165400.0, 252773.0, 235800.0, 234040.0, 267773.0,\n",
      "   170920.0]]]>, 'track_name_pl': <tf.RaggedTensor [[[b'This Is It', b'Steal Away', b'What A Fool Believes', b'Black Water',\n",
      "   b\"I Keep Forgettin' (Every Time You're Near)\", b'Sailing',\n",
      "   b'Baby Come Back', b'Rosanna', b'Biggest Part Of Me',\n",
      "   b'Summer Breeze', b\"I'd Really Love To See You Tonight\", b'How Long',\n",
      "   b'Baker Street', b'Ride Like The Wind',\n",
      "   b\"Brandy (You're A Fine Girl)\", b'Dance With Me', b\"I'm Not In Love\",\n",
      "   b'Sara Smile', b'Escape (The Pina Colada Song)',\n",
      "   b'Love Will Find A Way', b'Diamond Girl', b\"She's Gone\",\n",
      "   b'Dream Weaver', b'The Things We Do For Love', b'Sister Golden Hair',\n",
      "   b'Make It With You', b'Whenever I Call You \"Friend\"', b'I Go Crazy',\n",
      "   b'You Are The Woman', b'Crazy Love', b'Key Largo', b'Longer',\n",
      "   b'Thunder Island', b'If You Could Read My Mind',\n",
      "   b'Fooled Around And Fell In Love', b'Afternoon Delight',\n",
      "   b'Cool Change - 2010 Digital Remaster', b'Goodbye Girl',\n",
      "   b'Foolish Heart', b'Kiss You All Over',\n",
      "   b'We May Never Pass This Way - Again', b'Fire And Rain',\n",
      "   b'Alone Again (Naturally)', b'Love Is The Answer',\n",
      "   b'Your Smiling Face', b'Rhiannon', b'Hold the Line', b'Still The One',\n",
      "   b'Right Down The Line', b'Nights Are Forever Without You']]]>, 'track_pop_pl': <tf.RaggedTensor [[[59.0, 56.0, 73.0, 65.0, 68.0, 73.0, 0.0, 75.0, 67.0, 68.0, 70.0, 65.0,\n",
      "   72.0, 69.0, 77.0, 63.0, 0.0, 70.0, 77.0, 59.0, 43.0, 68.0, 63.0, 0.0,\n",
      "   72.0, 69.0, 59.0, 59.0, 59.0, 61.0, 59.0, 66.0, 58.0, 69.0, 64.0, 0.0,\n",
      "   68.0, 64.0, 0.0, 47.0, 51.0, 3.0, 72.0, 55.0, 65.0, 75.0, 81.0, 69.0,\n",
      "   82.0, 54.0]]]>})\n"
     ]
    }
   ],
   "source": [
    "for _ in parsed_dataset.batch(1).take(1):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3151a0-24ab-45fe-bd68-96f84401e042",
   "metadata": {},
   "source": [
    "## Train (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae847534-1357-4313-8b96-c9756644e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(ln):\n",
    "    q_ln = ln['query'] #grabs the query stuff in the json\n",
    "    c_ln = ln['candidate']\n",
    "    \n",
    "    # ===============================\n",
    "    # Ragged Features - Query\n",
    "    # ===============================\n",
    "    ragged_key_list = [\n",
    "        'track_name_pl',\n",
    "        'artist_name_pl',\n",
    "        'album_name_pl',\n",
    "        # 'track_uri_pl',\n",
    "        'duration_ms_songs_pl',\n",
    "        'artist_pop_pl',\n",
    "        'artists_followers_pl',\n",
    "        'track_pop_pl',\n",
    "        'artist_genres_pl',\n",
    "    ]\n",
    "    \n",
    "    ragged_dict = {}\n",
    "    \n",
    "    for _ in ragged_key_list:\n",
    "        ragged_dict[_] = []\n",
    "        \n",
    "    for x in q_ln['track_name_pl']:\n",
    "        ragged_dict['track_name_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    for x in q_ln['artist_name_pl']:\n",
    "        ragged_dict['artist_name_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    for x in q_ln['album_name_pl']:\n",
    "        ragged_dict['album_name_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    # for x in q_ln['track_uri_pl']:\n",
    "    #     ragged_dict['track_uri_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    for x in q_ln['duration_ms_songs_pl']:\n",
    "        ragged_dict['duration_ms_songs_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['artist_pop_pl']:\n",
    "        ragged_dict['artist_pop_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['artists_followers_pl']:\n",
    "        ragged_dict['artists_followers_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['track_pop_pl']:\n",
    "        ragged_dict['track_pop_pl'].append(x)\n",
    "        \n",
    "    for x in q_ln['artist_genres_pl']:\n",
    "        ragged_dict['artist_genres_pl'].append(x.encode('utf8'))\n",
    "        \n",
    "    # Set List Types\n",
    "    # Bytes\n",
    "    track_name_pl = BytesList(value=ragged_dict['track_name_pl'])\n",
    "    artist_name_pl = BytesList(value=ragged_dict['artist_name_pl'])\n",
    "    album_name_pl = BytesList(value=ragged_dict['album_name_pl'])\n",
    "    # track_uri_pl = BytesList(value=ragged_dict['track_uri_pl'])\n",
    "    artist_genres_pl = BytesList(value=ragged_dict['artist_genres_pl'])\n",
    "    \n",
    "    # Float List\n",
    "    duration_ms_songs_pl = FloatList(value=ragged_dict['duration_ms_songs_pl'])\n",
    "    artist_pop_pl = FloatList(value=ragged_dict['artist_pop_pl'])\n",
    "    artists_followers_pl = FloatList(value=ragged_dict['artists_followers_pl'])\n",
    "    track_pop_pl = FloatList(value=ragged_dict['track_pop_pl'])\n",
    "    \n",
    "    # Set FeatureLists\n",
    "    # Bytes\n",
    "    track_name_pl = FeatureList(feature=[Feature(bytes_list=track_name_pl)])\n",
    "    artist_name_pl = FeatureList(feature=[Feature(bytes_list=artist_name_pl)])\n",
    "    album_name_pl = FeatureList(feature=[Feature(bytes_list=album_name_pl)])\n",
    "    # track_uri_pl = FeatureList(feature=[Feature(bytes_list=track_uri_pl)])\n",
    "    artist_genres_pl = FeatureList(feature=[Feature(bytes_list=artist_genres_pl)])\n",
    "    \n",
    "    # Float Lists\n",
    "    duration_ms_songs_pl = FeatureList(feature=[Feature(float_list=duration_ms_songs_pl)])\n",
    "    artist_pop_pl = FeatureList(feature=[Feature(float_list=artist_pop_pl)])\n",
    "    artists_followers_pl = FeatureList(feature=[Feature(float_list=artists_followers_pl)])\n",
    "    track_pop_pl = FeatureList(feature=[Feature(float_list=track_pop_pl)])\n",
    "    \n",
    "    # ===============================\n",
    "    # Create Context Features\n",
    "    # ===============================\n",
    "    context_features = {\n",
    "        # playlist - context features\n",
    "        \"name\": string_array(q_ln['name']),\n",
    "        'collaborative' : string_array(q_ln['collaborative']),\n",
    "        # 'duration_ms_seed_pl' : float_feature(q_ln['duration_ms_seed_pl']),\n",
    "        'n_songs_pl' : float_feature(q_ln['n_songs_pl']),\n",
    "        'num_artists_pl' : float_feature(q_ln['num_artists_pl']),\n",
    "        'num_albums_pl' : float_feature(q_ln['num_albums_pl']),\n",
    "        'description_pl' : string_array(q_ln['description_pl']),\n",
    "        \n",
    "        # seed track - context features\n",
    "        'track_name_seed_track' : string_array(q_ln['track_name_seed_track']),\n",
    "        'artist_name_seed_track' : string_array(q_ln['artist_name_seed_track']),\n",
    "        'album_name_seed_track' : string_array(q_ln['album_name_seed_track']),\n",
    "        # 'track_uri_seed_track' : string_array(q_ln['track_uri_seed_track']),\n",
    "        # 'artist_uri_seed_track' : string_array(q_ln['artist_uri_seed_track']),\n",
    "        # 'album_uri_seed_track' : string_array(q_ln['album_uri_seed_track']),\n",
    "        'duration_seed_track' : float_feature(q_ln['duration_seed_track']),\n",
    "        'track_pop_seed_track' : float_feature(q_ln['track_pop_seed_track']),\n",
    "        'artist_pop_seed_track' : float_feature(q_ln['artist_pop_seed_track']),\n",
    "        'artist_genres_seed_track' : string_array(q_ln['artist_genres_seed_track']),\n",
    "        'artist_followers_seed_track' : float_feature(q_ln['artist_followers_seed_track']),\n",
    "        \n",
    "        #candidate features\n",
    "        \"track_name_can\": string_array(c_ln['track_name_can']), \n",
    "        \"artist_name_can\": string_array(c_ln['artist_name_can']),\n",
    "        \"album_name_can\": string_array(c_ln['album_name_can']),\n",
    "        \"track_uri_can\": string_array(c_ln['track_uri_can']),\n",
    "        # \"artist_uri_can\": string_array(c_ln['artist_uri_can']),\n",
    "        # \"album_uri_can\": string_array(c_ln['album_uri_can']),\n",
    "        \"duration_ms_can\": float_feature(c_ln['duration_ms_can']),\n",
    "        \"track_pop_can\": float_feature(c_ln['track_pop_can']), \n",
    "        \"artist_pop_can\": float_feature(c_ln['artist_pop_can']),\n",
    "        \"artist_genres_can\": string_array(c_ln['artist_genres_can']),\n",
    "        \"artist_followers_can\": float_feature(c_ln['artist_followers_can']),\n",
    "    }\n",
    "    \n",
    "    # ===============================\n",
    "    # Create Sequence\n",
    "    # ===============================\n",
    "    seq = SequenceExample(\n",
    "        context=tf.train.Features(\n",
    "            feature=context_features\n",
    "        ),\n",
    "        feature_lists=FeatureLists(\n",
    "            feature_list={\n",
    "                \"track_name_pl\": track_name_pl,\n",
    "                \"artist_name_pl\": artist_name_pl,\n",
    "                \"album_name_pl\": album_name_pl,\n",
    "                # \"track_uri_pl\": track_uri_pl,\n",
    "                \"duration_ms_songs_pl\": duration_ms_songs_pl,\n",
    "                \"artist_pop_pl\": artist_pop_pl,\n",
    "                \"artists_followers_pl\": artists_followers_pl,\n",
    "                \"track_pop_pl\": track_pop_pl,\n",
    "                \"artist_genres_pl\": artist_genres_pl\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4e1e2-6b3c-428f-acbf-d3cb70c3a493",
   "metadata": {},
   "source": [
    "### Configure record count\n",
    "\n",
    "* original jsonl files have ~`13297` samples per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76b62930-93f8-4b97-b34c-75798fcd8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'gs://spotify-builtin-2t'\n",
    "SCHEMA_JSON = f'{BUCKET}/schema.json' # schema_small.json\n",
    "TRAIN_JSON = f'{BUCKET}/train_data/*.jsonl' # 000000000000.jsonl\n",
    "TRAIN_SAMPLE_FILE = 'gs://spotify-builtin-2t/train_data/000000000001.jsonl'\n",
    "# spotify-builtin-2t/candidate_songs\n",
    "\n",
    "TF_RECORDS_DIR = 'gs://spotify-tfrecords-blog/train_v2'\n",
    "\n",
    "BUCKET_NAME_TRAIN='spotify-builtin-2t'\n",
    "OBJ_PATH_TRAIN='train_data'\n",
    "\n",
    "files = []\n",
    "\n",
    "for blob in client.list_blobs(f'{BUCKET_NAME_TRAIN}', prefix=f'{OBJ_PATH_TRAIN}/', delimiter='/'):\n",
    "    files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53df439c-cf2a-4520-87cf-ecd12964be2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4746/3243024298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Calculate records per file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4746/3243024298.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Calculate records per file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;34mr\"\"\"Reads the next line, keeping \\n. At EOF, returns ''.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_samples = 0\n",
    "# num_samples = 0\n",
    "\n",
    "for file in files:\n",
    "    num_samples = 0\n",
    "    # Calculate records per file\n",
    "    num_samples = sum(1 for _ in file_io.FileIO(file, 'rb'))\n",
    "    total_samples = total_samples+num_samples\n",
    "\n",
    "print(\"Total number of samples: {}\".format(total_samples))\n",
    "\n",
    "samples_per_file = 12228\n",
    "\n",
    "num_tfrecords = total_samples // samples_per_file \n",
    "\n",
    "if num_records % total_samples:\n",
    "    num_tfrecords += 1\n",
    "\n",
    "print(\"Number of Expected TFRecords: {}\".format(num_tfrecords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "026504be-1ce4-48e3-9a43-f1426d7d5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 total:1\n",
      "Loop 2 total:3\n",
      "Loop 3 total:6\n",
      "Loop 4 total:10\n",
      "Loop 5 total:15\n",
      "Loop 6 total:21\n",
      "Loop 7 total:28\n"
     ]
    }
   ],
   "source": [
    "# total = 0\n",
    "# num_list = [1,2,3,4,5,6,7]\n",
    "\n",
    "# for num in num_list:\n",
    "#     total = total+num\n",
    "#     print(f'Loop {num} total:{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca9d4d-f573-4cd3-9d4c-ff6196ad8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick function to write the data as we read through it\n",
    "def write_a_tfrec(lns):\n",
    "    #next write to a tfrecord\n",
    "    with tf.io.TFRecordWriter(\n",
    "        GCS_DESTINATION + \"/spotify-%.6i-%i.tfrec\" % (tfrec_counter, len(lns))\n",
    "    ) as writer:\n",
    "        for ln in lns:\n",
    "            example = parse_line(ln)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "for file in files:\n",
    "    with file_io.FileIO(file, 'r') as reader:\n",
    "        for line in tqdm(reader):\n",
    "            record_counter += 1\n",
    "            if record_counter % num_samples == 0 or record_counter == num_records: \n",
    "                write_a_tfrec(lns) #write out a batch\n",
    "                lns = [] #reset to a new batch\n",
    "                tfrec_counter += 1\n",
    "            else:\n",
    "                lns.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66556afa-b4f0-4ce8-a074-f2fdee1cf6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185d9e2-024f-42ef-b963-7aecd3f9629a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275833c7-81c6-44be-8c57-5da3dd82e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d64dca7-e0ad-4860-a72f-d5d836b737da",
   "metadata": {},
   "source": [
    "## Candidate DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4202a8e9-fe8a-4b53-8a9a-2066fcde96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(ln):\n",
    "    c_ln = ln['candidate']\n",
    "\n",
    "    # ===============================\n",
    "    # Create Context Features\n",
    "    # ===============================\n",
    "    context_features = { \n",
    "        #candidate features\n",
    "        \"track_name_can\": string_array(c_ln['track_name_can']), \n",
    "        \"artist_name_can\": string_array(c_ln['artist_name_can']),\n",
    "        \"album_name_can\": string_array(c_ln['album_name_can']),\n",
    "        \"track_uri_can\": string_array(c_ln['track_uri_can']),\n",
    "        # \"artist_uri_can\": string_array(c_ln['artist_uri_can']),\n",
    "        # \"album_uri_can\": string_array(c_ln['album_uri_can']),\n",
    "        \"duration_ms_can\": float_feature(c_ln['duration_ms_can']),\n",
    "        \"track_pop_can\": float_feature(c_ln['track_pop_can']), \n",
    "        \"artist_pop_can\": float_feature(c_ln['artist_pop_can']),\n",
    "        \"artist_genres_can\": string_array(c_ln['artist_genres_can']),\n",
    "        \"artist_followers_can\": float_feature(c_ln['artist_followers_can']),\n",
    "    }\n",
    "    \n",
    "    ex = Example(\n",
    "        features=tf.train.Features(\n",
    "            feature=context_features\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "489bc7cf-4b02-402b-a08a-7d48dadf53b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://spotify-builtin-2t/candidate_songs/000000000000.jsonl',\n",
       " 'gs://spotify-builtin-2t/candidate_songs/000000000001.jsonl',\n",
       " 'gs://spotify-builtin-2t/candidate_songs/000000000002.jsonl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_NAME_TRAIN='spotify-builtin-2t'\n",
    "OBJ_PATH_TRAIN='candidate_songs'\n",
    "\n",
    "files = []\n",
    "\n",
    "for blob in client.list_blobs(f'{BUCKET_NAME_TRAIN}', prefix=f'{OBJ_PATH_TRAIN}/', delimiter='/'):\n",
    "    files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8242698b-67d4-48fb-aa4b-45f758e5ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "748949it [01:41, 7408.34it/s] \n",
      "750354it [01:39, 7524.24it/s] \n",
      "750258it [01:38, 7652.32it/s] \n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'gs://spotify-builtin-2t'\n",
    "candidate_files = f'{BUCKET}/candidate_songs/*.jsonl' # TRAIN_JSON\n",
    "\n",
    "GCS_DESTINATION = 'gs://spotify-tfrecords-blog/candidate_tracks_v2'\n",
    "\n",
    "record_counter = 0\n",
    "lns = [] \n",
    "tfrec_counter = 0\n",
    "\n",
    "# quick function to write the data as we read through it\n",
    "def write_a_tfrec(lns):\n",
    "    #next write to a tfrecord\n",
    "    with tf.io.TFRecordWriter(\n",
    "        GCS_DESTINATION + \"/spotify_%.6i-%i.tfrec\" % (tfrec_counter, len(lns))\n",
    "    ) as writer:\n",
    "        for ln in lns:\n",
    "            example = parse_line(ln)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "for file in files:\n",
    "    with file_io.FileIO(file, 'r') as reader:\n",
    "        for line in tqdm(reader):\n",
    "            record_counter += 1\n",
    "            if record_counter % num_samples == 0 or record_counter == num_records: \n",
    "                write_a_tfrec(lns) #write out a batch\n",
    "                lns = [] #reset to a new batch\n",
    "                tfrec_counter += 1\n",
    "            else:\n",
    "                lns.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d97b47-6c4b-46ab-879e-fa3544eb26be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confirm - read records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e183a44-af89-4744-b792-8ac257d9e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "context_features = {\n",
    "    #candidate features\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=(1)),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),\n",
    "}\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=context_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "train_files= []\n",
    "\n",
    "BUCKET_NAME_TRAIN = 'spotify-tfrecords-blog'\n",
    "OBJ_PATH_TRAIN = 'candidate_tracks_v2'\n",
    "# file = 'gs://spotify-tfrecords-blog/candidate_tracks/spotify_000100-12227.tfrec'\n",
    "\n",
    "for blob in client.list_blobs(f'{BUCKET_NAME_TRAIN}', prefix=f'{OBJ_PATH_TRAIN}/', delimiter='/'):\n",
    "    train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "raw_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "parsed_dataset = raw_dataset.map(\n",
    "        parse_tfrecord_fn,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "949f2a19-40ff-42c2-b7ce-60d8c66ea15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2237540>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = parsed_dataset.reduce(np.int64(0), lambda x, _: x + 1)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c98bd72e-4b04-4720-b2b8-964f518154ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in parsed_dataset.batch(35).take(1):\n",
    "#     print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d6a4f-d7f0-4fbf-aa84-ff623388a57c",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cea681cd-775f-4a4d-bda3-21740249fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://spotify-builtin-2t/schema.json...\n",
      "/ [1 files][  1.6 KiB/  1.6 KiB]                                                \n",
      "Operation completed over 1 objects/1.6 KiB.                                      \n",
      "Copying gs://spotify-builtin-2t/schema_small.json...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# !gsutil cp gs://spotify-builtin-2t/train_data/000000000000.jsonl train_test.jsonl\n",
    "# !gsutil cp gs://spotify-builtin-2t/candidate_songs/000000000000.jsonl candidate_test.jsonl\n",
    "\n",
    "# !gsutil cp gs://spotify-builtin-2t/schema.json .\n",
    "# !gsutil cp gs://spotify-builtin-2t/schema_small.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e269c-32bb-4371-8bac-a0cd857314d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_SCHEMA_JSON = f'{BUCKET}/schema_small.json'\n",
    "# small_TRAIN_JSON = f'{BUCKET}/train_data_small/000000000000.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c947dfb-401a-4de2-8f35-e0518f44b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_files = ['gs://limestone-recsys/tf-record-all-features/2022-05-05174504/file_00-12227.tfrec']\n",
    "\n",
    "# sequence_features_ = {\n",
    "#      \"last_viewed\": tf.io.RaggedFeature(tf.string),\n",
    "#        \"productTypeCombo_ss\": tf.io.RaggedFeature(tf.string),\n",
    "#        \"Searchable_t\": tf.io.RaggedFeature(tf.string),\n",
    "#        \"spellcheck\": tf.io.RaggedFeature(tf.string)\n",
    "# }\n",
    "\n",
    "# context_features_ = {\n",
    "#         \"query\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"IVM_s\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"description\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"total_ratings_i\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)), \n",
    "#         \"overall_ratings\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)), \n",
    "#         \"avg_rating_td\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)), \n",
    "#         \"parent_description\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"Brand_s\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"item_type\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"prc_rdc_amt\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)), \n",
    "#         \"quantity_sold\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)), \n",
    "#         \"sales_dollar_f\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)),  \n",
    "#         \"freight_term\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"is_energy_star_s\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"price_td\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(1)), \n",
    "#         \"PriceRange_s\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"clean_Brand_s\": tf.io.FixedLenFeature(dtype=tf.string, shape=(1)), \n",
    "#         \"visual\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(2048)), \n",
    "#         \"month\": tf.io.FixedLenFeature(dtype=tf.int64, shape=(1)),\n",
    "#         \"hour\": tf.io.FixedLenFeature(dtype=tf.int64, shape=(1))\n",
    "#     }\n",
    "\n",
    "# def parse_tfrecord_fn(example):\n",
    "#     example = tf.io.parse_single_sequence_example(example, sequence_features=sequence_features_, context_features=context_features_)\n",
    "#     return example\n",
    "\n",
    "# raw_test_ds = tf.data.TFRecordDataset(test_files)\n",
    "\n",
    "# options = tf.data.Options()\n",
    "# options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "# parsed_test_ds = raw_test_ds.map(\n",
    "#         parse_tfrecord_fn,\n",
    "#         num_parallel_calls=tf.data.AUTOTUNE).with_options(options)\n",
    "\n",
    "# def return_tensors(context, sequence):\n",
    "#         a = sequence['productTypeCombo_ss'].to_tensor(default_value='', shape=[None, 8])\n",
    "#         b = sequence['last_viewed'].to_tensor(default_value='', shape=[None, 3])\n",
    "#         context2 = context.copy()\n",
    "#         context2['productTypeCombo_ss'] = a\n",
    "#         context2['last_viewed'] = b\n",
    "#         return context2\n",
    "    \n",
    "# parsed_test_ds_2 = parsed_test_ds.map(return_tensors, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# for _ in parsed_test_ds_2.batch(1).take(1):\n",
    "#     print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ae75f-ae11-495f-acaa-9b49f40c73e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in parsed_test_ds.batch(1).take(1):\n",
    "    # print(_)\n",
    "    \n",
    "for raw_record in raw_test_ds.take(5):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
