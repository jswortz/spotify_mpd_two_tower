{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `two_tower_src/` for the source code and model code\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n",
    "\n",
    "We will use managed Tensorboard for training. Before beginning, create a new tensorboard instance by going to Vertex -> Experiments -> Tensorboard Instances -> Create\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders google-cloud-aiplatform --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "#### Restart kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex' \n",
    "LOCATION = 'us-central1' \n",
    "path = 'gs://jt-tfrs-central' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from src.two_tower_jt import two_tower_lite as tt\n",
    "#inside this tt module the data parsing functions, candidate dataset and model classes are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34msrc/two_tower_jt\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   ├── train_config.cpython-37.pyc\n",
      "│   ├── two_tower.cpython-37.pyc\n",
      "│   └── two_tower_lite.cpython-37.pyc\n",
      "├── data-pipeline.py\n",
      "├── interactive_train.py\n",
      "├── requirements.txt\n",
      "├── task.py\n",
      "├── train_config.py\n",
      "├── two_tower.py\n",
      "└── two_tower_lite.py\n",
      "\n",
      "1 directory, 12 files\n"
     ]
    }
   ],
   "source": [
    "!tree src/two_tower_jt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d8dc5-a796-4295-a1da-5474827ef859",
   "metadata": {},
   "source": [
    "## Create Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c26cf3b-6f23-476f-9806-27dd9697d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "\n",
    "batch_size = 1024 #*16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df741a-fbb5-416d-97db-b952f703e6de",
   "metadata": {},
   "source": [
    "### Option 1: outer paralellism\n",
    "\n",
    "* parallelize transforms\n",
    "* run multiple copies of the input pipeline over sharded inputs and combine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fc839d-81c1-41d0-929d-4f70e4f45264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path='gs://spotify-data-regimes/jtv10/valid_v9/*.tfrecords'\n",
    "\n",
    "# filenames = tf.data.Dataset.list_files(file_path, shuffle=None)\n",
    "# filenames.cache()\n",
    "\n",
    "# NUM_SHARDS=2\n",
    "\n",
    "# def make_dataset(shard_index):\n",
    "#     files = filenames.shard(NUM_SHARDS, shard_index)\n",
    "#     dataset = tf.data.TFRecordDataset(files)\n",
    "#     return dataset.batch(batch_size)\n",
    "\n",
    "# indices = tf.data.Dataset.range(NUM_SHARDS)\n",
    "\n",
    "# train_dataset = indices.interleave(\n",
    "#     make_dataset,\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE\n",
    "# ).map(\n",
    "#     tt.parse_tfrecord, \n",
    "#     num_parallel_calls=tf.data.AUTOTUNE\n",
    "# ).repeat(\n",
    "#     args.num_epochs\n",
    "# ).prefetch(\n",
    "#     tf.data.AUTOTUNE\n",
    "# ).with_options(\n",
    "#     options\n",
    "# )\n",
    "# # train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1aef5f7-9c8b-4166-98fb-aa812f54910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'gs://spotify-data-regimes/jtv10/valid_v9/-00000-of-00006.tfrecords', shape=(), dtype=string)\n",
      "tf.Tensor(b'gs://spotify-data-regimes/jtv10/valid_v9/-00005-of-00006.tfrecords', shape=(), dtype=string)\n",
      "tf.Tensor(b'gs://spotify-data-regimes/jtv10/valid_v9/-00004-of-00006.tfrecords', shape=(), dtype=string)\n",
      "tf.Tensor(b'gs://spotify-data-regimes/jtv10/valid_v9/-00002-of-00006.tfrecords', shape=(), dtype=string)\n",
      "tf.Tensor(b'gs://spotify-data-regimes/jtv10/valid_v9/-00003-of-00006.tfrecords', shape=(), dtype=string)\n",
      "tf.Tensor(b'gs://spotify-data-regimes/jtv10/valid_v9/-00001-of-00006.tfrecords', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# for file in filenames:\n",
    "#     print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6827209-b916-4291-8f56-6afdb33c26ee",
   "metadata": {},
   "source": [
    "### Option 2: interleave --> map --> batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'spotify-data-regimes'\n",
    "train_dir_prefix = 'jtv10/valid_v9' # valid_v9 | train_v9\n",
    "\n",
    "train_files = []\n",
    "for blob in storage_client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(\n",
    "    tt.parse_tfrecord, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5118021e-5bef-4a41-8894-19d939e8abad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_uri_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'spotify:album:0Jy2FoyFXxrHi6XIa8cHzU',\n",
      "        b'spotify:album:0jAuXoXXgM4EjiRBEMHFav',\n",
      "        b'spotify:album:1lAMkHFW0e51taMt34LUQ2', ...,\n",
      "        b'spotify:album:6rg15XPgPhunxqpsUxmbfM',\n",
      "        b'spotify:album:2E5QEP74QC8pJachhCViSZ',\n",
      "        b'spotify:album:5jkFiJdMrdDxbhxCZ9hM5m']], dtype=object)>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'spotify:album:39Mc1rLpJeiG5BYuSOwGet',\n",
      "         b'spotify:album:2Z9WUERfMjOgQ6ze9TcGbF',\n",
      "         b'spotify:album:50wolXldayJCEtNKyzJERs',\n",
      "         b'spotify:album:0IuHVgAvbNDJnJepuSZ8Oz',\n",
      "         b'spotify:album:2dqn5yOQWdyGwOpOIi9O4x'],\n",
      "        [b'spotify:album:3IFuRY2wRpJa9FTXj4aTTB',\n",
      "         b'spotify:album:2oPdRL0fDdnW9e1zoMnrDk',\n",
      "         b'spotify:album:0jAuXoXXgM4EjiRBEMHFav',\n",
      "         b'spotify:album:0I8K07F4nXcRexkF6BrDN5',\n",
      "         b'spotify:album:0I8K07F4nXcRexkF6BrDN5'],\n",
      "        [b'spotify:album:0IuHVgAvbNDJnJepuSZ8Oz',\n",
      "         b'spotify:album:1azUkThwd2HfUDdeNeT147',\n",
      "         b'spotify:album:0kJbDT8VGMScK8YDzNNvzV',\n",
      "         b'spotify:album:6Q7yIbfFPzplTCBM7d1WRO',\n",
      "         b'spotify:album:7oiJYvEJHsmYtrgviAVIBD'],\n",
      "        ...,\n",
      "        [b'spotify:album:5X7llPMkpMaRuKsCtBO2zg',\n",
      "         b'spotify:album:5X7llPMkpMaRuKsCtBO2zg',\n",
      "         b'spotify:album:3B1IAkpY823egwq7AVTY25',\n",
      "         b'spotify:album:7783ykNzfJzUynGavNKYRo',\n",
      "         b'spotify:album:255CxlOCOqnkaUm1CWqmnj'],\n",
      "        [b'spotify:album:3oylWMc9TTC6Nx4I6U3axc',\n",
      "         b'spotify:album:4JPguzRps3kuWDD5GS6oXr',\n",
      "         b'spotify:album:71QyofYesSsRMwFOTafnhB',\n",
      "         b'spotify:album:7Bh5oQckPzHqO7GHVGY5LE',\n",
      "         b'spotify:album:47y3PbX8oIDCkYAFylCJz0'],\n",
      "        [b'spotify:album:68Rqd9Imx4ruxmzuZ9CyrW',\n",
      "         b'spotify:album:2dXioSzyYtobFIpmEwGOrg',\n",
      "         b'spotify:album:3RzBrW2M1bwids8ItBV7tl',\n",
      "         b'spotify:album:4uKFNr3KNqr4zeLWJfBC66',\n",
      "         b'spotify:album:2Kdc3Ye2lovbdzawshfF2K']]], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[    0.,     0.,     0., ...,  6157.,  4462., 59496.]],\n",
      "      dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b\"'detroit hip hop'\",\n",
      "        b\"'classic bollywood', 'desi pop', 'filmi', 'modern bollywood'\",\n",
      "        b\"'yacht rock'\", ..., b\"'praise'\", b\"'south african rock'\",\n",
      "        b\"'edm', 'pop dance', 'progressive house', 'progressive trance', 'russian trance', 'trance', 'uplifting trance'\"]],\n",
      "      dtype=object)>,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b\"'dance pop', 'post-teen pop', 'social media pop', 'viral pop'\",\n",
      "         b\"'acoustic pop', 'dance pop', 'hollywood', 'lilith', 'neo mellow', 'pop', 'pop rock'\",\n",
      "         b\"'pop'\", b\"'dance pop', 'pop', 'post-teen pop'\", b\"'pop'\"],\n",
      "        [b\"'desi pop', 'filmi', 'modern bollywood', 'sufi'\",\n",
      "         b\"'filmi', 'ghazal', 'tamil pop'\",\n",
      "         b\"'chutney', 'classic bollywood', 'desi pop', 'filmi', 'sufi'\",\n",
      "         b\"'chutney', 'classic bollywood', 'desi pop', 'filmi'\",\n",
      "         b\"'chutney', 'classic bollywood', 'desi pop', 'filmi'\"],\n",
      "        [b\"'dance pop', 'pop', 'post-teen pop'\",\n",
      "         b\"'british soul', 'pop', 'pop soul', 'uk pop'\",\n",
      "         b\"'dance pop', 'pop', 'uk pop'\",\n",
      "         b\"'dance pop', 'pop', 'post-teen pop'\",\n",
      "         b\"'pop', 'talent show', 'uk pop'\"],\n",
      "        ...,\n",
      "        [b\"'contemporary gospel', 'gospel'\",\n",
      "         b\"'contemporary gospel', 'gospel'\",\n",
      "         b\"'contemporary gospel', 'gospel'\", b\"'gospel', 'praise'\",\n",
      "         b\"'gospel', 'gospel r&b'\"],\n",
      "        [b\"'indie rock', 'indietronica', 'la indie', 'modern alternative rock', 'modern rock', 'pop rock', 'rock', 'stomp and holler'\",\n",
      "         b\"'dance pop', 'edm', 'electropop', 'pop', 'pop dance', 'tropical house'\",\n",
      "         b\"'chicago rap', 'conscious hip hop', 'hip hop', 'pop rap', 'rap'\",\n",
      "         b\"'art pop', 'dance pop', 'pop'\",\n",
      "         b\"'hip hop', 'ohio hip hop', 'rap'\"],\n",
      "        [b\"'dutch trance', 'edm', 'pop dance', 'progressive house', 'progressive trance', 'trance', 'uplifting trance'\",\n",
      "         b\"'dance pop', 'dutch edm', 'edm', 'pop', 'pop dance', 'progressive house', 'tropical house'\",\n",
      "         b\"'sky room'\",\n",
      "         b\"'canadian electronic', 'edm', 'electro house', 'pop dance', 'progressive house'\",\n",
      "         b\"'edm', 'german techno', 'german trance', 'pop dance', 'progressive house', 'progressive trance', 'trance', 'uplifting trance'\"]]],\n",
      "      dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[65., 67., 25., ..., 25., 31., 52.]], dtype=float32)>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[65., 71., 98., 86., 98.],\n",
      "        [75., 71., 69., 77., 77.],\n",
      "        [86., 91., 86., 74., 83.],\n",
      "        ...,\n",
      "        [44., 44., 43., 42., 49.],\n",
      "        [70., 85., 80., 87., 86.],\n",
      "        [58., 81., 38., 70., 58.]]], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'spotify:artist:1l7P8zlCKFbvOtUYYoJtoV',\n",
      "        b'spotify:artist:7kkSDNV8Q38QvQGBTaIxRn',\n",
      "        b'spotify:artist:1sFmYEcBTHjGELXH5vxSi9', ...,\n",
      "        b'spotify:artist:1zf8KLjJNFnIpMUavKJ1PI',\n",
      "        b'spotify:artist:7opSSXbFHlnoN8edZUv2YD',\n",
      "        b'spotify:artist:4zNhfG6i4QlfUuzt1hBGu2']], dtype=object)>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'spotify:artist:1KYszkVzlhV3rAqmAcYIgd',\n",
      "         b'spotify:artist:2Sqr0DXoaYABbjBo9HaMkM',\n",
      "         b'spotify:artist:06HL4z0CvFAxyc27GXpf02',\n",
      "         b'spotify:artist:5YGY8feqx7naU7z4HrwZM6',\n",
      "         b'spotify:artist:06HL4z0CvFAxyc27GXpf02'],\n",
      "        [b'spotify:artist:3eDT9fwXKuHWFvgZaaYC5v',\n",
      "         b'spotify:artist:2NoJ7NuNs9nyj8Thoh1kbu',\n",
      "         b'spotify:artist:5as8A4G47Ohu9NSWs3Je8U',\n",
      "         b'spotify:artist:70B80Lwx2sxti0M1Ng9e8K',\n",
      "         b'spotify:artist:70B80Lwx2sxti0M1Ng9e8K'],\n",
      "        [b'spotify:artist:5YGY8feqx7naU7z4HrwZM6',\n",
      "         b'spotify:artist:4dpARuHxo51G3z768sgnrY',\n",
      "         b'spotify:artist:2wY79sveU1sp5g7SokKOiI',\n",
      "         b'spotify:artist:1vSN1fsvrzpbttOYGsliDr',\n",
      "         b'spotify:artist:4IWBUUAFIplrNtaOHcJPRM'],\n",
      "        ...,\n",
      "        [b'spotify:artist:50DI0MpQBOtBO0PFtKVQRx',\n",
      "         b'spotify:artist:50DI0MpQBOtBO0PFtKVQRx',\n",
      "         b'spotify:artist:1bxsoj9E6Z2GoHVIswbRez',\n",
      "         b'spotify:artist:0kU5fC7WVwJlfd1eNj9cMn',\n",
      "         b'spotify:artist:0sD8Amms4kSxs5tBV4CUmR'],\n",
      "        [b'spotify:artist:3kVUvbeRdcrqQ3oHk5hPdx',\n",
      "         b'spotify:artist:69GGBxA162lTqCwzJG5jLp',\n",
      "         b'spotify:artist:1anyVhU62p31KFi8MEzkbf',\n",
      "         b'spotify:artist:1HY2Jd0NmPuamShAr6KMms',\n",
      "         b'spotify:artist:0fA0VVWsXO9YnASrzqfmYu'],\n",
      "        [b'spotify:artist:2ohlvFf9PBsDELdRstPtlP',\n",
      "         b'spotify:artist:60d24wfXkVzDSfLS6hyCjZ',\n",
      "         b'spotify:artist:3QjbhhPrW6clls3VPRGkXu',\n",
      "         b'spotify:artist:2CIMQHirSU0MQqyYHq0eOx',\n",
      "         b'spotify:artist:6ySxYu68zTsO5ghsThpGtS']]], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[1.6516030e+06, 1.7751560e+06, 5.0762360e+07, 1.7680286e+07,\n",
      "         5.0762360e+07],\n",
      "        [8.6296110e+06, 2.4587170e+06, 3.1364000e+06, 5.6022480e+06,\n",
      "         5.6022480e+06],\n",
      "        [1.7680286e+07, 3.5735212e+07, 1.9080876e+07, 2.0158480e+06,\n",
      "         9.5090940e+06],\n",
      "        ...,\n",
      "        [1.7826200e+05, 1.7826200e+05, 1.9369400e+05, 3.8785000e+04,\n",
      "         2.7389500e+05],\n",
      "        [1.0759690e+06, 1.8906144e+07, 5.5914660e+06, 2.1511274e+07,\n",
      "         5.6599930e+06],\n",
      "        [2.3878900e+05, 1.5448013e+07, 3.9238000e+04, 2.6994760e+06,\n",
      "         2.2975100e+05]]], dtype=float32)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[225506., 481210., 159106., ..., 273693., 249800., 199777.]],\n",
      "      dtype=float32)>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[218266., 258826., 203040., 234520., 231133.],\n",
      "        [334000., 435493., 412000., 305866., 402840.],\n",
      "        [248586., 346813., 232234., 188939., 211466.],\n",
      "        ...,\n",
      "        [529040., 180413., 311933., 316386., 187133.],\n",
      "        [210426., 221506., 226494., 211363., 295293.],\n",
      "        [197000., 198760., 180068., 386442., 281364.]]], dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[28., 30., 65., ..., 52., 62., 90.]], dtype=float32)>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[25., 21., 47., ..., 30., 54., 48.]], dtype=float32)>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[ 28.,  45.,  69., ...,  84.,  72., 110.]], dtype=float32)>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[ 6252016., 16770515., 15719750., ..., 27736596., 15877404.,\n",
      "        32618706.]], dtype=float32)>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'ME', b'indian music', b'justin', ..., b'Gospel', b'SUMMER 17',\n",
      "        b'Electronic']], dtype=object)>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=array([[b'4', b'4', b'4', ..., b'4', b'4', b'4']], dtype=object)>,\n",
      " 'time_signature_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'3', b'4', b'4', b'5', b'4'],\n",
      "        ...,\n",
      "        [b'4', b'4', b'4', b'4', b'5'],\n",
      "        [b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'4', b'4', b'4', b'4', b'4']]], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.0383  , 0.373   , 0.184   , ..., 0.00464 , 0.000643, 0.00167 ]],\n",
      "      dtype=float32)>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[3.98e-04, 2.08e-02, 2.88e-01, 6.35e-02, 1.62e-01],\n",
      "        [5.02e-02, 1.58e-01, 2.39e-02, 4.49e-01, 4.63e-02],\n",
      "        [1.42e-01, 2.95e-01, 9.43e-01, 3.55e-01, 6.95e-01],\n",
      "        ...,\n",
      "        [2.83e-02, 5.41e-01, 3.60e-01, 5.49e-02, 8.47e-01],\n",
      "        [1.22e-01, 2.15e-02, 2.57e-01, 7.45e-02, 4.84e-01],\n",
      "        [2.66e-02, 9.76e-04, 4.67e-03, 1.47e-03, 1.50e-01]]],\n",
      "      dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0.661, 0.538, 0.62 , ..., 0.319, 0.579, 0.566]], dtype=float32)>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.613, 0.583, 0.621, 0.336, 0.687],\n",
      "        [0.748, 0.445, 0.613, 0.734, 0.625],\n",
      "        [0.459, 0.464, 0.506, 0.374, 0.358],\n",
      "        ...,\n",
      "        [0.279, 0.19 , 0.471, 0.662, 0.446],\n",
      "        [0.588, 0.653, 0.705, 0.696, 0.63 ],\n",
      "        [0.581, 0.495, 0.361, 0.461, 0.544]]], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0.88 , 0.612, 0.556, ..., 0.968, 0.815, 0.755]], dtype=float32)>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.917 , 0.786 , 0.417 , 0.602 , 0.783 ],\n",
      "        [0.663 , 0.188 , 0.842 , 0.429 , 0.711 ],\n",
      "        [0.545 , 0.467 , 0.124 , 0.344 , 0.557 ],\n",
      "        ...,\n",
      "        [0.383 , 0.0283, 0.584 , 0.954 , 0.312 ],\n",
      "        [0.598 , 0.658 , 0.453 , 0.503 , 0.605 ],\n",
      "        [0.64  , 0.811 , 0.743 , 0.912 , 0.766 ]]], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.00e+00, 6.53e-05, 0.00e+00, ..., 0.00e+00, 1.42e-05, 9.33e-01]],\n",
      "      dtype=float32)>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[9.69e-06, 0.00e+00, 0.00e+00, 0.00e+00, 1.35e-05],\n",
      "        [5.55e-04, 0.00e+00, 3.47e-01, 5.05e-04, 1.17e-03],\n",
      "        [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "        ...,\n",
      "        [0.00e+00, 8.63e-05, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "        [0.00e+00, 1.66e-06, 0.00e+00, 0.00e+00, 9.29e-05],\n",
      "        [0.00e+00, 2.49e-01, 1.13e-03, 5.56e-01, 3.55e-01]]],\n",
      "      dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=array([[b'1', b'9', b'5', ..., b'6', b'11', b'5']], dtype=object)>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'8', b'2', b'10', b'4', b'6'],\n",
      "        [b'2', b'3', b'0', b'7', b'11'],\n",
      "        [b'6', b'5', b'0', b'2', b'10'],\n",
      "        ...,\n",
      "        [b'3', b'6', b'10', b'6', b'1'],\n",
      "        [b'11', b'2', b'3', b'8', b'0'],\n",
      "        [b'5', b'5', b'2', b'9', b'1']]], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.782 , 0.0749, 0.301 , ..., 0.393 , 0.147 , 0.355 ]],\n",
      "      dtype=float32)>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.159 , 0.188 , 0.119 , 0.141 , 0.114 ],\n",
      "        [0.277 , 0.0958, 0.131 , 0.0898, 0.192 ],\n",
      "        [0.105 , 0.141 , 0.081 , 0.0966, 0.0902],\n",
      "        ...,\n",
      "        [0.395 , 0.414 , 0.333 , 0.983 , 0.103 ],\n",
      "        [0.117 , 0.0939, 0.143 , 0.0869, 0.298 ],\n",
      "        [0.572 , 0.899 , 0.115 , 0.105 , 0.071 ]]], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[ -2.978,  -6.919, -12.044, ...,  -5.706,  -7.715,  -6.075]],\n",
      "      dtype=float32)>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[ -4.754,  -3.142,  -6.941,  -6.354,  -4.44 ],\n",
      "        [-11.269, -13.885,  -7.966,  -9.456,  -7.511],\n",
      "        [ -4.874,  -5.306, -12.346, -11.94 ,  -7.398],\n",
      "        ...,\n",
      "        [-12.37 , -31.656,  -6.954,  -4.008,  -7.733],\n",
      "        [ -8.061,  -6.428,  -8.174,  -4.842,  -8.951],\n",
      "        [ -8.367,  -6.189,  -5.252,  -6.797,  -7.903]]], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=array([[b'1', b'0', b'1', ..., b'1', b'0', b'0']], dtype=object)>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'1', b'0', b'1', b'1', b'1'],\n",
      "        [b'1', b'1', b'1', b'1', b'0'],\n",
      "        [b'1', b'1', b'1', b'1', b'1'],\n",
      "        ...,\n",
      "        [b'0', b'1', b'1', b'1', b'1'],\n",
      "        [b'1', b'1', b'1', b'1', b'1'],\n",
      "        [b'1', b'0', b'1', b'1', b'0']]], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'Lolly', b'Eli Re Eli', b\"I'd Really Love To See You Tonight\",\n",
      "        ..., b'Not About Us', b'Smells Like Summer',\n",
      "        b'Born To Love - Radio Edit']], dtype=object)>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b\"Best Friend's Brother\", b'Love Song',\n",
      "         b'Teardrops On My Guitar', b'The Climb', b'You Belong With Me'],\n",
      "        [b'Mehboob Mere (From \"Fiza\")',\n",
      "         b'Tu Hi Re - Bombay / Soundtrack Version',\n",
      "         b'Jab Dil Mile (From \"Yaadein\")',\n",
      "         b'Socho Ke Jheelon (From \"Mission Kashmir\")',\n",
      "         b'Aaja Mahiya (From \"Fiza\")'],\n",
      "        [b'When I Look At You', b'One And Only', b'How Will I Know',\n",
      "         b'I Was Made For Loving You', b\"Say You Won't Let Go\"],\n",
      "        ...,\n",
      "        [b'Father Me', b'Father Me Reprise', b'Royalty - Radio Edit',\n",
      "         b'Giants', b'Run Til I Finish'],\n",
      "        [b'Naked Kids', b'Paris', b'Smoke Break (feat. Future)',\n",
      "         b'The Cure', b'Pursuit Of Happiness (nightmare)'],\n",
      "        [b'Many Ways - Radio Edit', b'Virus (How About Now)',\n",
      "         b'Step Into Your Light - Radio Edit',\n",
      "         b'The Veldt (deadmau5 Vs. Eric Prydz Edit)',\n",
      "         b\"Going Home - Gareth Emery Remix - Armin van Buuren's Intro Mix\"]]],\n",
      "      dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[ 0.,  0., 70., ..., 40., 45., 12.]], dtype=float32)>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[50., 77.,  0., 76., 73.],\n",
      "        [ 0., 57.,  0.,  0.,  0.],\n",
      "        [76.,  1.,  1., 69., 88.],\n",
      "        ...,\n",
      "        [23., 16.,  0., 28., 31.],\n",
      "        [46., 77., 64.,  0., 81.],\n",
      "        [16.,  0., 18., 28., 21.]]], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.296 , 0.0702, 0.0336, ..., 0.259 , 0.0406, 0.0337]],\n",
      "      dtype=float32)>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.0637, 0.0301, 0.0231, 0.0325, 0.0386],\n",
      "        [0.06  , 0.0336, 0.052 , 0.0281, 0.1   ],\n",
      "        [0.0282, 0.0376, 0.0719, 0.0304, 0.059 ],\n",
      "        ...,\n",
      "        [0.0397, 0.0348, 0.0567, 0.166 , 0.0387],\n",
      "        [0.0361, 0.0304, 0.196 , 0.0356, 0.0414],\n",
      "        [0.0365, 0.0386, 0.0477, 0.0293, 0.0402]]], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[152.221,  92.781, 119.172, ..., 203.804, 140.008, 132.005]],\n",
      "      dtype=float32)>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[140.001, 123.055,  99.953, 161.01 , 129.964],\n",
      "        [ 95.975,  99.718, 171.89 , 100.021, 170.391],\n",
      "        [137.941,  51.66 ,  84.046, 106.415,  85.043],\n",
      "        ...,\n",
      "        [105.355,  78.704,  89.727, 138.006, 128.891],\n",
      "        [105.024,  99.99 , 124.942,  99.977, 115.277],\n",
      "        [128.001, 128.074, 127.957, 127.985, 132.008]]], dtype=float32)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'spotify:track:1x7QWWVpQdoiOGDRWuSK5l',\n",
      "        b'spotify:track:2gOKYvjjDFynSfTs0yblpI',\n",
      "        b'spotify:track:2r008pcfVYc0zgQvSRqUJE', ...,\n",
      "        b'spotify:track:3s4oYZa7iRKotV0HEcsMv1',\n",
      "        b'spotify:track:0ir8h6HSxpbCgAlfv1RKPb',\n",
      "        b'spotify:track:0pq83WS1fMJj5cAUfe4YC6']], dtype=object)>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'spotify:track:0VRh0HgB1RsgqjH7YswsJK',\n",
      "         b'spotify:track:4E6cwWJWZw2zWf7VFbH7wf',\n",
      "         b'spotify:track:4tXsR2Hv3l85TQTwgEn3Um',\n",
      "         b'spotify:track:5x5JM1BSB6vollcIzDocqT',\n",
      "         b'spotify:track:3GCL1PydwsLodcpv0Ll1ch'],\n",
      "        [b'spotify:track:6EXhrp3mHSgAs4U7hOL2sJ',\n",
      "         b'spotify:track:6nwRC0UkS1MdOOMjcJsrbX',\n",
      "         b'spotify:track:0bSnqjpsK7QT90xta63HiD',\n",
      "         b'spotify:track:6xTjqLFNXQbGR5gXttaJ1z',\n",
      "         b'spotify:track:5ZSfLm2a186NVHHQhpGS1T'],\n",
      "        [b'spotify:track:6ZfXA2xakAvphXOSOJ3u1W',\n",
      "         b'spotify:track:4I3KMa9p00MJwWbT0vi5iX',\n",
      "         b'spotify:track:64oxbrbRQV6MZto7o8Y42P',\n",
      "         b'spotify:track:3vOmmLuvEUgGaVuRsCs2QF',\n",
      "         b'spotify:track:5uCax9HTNlzGybIStD3vDh'],\n",
      "        ...,\n",
      "        [b'spotify:track:2hmL2KroDnZioWeA7Gpngz',\n",
      "         b'spotify:track:25z5c6NiDDlMEujqlim4XS',\n",
      "         b'spotify:track:4y4SqbvQzSRo3ImDJc1PKM',\n",
      "         b'spotify:track:6vwfHkpyngJeJJxAkA6EoS',\n",
      "         b'spotify:track:70f2csknABwJHInhZD03hq'],\n",
      "        [b'spotify:track:3awm1x3kGmYIVrkNDBFP6U',\n",
      "         b'spotify:track:72jbDTw1piOOj770jWNeaG',\n",
      "         b'spotify:track:1Uq3IOIy1CUlHUgP6vWpum',\n",
      "         b'spotify:track:51PIvodunv6NmX5250zxAh',\n",
      "         b'spotify:track:5iSEsR6NKjlC9SrIJkyL3k'],\n",
      "        [b'spotify:track:7m95IrQVEV0xxGmEhCpbH4',\n",
      "         b'spotify:track:4rPZWx1jS9M2qap8KxUH62',\n",
      "         b'spotify:track:03boBslBzyNXZyNYvzL0NJ',\n",
      "         b'spotify:track:4rHk2tXZ0r8HCKsPLqXQPT',\n",
      "         b'spotify:track:1WCaSFh1cI0PgESqzAoNMg']]], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0.827, 0.511, 0.592, ..., 0.586, 0.722, 0.233]], dtype=float32)>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.77  , 0.573 , 0.289 , 0.299 , 0.443 ],\n",
      "        [0.748 , 0.357 , 0.722 , 0.275 , 0.675 ],\n",
      "        [0.194 , 0.169 , 0.301 , 0.216 , 0.494 ],\n",
      "        ...,\n",
      "        [0.174 , 0.111 , 0.424 , 0.595 , 0.656 ],\n",
      "        [0.292 , 0.219 , 0.283 , 0.559 , 0.266 ],\n",
      "        [0.288 , 0.0843, 0.419 , 0.15  , 0.0349]]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0ccf9-4602-49b8-bde7-dbb962d6cc25",
   "metadata": {},
   "source": [
    "### Create Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4983881f-099b-43d6-b296-381cf3e1d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = 'spotify-data-regimes'\n",
    "valid_dir_prefix = 'jtv10/valid_v9'\n",
    "\n",
    "valid_files = []\n",
    "for blob in storage_client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(\n",
    "    tt.parse_tfrecord, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "# valid_dataset = valid_dataset.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)\n",
    "\n",
    "# valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bafcb1ea-d55d-4628-9eb7-6cf2f5ee0f7b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_uri_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'spotify:album:0Jy2FoyFXxrHi6XIa8cHzU',\n",
      "        b'spotify:album:0jAuXoXXgM4EjiRBEMHFav',\n",
      "        b'spotify:album:1lAMkHFW0e51taMt34LUQ2', ...,\n",
      "        b'spotify:album:3j1hDhDSQSdlVcZf2kfecY',\n",
      "        b'spotify:album:2K0iHDNNIzhuclKtsugZxt',\n",
      "        b'spotify:album:7j7q1pRH9QoQPkEXOfmFsz']], dtype=object)>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'spotify:album:39Mc1rLpJeiG5BYuSOwGet',\n",
      "         b'spotify:album:2Z9WUERfMjOgQ6ze9TcGbF',\n",
      "         b'spotify:album:50wolXldayJCEtNKyzJERs',\n",
      "         b'spotify:album:0IuHVgAvbNDJnJepuSZ8Oz',\n",
      "         b'spotify:album:2dqn5yOQWdyGwOpOIi9O4x'],\n",
      "        [b'spotify:album:3IFuRY2wRpJa9FTXj4aTTB',\n",
      "         b'spotify:album:2oPdRL0fDdnW9e1zoMnrDk',\n",
      "         b'spotify:album:0jAuXoXXgM4EjiRBEMHFav',\n",
      "         b'spotify:album:0I8K07F4nXcRexkF6BrDN5',\n",
      "         b'spotify:album:0I8K07F4nXcRexkF6BrDN5'],\n",
      "        [b'spotify:album:0IuHVgAvbNDJnJepuSZ8Oz',\n",
      "         b'spotify:album:1azUkThwd2HfUDdeNeT147',\n",
      "         b'spotify:album:0kJbDT8VGMScK8YDzNNvzV',\n",
      "         b'spotify:album:6Q7yIbfFPzplTCBM7d1WRO',\n",
      "         b'spotify:album:7oiJYvEJHsmYtrgviAVIBD'],\n",
      "        ...,\n",
      "        [b'spotify:album:6ciJlSCd5DkKV8DJmty2Zl',\n",
      "         b'spotify:album:3ZJKwvzl6ePz3APzPaCgQM',\n",
      "         b'spotify:album:6V7UTQKQXzg6jwNTxPxd2w',\n",
      "         b'spotify:album:6LFFAA4z6BrTDFVBxnKKjB',\n",
      "         b'spotify:album:26hZA3KTNLcqcLaj0zSBkq'],\n",
      "        [b'spotify:album:2K0iHDNNIzhuclKtsugZxt',\n",
      "         b'spotify:album:2K0iHDNNIzhuclKtsugZxt',\n",
      "         b'spotify:album:2K0iHDNNIzhuclKtsugZxt',\n",
      "         b'spotify:album:2K0iHDNNIzhuclKtsugZxt',\n",
      "         b'spotify:album:2L4TJGv4npQYBHpiU7tHMI'],\n",
      "        [b'spotify:album:61yPCznT8tXb3Qoy0VbRcf',\n",
      "         b'spotify:album:6SbAwyk3P7BPW4uKv3UOZB',\n",
      "         b'spotify:album:61MUZCoQITIcWwghwrgYHM',\n",
      "         b'spotify:album:5D9xxNS25LKZCsjOpG1oHP',\n",
      "         b'spotify:album:3dqdHka71CKMFqfKX0tSgZ']]], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[    0.,     0.,     0., ...,  1221., 13466.,  2308.]],\n",
      "      dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b\"'detroit hip hop'\",\n",
      "        b\"'classic bollywood', 'desi pop', 'filmi', 'modern bollywood'\",\n",
      "        b\"'yacht rock'\", ..., b'NONE',\n",
      "        b\"'christian indie', 'roots worship'\",\n",
      "        b\"'louisiana blues', 'new orleans blues', 'rhythm and blues'\"]],\n",
      "      dtype=object)>,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b\"'dance pop', 'post-teen pop', 'social media pop', 'viral pop'\",\n",
      "         b\"'acoustic pop', 'dance pop', 'hollywood', 'lilith', 'neo mellow', 'pop', 'pop rock'\",\n",
      "         b\"'pop'\", b\"'dance pop', 'pop', 'post-teen pop'\", b\"'pop'\"],\n",
      "        [b\"'desi pop', 'filmi', 'modern bollywood', 'sufi'\",\n",
      "         b\"'filmi', 'ghazal', 'tamil pop'\",\n",
      "         b\"'chutney', 'classic bollywood', 'desi pop', 'filmi', 'sufi'\",\n",
      "         b\"'chutney', 'classic bollywood', 'desi pop', 'filmi'\",\n",
      "         b\"'chutney', 'classic bollywood', 'desi pop', 'filmi'\"],\n",
      "        [b\"'dance pop', 'pop', 'post-teen pop'\",\n",
      "         b\"'british soul', 'pop', 'pop soul', 'uk pop'\",\n",
      "         b\"'dance pop', 'pop', 'uk pop'\",\n",
      "         b\"'dance pop', 'pop', 'post-teen pop'\",\n",
      "         b\"'pop', 'talent show', 'uk pop'\"],\n",
      "        ...,\n",
      "        [b\"'folk-pop', 'indie poptimism', 'indiecoustica', 'modern alternative rock', 'modern rock', 'pop rock', 'stomp and holler'\",\n",
      "         b'NONE',\n",
      "         b\"'folk-pop', 'indie poptimism', 'indiecoustica', 'modern alternative rock', 'modern rock', 'pop rock', 'stomp and holler'\",\n",
      "         b\"'indie poptimism', 'modern rock', 'pop rock', 'shimmer pop'\",\n",
      "         b\"'lincoln ne indie', 'olympia wa indie'\"],\n",
      "        [b\"'christian indie', 'roots worship'\",\n",
      "         b\"'christian indie', 'roots worship'\",\n",
      "         b\"'christian indie', 'roots worship'\",\n",
      "         b\"'christian indie', 'roots worship'\",\n",
      "         b\"'anthem worship', 'ccm', 'christian music', 'deep ccm', 'world worship', 'worship'\"],\n",
      "        [b\"'boogie-woogie', 'jump blues', 'louisiana blues', 'memphis blues', 'new orleans blues', 'rhythm and blues', 'rock-and-roll'\",\n",
      "         b'NONE', b\"'country rock', 'folk'\",\n",
      "         b\"'country blues', 'piano blues', 'traditional blues'\",\n",
      "         b\"'new orleans jazz'\"]]], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[65., 67., 25., ...,  9., 26., 28.]], dtype=float32)>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[65., 71., 98., 86., 98.],\n",
      "        [75., 71., 69., 77., 77.],\n",
      "        [86., 91., 86., 74., 83.],\n",
      "        ...,\n",
      "        [59., 37., 59., 46., 29.],\n",
      "        [26., 26., 26., 26., 62.],\n",
      "        [32., 11., 35., 21.,  5.]]], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'spotify:artist:1l7P8zlCKFbvOtUYYoJtoV',\n",
      "        b'spotify:artist:7kkSDNV8Q38QvQGBTaIxRn',\n",
      "        b'spotify:artist:1sFmYEcBTHjGELXH5vxSi9', ...,\n",
      "        b'spotify:artist:52w5uE4KlK3ZKq6EUwmkDp',\n",
      "        b'spotify:artist:2YPUYmSXbes3Y0SWEAkp3F',\n",
      "        b'spotify:artist:3mCIMoeTyKjHlgNv7wFZYI']], dtype=object)>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'spotify:artist:1KYszkVzlhV3rAqmAcYIgd',\n",
      "         b'spotify:artist:2Sqr0DXoaYABbjBo9HaMkM',\n",
      "         b'spotify:artist:06HL4z0CvFAxyc27GXpf02',\n",
      "         b'spotify:artist:5YGY8feqx7naU7z4HrwZM6',\n",
      "         b'spotify:artist:06HL4z0CvFAxyc27GXpf02'],\n",
      "        [b'spotify:artist:3eDT9fwXKuHWFvgZaaYC5v',\n",
      "         b'spotify:artist:2NoJ7NuNs9nyj8Thoh1kbu',\n",
      "         b'spotify:artist:5as8A4G47Ohu9NSWs3Je8U',\n",
      "         b'spotify:artist:70B80Lwx2sxti0M1Ng9e8K',\n",
      "         b'spotify:artist:70B80Lwx2sxti0M1Ng9e8K'],\n",
      "        [b'spotify:artist:5YGY8feqx7naU7z4HrwZM6',\n",
      "         b'spotify:artist:4dpARuHxo51G3z768sgnrY',\n",
      "         b'spotify:artist:2wY79sveU1sp5g7SokKOiI',\n",
      "         b'spotify:artist:1vSN1fsvrzpbttOYGsliDr',\n",
      "         b'spotify:artist:4IWBUUAFIplrNtaOHcJPRM'],\n",
      "        ...,\n",
      "        [b'spotify:artist:6ZUjdwG0NvY6MT7vvmluhV',\n",
      "         b'spotify:artist:2ITSMMQkSxMMULKrwOFY3V',\n",
      "         b'spotify:artist:6ZUjdwG0NvY6MT7vvmluhV',\n",
      "         b'spotify:artist:6ejhZKxWJr9apHAzj74DHv',\n",
      "         b'spotify:artist:5JBjc1UhLlvqmifk3WLAFg'],\n",
      "        [b'spotify:artist:2YPUYmSXbes3Y0SWEAkp3F',\n",
      "         b'spotify:artist:2YPUYmSXbes3Y0SWEAkp3F',\n",
      "         b'spotify:artist:2YPUYmSXbes3Y0SWEAkp3F',\n",
      "         b'spotify:artist:2YPUYmSXbes3Y0SWEAkp3F',\n",
      "         b'spotify:artist:0Onvkz1Nbs4wHXXUwOIGk8'],\n",
      "        [b'spotify:artist:01PkggcasHgNtRfgRw51Kk',\n",
      "         b'spotify:artist:7122Kwu5YJVy0AryshFC72',\n",
      "         b'spotify:artist:0n5eyZr2XjOLUODPGZrlLB',\n",
      "         b'spotify:artist:1MzNMhcJhkG0pCk2sg3PTR',\n",
      "         b'spotify:artist:38xxAX1RVE3vsn3LU61IiY']]], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[1.6516030e+06, 1.7751560e+06, 5.0762360e+07, 1.7680286e+07,\n",
      "         5.0762360e+07],\n",
      "        [8.6296110e+06, 2.4587170e+06, 3.1364000e+06, 5.6022480e+06,\n",
      "         5.6022480e+06],\n",
      "        [1.7680286e+07, 3.5735212e+07, 1.9080876e+07, 2.0158480e+06,\n",
      "         9.5090940e+06],\n",
      "        ...,\n",
      "        [8.7054000e+04, 6.1910000e+03, 8.7054000e+04, 8.9017000e+04,\n",
      "         7.8670000e+03],\n",
      "        [1.3466000e+04, 1.3466000e+04, 1.3466000e+04, 1.3466000e+04,\n",
      "         1.0886660e+06],\n",
      "        [6.2630000e+03, 9.3500000e+02, 1.7697000e+04, 5.1320000e+03,\n",
      "         1.6900000e+02]]], dtype=float32)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[225506., 481210., 159106., ..., 184426., 172426., 175800.]],\n",
      "      dtype=float32)>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[218266., 258826., 203040., 234520., 231133.],\n",
      "        [334000., 435493., 412000., 305866., 402840.],\n",
      "        [248586., 346813., 232234., 188939., 211466.],\n",
      "        ...,\n",
      "        [209585., 164913., 165720., 232746., 255426.],\n",
      "        [448306., 213146., 204013., 149746., 545560.],\n",
      "        [151120., 165306., 151160., 179600., 390026.]]], dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[28., 30., 65., ..., 30., 86., 65.]], dtype=float32)>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[25., 21., 47., ..., 29., 71., 60.]], dtype=float32)>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[ 28.,  45.,  69., ...,  30., 245.,  73.]], dtype=float32)>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[ 6252016., 16770515., 15719750., ...,  6359293., 80966032.,\n",
      "        16754636.]], dtype=float32)>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'ME', b'indian music', b'justin', ..., b'Car', b'Worship',\n",
      "        b'New Orleans']], dtype=object)>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=array([[b'4', b'4', b'4', ..., b'4', b'4', b'4']], dtype=object)>,\n",
      " 'time_signature_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'3', b'4', b'4', b'5', b'4'],\n",
      "        ...,\n",
      "        [b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'4', b'4', b'4', b'4', b'4'],\n",
      "        [b'3', b'3', b'4', b'4', b'3']]], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.0383 , 0.373  , 0.184  , ..., 0.00502, 0.397  , 0.596  ]],\n",
      "      dtype=float32)>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[3.98e-04, 2.08e-02, 2.88e-01, 6.35e-02, 1.62e-01],\n",
      "        [5.02e-02, 1.58e-01, 2.39e-02, 4.49e-01, 4.63e-02],\n",
      "        [1.42e-01, 2.95e-01, 9.43e-01, 3.55e-01, 6.95e-01],\n",
      "        ...,\n",
      "        [4.56e-01, 4.30e-04, 2.80e-02, 8.76e-02, 4.08e-01],\n",
      "        [5.48e-01, 4.38e-04, 6.13e-01, 8.42e-01, 2.61e-01],\n",
      "        [4.83e-01, 8.50e-01, 4.38e-01, 7.46e-01, 8.39e-01]]],\n",
      "      dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0.661, 0.538, 0.62 , ..., 0.707, 0.615, 0.732]], dtype=float32)>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.613, 0.583, 0.621, 0.336, 0.687],\n",
      "        [0.748, 0.445, 0.613, 0.734, 0.625],\n",
      "        [0.459, 0.464, 0.506, 0.374, 0.358],\n",
      "        ...,\n",
      "        [0.639, 0.628, 0.646, 0.472, 0.64 ],\n",
      "        [0.509, 0.519, 0.25 , 0.211, 0.339],\n",
      "        [0.607, 0.591, 0.659, 0.725, 0.452]]], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0.88 , 0.612, 0.556, ..., 0.826, 0.491, 0.421]], dtype=float32)>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.917, 0.786, 0.417, 0.602, 0.783],\n",
      "        [0.663, 0.188, 0.842, 0.429, 0.711],\n",
      "        [0.545, 0.467, 0.124, 0.344, 0.557],\n",
      "        ...,\n",
      "        [0.654, 0.767, 0.85 , 0.881, 0.407],\n",
      "        [0.663, 0.783, 0.352, 0.322, 0.609],\n",
      "        [0.58 , 0.297, 0.687, 0.33 , 0.313]]], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.00e+00, 6.53e-05, 0.00e+00, ..., 1.90e-03, 8.98e-01, 6.35e-05]],\n",
      "      dtype=float32)>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[9.69e-06, 0.00e+00, 0.00e+00, 0.00e+00, 1.35e-05],\n",
      "        [5.55e-04, 0.00e+00, 3.47e-01, 5.05e-04, 1.17e-03],\n",
      "        [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "        ...,\n",
      "        [8.45e-05, 8.57e-03, 7.21e-05, 0.00e+00, 1.01e-04],\n",
      "        [7.33e-01, 3.73e-02, 9.61e-01, 9.26e-01, 4.42e-05],\n",
      "        [1.22e-05, 1.11e-06, 0.00e+00, 3.03e-05, 5.71e-01]]],\n",
      "      dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=array([[b'1', b'9', b'5', ..., b'9', b'0', b'1']], dtype=object)>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'8', b'2', b'10', b'4', b'6'],\n",
      "        [b'2', b'3', b'0', b'7', b'11'],\n",
      "        [b'6', b'5', b'0', b'2', b'10'],\n",
      "        ...,\n",
      "        [b'7', b'9', b'7', b'2', b'2'],\n",
      "        [b'9', b'0', b'0', b'0', b'0'],\n",
      "        [b'4', b'0', b'7', b'0', b'0']]], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.782 , 0.0749, 0.301 , ..., 0.0802, 0.116 , 0.0479]],\n",
      "      dtype=float32)>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.159 , 0.188 , 0.119 , 0.141 , 0.114 ],\n",
      "        [0.277 , 0.0958, 0.131 , 0.0898, 0.192 ],\n",
      "        [0.105 , 0.141 , 0.081 , 0.0966, 0.0902],\n",
      "        ...,\n",
      "        [0.16  , 0.0986, 0.281 , 0.0698, 0.521 ],\n",
      "        [0.207 , 0.0877, 0.156 , 0.113 , 0.413 ],\n",
      "        [0.367 , 0.106 , 0.218 , 0.0511, 0.132 ]]], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[ -2.978,  -6.919, -12.044, ...,  -2.293,  -8.646,  -9.596]],\n",
      "      dtype=float32)>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[ -4.754,  -3.142,  -6.941,  -6.354,  -4.44 ],\n",
      "        [-11.269, -13.885,  -7.966,  -9.456,  -7.511],\n",
      "        [ -4.874,  -5.306, -12.346, -11.94 ,  -7.398],\n",
      "        ...,\n",
      "        [ -5.287,  -4.906,  -5.145,  -5.252,  -8.23 ],\n",
      "        [ -9.054,  -8.675, -10.984, -13.943,  -6.613],\n",
      "        [ -8.205,  -8.586,  -5.477, -11.878,  -9.984]]], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=array([[b'1', b'0', b'1', ..., b'1', b'0', b'1']], dtype=object)>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'1', b'0', b'1', b'1', b'1'],\n",
      "        [b'1', b'1', b'1', b'1', b'0'],\n",
      "        [b'1', b'1', b'1', b'1', b'1'],\n",
      "        ...,\n",
      "        [b'0', b'0', b'1', b'1', b'1'],\n",
      "        [b'1', b'1', b'1', b'1', b'1'],\n",
      "        [b'1', b'1', b'0', b'1', b'1']]], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'Lolly', b'Eli Re Eli', b\"I'd Really Love To See You Tonight\",\n",
      "        ..., b'Cannibal', b'Give Us This Day Our Daily Bread',\n",
      "        b'Something You Got']], dtype=object)>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b\"Best Friend's Brother\", b'Love Song',\n",
      "         b'Teardrops On My Guitar', b'The Climb', b'You Belong With Me'],\n",
      "        [b'Mehboob Mere (From \"Fiza\")',\n",
      "         b'Tu Hi Re - Bombay / Soundtrack Version',\n",
      "         b'Jab Dil Mile (From \"Yaadein\")',\n",
      "         b'Socho Ke Jheelon (From \"Mission Kashmir\")',\n",
      "         b'Aaja Mahiya (From \"Fiza\")'],\n",
      "        [b'When I Look At You', b'One And Only', b'How Will I Know',\n",
      "         b'I Was Made For Loving You', b\"Say You Won't Let Go\"],\n",
      "        ...,\n",
      "        [b'Carry On', b'Just Our Style', b'High', b'Paris',\n",
      "         b'Box of Blue'],\n",
      "        [b'Your Will Be Done On Earth As In Heaven',\n",
      "         b'Your Kingdom Come', b'Our Father In Heaven',\n",
      "         b'Hallowed Be Your Name', b'I Want To Know You - Live'],\n",
      "        [b'I Hear You Knocking', b\"Can't Nobody Love You\",\n",
      "         b\"The I Don't Know Where I'm Going But I'm Going Nowhere In A Hurry Blues\",\n",
      "         b\"You've Been A Good Ole Wagon (But You Done Broke Down)\",\n",
      "         b'Burgundy Street Blues']]], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[ 0.,  0., 70., ..., 17.,  0., 19.]], dtype=float32)>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[50., 77.,  0., 76., 73.],\n",
      "        [ 0., 57.,  0.,  0.,  0.],\n",
      "        [76.,  1.,  1., 69., 88.],\n",
      "        ...,\n",
      "        [51.,  0.,  0., 47., 12.],\n",
      "        [ 0.,  0.,  0.,  0., 34.],\n",
      "        [ 0.,  0., 16.,  5.,  0.]]], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[0.296 , 0.0702, 0.0336, ..., 0.0395, 0.0279, 0.0286]],\n",
      "      dtype=float32)>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.0637, 0.0301, 0.0231, 0.0325, 0.0386],\n",
      "        [0.06  , 0.0336, 0.052 , 0.0281, 0.1   ],\n",
      "        [0.0282, 0.0376, 0.0719, 0.0304, 0.059 ],\n",
      "        ...,\n",
      "        [0.0528, 0.043 , 0.043 , 0.0524, 0.0271],\n",
      "        [0.0358, 0.0273, 0.0325, 0.0367, 0.0349],\n",
      "        [0.026 , 0.0317, 0.0568, 0.0472, 0.0846]]], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[152.221,  92.781, 119.172, ..., 121.957, 109.973, 109.322]],\n",
      "      dtype=float32)>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[140.001, 123.055,  99.953, 161.01 , 129.964],\n",
      "        [ 95.975,  99.718, 171.89 , 100.021, 170.391],\n",
      "        [137.941,  51.66 ,  84.046, 106.415,  85.043],\n",
      "        ...,\n",
      "        [ 91.933, 134.986, 116.999, 178.858,  84.984],\n",
      "        [138.014, 124.977, 101.969,  78.736, 141.565],\n",
      "        [135.156,  80.675, 120.496,  98.802, 183.236]]], dtype=float32)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1, 1024), dtype=string, numpy=\n",
      "array([[b'spotify:track:1x7QWWVpQdoiOGDRWuSK5l',\n",
      "        b'spotify:track:2gOKYvjjDFynSfTs0yblpI',\n",
      "        b'spotify:track:2r008pcfVYc0zgQvSRqUJE', ...,\n",
      "        b'spotify:track:47VT9sbPqrVzJLltnl1YIA',\n",
      "        b'spotify:track:2Syb7DYgByCd1gB0Sx8n7r',\n",
      "        b'spotify:track:25RjrV1Zw6y6ROYs1me2gJ']], dtype=object)>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=string, numpy=\n",
      "array([[[b'spotify:track:0VRh0HgB1RsgqjH7YswsJK',\n",
      "         b'spotify:track:4E6cwWJWZw2zWf7VFbH7wf',\n",
      "         b'spotify:track:4tXsR2Hv3l85TQTwgEn3Um',\n",
      "         b'spotify:track:5x5JM1BSB6vollcIzDocqT',\n",
      "         b'spotify:track:3GCL1PydwsLodcpv0Ll1ch'],\n",
      "        [b'spotify:track:6EXhrp3mHSgAs4U7hOL2sJ',\n",
      "         b'spotify:track:6nwRC0UkS1MdOOMjcJsrbX',\n",
      "         b'spotify:track:0bSnqjpsK7QT90xta63HiD',\n",
      "         b'spotify:track:6xTjqLFNXQbGR5gXttaJ1z',\n",
      "         b'spotify:track:5ZSfLm2a186NVHHQhpGS1T'],\n",
      "        [b'spotify:track:6ZfXA2xakAvphXOSOJ3u1W',\n",
      "         b'spotify:track:4I3KMa9p00MJwWbT0vi5iX',\n",
      "         b'spotify:track:64oxbrbRQV6MZto7o8Y42P',\n",
      "         b'spotify:track:3vOmmLuvEUgGaVuRsCs2QF',\n",
      "         b'spotify:track:5uCax9HTNlzGybIStD3vDh'],\n",
      "        ...,\n",
      "        [b'spotify:track:4dpD3TDufxz2rQ9JLkYPgV',\n",
      "         b'spotify:track:0RKtiYWRTP3Ze0lhNQDegm',\n",
      "         b'spotify:track:3LfO09R3zh96w0qGURCvrr',\n",
      "         b'spotify:track:6kF2DYkORE9d17oPFomMPJ',\n",
      "         b'spotify:track:4hUHpNkQVdfZHnsmL2a6jk'],\n",
      "        [b'spotify:track:144ruDIT8AQvh4wxFtD7ZP',\n",
      "         b'spotify:track:0LMxoRLJzbWwXZH5wHPmsc',\n",
      "         b'spotify:track:2n10z5lxmByDF5MEY2HXEu',\n",
      "         b'spotify:track:0ohQAwDdCXRPO1IHdFN9MX',\n",
      "         b'spotify:track:2tscU6TS7ggmM8gkKJlHZC'],\n",
      "        [b'spotify:track:26Li9pGp5LeTsUXoD0yQPK',\n",
      "         b'spotify:track:3OCvALei9LBEWqD0XeRSV8',\n",
      "         b'spotify:track:09hJo5CHhjgupHumH2VOke',\n",
      "         b'spotify:track:7sN1QejLACoDSs10EtEt4v',\n",
      "         b'spotify:track:3aLJ1BoXYFh7KNrNsPoanO']]], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0.827, 0.511, 0.592, ..., 0.776, 0.207, 0.964]], dtype=float32)>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(1, 1024, 5), dtype=float32, numpy=\n",
      "array([[[0.77  , 0.573 , 0.289 , 0.299 , 0.443 ],\n",
      "        [0.748 , 0.357 , 0.722 , 0.275 , 0.675 ],\n",
      "        [0.194 , 0.169 , 0.301 , 0.216 , 0.494 ],\n",
      "        ...,\n",
      "        [0.595 , 0.856 , 0.518 , 0.502 , 0.216 ],\n",
      "        [0.16  , 0.478 , 0.0855, 0.0618, 0.041 ],\n",
      "        [0.864 , 0.322 , 0.702 , 0.731 , 0.456 ]]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf15fc9-5d2d-470c-83d6-29354ff813d9",
   "metadata": {},
   "source": [
    "### Create Candidates dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b115e4b4-f616-4314-ac65-b956bbc2d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_FILE_DIR = 'spotify-data-regimes'\n",
    "CANDIDATE_PREFIX = 'jtv10/candidates' \n",
    "\n",
    "candidate_files = []\n",
    "for blob in storage_client.list_blobs(f\"{CANDIDATE_FILE_DIR}\", prefix=f'{CANDIDATE_PREFIX}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "candidate_dataset = tf.data.Dataset.from_tensor_slices(candidate_files)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False\n",
    ").map(\n",
    "    tt.parse_candidate_tfrecord_fn, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").with_options(\n",
    "    options\n",
    ")\n",
    "\n",
    "parsed_candidate_dataset = parsed_candidate_dataset.cache() #400 MB on machine mem\n",
    "\n",
    "# parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02633e13-187a-41dc-8164-a3a9c5620c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:album:4U91uJBtdsedXEuRMjgZRP'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([28450.], dtype=float32)>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b\"'edm', 'pop dance', 'progressive house', 'progressive trance', 'trance', 'uplifting trance'\"],\n",
      "      dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([49.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:artist:7iVuXpgNEl87BwdwV1L6he'], dtype=object)>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([420000.], dtype=float32)>,\n",
      " 'time_signature_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.000864], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.615], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.697], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.624], dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0341], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.563], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4U - Original Mix'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0358], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([127.985], dtype=float32)>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'spotify:track:3EK4rJ1JAcqpbNN2xG5hhR'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.301], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for x in parsed_candidate_dataset.batch(1).take(1):\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a914a-e3d4-4c5c-a42a-9d39a6bde63c",
   "metadata": {},
   "source": [
    "## Adapt Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59e5bf-cba2-40c3-9e71-ef8c89928435",
   "metadata": {},
   "source": [
    "#### adapt normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba21d8e5-bf87-4812-8cc4-3a4e9021a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_duration_ms_can = train_dataset.map(lambda x: x[\"duration_ms_can\"]).reduce(np.Inf, tf.math.minimum)\n",
    "# max_duration_ms_can = train_dataset.map(lambda x: x[\"duration_ms_can\"]).reduce(-np.Inf, tf.math.maximum)\n",
    "\n",
    "\n",
    "# print(f\"max_duration_ms_can: {max_duration_ms_can}\")\n",
    "# print(f\"min_duration_ms_can: {min_duration_ms_can}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90504826-dfdd-4f73-90e4-7c86ce52a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration_ms_can\n",
    "\n",
    "# max_duration_ms_can = train_dataset.map(lambda x: x[\"duration_ms_can\"]).reduce(\n",
    "#     tf.cast(0.0, tf.float32), tf.maximum).numpy().max()\n",
    "\n",
    "# min_duration_ms_can = train_dataset.map(lambda x: x[\"duration_ms_can\"]).reduce(\n",
    "#     tf.cast(0.0, tf.float32), tf.minimum).numpy().min()\n",
    "\n",
    "# avg_duration_ms_can = train_dataset.map(lambda x: x[\"duration_ms_can\"]).reduce(\n",
    "#     tf.cast(0.0, tf.float32), tf.minimum).numpy().mean()\n",
    "\n",
    "# var_duration_ms_can = train_dataset.map(lambda x: x[\"duration_ms_can\"]).reduce(\n",
    "#     tf.cast(0.0, tf.float32), tf.minimum).numpy().var()\n",
    "\n",
    "# print(f\"max_duration_ms_can: {max_duration_ms_can}\")\n",
    "# print(f\"min_duration_ms_can: {min_duration_ms_can}\")\n",
    "# print(f\"avg_duration_ms_can: {avg_duration_ms_can}\")\n",
    "# print(f\"var_duration_ms_can: {var_duration_ms_can}\")\n",
    "\n",
    "\n",
    "# track_pop_can\n",
    "# artist_pop_can\n",
    "# artist_followers_can\n",
    "# track_danceability_can\n",
    "# track_energy_can\n",
    "# track_loudness_can\n",
    "# track_speechiness_can\n",
    "# track_acousticness_can\n",
    "# track_instrumentalness_can\n",
    "# track_liveness_can\n",
    "# track_valence_can\n",
    "# track_tempo_can\n",
    "\n",
    "# pl_duration_ms_new\n",
    "# num_pl_songs_new     # | n_songs_pl_new\n",
    "# num_pl_artists_new\n",
    "# num_pl_albums_new\n",
    "\n",
    "\n",
    "\n",
    "# duration_ms_songs_pl\n",
    "# track_pop_pl\n",
    "# artist_pop_pl\n",
    "# artists_followers_pl\n",
    "# track_danceability_pl\n",
    "# track_energy_pl\n",
    "# track_loudness_pl\n",
    "# track_speechiness_pl\n",
    "# track_acousticness_pl\n",
    "# track_instrumentalness_pl\n",
    "# track_liveness_pl\n",
    "# track_valence_pl\n",
    "# track_tempo_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8ad80-0c5d-43ed-a77b-d75289aa2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean & variance --> normalization\n",
    "\n",
    "# np.mean(a)\n",
    "# np.var(a)\n",
    "\n",
    "# min & max --> descritized buckets\n",
    "\n",
    "# track_pop_pl_buckets = np.linspace(\n",
    "#     vocab_dict['min_track_pop'], \n",
    "#     vocab_dict['max_track_pop'], \n",
    "#     num=10\n",
    "# )\n",
    "\n",
    "\n",
    "max_timestamp = train_dataset.map(lambda x: x[\"timestamp\"]).reduce(\n",
    "    tf.cast(0, tf.int64), tf.maximum).numpy().max()\n",
    "min_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
    "    np.int64(1e9), tf.minimum).numpy().min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000)\n",
    "\n",
    "print(f\"Buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6054cdf-4d71-4228-adfe-1cc33790f49c",
   "metadata": {},
   "source": [
    "#### adapt text vectorization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0475e4-d796-4e6d-8fa1-d37f07c8fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name_pl\n",
    "pl_name_src\n",
    "artist_genres_pl\n",
    "\n",
    "track_name_can\n",
    "artist_genres_can\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83159b76-b529-4297-ae89-443e15da477b",
   "metadata": {},
   "source": [
    "### load saved vocab dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be17f6f9-1305-4d7d-ac8c-a5777e79e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system('gsutil cp gs://two-tower-models/vocabs/vocab_dict.pkl .')  # TODO - paramterize\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'rb')\n",
    "vocab_dict = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873a9d8-7dbd-4168-b47c-a9196b6793aa",
   "metadata": {},
   "source": [
    "## Build and Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[512,256]\n",
    "\n",
    "model = tt.TheTwoTowers(layer_sizes, vocab_dict, parsed_candidate_dataset)\n",
    "\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec331ba6-0b38-4089-9432-097c43ed3bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.two_tower_jt.two_tower.TheTwoTowers at 0x7f3daa1a3b10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3414bbf-43af-4e95-96db-95b36a980ce9",
   "metadata": {},
   "source": [
    "### inspect layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_duration_ms_new_emb_model\n",
      "3 num_pl_songs_new_emb_model\n",
      "4 num_pl_artists_new_emb_model\n",
      "5 num_pl_albums_new_emb_model\n",
      "6 track_uri_pl_emb_model\n",
      "7 track_name_pl_emb_model\n",
      "8 artist_uri_pl_emb_model\n",
      "9 artist_name_pl_emb_model\n",
      "10 album_uri_pl_emb_model\n",
      "11 album_name_pl_emb_model\n",
      "12 artist_genres_pl_emb_model\n",
      "13 duration_ms_songs_pl_emb_model\n",
      "14 track_pop_pl_emb_model\n",
      "15 artist_pop_pl_emb_model\n",
      "16 artists_followers_pl_emb_model\n",
      "17 track_danceability_pl_emb_model\n",
      "18 track_energy_pl_emb_model\n",
      "19 track_key_pl_emb_model\n",
      "20 track_loudness_pl_emb_model\n",
      "21 track_mode_pl_emb_model\n",
      "22 track_speechiness_pl_emb_model\n",
      "23 track_acousticness_pl_emb_model\n",
      "24 track_instrumentalness_pl_emb_model\n",
      "25 track_liveness_pl_emb_model\n",
      "26 track_valence_pl_emb_model\n",
      "27 track_tempo_pl_emb_model\n",
      "28 time_signature_pl_emb_model\n",
      "29 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 time_signature_can_emb_model\n",
      "23 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4de78f-a955-43a2-9940-b8d9f8aa4911",
   "metadata": {},
   "source": [
    "### setup Vertex Exeperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c84c47-bd82-4ca3-9f37-d3160e3ca376",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f'build-local-v2'\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location='us-central1',\n",
    "    # experiment=EXPERIMENT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### setup Tensorboard callbacks\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph\n",
    "\n",
    "**TODO:** clean up notebook section \n",
    "\n",
    "> *Note:* While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8238845-82bb-45a2-98b6-df8fb7589d90",
   "metadata": {},
   "source": [
    "#### Managed Tensorboard Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c0f152f-930f-4640-ab6d-7b540e6084b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB_RESOURCE_NAME: projects/934903580331/locations/us-central1/tensorboards/472921941339013120\n"
     ]
    }
   ],
   "source": [
    "# use existing TB instance\n",
    "# TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/472921941339013120'\n",
    "\n",
    "# # create new TB instance\n",
    "TENSORBOARD_DISPLAY_NAME=f\"{EXPERIMENT_NAME}\"\n",
    "tensorboard = vertex_ai.Tensorboard.create(display_name=TENSORBOARD_DISPLAY_NAME)\n",
    "TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "\n",
    "\n",
    "print(f\"TB_RESOURCE_NAME: {TB_RESOURCE_NAME}\")\n",
    "# projects/934903580331/locations/us-central1/tensorboards/472921941339013120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a034b-7959-4bd0-bf9c-45da1b695055",
   "metadata": {},
   "source": [
    "#### train config\n",
    "\n",
    "* consider experiment and experiment-run naming convention so names don't collide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2eeffe1-efc0-4a2d-b168-6f10a43b1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_NAME: run-20230104-153318\n",
      "LOG_DIR: gs://jt-tfrs-central/build-local-v2/run-20230104-153318/tb-logs\n"
     ]
    }
   ],
   "source": [
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "RUN_NAME = f'run-{invoke_time}'\n",
    "\n",
    "LOG_DIR = f\"{path}/{EXPERIMENT_NAME}/{RUN_NAME}/tb-logs\"\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "VALID_FREQUENCY=5\n",
    "\n",
    "HIST_FREQ = 0\n",
    "EMBED_FREQ = 0\n",
    "\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")\n",
    "print(f\"LOG_DIR: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "* train model in-notebook\n",
    "* write metrics to Vertex AI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 15s 263ms/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 14208.3160 - regularization_loss: 0.0000e+00 - total_loss: 14208.3160\n"
     ]
    }
   ],
   "source": [
    "# tensorboard callback\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    ecapsulates one-shot log uploader via a custom callback\n",
    "\n",
    "    '''\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))\n",
    "        \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=HIST_FREQ, \n",
    "        write_graph=True,\n",
    "        embeddings_freq=EMBED_FREQ,\n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "\n",
    "layer_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=VALID_FREQUENCY,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=10,\n",
    "    validation_steps=100,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        UploadTBLogsBatchEnd()\n",
    "    ], \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params(\n",
    "    {\n",
    "        \"layers\": str(layer_sizes), \n",
    "        \"learning_rate\": LR,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"valid_freq\": VALID_FREQUENCY,\n",
    "    }\n",
    ")\n",
    "\n",
    "gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "\n",
    "vertex_ai.log_metrics(metrics_dict) # JT TODO removed for 'total_loss' getting nan\n",
    "\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3a789c8-598f-47e1-a72c-2f3dc30b6be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcdc23e750>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1b5e576-db76-46ee-954e-5b6742db8a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.two_tower_jt.two_tower.TheTwoTowers at 0x7f3daa1a3b10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450b70a-d6dd-44e9-b7ce-dc439594d0bc",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f08e0-7fb7-48d2-99d2-640cd7405b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "eval_dict_v1 = model.evaluate(valid_dataset, return_dict=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_mins: {elapsed_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b0c75-7eaf-466c-b452-680addc20a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43294b-3a5d-482c-a0fc-ea37f1d6cb78",
   "metadata": {},
   "source": [
    "### Efficient eval\n",
    "\n",
    "* approximate with scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cca1457-4917-4aa3-81c1-6227e4bea23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    num_reordering_candidates=500,\n",
    "    num_leaves_to_search=30\n",
    ")\n",
    "scann.index_from_dataset(candidates=parsed_candidate_dataset.batch(128).cache().map(lambda x: (x['track_uri_can'], model.candidate_tower(x))))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_scann_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_scann_mins: {elapsed_scann_mins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0607f90f-843e-4d11-b05c-5085d6e61910",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=scann\n",
    ")\n",
    "model.compile()\n",
    "\n",
    "scann_result = model.evaluate(valid_dataset, return_dict=True, verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_scann_eval_mins = int((end_time - start_time) / 60)\n",
    "print(f\"elapsed_scann_eval_mins: {elapsed_scann_eval_mins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:\n",
    "\n",
    "![](img/experiment-console.png)\n",
    "\n",
    "![](img/tensorboard.png)\n",
    "\n",
    "### Also, while this is running - check out the Tensorboard profiler in `utils`.\n",
    "\n",
    "![](img/tb-profiler.png)\n",
    "\n",
    "### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`\n",
    "\n",
    "![](img/nvtop-optimized.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 105 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ceb80-2365-4b85-8218-3f721ddebada",
   "metadata": {},
   "source": [
    "### When complete you get a decent model with around 30-40 hit rate for top 1\n",
    "\n",
    "![](img/tb-metrics.png)\n",
    "![](img/tb-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train-time-minutes': 222,\n",
       " 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.0,\n",
       " 'loss': 100245.734375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 100245.734375}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559139c-d669-43b1-8ac2-6155b10ef83e",
   "metadata": {},
   "source": [
    "### Now, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1957-1883-4527-83ee-fd5c9857f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the bucket to store the tensorflow models\n",
    "# ! gsutil mb -l us-central1 $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "559d57ed-540c-41f4-b7cf-d3dad716f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://two-tower-models/run-spotify-nb-train-full-jt-20221227-214932/query_model/assets\n",
      "INFO:tensorflow:Assets written to: gs://two-tower-models/run-spotify-nb-train-full-jt-20221227-214932/candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=path + f\"/{RUN_NAME}/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=path + f\"/{RUN_NAME}/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'candidate_embeddings.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File candidate_embeddings.json uploaded to run-spotify-nb-train-full-jt-20221227-214932/candidates/candidate_embeddings.json.\n"
     ]
    }
   ],
   "source": [
    "tt.upload_blob(\n",
    "    'two-tower-models', \n",
    "    'candidate_embeddings.json', \n",
    "    f'{RUN_NAME}/candidates/candidate_embeddings.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    "(base) jupyter@tf28-jsw-sep-a100:~/spotify_mpd_two_tower$ wc -l candidate_embeddings.json \n",
    "2249561 candidate_embeddings.json\n",
    "```\n",
    "\n",
    "### Finished\n",
    "\n",
    "Go on to the [03 notebook](03-matching-engine.ipynb)\n",
    "\n",
    "You should see results similar to the screenshot below\n",
    "![](img/embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2e2b2-74a8-4485-9db0-22146e4a5159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
