{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9e26ae-a92b-4880-9716-975d977d4a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspect Layer Vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600a4a2-b3f3-4a88-8296-dc14ca5ed1ae",
   "metadata": {},
   "source": [
    "### pip if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5b635b-262e-4e46-8991-dc469ece82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# # The Vertex AI Workbench Notebook product has specific requirements\n",
    "# IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "# IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "#     \"/opt/deeplearning/metadata/env_version\"\n",
    "# )\n",
    "\n",
    "# # Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "# USER_FLAG = \"\"\n",
    "# if IS_WORKBENCH_NOTEBOOK:\n",
    "#     USER_FLAG = \"--user\"\n",
    "\n",
    "# ! pip3 install --upgrade {USER_FLAG} -q google-cloud-storage {USER_FLAG} \\\n",
    "#                                         kfp \\\n",
    "#                                         google-cloud-pipeline-components\n",
    "\n",
    "# if not os.getenv(\"IS_TESTING\"):\n",
    "#     # Automatically restart kernel after installs\n",
    "#     import IPython\n",
    "\n",
    "#     app = IPython.Application.instance()\n",
    "#     app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24675ff-40a3-4651-9bc7-7a1d174da49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp --user --q\n",
    "# !pip install google-cloud-pipeline-components==1.0.8 --user --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bbe5cb-1e4a-497c-bb2e-553bbdc88ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "# ! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "# ! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecdd4a6-bd94-4f38-b9fa-a6229cee4d04",
   "metadata": {},
   "source": [
    "### Set env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e03082-e381-4200-902d-15f130c93235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "BUCKET = 'spotify-data-regimes'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")\n",
    "\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c5d43-5034-4e92-a8fc-5b409909dcd2",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd11f08c-522b-4c68-8c0a-3e37dfaa40f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 05:47:33.949389: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 05:47:34.084115: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-28 05:47:34.132967: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-28 05:47:34.894657: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-28 05:47:34.894777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-28 05:47:34.894789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle as pkl\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668ccc1-0334-4ecc-a05f-92caaffefc1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load previously created vocab pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9456ddb1-4163-4d77-9437-dd1fe235d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://spotify-data-regimes/test/jw_vocab_dict_1220.pkl .\n",
    "# !gsutil cp gs://two-tower-models/vocabs/vocab_dict.pkl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c551b484-ca6c-4ed4-be7d-bb1d374548bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VOCAB_LOCAL_FILE = 'vocab_dict.pkl'\n",
    "\n",
    "# filehandler = open(f'{VOCAB_LOCAL_FILE}', 'rb')\n",
    "# vocab_dict_load = pkl.load(filehandler)\n",
    "# filehandler.close()\n",
    "# vocab_dict_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2103cb-4898-4bda-a0bf-246e142faa43",
   "metadata": {},
   "source": [
    "# Vocab pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32947ef4-b74b-4323-a9b8-2254ff1f6c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/jw-repo/spotify_mpd_two_tower'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97633de5-92c0-4391-8562-3788ced2251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "PIPELINES_SUB_DIR = 'vocab_pipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1eef53-f438-47de-a7ac-7b4038af6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662b921-7305-4009-bc15-2860e7546293",
   "metadata": {},
   "source": [
    "## Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a00c00-cc6a-4f12-acaa-212d7183d02b",
   "metadata": {},
   "source": [
    "### Adapt: `text` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4a5e9f-fcf1-4a66-a331-2e539ff777c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/vocab_pipes/adapt_fixed_text_layer_vocab.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/adapt_fixed_text_layer_vocab.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        # 'google-cloud-aiplatform==1.18.1',\n",
    "        'google-cloud-storage',\n",
    "        'tensorflow==2.8.3',\n",
    "    ],\n",
    ")\n",
    "def adapt_fixed_text_layer_vocab(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    data_dir_bucket_name: str,\n",
    "    data_dir_path_prefix: str,\n",
    "    vocab_path_prefix: str,\n",
    "    max_playlist_length: int,\n",
    "    max_tokens: int,\n",
    "    ngrams: int,\n",
    "    feature_name: str,\n",
    "    # feat_type: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vocab_gcs_uri', str),\n",
    "    # ('feature_name', str),\n",
    "]):\n",
    "\n",
    "    \"\"\"\n",
    "    custom pipeline component to adapt the `pl_name_src` layer\n",
    "    writes vocab to pickled dict in GCS\n",
    "    dict combined with other layer vocabs and used in Two Tower training\n",
    "    \"\"\"\n",
    "    \n",
    "    # import packages\n",
    "    import os\n",
    "    import logging\n",
    "    import pickle as pkl\n",
    "    import time\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # setup clients\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    logging.info(f\"feature_name: {feature_name}\")\n",
    "    # logging.info(f\"feat_type: {feat_type}\")\n",
    "    \n",
    "    MAX_PLAYLIST_LENGTH = max_playlist_length\n",
    "    logging.info(f\"MAX_PLAYLIST_LENGTH: {MAX_PLAYLIST_LENGTH}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # tfrecord parser\n",
    "    # ===================================================\n",
    "    feats = {\n",
    "        # ===================================================\n",
    "        # candidate track features\n",
    "        # ===================================================\n",
    "        \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "        \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "        \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "        \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "        \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "        \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"time_signature_can\": tf.io.FixedLenFeature(dtype=tf.string, shape=()), # track_time_signature_can\n",
    "    \n",
    "        # ===================================================\n",
    "        # summary playlist features\n",
    "        # ===================================================\n",
    "        \"pl_name_src\" : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "        'pl_collaborative_src' : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "        # 'num_pl_followers_src' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        'pl_duration_ms_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        'num_pl_songs_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), # n_songs_pl_new | num_pl_songs_new\n",
    "        'num_pl_artists_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        'num_pl_albums_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        # 'avg_track_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        # 'avg_artist_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        # 'avg_art_followers_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "\n",
    "        # ===================================================\n",
    "        # ragged playlist features\n",
    "        # ===================================================\n",
    "        # bytes / string\n",
    "        \"track_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"album_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"album_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_genres_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        # \"tracks_playlist_titles_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_key_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_mode_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"time_signature_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "\n",
    "        # Float List\n",
    "        \"duration_ms_songs_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artists_followers_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_danceability_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_energy_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_loudness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_speechiness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_acousticness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_instrumentalness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_liveness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_valence_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_tempo_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    }\n",
    "    \n",
    "    # parsing function\n",
    "    def parse_tfrecord(example):\n",
    "        \"\"\"\n",
    "        Reads a serialized example from GCS and converts to tfrecord\n",
    "        \"\"\"\n",
    "        # example = tf.io.parse_single_example(\n",
    "        example = tf.io.parse_example(\n",
    "            example,\n",
    "            feats\n",
    "            # features=feats\n",
    "        )\n",
    "        return example\n",
    "\n",
    "    # list blobs (tfrecords)\n",
    "    train_files = []\n",
    "    for blob in storage_client.list_blobs(f'{data_dir_bucket_name}', prefix=f'{data_dir_path_prefix}'):\n",
    "        if '.tfrecords' in blob.name:\n",
    "            train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "#     for blob in storage_client.list_blobs(f'{data_dir_bucket_name}', prefix=f'{data_dir_path_prefix}', delimiter=\"/\"):\n",
    "#         train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "#     # skip folder path prefix\n",
    "#     train_files = train_files[1:]\n",
    "    logging.info(f\"TFRecord file count: {len(train_files)}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # create TF dataset\n",
    "    # ===================================================\n",
    "    logging.info(f\"Creating TFRecordDataset...\")\n",
    "    train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "    train_parsed = train_dataset.map(parse_tfrecord)\n",
    "    \n",
    "    # ===================================================\n",
    "    # adapt layer for feature\n",
    "    # ===================================================\n",
    "    \n",
    "    # if feat_type == 'ragged':\n",
    "    #     start = time.time()\n",
    "    #     text_layer = tf.keras.layers.TextVectorization()\n",
    "    #     text_layer.adapt(train_parsed.map(lambda x: tf.reshape(x[f'{feature_name}'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "    #     end = time.time()\n",
    "    # else:\n",
    "    #     start = time.time()\n",
    "    #     text_layer = tf.keras.layers.TextVectorization()\n",
    "    #     text_layer.adapt(train_parsed.map(lambda x: x[f'{feature_name}']))\n",
    "    #     end = time.time()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    text_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens,\n",
    "        ngrams=ngrams\n",
    "    )\n",
    "    \n",
    "    text_layer.adapt(train_parsed.map(lambda x: x[f'{feature_name}']))\n",
    "    end = time.time()\n",
    "\n",
    "    logging.info(f'Layer adapt elapsed time: {round((end - start), 2)} seconds')\n",
    "    \n",
    "    # ===================================================\n",
    "    # test layer\n",
    "    # ===================================================\n",
    "#     logging.info(f\"Inspect {feature_name} layer's tokens and learned vocab...\")\n",
    "    \n",
    "#     for row in train_parsed.batch(1).map(lambda x: x[f'{feature_name}']).take(1):\n",
    "#       logging.info(f\"{feature_name} tokens: {text_layer(row)}\")\n",
    "        \n",
    "#     logging.info(f\"{feature_name} vocab: {text_layer.get_vocabulary()[0:5]}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # write vocab to pickled dict --> gcs\n",
    "    # ===================================================\n",
    "    logging.info(f\"Writting pickled dict to GCS...\")\n",
    "                 \n",
    "    VOCAB_LOCAL_FILE = f'{feature_name}_vocab_dict.pkl'\n",
    "    VOCAB_GCS_OBJ = f'{vocab_path_prefix}/{VOCAB_LOCAL_FILE}' # destination folder prefix and blob name\n",
    "    VOCAB_DICT = {f'{feature_name}' : text_layer.get_vocabulary(),}\n",
    "    \n",
    "    logging.info(f\"VOCAB_LOCAL_FILE: {VOCAB_LOCAL_FILE}\")\n",
    "    logging.info(f\"VOCAB_GCS_OBJ: {VOCAB_GCS_OBJ}\")\n",
    "\n",
    "    # pickle\n",
    "    filehandler = open(f'{VOCAB_LOCAL_FILE}', 'wb')\n",
    "    pkl.dump(VOCAB_DICT, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # upload to GCS\n",
    "    bucket_client = storage_client.bucket(data_dir_bucket_name)\n",
    "    blob = bucket_client.blob(VOCAB_GCS_OBJ)\n",
    "    blob.upload_from_filename(VOCAB_LOCAL_FILE)\n",
    "    \n",
    "    vocab_uri = f'gs://{data_dir_bucket_name}/{VOCAB_GCS_OBJ}'\n",
    "    \n",
    "    logging.info(f\"File {VOCAB_LOCAL_FILE} uploaded to {vocab_uri}\")\n",
    "    \n",
    "    return(\n",
    "        vocab_uri,\n",
    "        # feature_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673ecaf8-79d0-48e1-adbb-76dd86cf3dcd",
   "metadata": {},
   "source": [
    "### ragged adapts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd9e03c-4f19-44f9-b613-23238b0a3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/vocab_pipes/adapt_ragged_text_layer_vocab.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/adapt_ragged_text_layer_vocab.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        # 'google-cloud-aiplatform==1.18.1',\n",
    "        'google-cloud-storage',\n",
    "        'tensorflow==2.8.3',\n",
    "    ],\n",
    ")\n",
    "def adapt_ragged_text_layer_vocab(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    data_dir_bucket_name: str,\n",
    "    data_dir_path_prefix: str,\n",
    "    vocab_path_prefix: str,\n",
    "    max_playlist_length: int,\n",
    "    max_tokens: int,\n",
    "    ngrams: int,\n",
    "    feature_name: str,\n",
    "    # feat_type: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vocab_gcs_uri', str),\n",
    "    # ('feature_name', str),\n",
    "]):\n",
    "\n",
    "    \"\"\"\n",
    "    custom pipeline component to adapt the `pl_name_src` layer\n",
    "    writes vocab to pickled dict in GCS\n",
    "    dict combined with other layer vocabs and used in Two Tower training\n",
    "    \"\"\"\n",
    "    \n",
    "    # import packages\n",
    "    import os\n",
    "    import logging\n",
    "    import pickle as pkl\n",
    "    import time\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # setup clients\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    logging.info(f\"feature_name: {feature_name}\")\n",
    "    # logging.info(f\"feat_type: {feat_type}\")\n",
    "    \n",
    "    MAX_PLAYLIST_LENGTH = max_playlist_length\n",
    "    logging.info(f\"MAX_PLAYLIST_LENGTH: {MAX_PLAYLIST_LENGTH}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # tfrecord parser\n",
    "    # ===================================================\n",
    "    feats = {\n",
    "        # ===================================================\n",
    "        # candidate track features\n",
    "        # ===================================================\n",
    "        \"track_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),            \n",
    "        \"track_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"artist_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"artist_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"album_uri_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),           \n",
    "        \"album_name_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "        \"duration_ms_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "        \"track_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),      \n",
    "        \"artist_pop_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"artist_genres_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"artist_followers_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        # \"track_pl_titles_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"track_danceability_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_energy_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_key_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"track_loudness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_mode_can\":tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "        \"track_speechiness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_acousticness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_instrumentalness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_liveness_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_valence_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"track_tempo_can\":tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        \"time_signature_can\": tf.io.FixedLenFeature(dtype=tf.string, shape=()), # track_time_signature_can\n",
    "    \n",
    "        # ===================================================\n",
    "        # summary playlist features\n",
    "        # ===================================================\n",
    "        \"pl_name_src\" : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "        'pl_collaborative_src' : tf.io.FixedLenFeature(dtype=tf.string, shape=()), \n",
    "        # 'num_pl_followers_src' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        'pl_duration_ms_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        'num_pl_songs_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), # n_songs_pl_new | num_pl_songs_new\n",
    "        'num_pl_artists_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "        'num_pl_albums_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        # 'avg_track_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        # 'avg_artist_pop_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "        # 'avg_art_followers_pl_new' : tf.io.FixedLenFeature(dtype=tf.float32, shape=()), \n",
    "\n",
    "        # ===================================================\n",
    "        # ragged playlist features\n",
    "        # ===================================================\n",
    "        # bytes / string\n",
    "        \"track_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"album_uri_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"album_name_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_genres_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        # \"tracks_playlist_titles_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_key_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_mode_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"time_signature_pl\": tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)), \n",
    "\n",
    "        # Float List\n",
    "        \"duration_ms_songs_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artist_pop_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"artists_followers_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_danceability_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_energy_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_loudness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_speechiness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_acousticness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_instrumentalness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_liveness_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_valence_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "        \"track_tempo_pl\": tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    }\n",
    "    \n",
    "    # parsing function\n",
    "    def parse_tfrecord(example):\n",
    "        \"\"\"\n",
    "        Reads a serialized example from GCS and converts to tfrecord\n",
    "        \"\"\"\n",
    "        # example = tf.io.parse_single_example(\n",
    "        example = tf.io.parse_example(\n",
    "            example,\n",
    "            feats\n",
    "            # features=feats\n",
    "        )\n",
    "        return example\n",
    "\n",
    "    # list blobs (tfrecords)\n",
    "    train_files = []\n",
    "    for blob in storage_client.list_blobs(f'{data_dir_bucket_name}', prefix=f'{data_dir_path_prefix}'):\n",
    "        if '.tfrecords' in blob.name:\n",
    "            train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "#     for blob in storage_client.list_blobs(f'{data_dir_bucket_name}', prefix=f'{data_dir_path_prefix}', delimiter=\"/\"):\n",
    "#         train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "#     # skip folder path prefix\n",
    "#     train_files = train_files[1:]\n",
    "    logging.info(f\"TFRecord file count: {len(train_files)}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # create TF dataset\n",
    "    # ===================================================\n",
    "    logging.info(f\"Creating TFRecordDataset...\")\n",
    "    train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "    train_parsed = train_dataset.map(parse_tfrecord)\n",
    "    \n",
    "    # ===================================================\n",
    "    # adapt layer for feature\n",
    "    # ===================================================\n",
    "    \n",
    "    # if feat_type == 'ragged':\n",
    "    #     start = time.time()\n",
    "    #     text_layer = tf.keras.layers.TextVectorization()\n",
    "    #     text_layer.adapt(train_parsed.map(lambda x: tf.reshape(x[f'{feature_name}'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "    #     end = time.time()\n",
    "    # else:\n",
    "    #     start = time.time()\n",
    "    #     text_layer = tf.keras.layers.TextVectorization()\n",
    "    #     text_layer.adapt(train_parsed.map(lambda x: x[f'{feature_name}']))\n",
    "    #     end = time.time()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    text_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens,\n",
    "        ngrams=ngrams\n",
    "    )\n",
    "    \n",
    "    text_layer.adapt(train_parsed.map(lambda x: tf.reshape(x[f'{feature_name}'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "    end = time.time()\n",
    "\n",
    "    logging.info(f'Layer adapt elapsed time: {round((end - start), 2)} seconds')\n",
    "    \n",
    "    # ===================================================\n",
    "    # test layer\n",
    "    # ===================================================\n",
    "#     logging.info(f\"Inspect {feature_name} layer's tokens and learned vocab...\")\n",
    "    \n",
    "#     for row in train_parsed.batch(1).map(lambda x: x[f'{feature_name}']).take(1):\n",
    "#       logging.info(f\"{feature_name} tokens: {text_layer(row)}\")\n",
    "        \n",
    "#     logging.info(f\"{feature_name} vocab: {text_layer.get_vocabulary()[0:5]}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # write vocab to pickled dict --> gcs\n",
    "    # ===================================================\n",
    "    logging.info(f\"Writting pickled dict to GCS...\")\n",
    "                 \n",
    "    VOCAB_LOCAL_FILE = f'{feature_name}_vocab_dict.pkl'\n",
    "    VOCAB_GCS_OBJ = f'{vocab_path_prefix}/{VOCAB_LOCAL_FILE}' # destination folder prefix and blob name\n",
    "    VOCAB_DICT = {f'{feature_name}' : text_layer.get_vocabulary(),}\n",
    "    \n",
    "    logging.info(f\"VOCAB_LOCAL_FILE: {VOCAB_LOCAL_FILE}\")\n",
    "    logging.info(f\"VOCAB_GCS_OBJ: {VOCAB_GCS_OBJ}\")\n",
    "\n",
    "    # pickle\n",
    "    filehandler = open(f'{VOCAB_LOCAL_FILE}', 'wb')\n",
    "    pkl.dump(VOCAB_DICT, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # upload to GCS\n",
    "    bucket_client = storage_client.bucket(data_dir_bucket_name)\n",
    "    blob = bucket_client.blob(VOCAB_GCS_OBJ)\n",
    "    blob.upload_from_filename(VOCAB_LOCAL_FILE)\n",
    "    \n",
    "    vocab_uri = f'gs://{data_dir_bucket_name}/{VOCAB_GCS_OBJ}'\n",
    "    \n",
    "    logging.info(f\"File {VOCAB_LOCAL_FILE} uploaded to {vocab_uri}\")\n",
    "    \n",
    "    return(\n",
    "        vocab_uri,\n",
    "        # feature_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2eb698-ff93-4f2f-a413-6424b608b619",
   "metadata": {},
   "source": [
    "### create master vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a4fd88-85c5-4687-a70a-8fce50444117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/vocab_pipes/create_master_vocab.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_master_vocab.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        # 'google-cloud-aiplatform==1.18.1',\n",
    "        'google-cloud-storage',\n",
    "        'numpy',\n",
    "        # 'tensorflow==2.8.3',\n",
    "    ],\n",
    ")\n",
    "def create_master_vocab(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    data_dir_bucket_name: str,\n",
    "    data_dir_path_prefix: str,\n",
    "    vocab_path_prefix: str,\n",
    "    master_dict_path_prefix: str,\n",
    "    vocab_uri_1: str,\n",
    "    vocab_uri_2: str,\n",
    "    vocab_uri_3: str,\n",
    "    vocab_uri_4: str,\n",
    "    vocab_uri_5: str,\n",
    "    vocab_uri_6: str,\n",
    "    vocab_uri_7: str,\n",
    "    vocab_uri_8: str,\n",
    "    vocab_uri_9: str,\n",
    "    # vocab_uri_10: str,\n",
    "    # vocab_uri_11: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('master_vocab_gcs_uri', str),\n",
    "    # ('feature_name': str),\n",
    "]):\n",
    "\n",
    "    \"\"\"\n",
    "    combine layer dictionaires to master dictionary\n",
    "    master dictionary passed to train job for layer vocabs\n",
    "    \"\"\"\n",
    "    \n",
    "    # import packages\n",
    "    import os\n",
    "    import logging\n",
    "    import pickle as pkl\n",
    "    import time\n",
    "    import numpy as np\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    \n",
    "    # setup clients\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # ===================================================\n",
    "    # Create list of all layer vocab dict uris\n",
    "    # ===================================================\n",
    "    \n",
    "    vocab_dict_uris = [\n",
    "        vocab_uri_1, vocab_uri_2, \n",
    "        vocab_uri_3, vocab_uri_4, \n",
    "        vocab_uri_5, vocab_uri_6, \n",
    "        vocab_uri_7, vocab_uri_8, \n",
    "        vocab_uri_9, \n",
    "        # vocab_uri_10, \n",
    "        # vocab_uri_11,\n",
    "    ]\n",
    "        \n",
    "    # vocab_dict_uris = []\n",
    "    # for blob in storage_client.list_blobs(f'{data_dir_bucket_name}', prefix=f'{vocab_path_prefix}'):\n",
    "    #     if '.pkl' in blob.name:\n",
    "    #         vocab_dict_uris.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "        \n",
    "    # logging.info(f\"vocab_dict_uris[0]: {vocab_dict_uris[0]}\")\n",
    "    \n",
    "    # skip folder path prefix\n",
    "    # vocab_dict_uris = vocab_dict_uris[1:]\n",
    "    logging.info(f\"count of vocab_dict_uris: {len(vocab_dict_uris)}\")\n",
    "    logging.info(f\"vocab_dict_uris: {vocab_dict_uris}\")\n",
    "    \n",
    "    # ===================================================\n",
    "    # load pickled dicts\n",
    "    # ===================================================\n",
    "    \n",
    "    loaded_pickle_list = []\n",
    "    for i, pickled_dict in enumerate(vocab_dict_uris):\n",
    "        \n",
    "        with open(f\"v{i}_vocab_pre_load\", 'wb') as local_vocab_file:\n",
    "            storage_client.download_blob_to_file(pickled_dict, local_vocab_file)\n",
    "\n",
    "        with open(f\"v{i}_vocab_pre_load\", 'rb') as pickle_file:\n",
    "            loaded_vocab_dict = pkl.load(pickle_file)\n",
    "            \n",
    "        loaded_pickle_list.append(loaded_vocab_dict)\n",
    "        \n",
    "    # ===================================================\n",
    "    # create master vocab dict\n",
    "    # ===================================================\n",
    "    master_dict = {}\n",
    "    for loaded_dict in loaded_pickle_list:\n",
    "        master_dict.update(loaded_dict)\n",
    "    \n",
    "    # ===================================================\n",
    "    # Upload master to GCS\n",
    "    # ===================================================\n",
    "    MASTER_VOCAB_LOCAL_FILE = f'{version}_master_vocab_dict.pkl'\n",
    "    MASTER_VOCAB_GCS_OBJ = f'{master_dict_path_prefix}/{MASTER_VOCAB_LOCAL_FILE}' # destination folder prefix and blob name\n",
    "    \n",
    "    # pickle\n",
    "    filehandler = open(f'{MASTER_VOCAB_LOCAL_FILE}', 'wb')\n",
    "    pkl.dump(master_dict, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # upload to GCS\n",
    "    bucket_client = storage_client.bucket(data_dir_bucket_name)\n",
    "    blob = bucket_client.blob(MASTER_VOCAB_GCS_OBJ)\n",
    "    blob.upload_from_filename(MASTER_VOCAB_LOCAL_FILE)\n",
    "    \n",
    "    master_vocab_uri = f'gs://{data_dir_bucket_name}/{MASTER_VOCAB_GCS_OBJ}'\n",
    "    \n",
    "    logging.info(f\"File {MASTER_VOCAB_LOCAL_FILE} uploaded to {master_vocab_uri}\")\n",
    "    \n",
    "    return(\n",
    "        master_vocab_uri,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e2e55-7775-485c-84d9-cf463a554f6a",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66001b7d-37c6-4eab-80f3-90a47cdd72c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/vocab_pipes/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/config.py\n",
    "\n",
    "\"\"\"Vertex pipeline configurations.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\", \"\")\n",
    "LOCATION = os.getenv(\"LOCATION\", \"us-central1\")\n",
    "BUCKET = os.getenv(\"BUCKET\", \"\")\n",
    "\n",
    "INSTANCE_TYPE = os.getenv(\"INSTANCE_TYPE\", \"n1-highmem-64\")\n",
    "CPU_LIMIT = os.getenv(\"CPU_LIMIT\", \"64\")\n",
    "MEMORY_LIMIT = os.getenv(\"MEMORY_LIMIT\", \"416\")\n",
    "GPU_LIMIT = os.getenv(\"GPU_LIMIT\", \"4\")\n",
    "GPU_TYPE = os.getenv(\"GPU_TYPE\", \"NVIDIA_TESLA_T4\")\n",
    "\n",
    "MACHINE_TYPE = os.getenv(\"MACHINE_TYPE\", \"a2-highgpu-4g\")\n",
    "REPLICA_COUNT = os.getenv(\"REPLICA_COUNT\", \"1\")\n",
    "ACCELERATOR_TYPE = os.getenv(\"ACCELERATOR_TYPE\", \"NVIDIA_TESLA_A100\")\n",
    "ACCELERATOR_NUM = os.getenv(\"ACCELERATOR_NUM\", \"4\")\n",
    "NUM_WORKERS = os.getenv(\"NUM_WORKERS\", \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce9ebc-64aa-4d45-a3e0-1f5abf381d3d",
   "metadata": {},
   "source": [
    "## Build & Compile Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe35298-56e6-45cd-8a1b-4d86194e5362",
   "metadata": {},
   "source": [
    "`parallelFor` [docs](https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#kfp.dsl.ParallelFor)\n",
    "\n",
    "```\n",
    "with dsl.ParallelFor([{'a': 1, 'b': 10}, {'a': 2, 'b': 20}]) as item:\n",
    "  op1 = ContainerOp(..., args=['echo {}'.format(item.a)])\n",
    "  op2 = ContainerOp(..., args=['echo {}'.format(item.b])\n",
    "```\n",
    "\n",
    "> In this case `op1` would be executed twice, once with case `args=['echo 1']` and once with case `args=['echo 2']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85361b93-cd13-4f9e-a5ad-d5778408f5de",
   "metadata": {},
   "source": [
    "aggregating output \n",
    "* [stack overflow](https://stackoverflow.com/questions/73052584/set-the-name-for-each-parallelfor-iteration-in-kfp-v2-on-vertex-ai)\n",
    "* [github issue](https://github.com/kubeflow/pipelines/issues/3412)\n",
    "```\n",
    "@func_to_container_op\n",
    "def print_results(results: ForLoopResults()):\n",
    "    print(results[\"process_parameters\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428691fc-51ea-4cf3-9be7-5b40a3d16af2",
   "metadata": {},
   "source": [
    "### pipe configs\n",
    "\n",
    "* see [example](https://github.com/GoogleCloudPlatform/nvidia-merlin-on-vertex-aihttps://github.com/GoogleCloudPlatform/nvidia-merlin-on-vertex-ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac35db12-ab23-47a2-bc99-357b8575ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: tfrs-vocab-pipe-jtv10\n"
     ]
    }
   ],
   "source": [
    "os.environ['PROJECT_ID'] = PROJECT_ID\n",
    "os.environ['LOCATION'] = LOCATION\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "\n",
    "PIPELINE_VERSION = 'jtv10' # pipeline code\n",
    "PIPELINE_TAG = f'tfrs-vocab-pipe-{PIPELINE_VERSION}'\n",
    "\n",
    "os.environ['PIPELINE_VERSION'] = PIPELINE_VERSION\n",
    "os.environ['PIPELINE_TAG'] = PIPELINE_TAG\n",
    "\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)\n",
    "\n",
    "# Instance configuration\n",
    "GPU_LIMIT = '8'\n",
    "GPU_TYPE = 'NVIDIA_TESLA_A100'\n",
    "CPU_LIMIT = '96'\n",
    "MEMORY_LIMIT = '624' # '680'\n",
    "\n",
    "os.environ['GPU_LIMIT'] = GPU_LIMIT\n",
    "os.environ['GPU_TYPE'] = GPU_TYPE\n",
    "os.environ['CPU_LIMIT'] = CPU_LIMIT\n",
    "os.environ['MEMORY_LIMIT'] = MEMORY_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c895c844-93bb-492c-977c-0e91a7d0032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vocab_pipes import adapt_ragged_text_layer_vocab, adapt_fixed_text_layer_vocab, create_master_vocab, config\n",
    "\n",
    "@kfp.v2.dsl.pipeline(\n",
    "    name=f'{PIPELINE_VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    pipeline_version: str,\n",
    "    data_version: str,\n",
    "    data_dir_bucket_name: str,\n",
    "    data_dir_path_prefix: str,\n",
    "    vocab_path_prefix: str,\n",
    "    master_dict_path_prefix: str,\n",
    "    max_playlist_length: int,\n",
    "    max_tokens: int,\n",
    "    ngrams: int,\n",
    "    # feature_name_list: str,\n",
    "    fixed_features_list: list,\n",
    "    ragged_features_list: list,\n",
    "):\n",
    "    \n",
    "    from kfp.v2.components import importer_node\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    \n",
    "    # ================================================================================\n",
    "    # ParallelFor with feature lists\n",
    "    # ================================================================================\n",
    "    \n",
    "#     # ====================================================\n",
    "#     # fixed-length features\n",
    "#     # ====================================================\n",
    "    \n",
    "#     fixed_for_loop_op = kfp.dsl.ParallelFor(fixed_features_list)\n",
    "    \n",
    "#     with fixed_for_loop_op as fixed_feat_param:\n",
    "        \n",
    "#         adapt_fixed_features_op = (\n",
    "#             adapt_fixed_text_layer_vocab.adapt_fixed_text_layer_vocab(\n",
    "#                 project=project,\n",
    "#                 location=location,\n",
    "#                 version=pipeline_version,\n",
    "#                 data_dir_bucket_name=data_dir_bucket_name,\n",
    "#                 data_dir_path_prefix=data_dir_path_prefix,\n",
    "#                 vocab_path_prefix=vocab_path_prefix,\n",
    "#                 max_playlist_length=max_playlist_length,\n",
    "#                 feature_name=fixed_feat_param,\n",
    "#             )\n",
    "#             .set_display_name(f\"adapt: {fixed_feat_param}\") # fixed_features_list\n",
    "#             # .set_caching_options(True)\n",
    "#         )\n",
    "        \n",
    "#     # ====================================================\n",
    "#     # ragged features\n",
    "#     # ====================================================\n",
    "        \n",
    "#     ragged_for_loop_op = kfp.dsl.ParallelFor(ragged_features_list)\n",
    "    \n",
    "#     with ragged_for_loop_op as ragged_feat_param:\n",
    "        \n",
    "#         adapt_ragged_features_op = (\n",
    "#             adapt_ragged_text_layer_vocab.adapt_ragged_text_layer_vocab(\n",
    "#                 project=project,\n",
    "#                 location=location,\n",
    "#                 version=pipeline_version,\n",
    "#                 data_dir_bucket_name=data_dir_bucket_name,\n",
    "#                 data_dir_path_prefix=data_dir_path_prefix,\n",
    "#                 vocab_path_prefix=vocab_path_prefix,\n",
    "#                 max_playlist_length=max_playlist_length,\n",
    "#                 feature_name=ragged_feat_param,\n",
    "#             )\n",
    "#             .set_display_name(f\"adapt: {ragged_feat_param}\") # ragged_features_list\n",
    "#             # .set_caching_options(True)\n",
    "#         )\n",
    "        \n",
    "    # ================================================================================\n",
    "    # explicit components\n",
    "    # ================================================================================\n",
    "    # fixed length feats\n",
    "\n",
    "    # pl_name_src\n",
    "    adapt_pl_name_src_op = (\n",
    "        adapt_fixed_text_layer_vocab.adapt_fixed_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='pl_name_src',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: pl_name_src\")\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # track_name_can\n",
    "    adapt_track_name_can_op = (\n",
    "        adapt_fixed_text_layer_vocab.adapt_fixed_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='track_name_can',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: track_name_can\")\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    # artist_name_can\n",
    "    adapt_artist_name_can_op = (\n",
    "        adapt_fixed_text_layer_vocab.adapt_fixed_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='artist_name_can',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: artist_name_can\")\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    # album_name_can\n",
    "    adapt_album_name_can_op = (\n",
    "        adapt_fixed_text_layer_vocab.adapt_fixed_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='album_name_can',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: album_name_can\")\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    # artist_genres_can\n",
    "    adapt_artist_genres_can_op = (\n",
    "        adapt_fixed_text_layer_vocab.adapt_fixed_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='artist_genres_can',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: artist_genres_can\")\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "        \n",
    "    # raggeds       \n",
    "\n",
    "    # track_name_pl\n",
    "    adapt_track_name_pl_features_op = (\n",
    "        adapt_ragged_text_layer_vocab.adapt_ragged_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='track_name_pl',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: track_name_pl\") # ragged_features_list\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    # artist_name_pl\n",
    "    adapt_artist_name_pl_op = (\n",
    "        adapt_ragged_text_layer_vocab.adapt_ragged_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='artist_name_pl',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: artist_name_pl\") # ragged_features_list\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    # album_name_pl\n",
    "    adapt_album_name_pl_op = (\n",
    "        adapt_ragged_text_layer_vocab.adapt_ragged_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='album_name_pl',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: album_name_pl\") # ragged_features_list\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "    # artist_genres_pl\n",
    "    adapt_artist_genres_pl_op = (\n",
    "        adapt_ragged_text_layer_vocab.adapt_ragged_text_layer_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            max_playlist_length=max_playlist_length,\n",
    "            max_tokens=max_tokens,\n",
    "            ngrams=ngrams,\n",
    "            feature_name='artist_genres_pl',\n",
    "        )\n",
    "        .set_display_name(f\"adapt: artist_genres_pl\") # ragged_features_list\n",
    "        .set_cpu_limit(config.CPU_LIMIT)\n",
    "        .set_memory_limit(config.MEMORY_LIMIT)\n",
    "        # .set_gpu_limit(config.GPU_LIMIT)\n",
    "        # .set_caching_options(True)\n",
    "    )\n",
    "        \n",
    "        \n",
    "    # ====================================================\n",
    "    # Aggregate all Dicts\n",
    "    # ====================================================\n",
    "    \n",
    "    create_master_vocab_op = (\n",
    "        create_master_vocab.create_master_vocab(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=pipeline_version,\n",
    "            data_dir_bucket_name=data_dir_bucket_name,\n",
    "            data_dir_path_prefix=data_dir_path_prefix,\n",
    "            vocab_path_prefix=vocab_path_prefix,\n",
    "            master_dict_path_prefix=master_dict_path_prefix,\n",
    "            vocab_uri_1=adapt_pl_name_src_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_2=adapt_track_name_can_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_3=adapt_artist_name_can_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_4=adapt_album_name_can_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_5=adapt_artist_genres_can_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_6=adapt_track_name_pl_features_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_7=adapt_artist_name_pl_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_8=adapt_album_name_pl_op.outputs['vocab_gcs_uri'], \n",
    "            vocab_uri_9=adapt_artist_genres_pl_op.outputs['vocab_gcs_uri'],\n",
    "        )\n",
    "        # .after(fixed_for_loop_op).after(ragged_for_loop_op)\n",
    "        .set_display_name(\"create master vocab\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db718ec4-95d4-4723-8994-9681cc7b63c3",
   "metadata": {},
   "source": [
    "## Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29630306-e45f-4525-8f16-6b0aa20c9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPE_GCS_DIR: gs://spotify-data-regimes/jtv10/vocab-pipelines-root/jtv10\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'spotify-data-regimes'\n",
    "BUCKET_URI = f'gs://{BUCKET}'\n",
    "PIPELINE_ROOT = 'vocab-pipelines-root'\n",
    "DATA_VERSION = 'jtv10'\n",
    "PIPE_GCS_DIR = f'{BUCKET_URI}/{DATA_VERSION}/{PIPELINE_ROOT}/{PIPELINE_VERSION}'\n",
    "print(f\"PIPE_GCS_DIR: {PIPE_GCS_DIR}\")\n",
    "\n",
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "PIPELINES_SUB_DIR = 'vocab_pipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32ee678b-3c0f-4d21-94fb-edc75d8a4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b167df1-7bba-4eb2-b218-1bf2f97308bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://custom_container_pipeline_spec.json [Content-Type=application/json]...\n",
      "/ [1 files][143.5 KiB/143.5 KiB]                                                \n",
      "Operation completed over 1 objects/143.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp custom_container_pipeline_spec.json $PIPE_GCS_DIR/pipeline_spec.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e710cf5-c226-4f74-aa8c-64baf5f99845",
   "metadata": {},
   "source": [
    "### pipeline args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bed7fb6d-883a-4405-8b73-f8a023329d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_path_prefix: jtv10/vocabs/layer-dicts-jtv10\n"
     ]
    }
   ],
   "source": [
    "project = PROJECT_ID\n",
    "location = LOCATION\n",
    "\n",
    "data_dir_bucket_name = 'spotify-data-regimes'\n",
    "data_dir_path_prefix = f'{DATA_VERSION}/train_v9' # train_minimum | 'train_subset | train_flat_last_5_v8\n",
    "# vocab_path_prefix = \"jtv8/test_vocabs\"\n",
    "vocab_path_prefix = f\"{DATA_VERSION}/vocabs/layer-dicts-{PIPELINE_VERSION}\"\n",
    "master_dict_path_prefix = f'{DATA_VERSION}/vocabs'\n",
    "\n",
    "max_playlist_length = 5\n",
    "fixed_features_list = [\n",
    "    'pl_name_src',\n",
    "    'track_name_can',\n",
    "    'artist_name_can',\n",
    "    'album_name_can',\n",
    "    'artist_genres_can',\n",
    "    # 'track_pl_titles_can',\n",
    "]\n",
    "\n",
    "ragged_features_list = [\n",
    "    'track_name_pl',\n",
    "    'artist_name_pl',\n",
    "    'album_name_pl',\n",
    "    'artist_genres_pl',\n",
    "    # 'tracks_playlist_titles_pl',\n",
    "]\n",
    "\n",
    "print(f\"vocab_path_prefix: {vocab_path_prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7f59c-0331-40d6-ba24-5d38cccfaee7",
   "metadata": {},
   "source": [
    "## submit pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c6dc45-80ff-43a3-a3e0-09821ce233e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018?project=934903580331\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/jtv10-tfrs-vocab-pipe-jtv10-20221228055018 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "overwrite = True\n",
    "\n",
    "job = vertex_ai.PipelineJob(\n",
    "    display_name=f'{PIPELINE_VERSION}-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "    template_path='custom_container_pipeline_spec.json',\n",
    "    pipeline_root=f'{PIPE_GCS_DIR}',\n",
    "    # enable_caching=False,\n",
    "    parameter_values={\n",
    "        'project': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'pipeline_version': PIPELINE_VERSION,\n",
    "        'data_version': DATA_VERSION,\n",
    "        'data_dir_bucket_name': data_dir_bucket_name,\n",
    "        'data_dir_path_prefix': data_dir_path_prefix,\n",
    "        'vocab_path_prefix': vocab_path_prefix,\n",
    "        'master_dict_path_prefix': master_dict_path_prefix,\n",
    "        'max_playlist_length': 5,\n",
    "        'max_tokens': 20000,\n",
    "        'ngrams': 2,\n",
    "        # 'feature_name_list': feature_name_list,  # regular list\n",
    "        'fixed_features_list': fixed_features_list,\n",
    "        'ragged_features_list': ragged_features_list,\n",
    "    },\n",
    ")\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bce68c-e259-4c09-bd41-4e42ad45e845",
   "metadata": {},
   "source": [
    "# Local Testing (wip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48c0b528-f512-475a-a095-5b58a662e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "train_dir = 'spotify-data-regimes'\n",
    "train_dir_prefix = 'jtv8/train_minimum' # train_minimum | train_subset\n",
    "delimiter = '/'\n",
    "\n",
    "train_files = []\n",
    "# for blob in storage_client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}', delimiter=f'{delimiter}'):\n",
    "for blob in storage_client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d512cc18-79cd-4d55-a01c-5c94f7ab2161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://spotify-data-regimes/jtv8/train_minimum/-00000-of-02375.tfrecords',\n",
       " 'gs://spotify-data-regimes/jtv8/train_minimum/-00001-of-02375.tfrecords']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad639b8a-dcf8-4d02-994a-f76efd0012b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:56:36.479899: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 19:56:37.179742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37629 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from two_tower_jt import two_tower as tt\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(train_files_n).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "train_parsed = train_dataset.map(tt.parse_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63049381-7b01-4baf-ad2f-0beadfabb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20feb02a-2355-4729-b137-c0fbf61b8119",
   "metadata": {},
   "source": [
    "## test layer adapts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db07e83e-f898-4390-9aa9-a876a79da25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLAYLIST_LENGTH=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a97c2-d4b6-402e-b53b-843a16e597b2",
   "metadata": {},
   "source": [
    "### adapt test `track_name_pl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e9751f-6558-4441-9e82-fb9a0e06eac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 101.56 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# pl_name_src\n",
    "track_name_pl_text_layer = tf.keras.layers.TextVectorization()\n",
    "track_name_pl_text_layer.adapt(train_parsed.map(lambda x: x['track_name_pl']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fc578b6-419d-432a-8548-d520984a9c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'you', 'feat']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_name_pl_text_layer.get_vocabulary()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "976655eb-e497-49f3-ad10-b1d3d6fd3b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 95.15 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# pl_name_src\n",
    "track_name_pl_text_layer_2 = tf.keras.layers.TextVectorization()\n",
    "track_name_pl_text_layer_2.adapt(train_parsed.map(lambda x: tf.reshape(x['track_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b49d85e4-0eee-4211-8f2e-50e526ad205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'you', 'feat']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_name_pl_text_layer_2.get_vocabulary()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad9e6b-df03-4004-a92f-efdf8665f3a0",
   "metadata": {},
   "source": [
    "### adapt test `artist_name_pl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75641755-f19a-4eec-9e72-b6bc781f69a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb240a-c7bd-47ee-9b17-218cf4b205d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aa84040-355b-44ab-a1c3-cd66c14ed79d",
   "metadata": {},
   "source": [
    "### adapt test `album_name_pl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3cb79-e25e-4aa8-8dc0-da617b36109f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7674f32-c43d-4ad9-8944-27468f444a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e757688e-86b4-46d9-bc88-438951cfd6d2",
   "metadata": {},
   "source": [
    "### adapt test `artist_genres_pl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd73555f-5b89-4d4e-b212-f2957b6d7b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 98.09 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# pl_name_src\n",
    "artist_genres_pl_text_layer = tf.keras.layers.TextVectorization()\n",
    "artist_genres_pl_text_layer.adapt(train_parsed.map(lambda x: x['artist_genres_pl']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f1129f4-40ab-4e62-b9ae-88f82476d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'pop', 'rock', 'rap']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_genres_pl_text_layer.get_vocabulary()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ed24b-4372-4b90-968f-039996fd0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# pl_name_src\n",
    "artist_genres_pl_text_layer_2 = tf.keras.layers.TextVectorization()\n",
    "artist_genres_pl_text_layer_2.adapt(train_parsed.map(lambda x: tf.reshape(x['artist_genres_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428ef79-6b2e-474a-b898-7fa397f88f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_genres_pl_text_layer_2.get_vocabulary()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88080573-8271-4031-829a-6a543a582676",
   "metadata": {},
   "source": [
    "### adapt test `pl_name_src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56f61896-6298-44ee-a27f-7162c33561a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 695.44 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# pl_name_src\n",
    "pl_name_src_text_layer = tf.keras.layers.TextVectorization() # max_tokens=MAX_TOKENS,ngrams=2,\n",
    "pl_name_src_text_layer.adapt(train_parsed.map(lambda x: x['pl_name_src']))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Elapsed time: {round((end - start), 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1588b9b9-863f-4644-a018-67b78917401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[723]], shape=(1, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in train_parsed.batch(1).map(lambda x: x[\"pl_name_src\"]).take(1):\n",
    "  print(pl_name_src_text_layer(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13add783-df36-4f49-bab9-42b6d36ebde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'country', 'music', 'rock']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_name_src_text_layer.get_vocabulary()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cba92ebb-9bbf-44ae-9255-ddd217cd84d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_LOCAL_FILE v3_test_pl_dict.pkl\n",
      "VOCAB_GCS_OBJ jtv8/test_vocabs/v3_test_pl_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'spotify-data-regimes'\n",
    "VOCAB_LOCAL_FILE = 'v3_test_pl_dict.pkl'\n",
    "VOCAB_GCS_OBJ = f'jtv8/test_vocabs/{VOCAB_LOCAL_FILE}'\n",
    "\n",
    "print(f\"VOCAB_LOCAL_FILE {VOCAB_LOCAL_FILE}\")\n",
    "print(f\"VOCAB_GCS_OBJ {VOCAB_GCS_OBJ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22b1d57f-029f-4926-92b6-aaab21181387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File v3_test_pl_dict.pkl uploaded to jtv8/test_vocabs/v3_test_pl_dict.pkl.\n"
     ]
    }
   ],
   "source": [
    "test_pl_dict = {\n",
    "    'v3_pl_name_src' : pl_name_src_text_layer.get_vocabulary()[0:5],\n",
    "}\n",
    "\n",
    "filehandler = open(f'{VOCAB_LOCAL_FILE}', 'wb')\n",
    "pkl.dump(test_pl_dict, filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob(f'{BUCKET}', f'{VOCAB_LOCAL_FILE}', f'{VOCAB_GCS_OBJ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46bf8be3-542f-4c4d-956d-49133f2a7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filehandler = open(f'{VOCAB_LOCAL_FILE}', 'rb')\n",
    "# vocab_dict_load = pkl.load(filehandler)\n",
    "# filehandler.close()\n",
    "# vocab_dict_load\n",
    "\n",
    "# https://storage.cloud.google.com/spotify-data-regimes/jtv8/test_vocabs/test_pl_dict.pkl\n",
    "\n",
    "with open(\"v3_new_vocab_pre_load\", 'wb') as local_vocab_jt3:\n",
    "        storage_client.download_blob_to_file(\n",
    "            f\"gs://{BUCKET}/{VOCAB_GCS_OBJ}\", local_vocab_jt3\n",
    "        )\n",
    "# local_vocab_jt1 --> <_io.BufferedWriter name='new_vocab_pre_load'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf419782-f7af-4e72-a602-fb62025eacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"v3_new_vocab_pre_load\", 'rb') as pickle_file_v3:\n",
    "    loaded_vocab_dict_v3 = pkl.load(pickle_file_v3)\n",
    "    \n",
    "# loaded_vocab_dict\n",
    "# loaded_vocab_dict_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e23c8ea5-1fb1-4360-8f47-ac29ebd90b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pl_name_src': ['', '[UNK]', 'country', 'music', 'rock']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_vocab_dict_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f61ece96-ec2d-4504-a639-d69d7f13395f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicts updated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pl_name_src': ['', '[UNK]', 'country', 'music', 'rock'],\n",
       " 'v2_pl_name_src': ['', '[UNK]', 'country', 'music', 'rock'],\n",
       " 'v3_pl_name_src': ['', '[UNK]', 'country', 'music', 'rock']}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python code to merge dict using update() method\n",
    "def merge_dicts(dict_list):\n",
    "    dict_1 = dict_list[0]\n",
    "    \n",
    "    for vocab_dict in dict_list[1:]:\n",
    "        dict_1.update(vocab_dict)\n",
    "    \n",
    "    return(print(\"dicts updated\"))\n",
    "\n",
    "merge_dicts(dict_list=[loaded_vocab_dict_v1, loaded_vocab_dict_v2, loaded_vocab_dict_v3])\n",
    "\n",
    "loaded_vocab_dict_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e92a1a81-ad06-42f0-9dce-c933491da014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_dict_uris: ['gs://spotify-data-regimes/jtv8/test_vocabs/', 'gs://spotify-data-regimes/jtv8/test_vocabs/test_pl_dict.pkl', 'gs://spotify-data-regimes/jtv8/test_vocabs/v2_test_pl_dict.pkl', 'gs://spotify-data-regimes/jtv8/test_vocabs/v3_test_pl_dict.pkl']\n",
      "count of vocab_dict_uris: 4\n",
      "count of vocab_dict_uris_removed: 3\n",
      "vocab_dict_uris_removed: ['gs://spotify-data-regimes/jtv8/test_vocabs/test_pl_dict.pkl', 'gs://spotify-data-regimes/jtv8/test_vocabs/v2_test_pl_dict.pkl', 'gs://spotify-data-regimes/jtv8/test_vocabs/v3_test_pl_dict.pkl']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pl_name_src': ['', '[UNK]', 'country', 'music', 'rock']},\n",
       " {'v2_pl_name_src': ['', '[UNK]', 'country', 'music', 'rock']},\n",
       " {'v3_pl_name_src': ['', '[UNK]', 'country', 'music', 'rock']}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_path_prefix = 'jtv8/test_vocabs/'\n",
    "\n",
    "vocab_dict_uris = []\n",
    "for blob in storage_client.list_blobs(f'{BUCKET}', prefix=f'{vocab_path_prefix}', delimiter=\"/\"):\n",
    "    vocab_dict_uris.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "print(f\"vocab_dict_uris: {vocab_dict_uris}\")\n",
    "print(f\"count of vocab_dict_uris: {len(vocab_dict_uris)}\")\n",
    "\n",
    "# skip folder path prefix\n",
    "vocab_dict_uris_removed = vocab_dict_uris[1:]\n",
    "print(f\"count of vocab_dict_uris_removed: {len(vocab_dict_uris_removed)}\")\n",
    "print(f\"vocab_dict_uris_removed: {vocab_dict_uris_removed}\")\n",
    "\n",
    "loaded_pickle_list = []\n",
    "for i, pickled_dict in enumerate(vocab_dict_uris_removed):\n",
    "\n",
    "    with open(f\"v{i}_vocab_pre_load\", 'wb') as local_vocab_file:\n",
    "        storage_client.download_blob_to_file(pickled_dict, local_vocab_file)\n",
    "\n",
    "    with open(f\"v{i}_vocab_pre_load\", 'rb') as pickle_file:\n",
    "        loaded_vocab_dict = pkl.load(pickle_file)\n",
    "    \n",
    "    loaded_pickle_list.append(loaded_vocab_dict)\n",
    "    \n",
    "loaded_pickle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8953431f-b8e5-47de-b20b-ad5378bc06f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pl_name_src': ['', '[UNK]', 'country', 'music', 'rock'],\n",
       " 'v2_pl_name_src': ['', '[UNK]', 'country', 'music', 'rock'],\n",
       " 'v3_pl_name_src': ['', '[UNK]', 'country', 'music', 'rock']}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dict = {}\n",
    "for thing in loaded_pickle_list:\n",
    "    master_dict.update(thing)\n",
    "    \n",
    "master_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee66085a-e084-4df6-8fe7-22cdbbd44817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'country', 'music', 'rock']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dict['pl_name_src']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229b688-3c14-4189-8592-b69d6d27a169",
   "metadata": {},
   "source": [
    "## feature data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aea641-45ad-4379-a97c-799007ad8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_string = json.dumps(\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"pl_name_src\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"track_name_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_name_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"album_name_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_genres_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"track_name_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_name_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"album_name_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_genres_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "feature_list_ = [\n",
    "        {\n",
    "            \"name\": \"pl_name_src\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"track_name_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_name_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"album_name_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_genres_pl\",\n",
    "            \"feat_type\": \"ragged\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"track_name_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_name_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"album_name_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"artist_genres_can\",\n",
    "            \"feat_type\": \"fixed_length\",\n",
    "        },\n",
    "    ],\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(feature_list_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f8b89-ae46-4b86-bab6-c001aca28405",
   "metadata": {},
   "source": [
    "### jw code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7040ef-10fe-41dc-a23c-de1e74c58651",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLAYLIST_LENGTH = 5 # this is set upstream by the BigQuery max length\n",
    "    \n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['pl_name_src']))\n",
    "print('pl_name_src adapts complete')\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['track_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('track_name_pl adapts complete')\n",
    "model.query_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1]))) \n",
    "print('artist_name_pl adapts complete')\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['album_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('album_name_pl adapts complete')\n",
    "model.query_tower.layers[12].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_genres_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('artist_genres_pl adapts complete')\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['tracks_playlist_titles_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "# print('tracks_playlist_titles_pl adapts complete')\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['track_name_can'])) \n",
    "print('track_name_can adapts complete')\n",
    "model.candidate_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_name_can'])) \n",
    "print('artist_name_can adapts complete')\n",
    "model.candidate_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['album_name_can'])) \n",
    "print('album_name_can adapts complete')\n",
    "model.candidate_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_genres_can'])) \n",
    "print('artist_genres_can adapts complete')\n",
    "# model.candidate_tower.layers[11].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: x['track_pl_titles_can'])) \n",
    "# print('track_pl_titles_can adapts complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aacf37-ad68-46ab-96dc-c01cf6217ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {\n",
    "    'pl_name_src' : model.query_tower.layers[0].layers[0].get_vocabulary(),\n",
    "    'track_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(),\n",
    "    'artist_name_pl' : model.query_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'album_name_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(),\n",
    "    'artist_genres_pl' : model.query_tower.layers[12].layers[0].get_vocabulary(),\n",
    "    'tracks_playlist_titles_pl' : model.query_tower.layers[13].layers[0].get_vocabulary(),\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(),\n",
    "    'artist_name_can' : model.candidate_tower.layers[3].layers[0].get_vocabulary(),\n",
    "    'album_name_can' : model.candidate_tower.layers[5].layers[0].get_vocabulary(),\n",
    "    'artist_genres_can' : model.candidate_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'track_pl_titles_can' : model.candidate_tower.layers[11].layers[0].get_vocabulary(),\n",
    "}\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
