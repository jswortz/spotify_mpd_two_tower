{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVKyuWRezBGF"
   },
   "source": [
    "# Spotify API Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgGWdClhze9D",
    "tags": []
   },
   "source": [
    "* Spotify Mlllion Playlist Dataset Challenge [Homepage](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n",
    "* [Spotify Web API docs](https://developer.spotify.com/documentation/web-api/reference/#/)\n",
    "\n",
    "**Community Examples**\n",
    "* [Extracting song lists](https://github.com/tojhe/recsys-spotify/blob/master/processing/songlist_extraction.py)\n",
    "* [construct audio features with Spotify API](https://github.com/tojhe/recsys-spotify/blob/master/processing/audio_features_construction.py)\n",
    "* [Using Spotify API](https://towardsdatascience.com/extracting-song-data-from-the-spotify-api-using-python-b1e79388d50)\n",
    "\n",
    "#### After reading through these, create a new Spotify App and get the customer id, secret\n",
    "![](img/spotify-dev-console.png)\n",
    "\n",
    "This example uses a local json credentials and if you are concerned over visibility to apikeys, please see [GCP Secret Manager](https://cloud.google.com/secret-manager)\n",
    "\n",
    "Below is an example if you were to add the json file to secret manager (keys: `secret`, `id`)\n",
    "\n",
    "```python\n",
    "from google.cloud import secretmanager\n",
    "\n",
    "###Note you copy/paste this from secret manager in console\n",
    "SECRET_VERSION = 'projects/934903580331/secrets/spotify-creds1/versions/1'\n",
    "\n",
    "sm_client = secretmanager.SecretManagerServiceClient()\n",
    "\n",
    "name = sm_client.secret_path(PROJECT_ID, SECRET_ID)\n",
    "\n",
    "response = client.access_secret_version(request={\"name\": SECRET_VERSION})   \n",
    "\n",
    "payload = json.loads(response.payload.data.decode(\"UTF-8\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RRSdCB_HSBSl",
    "outputId": "b272ec83-d189-4a22-da3e-5ef650c574b7",
    "tags": []
   },
   "source": [
    "### Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U spotipy google-cloud-storage google-cloud-aiplatform gcsfs --user -q\n",
    "# ! pip3 install --user kfp google-cloud-pipeline-components --upgrade -q\n",
    "# !pip3 install --user -q google-cloud-secret-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irhbKrY3fcG8",
    "outputId": "2008a7ca-303d-4943-e56b-a57040c9abd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.19\n",
      "google_cloud_pipeline_components version: 1.0.39\n",
      "aiplatform SDK version: 1.22.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCbr2tLuzTJK"
   },
   "source": [
    "### Constants - setup to your config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wwktfnCyzWO",
    "outputId": "6afe4a17-ebc2-40dc-d23a-1f447f394046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: v6-spotify-feature-enrich\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'hybrid-vertex' #update\n",
    "LOCATION = 'us-central1' \n",
    "\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "# BUCKET_NAME = 'spotify-million-playlists'\n",
    "\n",
    "VERSION = 6\n",
    "PIPELINE_VERSION = 'v6' # pipeline code\n",
    "PIPELINE_TAG = f'{PIPELINE_VERSION}-spotify-feature-enrich'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Bucket if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l $LOCATION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GqhJlsodR-xX"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "# GCP\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_NAME\n",
    ")\n",
    "\n",
    "# Get spotify credentials\n",
    "# This file has id and secret stored as attributes\n",
    "\n",
    "creds = open('spotify-creds.json')\n",
    "spotify_creds = json.load(creds)\n",
    "creds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuJk9A5I9ZfF"
   },
   "source": [
    "### Clients & credentials\n",
    "\n",
    "Setup Vertex AI client for pipelines\n",
    "\n",
    "Spotify shoulld be stored in a json file with a your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCbHe1G_gICe",
    "outputId": "c3f7d046-4997-4b59-9bcc-44df8feba2ed"
   },
   "outputs": [],
   "source": [
    "# # Setup clients\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spotify credentials\n",
    "# This file has id and secret stored as attributes\n",
    "\n",
    "creds = open('spotify-creds.json')\n",
    "spotify_creds = json.load(creds)\n",
    "creds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbeNm6_whXMG"
   },
   "source": [
    "# Create Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m3D974DjTbE"
   },
   "source": [
    "### Audio Features\n",
    "\n",
    "[Link to artist API and related features we will pull](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "86ZuQqElhZrS"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec', 'google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4',\n",
    "                        ])\n",
    "def call_spotify_api_audio(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    client_id: str,\n",
    "    batch_size: int,\n",
    "    batches_to_store: int,\n",
    "    target_table: str,\n",
    "    client_secret: str,\n",
    "    unique_table: str,\n",
    "    sleep_param: float,\n",
    ") -> NamedTuple('Outputs', [('done_message', str),]):\n",
    "    print(f'pip install complete')\n",
    "    import os\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import time\n",
    "    from google.cloud import storage\n",
    "    import gcsfs\n",
    "    import numpy as np\n",
    "    from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "    from absl import logging\n",
    "    from google.cloud import bigquery\n",
    "    import pandas_gbq\n",
    "\n",
    "    # print(f'package import complete')\n",
    "\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    logging.info(f'package import complete')\n",
    "\n",
    "    \n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "    )\n",
    "\n",
    "    logging.info(f'spotipy auth complete')\n",
    "    def spot_audio_features(uri, client_id, client_secret):\n",
    "\n",
    "        # Authenticate\n",
    "        client_credentials_manager = SpotifyClientCredentials(\n",
    "            client_id=client_id, \n",
    "            client_secret=client_secret\n",
    "        )\n",
    "        sp = spotipy.Spotify(\n",
    "            client_credentials_manager = client_credentials_manager, \n",
    "            requests_timeout=10, \n",
    "            retries=10 )\n",
    "        ############################################################################\n",
    "        # Create Track Audio Features DF\n",
    "        ############################################################################\n",
    "\n",
    "        #Audio features\n",
    "        uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "        a_feats = sp.audio_features(uri)\n",
    "        features = pd.json_normalize(a_feats, )#.to_dict('list')\n",
    "        features['track_uri'] = uri\n",
    "        return features\n",
    "\n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "    )\n",
    "\n",
    "    query = f\"select distinct track_uri from `{unique_table}`\" \n",
    "\n",
    "    count = 1\n",
    "    uri_batch = []\n",
    "\n",
    "    #refactor\n",
    "    schema = [{'name':'danceability', 'type': 'FLOAT'},\n",
    "            {'name':'energy', 'type': 'FLOAT'},\n",
    "            {'name':'key', 'type': 'FLOAT'},\n",
    "            {'name':'loudness', 'type': 'FLOAT'},\n",
    "            {'name':'mode', 'type': 'INTEGER'},\n",
    "            {'name':'speechiness', 'type': 'FLOAT'},\n",
    "            {'name':'acousticness', 'type': 'FLOAT'},\n",
    "            {'name':'instrumentalness', 'type': 'FLOAT'},\n",
    "            {'name':'liveness', 'type': 'FLOAT'},\n",
    "            {'name':'valence', 'type': 'FLOAT'},\n",
    "            {'name':'followers', 'type': 'FLOAT'},\n",
    "            {'name':'tempo', 'type': 'FLOAT'},\n",
    "            {'name':'type', 'type': 'STRING'},\n",
    "            {'name':'id', 'type': 'STRING'},\n",
    "            {'name':'uri', 'type': 'STRING'},\n",
    "            {'name':'track_href', 'type': 'STRING'},\n",
    "            {'name':'analysis_url', 'type': 'STRING'},\n",
    "            {'name':'duration_ms_y', 'type': 'INTEGER'},\n",
    "            {'name':'time_signature', 'type': 'INTEGER'},\n",
    "            {'name':'track_uri', 'type': 'STRING'},\n",
    "    ]\n",
    "\n",
    "    tracks = bq_client.query(query).result().to_dataframe()\n",
    "    track_list = tracks.track_uri.to_list()\n",
    "    logging.info(f'finished downloading tracks')\n",
    "    uri_list_length = len(track_list)\n",
    "    inner_batch_count = 0 #avoiding calling the api on 0th iteration\n",
    "    for uri in track_list:\n",
    "        if count % batch_size == 0 or uri_list_length == count: #grab a batch of 50 songs\n",
    "            uri_batch.append(uri)\n",
    "            ### Try catch block for function\n",
    "            try:\n",
    "                audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "                time.sleep(sleep_param)\n",
    "            except ReadTimeout:\n",
    "                logging.info(\"'Spotify timed out... trying again...'\")\n",
    "                audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "                time.sleep(sleep_param)\n",
    "            except HTTPError as err: #JW ADDED\n",
    "                logging.info(f\"HTTP Error: {err}\")\n",
    "            except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "                logging.info(f\"Spotify error: {spotify_error}\")\n",
    "            # Accumulate batches on the machine before writing to BQ\n",
    "            if inner_batch_count <= batches_to_store or uri_list_length == count:\n",
    "                if inner_batch_count == 0:\n",
    "                    appended_data = audio_featureDF\n",
    "                else:\n",
    "                    appended_data = pd.concat([audio_featureDF, appended_data])\n",
    "                inner_batch_count += 1\n",
    "                uri_batch = []\n",
    "                count += 1\n",
    "            else:\n",
    "                try:\n",
    "                    appended_data.to_gbq(\n",
    "                        destination_table=target_table, \n",
    "                        project_id=f'{project}', \n",
    "                        location='us-central1', \n",
    "                        table_schema=schema,\n",
    "                        progress_bar=False, \n",
    "                        reauth=False, \n",
    "                        if_exists='append'\n",
    "                        )\n",
    "                except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "                    logging.info('invalid schema, skipping')\n",
    "                    pass\n",
    "                del appended_data\n",
    "                logging.info(f'{count} of {uri_list_length} complete!')\n",
    "                uri_batch = []\n",
    "                count += 1\n",
    "                inner_batch_count = 0\n",
    "        else:\n",
    "            uri_batch.append(uri)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    logging.info(f'audio features appended')\n",
    "\n",
    "    return (\n",
    "      f'DONE',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DEBUG\n",
    "\n",
    "# def spot_track_features(uri, client_id, client_secret):\n",
    "\n",
    "#     # Authenticate\n",
    "#     client_credentials_manager = SpotifyClientCredentials(\n",
    "#         client_id=client_id, \n",
    "#         client_secret=client_secret\n",
    "#     )\n",
    "#     sp = spotipy.Spotify(\n",
    "#         client_credentials_manager = client_credentials_manager, \n",
    "#         requests_timeout=3, \n",
    "#         retries=3 )\n",
    "\n",
    "#     ############################################################################\n",
    "#     # Create Track Audio Features DF\n",
    "#     ############################################################################ \n",
    "\n",
    "#     artists = sp.artists(uri)\n",
    "\n",
    "#     features = pd.json_normalize(artists).to_dict('list')\n",
    "#     artist_pop = []\n",
    "#     artist_genres = []\n",
    "#     followers = []\n",
    "#     id_list = uri\n",
    "#     for artist in artists['artists']:\n",
    "#         if artist is not None:\n",
    "#             artist_pop.append(artist['popularity'])\n",
    "#             artist_genres.append(artist['genres'])\n",
    "#             followers.append(artist['followers']['total'])\n",
    "#         else:\n",
    "#             artist_pop.append(-1)\n",
    "#             artist_genres.append('unknown')\n",
    "\n",
    "\n",
    "#     features[\"artist_pop\"] = artist_pop\n",
    "#     features[\"genres\"] = artist_genres\n",
    "#     features['followers'] = followers\n",
    "#     features['artist_uri'] = id_list\n",
    "#     audio_df = pd.DataFrame(features)\n",
    "#     audio_df['genres'] = audio_df['genres'].astype(str)\n",
    "#     return audio_df\n",
    "    \n",
    "# spot_track_features(['spotify:artist:000h2XLY65iWC9u5zgcL1M', 'spotify:artist:000xagx3GkcunHTFdB4ly0'], spotify_creds['id'], \n",
    "#                     spotify_creds['secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hppPSwkh1x2"
   },
   "source": [
    "### Artists \n",
    "\n",
    "[Link to artist API and related features we will pull](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-an-artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JYbgsLrtxPHl"
   },
   "outputs": [],
   "source": [
    "### Artist tracks api call\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',' google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4',\n",
    "                        'google-cloud-secret-manager'])\n",
    "def call_spotify_api_artist(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    unique_table: str,\n",
    "    batch_size: int,\n",
    "    batches_to_store: int,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: float,\n",
    "    target_table: str,\n",
    ") -> NamedTuple('Outputs', [('done_message', str),]):\n",
    "    print(f'pip install complete')\n",
    "    import os\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import time\n",
    "    from google.cloud import storage\n",
    "    import gcsfs\n",
    "    import numpy as np\n",
    "    from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "    from absl import logging\n",
    "    from google.cloud import bigquery\n",
    "    import pandas_gbq\n",
    "\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    logging.info(f'package import complete')\n",
    "\n",
    "    storage_client = storage.Client(\n",
    "        project=project\n",
    "    )\n",
    "    \n",
    "    logging.info(f'spotipy auth complete')\n",
    "    \n",
    "    def spot_track_features(uri, client_id, client_secret):\n",
    "\n",
    "        # Authenticate\n",
    "        client_credentials_manager = SpotifyClientCredentials(\n",
    "            client_id=client_id, \n",
    "            client_secret=client_secret\n",
    "        )\n",
    "        sp = spotipy.Spotify(\n",
    "            client_credentials_manager = client_credentials_manager, \n",
    "            requests_timeout=10, \n",
    "            retries=10 )\n",
    "        ############################################################################\n",
    "        # Create Track Audio Features DF\n",
    "        ############################################################################\n",
    "        #artists api call\n",
    "        uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "        artists = sp.artists(uri)\n",
    "        \n",
    "        features = pd.json_normalize(artists, ) #.to_dict('list')\n",
    "        return features\n",
    "        \n",
    "\n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "    )\n",
    "\n",
    "\n",
    "    query = f\"select distinct artist_uri from `{unique_table}`\"\n",
    "    \n",
    "\n",
    "    schema = [{'name': 'artist_pop', 'type': 'INTEGER'},\n",
    "            {'name':'genres', 'type': 'STRING'},\n",
    "            {'name':'followers', 'type': 'INTEGER'},\n",
    "            {'name':'artist_uri', 'type': 'STRING'}\n",
    "    ]\n",
    "    count = 1\n",
    "    uri_batch = []\n",
    "\n",
    "    ats = bq_client.query(query).result().to_dataframe()\n",
    "    artist_set = ats.artist_uri.to_list()\n",
    "    uri_list_length = len(artist_set)\n",
    "    logging.info(f'finished downloading tracks')\n",
    "    inner_batch_count = 0\n",
    "    for uri in artist_set:\n",
    "        if count % batch_size == 0 or uri_list_length == count: #grab a batch of 50 artists\n",
    "            uri_batch.append(uri)\n",
    "            ### Try catch block for function\n",
    "            try:\n",
    "                artists_featureDF = spot_track_features(uri_batch, client_id, client_secret)\n",
    "                time.sleep(sleep_param)\n",
    "            except ReadTimeout:\n",
    "                logging.info(\"'Spotify timed out... trying again...'\")\n",
    "                artists_featureDF = spot_track_features(uri_batch, client_id, client_secret)\n",
    "                time.sleep(sleep_param)\n",
    "            except HTTPError as err: \n",
    "                logging.info(f\"HTTP Error: {err}\")\n",
    "            except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "                logging.info(f\"Spotify error: {spotify_error}\")\n",
    "            # Accumulate batches on the machine before writing to BQ\n",
    "            if inner_batch_count <= batches_to_store or uri_list_length == count:\n",
    "                if inner_batch_count == 0:\n",
    "                    appended_data = artists_featureDF\n",
    "                else:\n",
    "                    appended_data = pd.concat([artists_featureDF, appended_data])\n",
    "                \n",
    "                inner_batch_count += 1\n",
    "                uri_batch = []\n",
    "                count += 1\n",
    "            else:\n",
    "                try:\n",
    "                    appended_data.to_gbq(\n",
    "                        destination_table=target_table, \n",
    "                        project_id=f'{project}', \n",
    "                        location='us-central1', \n",
    "                        table_schema=schema,\n",
    "                        progress_bar=False, \n",
    "                        reauth=False, \n",
    "                        if_exists='append'\n",
    "                        )\n",
    "                except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "                    logging.info('invalid schema, skipping')\n",
    "                    pass\n",
    "                \n",
    "                del appended_data\n",
    "                logging.info(f'{count} of {uri_list_length} complete!')\n",
    "                inner_batch_count = 0\n",
    "                uri_batch = []\n",
    "                count += 1\n",
    "        else:\n",
    "            uri_batch.append(uri)\n",
    "            count += 1\n",
    "    return (\n",
    "          f'DONE',\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma5qzpGkuYhD"
   },
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Buwtyt7rugt4"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'spotify-feature-enrichment-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    unique_table: str,\n",
    "    target_table_audio: str,\n",
    "    target_table_artist: str,\n",
    "    batch_size: int,\n",
    "    batches_to_store: int,\n",
    "    sleep_param: float,\n",
    "    spotify_id: str = spotify_creds['id'],\n",
    "    spotify_secret: str = spotify_creds['secret'],\n",
    "    ):\n",
    "\n",
    "\n",
    "    call_spotify_api_artist_op = call_spotify_api_artist(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret,\n",
    "        batch_size=batch_size,\n",
    "        sleep_param=sleep_param,\n",
    "        unique_table=unique_table,\n",
    "        target_table=target_table_artist,\n",
    "        batches_to_store=batches_to_store,\n",
    "    ).set_display_name(\"Get Artist Features From Spotify API\")\n",
    "\n",
    "    call_spotify_api_audio_op = call_spotify_api_audio(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret,\n",
    "        batch_size=batch_size,\n",
    "        sleep_param=sleep_param,\n",
    "        unique_table=unique_table,\n",
    "        target_table=target_table_audio,\n",
    "        batches_to_store=batches_to_store,\n",
    "    ).set_display_name(\"Get Track Audio Features From Spotify API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the pipeline to json\n",
    "This can be stored on gcs as well for broader orchastration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoBsfT1IyIXd",
    "outputId": "50a65461-1c7c-44c0-9362-5524aaac21c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the pipeline parameters\n",
    "\n",
    "Use a dictionary with the afforementioned types defined by your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "evUgOHllykr5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'hybrid-vertex',\n",
       " 'location': 'us-central1',\n",
       " 'unique_table': 'hybrid-vertex.mdp_eda_test.tracks_unique',\n",
       " 'target_table_audio': 'hybrid-vertex.mdp_eda_test.audio_features',\n",
       " 'target_table_artist': 'hybrid-vertex.mdp_eda_test.artist_features',\n",
       " 'batch_size': 50,\n",
       " 'batches_to_store': 100000,\n",
       " 'sleep_param': 0.05}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jtotten-project #\n",
    "GCS_BUCKET = 'matching-engine-content'\n",
    "BQ_DATASET = 'mdp_eda_test'\n",
    "\n",
    "\n",
    "\n",
    "PIPELINE_PARAMETERS = dict(\n",
    "    project = PROJECT_ID,\n",
    "    location = 'us-central1',\n",
    "    unique_table = f'{PROJECT_ID}.{BQ_DATASET}.tracks_unique', \n",
    "    target_table_audio = f'{PROJECT_ID}.{BQ_DATASET}.audio_features',\n",
    "    target_table_artist = f'{PROJECT_ID}.{BQ_DATASET}.artist_features',\n",
    "    batch_size = 50,\n",
    "    batches_to_store = 100000,\n",
    "    sleep_param = 0.05,\n",
    ")\n",
    "\n",
    "PIPELINE_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/spotify-feature-enrichment-v6-spotify-feature-enrich-20230224234340\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/spotify-feature-enrichment-v6-spotify-feature-enrich-20230224234340')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/spotify-feature-enrichment-v6-spotify-feature-enrich-20230224234340?project=934903580331\n"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(display_name = f'spotify-feature-enrichment-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "                             template_path = 'custom_container_pipeline_spec.json',\n",
    "                             pipeline_root = f'gs://{BUCKET_NAME}/{VERSION}',\n",
    "                             parameter_values = PIPELINE_PARAMETERS,\n",
    "                             project = PROJECT_ID,\n",
    "                             location = LOCATION,\n",
    "                              enable_caching=False)\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract-spotify-features-pipeline-parallel-for.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
