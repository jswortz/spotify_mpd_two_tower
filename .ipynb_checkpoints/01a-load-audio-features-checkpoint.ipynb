{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVKyuWRezBGF"
   },
   "source": [
    "# Spotify API Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgGWdClhze9D"
   },
   "source": [
    "* Spotify Mlllion Playlist Dataset Challenge [Homepage](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n",
    "* [Spotify Web API docs](https://developer.spotify.com/documentation/web-api/reference/#/)\n",
    "\n",
    "**Community Examples**\n",
    "* [Extracting song lists](https://github.com/tojhe/recsys-spotify/blob/master/processing/songlist_extraction.py)\n",
    "* [construct audio features with Spotify API](https://github.com/tojhe/recsys-spotify/blob/master/processing/audio_features_construction.py)\n",
    "* [Using Spotify API](https://towardsdatascience.com/extracting-song-data-from-the-spotify-api-using-python-b1e79388d50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RRSdCB_HSBSl",
    "outputId": "b272ec83-d189-4a22-da3e-5ef650c574b7",
    "tags": []
   },
   "source": [
    "### Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U spotipy google-cloud-storage google-cloud-aiplatform gcsfs --user -q\n",
    "# ! pip3 install --user kfp google-cloud-pipeline-components --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irhbKrY3fcG8",
    "outputId": "2008a7ca-303d-4943-e56b-a57040c9abd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.19\n",
      "google_cloud_pipeline_components version: 1.0.39\n",
      "aiplatform SDK version: 1.22.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCbr2tLuzTJK"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wwktfnCyzWO",
    "outputId": "6afe4a17-ebc2-40dc-d23a-1f447f394046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: v3-spotify-feature-enrich\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'hybrid-vertex' #update\n",
    "LOCATION = 'us-central1' \n",
    "\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "# BUCKET_NAME = 'spotify-million-playlists'\n",
    "\n",
    "PIPELINE_VERSION = 'v3' # pipeline code\n",
    "PIPELINE_TAG = f'{PIPELINE_VERSION}-spotify-feature-enrich'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Bucket if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l $LOCATION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GqhJlsodR-xX"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from io import BytesIO\n",
    "\n",
    "import time\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "# GCP\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rWNU-8n8__I"
   },
   "source": [
    "### clients & credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuJk9A5I9ZfF"
   },
   "source": [
    "GCP clients\n",
    "\n",
    "Spotify shoulld be stored in a json file with a your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCbHe1G_gICe",
    "outputId": "c3f7d046-4997-4b59-9bcc-44df8feba2ed"
   },
   "outputs": [],
   "source": [
    "# Setup clients\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spotify credentials\n",
    "# This file has id and secret stored as attributes\n",
    "\n",
    "creds = open('spotify-creds.json')\n",
    "spotify_creds = json.load(creds)\n",
    "creds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvxKv0M49cMR"
   },
   "source": [
    "Pipeline setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMPDTywpgpu-",
    "outputId": "37f31e4a-65d0-465e-cfda-7c9610d9aad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINES_FILEPATH: gs://matching-engine-content/pipelines/pipelines.json\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Stuff\n",
    "import os\n",
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = f'gs://{BUCKET_NAME}/pipelines/pipelines.json' # <--- TODO: CHANGE THIS; can be blank json file\n",
    "print(\"PIPELINES_FILEPATH:\", PIPELINES_FILEPATH)\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbeNm6_whXMG"
   },
   "source": [
    "# Create Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m3D974DjTbE"
   },
   "source": [
    "### Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "86ZuQqElhZrS"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec', 'google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4'])\n",
    "def call_spotify_api_split_audio(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    client_id: str,\n",
    "    target_table: str,\n",
    "    client_secret: str,\n",
    "    unique_table: str,\n",
    "    sleep_param: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_feat_split_1_gcs_uri', str),]):\n",
    "    print(f'pip install complete')\n",
    "    import os\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from io import BytesIO\n",
    "    import time\n",
    "    from google.cloud import storage\n",
    "    import gcsfs\n",
    "    import numpy as np\n",
    "    from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "    from absl import logging\n",
    "    from google.cloud import bigquery\n",
    "    import pandas_gbq\n",
    "\n",
    "    # print(f'package import complete')\n",
    "\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    logging.info(f'package import complete')\n",
    "\n",
    "    \n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "    )\n",
    "\n",
    "    logging.info(f'spotipy auth complete')\n",
    "    def spot_audio_features(uri, client_id, client_secret):\n",
    "\n",
    "        # Authenticate\n",
    "        client_credentials_manager = SpotifyClientCredentials(\n",
    "            client_id=client_id, \n",
    "            client_secret=client_secret\n",
    "        )\n",
    "        sp = spotipy.Spotify(\n",
    "            client_credentials_manager = client_credentials_manager, \n",
    "            requests_timeout=10, \n",
    "            retries=10 )\n",
    "        ############################################################################\n",
    "        # Create Track Audio Features DF for Split\n",
    "        ############################################################################\n",
    "\n",
    "        #Audio features\n",
    "        uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "        a_feats = sp.audio_features(uri)\n",
    "        features = pd.json_normalize(a_feats, ).to_dict('list')\n",
    "        if features is None:\n",
    "            features = {}\n",
    "        #Artist of the track, for genres and popularity\n",
    "        popularity = []\n",
    "        #tracks API call\n",
    "        tracks = sp.tracks(uri)\n",
    "        # if tracks:\n",
    "        for track in tracks['tracks']:\n",
    "            if track is not None:\n",
    "                popularity.append(track['popularity'])\n",
    "            else:\n",
    "                popularity.append(-1)\n",
    "\n",
    "        audio_df = pd.DataFrame(features)\n",
    "        audio_df['popularity'] = popularity\n",
    "        audio_df['track_uri'] = uri\n",
    "        return audio_df\n",
    "\n",
    "        bq_client = bigquery.Client(\n",
    "          project=project, location=location\n",
    "        )\n",
    "\n",
    "        audio_featureDF = pd.DataFrame()\n",
    "\n",
    "    query = f\"select distinct track_uri from `{unique_table}`\" \n",
    "    # uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "    # uri_list_length = uri_list_length_df['count'][0]\n",
    "\n",
    "    count = 1\n",
    "    uri_batch = []\n",
    "    # handling bad track/artist_uris\n",
    "\n",
    "    #refactor\n",
    "    schema = [{'name':'danceability', 'type': 'FLOAT'},\n",
    "            {'name':'energy', 'type': 'FLOAT'},\n",
    "            {'name':'key', 'type': 'FLOAT'},\n",
    "            {'name':'loudness', 'type': 'FLOAT'},\n",
    "            {'name':'mode', 'type': 'INTEGER'},\n",
    "            {'name':'speechiness', 'type': 'FLOAT'},\n",
    "            {'name':'acousticness', 'type': 'FLOAT'},\n",
    "            {'name':'instrumentalness', 'type': 'FLOAT'},\n",
    "            {'name':'liveness', 'type': 'FLOAT'},\n",
    "            {'name':'valence', 'type': 'FLOAT'},\n",
    "            {'name':'followers', 'type': 'FLOAT'},\n",
    "            {'name':'tempo', 'type': 'FLOAT'},\n",
    "            {'name':'type', 'type': 'STRING'},\n",
    "            {'name':'id', 'type': 'STRING'},\n",
    "            {'name':'uri', 'type': 'STRING'},\n",
    "            {'name':'track_href', 'type': 'STRING'},\n",
    "            {'name':'analysis_url', 'type': 'STRING'},\n",
    "            {'name':'duration_ms_y', 'type': 'INTEGER'},\n",
    "            {'name':'time_signature', 'type': 'INTEGER'},\n",
    "            {'name':'popularity', 'type': 'INTEGER'},\n",
    "            {'name':'track_uri', 'type': 'STRING'},\n",
    "    ]\n",
    "\n",
    "    tracks = bq_client.query(query).result().to_dataframe()\n",
    "    track_list = tracks.track_uri.to_list()\n",
    "    uri_list_length = len(track_list)\n",
    "    for uri in track_list:\n",
    "        if count % 50 == 0 or uri_list_length == count: #grab a batch of 50 songs\n",
    "            uri_batch.append(uri)\n",
    "            ### Try catch block for function\n",
    "            try:\n",
    "                audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "\n",
    "            except ReadTimeout:\n",
    "                logging.info(\"'Spotify timed out... trying again...'\")\n",
    "                audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "            except HTTPError as err: #JW ADDED\n",
    "                logging.info(f\"HTTP Error: {err}\")\n",
    "            except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "                logging.info(f\"Spotify error: {spotify_error}\")\n",
    "            try:\n",
    "                audio_featureDF.to_gbq(\n",
    "                    destination_table=target_table, \n",
    "                    project_id=f'{project}', # TODO: param\n",
    "                    location='us-central1', \n",
    "                    table_schema=schema,\n",
    "                    progress_bar=False, \n",
    "                    reauth=False, \n",
    "                    if_exists='append'\n",
    "                    )\n",
    "            except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "                logging.info('invalid schema, skipping')\n",
    "                pass\n",
    "            logging.info(f'{count} of {uri_list_length} complete!')\n",
    "            uri_batch = []\n",
    "            count += 1\n",
    "            time.sleep(sleep_param)\n",
    "        else:\n",
    "            uri_batch.append(uri)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    logging.info(f'audio features appended')\n",
    "\n",
    "    return (\n",
    "      f'DONE',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hppPSwkh1x2"
   },
   "source": [
    "### Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JYbgsLrtxPHl"
   },
   "outputs": [],
   "source": [
    "### Artist tsracks api call\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',' google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4'])\n",
    "def call_spotify_api_split_artist(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    unique_table: str,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: int,\n",
    "    target_table: str,\n",
    ") -> NamedTuple('Outputs', [('track_audio_feat_split_1_gcs_uri', str),]):\n",
    "    print(f'pip install complete')\n",
    "    import os\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "    import re\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from io import BytesIO\n",
    "    import time\n",
    "    from google.cloud import storage\n",
    "    import gcsfs\n",
    "    import numpy as np\n",
    "    from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "    from absl import logging\n",
    "    from google.cloud import bigquery\n",
    "    import pandas_gbq\n",
    "    # print(f'package import complete')\n",
    "\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    logging.info(f'package import complete')\n",
    "\n",
    "    storage_client = storage.Client(\n",
    "        project=project\n",
    "    )\n",
    "    \n",
    "    logging.info(f'spotipy auth complete')\n",
    "    \n",
    "    def spot_audio_features(uri, client_id, client_secret):\n",
    "\n",
    "        # Authenticate\n",
    "        client_credentials_manager = SpotifyClientCredentials(\n",
    "            client_id=client_id, \n",
    "            client_secret=client_secret\n",
    "        )\n",
    "        sp = spotipy.Spotify(\n",
    "            client_credentials_manager = client_credentials_manager, \n",
    "            requests_timeout=10, \n",
    "            retries=10 )\n",
    "        ############################################################################\n",
    "        # Create Track Audio Features DF for Split\n",
    "        ############################################################################\n",
    "\n",
    "        #Audio features\n",
    "\n",
    "        #Artist of the track, for genres and popularity\n",
    "        features = {}\n",
    "        #tracks API call\n",
    "        # if tracks:\n",
    "\n",
    "        #artists api call\n",
    "        uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "        artists = sp.artists(uri)\n",
    "\n",
    "        artist_pop = []\n",
    "        artist_genres = []\n",
    "        followers = []\n",
    "        id_list = uri\n",
    "        for artist in artists['artists']:\n",
    "            if artist is not None:\n",
    "                artist_pop.append(artist['popularity'])\n",
    "                artist_genres.append(artist['genres'])\n",
    "                # if artist['followers']['total'] is None:\n",
    "                followers.append(artist['followers']['total'])\n",
    "                # else:\n",
    "                #   followers.append(-1)\n",
    "            else:\n",
    "                artist_pop.append(-1)\n",
    "                artist_genres.append('unknown')\n",
    "\n",
    "        # logging.info(print(f\"artist: {artist_pop}\"))\n",
    "        # logging.info(print(f\"genres: {artist_genres}\"))\n",
    "        # logging.info(print(f\"followers: {followers}\"))\n",
    "        features[\"artist_pop\"] = artist_pop\n",
    "        features[\"genres\"] = artist_genres\n",
    "        features['followers'] = followers\n",
    "        features['artist_uri'] = id_list\n",
    "        audio_df = pd.DataFrame(features)\n",
    "        audio_df['genres'] = audio_df['genres'].astype(str)\n",
    "        # logging.info(print(audio_df)) #logging\n",
    "        return audio_df\n",
    "\n",
    "    bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "    )\n",
    "\n",
    "\n",
    "    query = f\"select distinct artist_uri from `{unique_table}`\"\n",
    "    logging.info(f'finished downloading tracks')\n",
    "    # uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "    # n_artists = uri_list_length_df['count'][0]\n",
    "    # logging.info(f'number of distinct artists: {n_artists}')\n",
    "    audio_featureDF = pd.DataFrame()\n",
    "\n",
    "\n",
    "    schema = [{'name': 'artist_pop', 'type': 'INTEGER'},\n",
    "            {'name':'genres', 'type': 'STRING'},\n",
    "            {'name':'followers', 'type': 'INTEGER'},\n",
    "            {'name':'artist_uri', 'type': 'STRING'}\n",
    "    ]\n",
    "    count = 1\n",
    "    uri_batch = []\n",
    "    # handling bad track/artist_uris\n",
    "\n",
    "    ats = bq_client.query(query).result().to_dataframe()\n",
    "    artist_set = ats.artist_uri.to_list()\n",
    "    uri_list_length = len(artist_set)\n",
    "    for uri in artist_set:\n",
    "        if count % 50 == 0 or uri_list_length == count: #grab a batch of 50 artists\n",
    "            uri_batch.append(uri)\n",
    "            ### Try catch block for function\n",
    "            try:\n",
    "                audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "            except ReadTimeout:\n",
    "                logging.info(\"'Spotify timed out... trying again...'\")\n",
    "                audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "            except HTTPError as err: #JW ADDED\n",
    "                logging.info(f\"HTTP Error: {err}\")\n",
    "            except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "                logging.info(f\"Spotify error: {spotify_error}\")\n",
    "            try:\n",
    "                audio_featureDF.to_gbq(\n",
    "                    destination_table=target_table, \n",
    "                    project_id=f'{project}', # TODO: param\n",
    "                    location='us-central1', \n",
    "                    # table_schema=schema,\n",
    "                    progress_bar=False, \n",
    "                    reauth=False, \n",
    "                    if_exists='append'\n",
    "                    )\n",
    "            except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "                logging.info('invalid schema, skipping')\n",
    "                pass\n",
    "            logging.info(f'{count} of {uri_list_length} complete!')\n",
    "            uri_batch = []\n",
    "            count += 1\n",
    "\n",
    "            time.sleep(sleep_param)\n",
    "\n",
    "        else:\n",
    "            uri_batch.append(uri)\n",
    "            count += 1\n",
    "\n",
    "    return (\n",
    "          f'DONE',\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma5qzpGkuYhD"
   },
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Buwtyt7rugt4"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'spotify-feature-enrichment-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    unique_table: str,\n",
    "    target_table_audio: str,\n",
    "    target_table_artist: str,\n",
    "    spotify_id: str = spotify_creds['id'],\n",
    "    spotify_secret: str = spotify_creds['secret'],\n",
    "    ):\n",
    "\n",
    "\n",
    "    call_spotify_api_split_artist_op = call_spotify_api_split_artist(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret,\n",
    "        sleep_param=20,\n",
    "        unique_table=unique_table,\n",
    "        target_table=target_table_artist,\n",
    "    )\n",
    "\n",
    "    call_spotify_api_split_audio_op = call_spotify_api_split_audio(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        client_id=spotify_id,\n",
    "        client_secret=spotify_secret,\n",
    "        sleep_param=20,\n",
    "        unique_table=unique_table,\n",
    "        target_table=target_table_audio,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoBsfT1IyIXd",
    "outputId": "50a65461-1c7c-44c0-9362-5524aaac21c4"
   },
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "evUgOHllykr5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'hybrid-vertex',\n",
       " 'location': 'us-central1',\n",
       " 'unique_table': 'hybrid-vertex.mdp_eda_test.tracks_unique'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jtotten-project #\n",
    "GCS_BUCKET = 'matching-engine-content'\n",
    "BQ_DATASET = 'mdp_eda_test'\n",
    "VERSION = 5\n",
    "\n",
    "\n",
    "PIPELINE_PARAMETERS = dict(\n",
    "    project = PROJECT_ID,\n",
    "    location = 'us-central1',\n",
    "    unique_table = f'{PROJECT_ID}.{BQ_DATASET}.tracks_unique'\n",
    "    target_table_audio = f'{PROJECT_ID}.{BQ_DATASET}.audio_features',\n",
    "    target_table_artist = f'{PROJECT_ID}.{BQ_DATASET}.artist_features',\n",
    ")\n",
    "\n",
    "PIPELINE_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/spotify-feature-enrichment-v3-spotify-feature-enrich-20230223220852\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/spotify-feature-enrichment-v3-spotify-feature-enrich-20230223220852')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/spotify-feature-enrichment-v3-spotify-feature-enrich-20230223220852?project=934903580331\n"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(display_name = f'spotify-feature-enrichment-{PIPELINE_TAG}'.replace('_', '-'),\n",
    "                             template_path = 'custom_container_pipeline_spec.json',\n",
    "                             pipeline_root = f'gs://{BUCKET_NAME}/{VERSION}',\n",
    "                             parameter_values = PIPELINE_PARAMETERS,\n",
    "                             project = PROJECT_ID,\n",
    "                             location = LOCATION,\n",
    "                              enable_caching=True)\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract-spotify-features-pipeline-parallel-for.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
