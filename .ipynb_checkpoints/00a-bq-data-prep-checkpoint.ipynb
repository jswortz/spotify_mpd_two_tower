{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68da0ab1",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "## In this notebook we will load the songs from the zip file, and perform transformations to prepare the data for two-tower training\n",
    "Steps\n",
    "1. Extract from the zip file\n",
    "2. Upload to BQ\n",
    "3. Enrich features for the playlist songs\n",
    "4. Cross-join songs with features (expected rows = n_songs x n_playlists)\n",
    "5. Remove after-the-fact (later position songs) from the newly generated samples\n",
    "6. Create a clean train table, and flatten structs or use arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d08efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your variables for your project, region, and dataset name\n",
    "SOURCE_BUCKET = 'spotify-million-playlist-dataset'\n",
    "PROJECT_ID = 'wortz-project-352116'\n",
    "REGION = 'us-central1'\n",
    "bq_dataset = 'spotify_e2e_test'\n",
    "\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bigquery_client = bigquery.Client(project=PROJECT_ID, location='US')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2890a40",
   "metadata": {},
   "source": [
    "## Now enrich the playlist songs with the new features\n",
    "\n",
    "`audio_features` - created from prior notebook via Spotify API\n",
    "\n",
    "+\n",
    "\n",
    "`artist_features` - created from prior notebook via Spotify API\n",
    "\n",
    "These are additional tables where features were added in the beginning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3066d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.5 ms, sys: 7.5 ms, total: 73 ms\n",
      "Wall time: 44.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40eab6c90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "enrich_query = f\"\"\"CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.enriched_data` AS (\n",
    "  WITH tf as (SELECT distinct * from `{PROJECT_ID}.{bq_dataset}.audio_features`),\n",
    "       af as (SELECT distinct * from `{PROJECT_ID}.{bq_dataset}.artist_features`) \n",
    "  \n",
    "    SELECT\n",
    "    a.* except(tracks),\n",
    "      ARRAY(\n",
    "    SELECT\n",
    "      AS STRUCT CAST(track.pos AS int64) AS pos_can,\n",
    "      case when track.artist_name = '' then 'NONE' else track.artist_name end AS artist_name_can,\n",
    "      case when track.track_uri = '' then 'NONE' else track.track_uri  end AS track_uri_can,\n",
    "      case when track.album_uri = '' then 'NONE' else track.album_uri  end AS album_uri_can,\n",
    "      case when track.artist_uri = '' then 'NONE' else track.artist_uri  end AS artist_uri_can,\n",
    "      case when track.track_name = '' then 'NONE' else track.track_name end AS track_name_can,\n",
    "      CAST(track.duration_ms AS float64) / 1.0 AS duration_ms_can,\n",
    "      case when track.album_name = '' then 'NONE' else track.album_name end AS album_name_can,\n",
    "      CAST(IFNULL(tf.track_pop, 0.0) as float64) / 1.0 AS track_pop_can,\n",
    "      CAST(IFNULL(af.artist_pop, 0.0) as float64) / 1.0  AS artist_pop_can,\n",
    "      CAST(IFNULL(af.genres, \"['NONE']\") as string)  AS artist_genres_can,\n",
    "      CAST(IFNULL(af.followers, 0.0) as float64) / 1.0 AS artist_followers_can\n",
    "    FROM\n",
    "      UNNEST(tracks) as track\n",
    "    INNER JOIN\n",
    "     tf --track features\n",
    "    ON\n",
    "      (track.track_uri = tf.track_uri)\n",
    "    INNER JOIN\n",
    "      af\n",
    "      ON\n",
    "      (track.artist_uri = af.artist_uri)\n",
    "      ) AS tracks\n",
    "  FROM \n",
    "  `{PROJECT_ID}.{bq_dataset}.playlists_nested` as a)\"\"\"\n",
    "\n",
    "bigquery_client.query(enrich_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933a3b9",
   "metadata": {},
   "source": [
    "## Cross join + get rid of after-the-fact `pos` data in playlist\n",
    "\n",
    "cross_join_songxplaylist_struct_query\n",
    "\n",
    "`hybrid-vertex.spotify_train_3.ordered_position_training`\n",
    "\n",
    "We create a data structure that creates unique song-playlist combos (every possible via cross-join). There is also a portion of pulling the last song in the playlist as the \"seed track\"\n",
    "________\n",
    "### Note on the approach\n",
    "\n",
    "Semantic matching requires pairs, triplets (tuples generally) of co-occurrences between pairs. This is a very broad definition, and with this newer approach many new use cases are being explored. A simple example are finding pairs of user queries and purchases. The training example pair are: (the features we know from the user query, the features we know on the product they ultimately purchased).\n",
    "\n",
    "There are other approaches where triples are considered, and there are advanced techniques on negative sampling, finding “bad” examples of query, product pairs, which we will not cover here.\n",
    "\n",
    "Note there are other sampling techniques we highlight below (different artist/album)\n",
    "\n",
    "The chosen task was predicting the next song on a playlist, given the playlist existing order. The approach taken was to create pairs for all children songs and their parent playlists. We did leveraging BigQuery’s `UNNEST` and `CROSS JOIN`. \n",
    "\n",
    "We also had rich features for playlists, albums and songs in another table that was later used to enrich post `CROSS JOIN`. This was done to optimize the computation since the cross-joining is expensive and it was subsequently much quicker to enrich after this step.\n",
    "\n",
    "Now that we completed this step, we had all combinations of child song, playlist pairs. The song was the candidate label but the playlist still contained the candidate label and all songs after. Additional criteria was added to remove the candidate song and all songs that occur after the candidate in the playlist. For the sake of performance we also only considered the last 5 played songs. Other sampling configurations are available in the example notebook as well (only predicting when there are album and artist switches).\n",
    "\n",
    "What this results in is a training dataset that has all possible child song candidates joined with the full playlist data, and the playlist data is properly censored as to only contain songs up to before the candidate song.\n",
    "\n",
    "![](img/semantic-pair.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0e136cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.1 ms, sys: 9.64 ms, total: 55.7 ms\n",
      "Wall time: 2min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40ea3ef10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cross_join_query = f\"\"\"\n",
    "  CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` AS (\n",
    "  WITH\n",
    "    -- get every combination of song and its parent playlist\n",
    "    unnest_cross AS(\n",
    "    SELECT\n",
    "      b.*,\n",
    "      CONCAT(b.pid,\"-\",track.pos_can) AS pid_pos_id,\n",
    "      CAST(track.pos_can AS int64) AS pos_can,\n",
    "      IFNULL(track.artist_name_can, \"NONE\") as artist_name_can ,\n",
    "      track.track_uri_can ,\n",
    "      track.album_uri_can,\n",
    "      IFNULL(track.track_name_can, \"NONE\") as track_name_can ,\n",
    "      track.artist_uri_can ,\n",
    "      CAST(track.duration_ms_can AS float64) AS duration_ms_can,\n",
    "      track.album_name_can ,\n",
    "      track.track_pop_can ,\n",
    "      track.artist_pop_can,\n",
    "      track.artist_genres_can as artist_genres_can ,\n",
    "      track.artist_followers_can \n",
    "    FROM (\n",
    "      SELECT\n",
    "        * EXCEPT(duration_ms)\n",
    "      FROM\n",
    "        `{PROJECT_ID}.{bq_dataset}.enriched_data`) AS b\n",
    "    CROSS JOIN\n",
    "      UNNEST(tracks) AS track)\n",
    "  SELECT\n",
    "    a.* EXCEPT(tracks,\n",
    "      num_tracks,\n",
    "      num_artists,\n",
    "      num_albums,\n",
    "      num_followers,\n",
    "      num_edits),\n",
    "    ARRAY(\n",
    "    SELECT\n",
    "      AS STRUCT CAST(track.pos_can AS int64) AS pos_pl,\n",
    "      track.artist_name_can AS artist_name_pl,\n",
    "      track.track_uri_can AS track_uri_pl,\n",
    "      track.track_name_can AS track_name_pl,\n",
    "      track.album_uri_can AS album_uri_pl,\n",
    "      track.artist_uri_can AS artist_uri_pl,\n",
    "      CAST(track.duration_ms_can AS float64) AS duration_ms_pl,\n",
    "      track.album_name_can AS album_name_pl,\n",
    "      track.track_pop_can AS track_pop_pl,\n",
    "      track.artist_pop_can AS artist_pop_pl,\n",
    "      track.artist_genres_can AS artist_genres_pl,\n",
    "      track.artist_followers_can AS artist_followers_pl,\n",
    "    FROM\n",
    "      UNNEST(tracks) AS track\n",
    "    WHERE\n",
    "      CAST(track.pos_can AS int64) < a.pos_can ORDER BY CAST(track.pos_can AS int64)) AS seed_playlist_tracks\n",
    "  FROM\n",
    "    unnest_cross AS a -- with statement\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "bigquery_client.query(cross_join_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a1393",
   "metadata": {},
   "source": [
    "## Update the playlist metadata with the new samples created above\n",
    "\n",
    "Add audio features from the tracks\n",
    "\n",
    "Get new metadata for the tracks now that there are updated track counts, durations, etc...\n",
    "\n",
    "`hybrid-vertex.spotify_train_3.train` will be produced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7985b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.9 ms, sys: 12.5 ms, total: 94.4 ms\n",
      "Wall time: 2min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40fa82310>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_new_metadata_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train` as (\n",
    "WITH\n",
    "  playlist_features_clean AS (\n",
    "  SELECT\n",
    "    pid_pos_id,\n",
    "    SUM(trx.duration_ms_pl) / 1.0 AS duration_ms_seed_pl,\n",
    "    COUNT(1) / 1.0 AS n_songs_pl,\n",
    "    COUNT(DISTINCT trx.artist_name_pl) / 1.0 AS num_artists_pl,\n",
    "    COUNT(DISTINCT trx.album_uri_pl) /1.0 AS num_albums_pl,\n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.ordered_position_training`,\n",
    "    UNNEST(seed_playlist_tracks) AS trx\n",
    "  GROUP BY\n",
    "    pid_pos_id)\n",
    "    \n",
    "SELECT\n",
    "  a.* except(artist_genres_can, track_pop_can, artist_pop_can, artist_followers_can),\n",
    "  b.* except(pid_pos_id),\n",
    "  a.artist_genres_can,\n",
    "  IFNULL(a.track_pop_can, 0.0) / 1.0 as  track_pop_can, \n",
    "  IFNULL(a.artist_pop_can, 0.0) / 1.0 as artist_pop_can,\n",
    "  IFNULL(a.artist_followers_can, 0.0) / 1.0 as artist_followers_can,\n",
    "\n",
    "  \n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.ordered_position_training` a\n",
    "INNER JOIN\n",
    "  playlist_features_clean b\n",
    "ON\n",
    "  a.pid_pos_id = b.pid_pos_id )\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_new_metadata_query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19113617-7da4-4c9d-a18e-a54b414abe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 ms, sys: 0 ns, total: 16.1 ms\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40e9e5e50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "### Get candidates\n",
    "\n",
    "get_unique_candidates = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.candidates` as (\n",
    "WITH\n",
    "af as (SELECT DISTINCT * FROM `{PROJECT_ID}.{bq_dataset}.audio_features`)\n",
    "\n",
    "SELECT DISTINCT\n",
    "    track_uri_can,\n",
    "    track_name_can,\n",
    "    artist_uri_can,\n",
    "    artist_name_can,\n",
    "    album_uri_can,\n",
    "    album_name_can,\n",
    "    duration_ms_can,\n",
    "    track_pop_can,\n",
    "    artist_pop_can,\n",
    "    artist_genres_can,\n",
    "    artist_followers_can,\n",
    "    \n",
    "    IFNULL(af.danceability, 0.) as track_danceability_can,\n",
    "    IFNULL(af.energy, 0.) as track_energy_can,\n",
    "    IFNULL(af.key, 0.) as track_key_can,\n",
    "    IFNULL(af.loudness, 0.) as track_loudness_can,\n",
    "    IFNULL(af.mode, 0) as track_mode_can,\n",
    "    IFNULL(af.speechiness, 0.) as track_speechiness_can,\n",
    "    IFNULL(af.acousticness, 0.) as track_acousticness_can,\n",
    "    IFNULL(af.instrumentalness, 0.) as track_instrumentalness_can,\n",
    "    IFNULL(af.liveness, 0.) as track_liveness_can,\n",
    "    IFNULL(af.valence, 0.) as track_valence_can,\n",
    "    IFNULL(af.tempo, 0.) as track_tempo_can,\n",
    "    IFNULL(af.time_signature, 0) as time_signature_can,\n",
    "FROM\n",
    "  `{PROJECT_ID}.{bq_dataset}.train` a\n",
    "   inner join af on af.track_uri = a.track_uri_can\n",
    "  )\n",
    "  \"\"\"\n",
    "\n",
    "bigquery_client.query(get_unique_candidates).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4517477d",
   "metadata": {},
   "source": [
    "## For TFRecords\n",
    "Get rid of structs by creating new table with arrays from playlist_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcaf70-5e96-435e-a888-ae832dc297aa",
   "metadata": {},
   "source": [
    "# Only selecting last 5 songs\n",
    "\n",
    "song_history is settable but it will impact `MAX_PLAYLIST_LENGTH` in `src/two_tower.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f8fa435-e2d7-48c4-a2b2-5a673d58b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_HISTORY=5 # length of playlist tracks to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83c31ae6-1126-4970-bf30-cbe40065d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 ms, sys: 94 µs, total: 29.9 ms\n",
      "Wall time: 56.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40ea0f890>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_flatten_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_a` as (\n",
    "WITH audio as (SELECT DISTINCT * FROM `{PROJECT_ID}.{bq_dataset}.audio_features`)\n",
    "SELECT \n",
    "    pid,\n",
    "    IFNULL(a.name, \"\") as pl_name_src,\n",
    "    collaborative as pl_collaborative_src,\n",
    "    duration_ms_seed_pl as pl_duration_ms_new,\n",
    "    n_songs_pl as num_pl_songs_new, \n",
    "    num_artists_pl as num_pl_artists_new,\n",
    "    num_albums_pl as num_pl_albums_new,\n",
    "    track_uri_can,\n",
    "    track_name_can,\n",
    "    artist_uri_can,\n",
    "    artist_name_can,\n",
    "    album_uri_can,\n",
    "    album_name_can,\n",
    "    duration_ms_can,\n",
    "    track_pop_can,\n",
    "    artist_pop_can,\n",
    "    artist_genres_can,\n",
    "    artist_followers_can,\n",
    "    IFNULL(audio.danceability, 0.0) as track_danceability_can,\n",
    "    IFNULL(audio.energy, 0.0) as track_energy_can,\n",
    "    IFNULL(audio.key, 0.0) as track_key_can,\n",
    "    IFNULL(audio.loudness, 0.0) as track_loudness_can,\n",
    "    IFNULL(audio.mode, 0) as track_mode_can,\n",
    "    IFNULL(audio.acousticness, 0.0) as track_acousticness_can,\n",
    "    IFNULL(audio.instrumentalness, 0.0) as track_instrumentalness_can,\n",
    "    IFNULL(audio.liveness, 0.0) as track_liveness_can,\n",
    "    IFNULL(audio.speechiness, 0.0) as track_speechiness_can,\n",
    "    IFNULL(audio.valence, 0.0) as track_valence_can,\n",
    "    IFNULL(audio.tempo, 0.0) as track_tempo_can,\n",
    "    IFNULL(audio.time_signature, 0) as track_time_signature_can,\n",
    "    \n",
    "    ARRAY(select t.artist_name_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_name_pl, \n",
    "    ARRAY(select t.artist_uri_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_uri_pl, \n",
    "    ARRAY(select t.track_uri_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as track_uri_pl,\n",
    "    ARRAY(select t.track_name_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as track_name_pl,\n",
    "    ARRAY(select t.duration_ms_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as duration_ms_songs_pl, \n",
    "    ARRAY(select t.album_name_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as album_name_pl,\n",
    "    ARRAY(select t.album_uri_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as album_uri_pl,\n",
    "    ARRAY(select cast(t.artist_pop_pl as FLOAT64) from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_pop_pl,\n",
    "    ARRAY(select t.artist_followers_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artists_followers_pl,\n",
    "    ARRAY(select t.track_pop_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as track_pop_pl, \n",
    "    ARRAY(select t.artist_genres_pl from UNNEST(seed_playlist_tracks) t \n",
    "        where pos_pl >= pos_can - {TRACK_HISTORY}) as artist_genres_pl\n",
    "    \n",
    "    from `{PROJECT_ID}.{bq_dataset}.train` a\n",
    "    INNER JOIN \n",
    "    audio on audio.track_uri = a.track_uri_can\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(train_flatten_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4d75b-48aa-42d9-abfd-7c8620d85a5e",
   "metadata": {},
   "source": [
    "#### Append the audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b96beea-92fa-4c74-9a10-913185d54f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 ms, sys: 43 ms, total: 358 ms\n",
      "Wall time: 26min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40e9b1910>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_flatten_query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_b` as (\n",
    "WITH audio as (SELECT DISTINCT * FROM `{PROJECT_ID}.{bq_dataset}.audio_features`)\n",
    "SELECT \n",
    "    a.*,\n",
    "    ARRAY(select IFNULL(audio.danceability, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_danceability_pl,\n",
    "    ARRAY(select IFNULL(audio.energy, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_energy_pl,\n",
    "    ARRAY(select IFNULL(audio.key, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_key_pl,\n",
    "    ARRAY(select IFNULL(audio.loudness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_loudness_pl,\n",
    "    ARRAY(select IFNULL(audio.mode, 0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_mode_pl,\n",
    "    ARRAY(select IFNULL(audio.acousticness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_acousticness_pl,\n",
    "    ARRAY(select IFNULL(audio.instrumentalness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_instrumentalness_pl,\n",
    "    ARRAY(select IFNULL(audio.liveness, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_liveness_pl,\n",
    "    ARRAY(select IFNULL(audio.valence, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_valence_pl,\n",
    "    ARRAY(select IFNULL(audio.tempo, 0.0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_tempo_pl,\n",
    "    ARRAY(select IFNULL(audio.time_signature, 0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_time_signature_pl,\n",
    "    ARRAY(select IFNULL(audio.speechiness, 0) from UNNEST(a.track_uri_pl) t, audio where audio.track_uri = t) as track_speechiness_pl\n",
    "    from `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_a` a\n",
    "    WHERE\n",
    "     ARRAY_LENGTH(a.track_uri_pl) = {TRACK_HISTORY}) --limiting here for performance\n",
    "\"\"\"\n",
    "\n",
    "bigquery_client.query(train_flatten_query).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b5571-175c-44ac-b8bf-1df0ce8c5160",
   "metadata": {},
   "source": [
    "## Important for validation strategy\n",
    "Different playlist ids were selected for validation to prevent cross-contamination with the sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a08d4f1-ea60-46b5-b520-1d61ec0e38ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 ms, sys: 4.42 ms, total: 16.7 ms\n",
      "Wall time: 17.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40e9bed10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.01\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_valid_last_{TRACK_HISTORY}` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_b` where MOD(pid, 100) = 0\n",
    "    AND ARRAY_LENGTH(track_uri_pl) = {TRACK_HISTORY})\"\"\" #complete examples only\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5db82a0-253c-4f84-bab3-d087888ab30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 ms, sys: 0 ns, total: 25.1 ms\n",
      "Wall time: 32.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff40e9ca7d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "VALIDATION_P = 0.01\n",
    "\n",
    "validation_creation = f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{PROJECT_ID}.{bq_dataset}.train_flatten_last_{TRACK_HISTORY}` AS (\n",
    "    SELECT * \n",
    "  FROM\n",
    "    `{PROJECT_ID}.{bq_dataset}.train_flatten_pre_split_b` where MOD(pid, 100) != 0\n",
    "    AND ARRAY_LENGTH(track_uri_pl) = {TRACK_HISTORY})\"\"\" #complete examples only\"\"\"\n",
    "\n",
    "bigquery_client.query(validation_creation).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bc3ad-35a2-4e14-b946-5faf7e14dca1",
   "metadata": {},
   "source": [
    "## Done - you can move on to the [next notebook](02-tfrecord-beam-pipeline.ipynb) \n",
    "\n",
    "Your data should look like this:\n",
    "    \n",
    "![](img/train-dataset-metadata.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa410e4-2d40-435b-a5d2-068c5c440b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
