{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d5a597-2658-4c2e-bdda-944c2dab87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform[prediction]@git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {},
   "source": [
    "# Sklearn with Pandas - Custom Prediction Routine to get Merlin Model predictions\n",
    "\n",
    "Your output should look like this - you are going to use the query model endpoint to create a CPR Endpoing\n",
    "\n",
    "![](img/merlin-bucket.png)\n",
    "\n",
    "This is similar to [the other notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) except we will be using pandas and bigquery\n",
    "\n",
    "Topics covered\n",
    "* Training sklearn locally, deploying to endpoint\n",
    "* Saving data as CSV and doing batch predict from GCS\n",
    "* Loading data to BQ, using BQ magics\n",
    "* Running a batch prediction from BQ to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b65e26b-31d7-459e-8f80-92e2c206fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://wortz-project-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PROJECT = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "REGION = 'us-central1' \n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "REPOSITORY = 'merlin-spotify-cpr'\n",
    "ARTIFACT_URI = f'{BUCKET}/merlin-processed'\n",
    "MODEL_DIR = f'{BUCKET}/merlin-processed/query_model_merlin'\n",
    "PREFIX = 'merlin-spotify'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831cdd6-8d18-40aa-88ba-50889c3624a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# New section - preprocessor creation.\n",
    "\n",
    "In this section we will create a pipeline object that stores a standard scaler \n",
    "using the `PipeLine` class is important as it provides a lot of flexibility and conforms to sklearn's framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c749d4-18ca-46a0-91f9-432dbf1220e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a generic sklearn container that returns instances\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb\n",
    "\n",
    "**highly recommend reviewing this notebook first as it breaks down the custom predictor interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf container_code\n",
    "! mkdir container_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile container_code/requirements.txt\n",
    "fastapi\n",
    "uvicorn==0.17.6\n",
    "joblib~=1.0\n",
    "numpy~=1.20\n",
    "pandas\n",
    "dask\n",
    "tensorflow\n",
    "nvtabular\n",
    "google-cloud-storage\n",
    "google-cloud-aiplatform[prediction]>=1.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c1627-edf8-4879-b1eb-10f28e19cb7a",
   "metadata": {},
   "source": [
    "### CPR Template from here https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d80c477-d403-4d39-9220-98d90511a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "\n",
    "class Predictor(ABC):\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self, artifacts_uri: str) -> None:\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        import nvtabular as nvt\n",
    "        import pandas as pd\n",
    "        import os\n",
    "        self._model = tf.keras.models.load_model(artifacts_uri + \"/query_model_merlin\")\n",
    "        self._workflow = nvt.Workflow.load(artifacts_uri + \"/2t-spotify-workflow\")\n",
    "        pass\n",
    "\n",
    "    def preprocess(self, prediction_input: Any) -> Any:\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        inputs = pd.DataFrame.from_dict(prediction_input, orient='index').T #we are using instances format here as we haven't changed the prediction handler (ie data looks the same here as inputs for predict\n",
    "        transformed_inputs = nvt.Dataset(inputs)\n",
    "        \n",
    "        return self._workflow.transform(transformed_inputs)\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, instances: Any) -> Any:\n",
    "        \"\"\"Performs prediction.\n",
    "        Args:\n",
    "            instances (Any):\n",
    "                Required. The instance(s) used for performing prediction.\n",
    "        Returns:\n",
    "            Prediction results.\n",
    "        \"\"\"\n",
    "        outputs = self._model.predict(instances) \n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, prediction_results: Any) -> Any:\n",
    "        \"\"\"Postprocesses the prediction results.\n",
    "        Args:\n",
    "            prediction_results (Any):\n",
    "                Required. The prediction results.\n",
    "        Returns:\n",
    "            The postprocessed prediction results.\n",
    "        \"\"\"\n",
    "        return prediction_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a17737-58ad-4819-9b2d-72de6fd6e827",
   "metadata": {},
   "source": [
    "### Build and push container to Artifact Registry\n",
    "#### Build your container\n",
    "To build a custom container, we also need to write an entrypoint of the image that starts the model server. However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e72acda9-ae76-4ce9-8600-71238d545f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# Create the repo if needed for the artifacts\n",
    "\n",
    "! gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1858a130-739b-4752-bf02-d0e8356a0829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9af44323-4e94-43d0-9dc8-649879be77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install google-cloud-aiplatform[prediction]>=1.16.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf27d9-03c8-46e7-9dd3-45b6586f1316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from container_code.predictor import CprPredictor\n",
    "\n",
    "SERVER_IMAGE = \"merlin-prediction-cpr\"  # @param {type:\"string\"} \n",
    "\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    \"container_code\",\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{SERVER_IMAGE}\",\n",
    "    predictor=CprPredictor,\n",
    "    base_image='python:3.9',\n",
    "    requirements_path=\"container_code/requirements.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80330616-933a-4ec9-9322-2dd5815c4947",
   "metadata": {},
   "source": [
    "### Test it out with a locally deployed endpoint\n",
    "Need to generate credentials to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01981a9-6972-4eb9-b7ba-18689a31b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae134d5-92da-48b5-afdb-7a330c88ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {'album_name_can': 'We Just Havent Met Yet', \n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "                 'artist_followers_can': 4339757.0, \n",
    "                 'artist_genres_can': \"'hawaiian hip hop', 'rap'\", \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_can': 'Russ', \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 #'artist_pop_pl': [82., 80., 90., 87., 65.], \n",
    "                 'artist_uri_can': 'spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS', \n",
    "                 #'artists_followers_pl': [ 4339757.,  5611842., 15046756., 30713126.,   603837.], \n",
    "                 'collaborative': 'false', \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_can': 237322.0, \n",
    "                 #'duration_ms_songs_pl': [237506., 217200., 219080., 226400., 121739.], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_can': 'We Just Havent Met Yet', \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_can': 57.0, \n",
    "                 #'track_pop_pl': [79., 58., 83., 71., 57.],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 'track_uri_can': 'spotify:track:0VzDv4wiuZsLsNOmfaUy2W', \n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c322126-7fca-4e71-ab14-96bd3facee99",
   "metadata": {},
   "source": [
    "### Generate credentials - use your \n",
    "\n",
    "Go to the console and search \"Service Accounts\" from there - select your compute account:\n",
    "\n",
    "![](img/compute_sa.png)\n",
    "\n",
    "Then add a json key and upload back to this notebook. Note where it's stored for use in the local model below\n",
    "\n",
    "![](img/create_keys.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657cad4-c000-4539-b4c9-b853af79846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"hybrid-vertex-7c7ca1ad947a.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968407e-f579-44ab-ab1f-5b47db30c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=MODEL_DIR,\n",
    "    credential_path=CREDENTIALS_FILE) as local_endpoint:\n",
    "    health_check_response = local_endpoint.run_health_check()\n",
    "    prediction = local_endpoint.predict(TEST_INSTANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa05b7-4303-4655-9cc0-069be8bcf969",
   "metadata": {},
   "source": [
    "#### Only run once to generate creds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a979a4-48a8-4453-90a3-3629957bd878",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload the model to Vertex using new Prediction Route Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59eb3650-759a-40a1-bd2f-704daad82410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_model.push_image() #push to container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80d8e71d-9702-4c7d-bd15-925278f759d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/679926387543/locations/us-central1/models/8299698706639224832/operations/6891626251677597696\n",
      "Model created. Resource name: projects/679926387543/locations/us-central1/models/8299698706639224832\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/679926387543/locations/us-central1/models/8299698706639224832')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "model = local_model.upload(\n",
    "        display_name='merlin spotify query model',\n",
    "        artifact_uri=BUCKET,\n",
    "        description='two tower model using merlin models with spotify data',\n",
    "        labels= {'version': 'v1_0'}, \n",
    "              \n",
    "        sync=True, #false will not bind up your notebook instance with the creation operation\n",
    "    ) \n",
    "# model = aiplatform.Model('projects/679926387543/locations/us-central1/models/5966834099661307904')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bee664-c1bd-438a-b8e3-6bb2f09129a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/679926387543/locations/us-central1/endpoints/7051678242322776064/operations/1548668243755925504\n",
      "Endpoint created. Resource name: projects/679926387543/locations/us-central1/endpoints/7051678242322776064\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/679926387543/locations/us-central1/endpoints/7051678242322776064')\n",
      "Deploying model to Endpoint : projects/679926387543/locations/us-central1/endpoints/7051678242322776064\n",
      "Deploy Endpoint model backing LRO: projects/679926387543/locations/us-central1/endpoints/7051678242322776064/operations/5585582359740153856\n",
      "Endpoint model deployed. Resource name: projects/679926387543/locations/us-central1/endpoints/7051678242322776064\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")\n",
    "# endpoint = aiplatform.Endpoint('projects/679926387543/locations/us-central1/endpoints/8555880517864521728')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ca04949-78d9-4885-8b11-069bb12f9e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.79, 0.21], [0.24, 0.76]], deployed_model_id='2882294965424095232', explanations=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.predict(instances=[[47.7, 83.1, 38.7], [53.6, 76.1, 24.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ecbb6a-059e-4dee-bcb7-9974a518965c",
   "metadata": {},
   "source": [
    "# You should be able to see the logging ops by searching for `aiplatform.googleapis.com`\n",
    "+ Make sure you click `show query` slider in case there are other limitations\n",
    "![](images/log_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8328221-1c7c-4c65-bf71-59b59b75a7b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25239/4292456183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minstances_formatted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m predict_response = model.predict(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mrequest_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances_formatted_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,3)), # we will do batch predictions based on this\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3'],\n",
    "              dtype='float64')\n",
    "\n",
    "instances_formatted_data = df2.to_numpy().tolist()\n",
    "\n",
    "predict_response = model.predict(\n",
    "        request_file=instances_formatted_data,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f67d-b47e-43de-a41e-0e927bff6e43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expected output\n",
    "From documentation:\n",
    "```\n",
    "array([[0.8 , 0.2 ],\n",
    "       [0.38, 0.62],\n",
    "       [0.61, 0.39],\n",
    "       [0.65, 0.35],\n",
    "       [0.56, 0.44],\n",
    "       [0.63, 0.37],\n",
    "       [0.55, 0.45],\n",
    "       [0.43, 0.57],\n",
    "       [0.43, 0.57],\n",
    "       [0.38, 0.62]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994f47d-37e8-4992-9c38-762a713818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import csv\n",
    "\n",
    "# save the csv with the header, no index\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "\n",
    "data_directory = BUCKET + \"/data\"\n",
    "storage_path = os.path.join(data_directory, 'df2.csv')\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "blob.upload_from_filename(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a10c6c-18c1-4bf8-9641-61e4e1fe4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='pandas batch predict job sklearn - VALUES JSON',\n",
    "        gcs_source=storage_path,\n",
    "        gcs_destination_prefix=BUCKET+\"/predictions\",\n",
    "        machine_type='n1-standard-2',\n",
    "        instances_format='csv', #This is key to parsing CSV input\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903dc3b1-3458-447d-ab53-a25774d6c2d6",
   "metadata": {},
   "source": [
    "### When successful you should see this\n",
    "```\n",
    "{\"instance\": [16.0, 64.0, 61.0], \"prediction\": [0.63, 0.37]}\n",
    "{\"instance\": [83.0, 27.0, 87.0], \"prediction\": [0.35, 0.65]}\n",
    "{\"instance\": [96.0, 83.0, 57.0], \"prediction\": [0.68, 0.32]}\n",
    "{\"instance\": [11.0, 62.0, 17.0], \"prediction\": [0.89, 0.11]}\n",
    "{\"instance\": [61.0, 28.0, 1.0], \"prediction\": [0.36, 0.64]}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
