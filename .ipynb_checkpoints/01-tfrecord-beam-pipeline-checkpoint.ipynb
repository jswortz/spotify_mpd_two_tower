{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df6c870-747a-44c2-854e-bcd5ed14f320",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beam conversion from Bigquery to TF Records\n",
    "\n",
    "In this notebook we use Apache Beam to convert to tfrecords\n",
    "The applications can be found in `beam_candidates` and `beam_training` for candidate generation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f365f-5d78-4114-b741-311ffcc64884",
   "metadata": {},
   "source": [
    "`pip install --upgrade 'apache-beam[gcp]'`\n",
    "\n",
    "#### IMPORTANT - make sure you upgrade Dataflow with the above command then restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bab01ef-6f4f-47fe-8f54-56bae24cae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade 'apache-beam[gcp]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3148ce99-d7d0-4298-a3d3-4ea5a1aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1176b3bf-c98f-4d44-a410-31f816b1998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil mb -l us-central1 gs://spotify-beam-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880e9bb8-c550-414b-9b65-b2124837e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "BUCKET_NAME = 'spotify-beam-v3' # 'spotify-tfrecords-blog' # Set your Bucket name\n",
    "REGION = 'us-central1' # Set the region for Dataflow jobs\n",
    "VERSION = 'v7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbe19-0ea7-42cc-ac89-db2705f4ae16",
   "metadata": {},
   "source": [
    "### Run the Dataflow app to convert from BQ to TFrecords\n",
    "\n",
    "Candidate generation can be found in `beam_candidates`\n",
    "Training and Validation generation can be found in `beam_training`\n",
    "\n",
    "Usage:\n",
    "\n",
    "  Candidate generation \n",
    "  \n",
    "  `beam_candidates\\python3 main.py`\n",
    "   \n",
    "  Training generation\n",
    "  \n",
    "  `beam_training\\python3 main-train.py <BQ_table> <gcs data subfolder> <desired partition size MB> <BQ dataset size MB> <version tag>`\n",
    "  \n",
    "  \n",
    "##### Be careful with quotas - running more than two jobs can run into quota issues with defaults\n",
    "\n",
    "Training data generation runs about 1 hour with 10 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2cb50a-b8a7-4b72-bf2e-1ab7290a25bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_candidates\u001b[00m\n",
      "├── README.md\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   └── __init__.cpython-37.pyc\n",
      "├── \u001b[01;34mbq_to_tfr\u001b[00m\n",
      "│   ├── __init__.py\n",
      "│   ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   │   ├── __init__.cpython-37.pyc\n",
      "│   │   └── candidate_pipeline.cpython-37.pyc\n",
      "│   └── candidate_pipeline.py\n",
      "├── main.py\n",
      "├── requirements.txt\n",
      "└── setup.py\n",
      "\n",
      "3 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b0304b-3da3-45f7-831d-413d2d248b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mbeam_training\u001b[00m\n",
      "├── README.MD\n",
      "├── __init__.py\n",
      "├── \u001b[01;34mbeam_training\u001b[00m\n",
      "│   ├── __init__.py\n",
      "│   ├── \u001b[01;34mcreate_tfrecords.egg-info\u001b[00m\n",
      "│   │   ├── SOURCES.txt\n",
      "│   │   └── requires.txt\n",
      "│   ├── \u001b[01;34mcreate_tfrecords_training.egg-info\u001b[00m\n",
      "│   │   ├── SOURCES.txt\n",
      "│   │   └── requires.txt\n",
      "│   ├── main-train.py\n",
      "│   ├── main-valid.py\n",
      "│   ├── setup.py\n",
      "│   └── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "│       ├── __init__.py\n",
      "│       ├── test.py\n",
      "│       ├── train_pipe.py\n",
      "│       └── train_pipe_shape.py\n",
      "├── main-train.py\n",
      "├── setup.py\n",
      "└── \u001b[01;34mtrain_pipeline\u001b[00m\n",
      "    ├── __init__.py\n",
      "    ├── \u001b[01;34m__pycache__\u001b[00m\n",
      "    │   ├── __init__.cpython-37.pyc\n",
      "    │   └── train_pipe.cpython-37.pyc\n",
      "    ├── train_pipe.py\n",
      "    └── train_pipe_shape.py\n",
      "\n",
      "6 directories, 21 files\n"
     ]
    }
   ],
   "source": [
    "!tree beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81357053-6541-4fd2-8e04-b96474b797b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify_mpd_two_tower/beam_training\n"
     ]
    }
   ],
   "source": [
    "%cd beam_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d635a3-cdf4-4537-abba-f7a43275ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 main-train.py train_flatten_last_5 train_last_5 100 88_940 $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ef22a-7aa2-419d-b9e1-78a13a842489",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 main-train.py train_flatten_valid_last_5 valid_last_5 100 920 $VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a33f54-c717-4130-b375-3108836e9e04",
   "metadata": {},
   "source": [
    "## Test the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7c9dd2-7b32-4cb9-a7f9-97a0b1cdd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing output\n",
    "candidate_features = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "}\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "# # gs://spotify-beam-v3/v3/candidates/*.tfrecords\n",
    "\n",
    "BUCKET = 'spotify-beam-v3'\n",
    "CANDIDATE_PREFIX = 'v3/candidates/'\n",
    "\n",
    "candidate_files = []\n",
    "for blob in client.list_blobs(f\"{BUCKET}\", prefix=f'{CANDIDATE_PREFIX}', delimiter=\"/\"):\n",
    "    candidate_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "\n",
    "def parse_candidate_tfrecord_fn(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=candidate_features\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn, num_parallel_calls=-1)\n",
    "\n",
    "parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn) ### THIS NEEDS TO BE FIXED SO THE UNIQUE PRODUCT DATASET HAS THE SAME FIELD NAMES (goes thru the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b57c12cb-6c95-4bac-ba29-4d389babc44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'The Sound of Everything Rmx',\n",
      "       b'World Psychedelic Classics 4: Nobody Can Live Forever: The Existential Soul of Tim Maia'],\n",
      "      dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'spotify:album:4a8tMD6qq6GUuUwNae38VI',\n",
      "       b'spotify:album:0NxPZv3nWPBMk1o51GfwEY'], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 277649., 1363781.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b\"'downtempo', 'electronica', 'funk', 'latin alternative', 'nu jazz', 'nu-cumbia', 'trip hop', 'world'\",\n",
      "       b\"'brazilian boogie', 'brazilian soul', 'mpb', 'samba'\"],\n",
      "      dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Quantic', b'Tim Maia'], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([64., 64.], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'spotify:artist:5ZMwoAjeDtLJ0XRwRTgaK8',\n",
      "       b'spotify:artist:0jOs0wnXCu1bGGP7kh5uIu'], dtype=object)>, 'duration_ms_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([267130., 199720.], dtype=float32)>, 'track_name_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'The Sound of Everything - Watch TV & Se\\xc3\\xb1orlobo Remix',\n",
      "       b'Brother Father Mother Sister'], dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([53.,  0.], dtype=float32)>, 'track_uri_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'spotify:track:27CDzo2P7Mf3dKoa76tNxb',\n",
      "       b'spotify:track:4Eub2uHpLjK4fY3qR9uX8U'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "for x in parsed_candidate_dataset.batch(2).take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49445d15-3782-42e3-9820-8494ad67ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLAYLIST_LENGTH = 5\n",
    "feats = {\n",
    "    'track_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_name_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'album_uri_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'duration_ms_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'track_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_pop_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'artist_genres_can': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'artist_followers_can': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'name': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'collaborative': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'n_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_artists_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'num_albums_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=()),\n",
    "    'description_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=()),\n",
    "    'track_name_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artist_name_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'album_name_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'track_uri_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH)),\n",
    "    'duration_ms_songs_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artist_pop_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artists_followers_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'track_pop_pl': tf.io.FixedLenFeature(dtype=tf.float32, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "    'artist_genres_pl': tf.io.FixedLenFeature(dtype=tf.string, shape=(MAX_PLAYLIST_LENGTH,)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdad96f5-0e70-427b-9525-081406b9c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing output\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "# # gs://spotify-beam-v3/v3/candidates/*.tfrecords\n",
    "\n",
    "train_dir = 'spotify-beam-v3'\n",
    "train_dir_prefix = 'v6/train_last_5_v2/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f\"{train_dir}\", prefix=f'{train_dir_prefix}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "valid = tf.data.TFRecordDataset(valid_files)\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(\n",
    "        example, \n",
    "        features=feats\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# parsed_candidate_dataset = candidate_dataset.map(parse_candidate_tfrecord_fn, num_parallel_calls=-1)\n",
    "\n",
    "valid_parsed = valid.map(parse_tfrecord) ### THIS NEEDS TO BE FIXED SO THE UNIQUE PRODUCT DATASET HAS THE SAME FIELD NAMES (goes thru the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b87491-5706-4204-a19e-582612c1b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Long Way Home', b'Another Level'], dtype=object)>, 'album_name_pl': <tf.Tensor: shape=(2, 5), dtype=string, numpy=\n",
      "array([[b'Storyteller', b'Ripcord', b'The Album About Nothing',\n",
      "        b'So Good', b'Cruel'],\n",
      "       [b'Bad To The Bone', b'All Saints', b'The Rhythm Of The Night',\n",
      "        b'Another Level', b'Another Level']], dtype=object)>, 'album_uri_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'spotify:album:6yhHW85d9Z6D3uyvLZSZxI',\n",
      "       b'spotify:album:6nUnNpoLKWpb9qxhYiT98S'], dtype=object)>, 'artist_followers_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([216415., 641020.], dtype=float32)>, 'artist_genres_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b\"'electropop', 'gauze pop'\",\n",
      "       b\"'boy band', 'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'new jack swing', 'pop rap', 'quiet storm', 'r&b', 'rap', 'urban contemporary'\"],\n",
      "      dtype=object)>, 'artist_genres_pl': <tf.Tensor: shape=(2, 5), dtype=string, numpy=\n",
      "array([[b\"'contemporary country', 'country', 'country dawn', 'country road', 'oklahoma country', 'post-teen pop'\",\n",
      "        b\"'australian country', 'australian pop', 'contemporary country', 'country', 'country road'\",\n",
      "        b\"'gangster rap', 'hip hop', 'pop', 'pop rap', 'r&b', 'rap', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
      "        b\"'dance pop', 'edm', 'electropop', 'pop', 'pop dance', 'post-teen pop', 'scandipop', 'swedish electropop', 'swedish pop', 'tropical house'\",\n",
      "        b\"'edm', 'electropop', 'pop', 'pop dance', 'tropical house'\"],\n",
      "       [b\"'reggae', 'reggae fusion', 'roots reggae'\",\n",
      "        b\"'dance pop', 'electropop', 'europop', 'girl group', 'new wave pop', 'pop rock'\",\n",
      "        b\"'bubblegum dance', 'diva house', 'eurodance', 'europop', 'hip house'\",\n",
      "        b\"'boy band', 'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'new jack swing', 'pop rap', 'quiet storm', 'r&b', 'rap', 'urban contemporary'\",\n",
      "        b\"'boy band', 'contemporary r&b', 'dance pop', 'hip hop', 'hip pop', 'neo soul', 'new jack swing', 'pop rap', 'quiet storm', 'r&b', 'rap', 'urban contemporary'\"]],\n",
      "      dtype=object)>, 'artist_name_can': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'L\\xc3\\xa5psley', b'Blackstreet'], dtype=object)>, 'artist_name_pl': <tf.Tensor: shape=(2, 5), dtype=string, numpy=\n",
      "array([[b'Carrie Underwood', b'Keith Urban', b'Wale', b'Zara Larsson',\n",
      "        b'Snakehips'],\n",
      "       [b'Inner Circle', b'All Saints', b'Corona', b'Blackstreet',\n",
      "        b'Blackstreet']], dtype=object)>, 'artist_pop_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([54., 67.], dtype=float32)>, 'artist_pop_pl': <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "array([[75., 74., 77., 79., 68.],\n",
      "       [64., 60., 62., 67., 67.]], dtype=float32)>, 'artist_uri_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'spotify:artist:27ze6hCgfr3HcDZAHY60pg',\n",
      "       b'spotify:artist:2P3cjUru4H3fhSXXNxE9kA'], dtype=object)>, 'artists_followers_pl': <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "array([[5089914., 4597703., 3561854., 9858516.,  339972.],\n",
      "       [ 307772.,  432270.,  156658.,  641020.,  641020.]], dtype=float32)>, 'collaborative': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'false', b'false'], dtype=object)>, 'description_pl': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'', b''], dtype=object)>, 'duration_ms_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([231467., 317160.], dtype=float32)>, 'duration_ms_songs_pl': <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "array([[204093., 230600., 216831., 224030., 228253.],\n",
      "       [229466., 387573., 264306., 304600., 304600.]], dtype=float32)>, 'n_songs_pl': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 83., 177.], dtype=float32)>, 'name': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'heck', b'90s/2000s'], dtype=object)>, 'num_albums_pl': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 36., 118.], dtype=float32)>, 'num_artists_pl': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([27., 57.], dtype=float32)>, 'track_name_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'Hurt Me', b\"We Gonna Take U Back (Lude)/ Don't Leave Me\"],\n",
      "      dtype=object)>, 'track_name_pl': <tf.Tensor: shape=(2, 5), dtype=string, numpy=\n",
      "array([[b'Dirty Laundry', b\"Blue Ain't Your Color\",\n",
      "        b'The Need To Know (feat. SZA)', b\"Ain't My Fault\", b'Cruel'],\n",
      "       [b'Bad Boys (Theme From Cops) - Original Version', b'Never Ever',\n",
      "        b'The Rhythm Of The Night', b'No Diggity', b'No Diggity']],\n",
      "      dtype=object)>, 'track_pop_can': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>, 'track_pop_pl': <tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
      "array([[66., 52., 69., 72., 62.],\n",
      "       [ 0., 66., 60., 80., 80.]], dtype=float32)>, 'track_uri_can': <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b'spotify:track:2MMFpdctgwEkUlfP3kyPDG',\n",
      "       b'spotify:track:16TcsLUp9nAKFq2C9Mvk5G'], dtype=object)>, 'track_uri_pl': <tf.Tensor: shape=(2, 5), dtype=string, numpy=\n",
      "array([[b'spotify:track:5qRRiqndqXaq2QBudIrkYU',\n",
      "        b'spotify:track:6ZOPiKQeibCn7fP8dncucL',\n",
      "        b'spotify:track:6KacmqPPQ3LNoiGFuqGChs',\n",
      "        b'spotify:track:0ADG9OgdVTL7fgREP75BrZ',\n",
      "        b'spotify:track:0B2RttXEiyXsMeQ7mMP3EI'],\n",
      "       [b'spotify:track:6HHrXbBPk5ybtKuYG9SZDH',\n",
      "        b'spotify:track:7ziHnshbknkpFLDW5yGBjO',\n",
      "        b'spotify:track:4oUr6mgNSjQjyGs8kbXzU5',\n",
      "        b'spotify:track:6MdqqkQ8sSC0WB4i8PyRuQ',\n",
      "        b'spotify:track:6MdqqkQ8sSC0WB4i8PyRuQ']], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(2).take(1):\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
