{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVKyuWRezBGF"
   },
   "source": [
    "# Spotify API Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgGWdClhze9D"
   },
   "source": [
    "* Spotify Mlllion Playlist Dataset Challenge [Homepage](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n",
    "* [Spotify Web API docs](https://developer.spotify.com/documentation/web-api/reference/#/)\n",
    "\n",
    "**Community Examples**\n",
    "* [Extracting song lists](https://github.com/tojhe/recsys-spotify/blob/master/processing/songlist_extraction.py)\n",
    "* [construct audio features with Spotify API](https://github.com/tojhe/recsys-spotify/blob/master/processing/audio_features_construction.py)\n",
    "* [Using Spotify API](https://towardsdatascience.com/extracting-song-data-from-the-spotify-api-using-python-b1e79388d50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCbr2tLuzTJK"
   },
   "source": [
    "### pip & package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wwktfnCyzWO",
    "outputId": "6afe4a17-ebc2-40dc-d23a-1f447f394046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'jtotten-project'\n",
    "# PROJECT_ID = 'matching-engine-playlist'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0EYoIoQy8xq"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQmbM2KC3L3A"
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo### Manual loading to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IEwMKvN0TvS"
   },
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "# import pandas_gbq\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# from google.cloud import bigquery\n",
    "# import numpy as np\n",
    "# from absl import logging\n",
    "\n",
    "# project = 'jtotten-project'\n",
    "# bq_project = 'jtotten-project'\n",
    "# bq_dataset = 'spotify_mpd'\n",
    "# location = 'us-central1'\n",
    "# split_id = 2\n",
    "\n",
    "\n",
    "# logging.set_verbosity(logging.INFO)\n",
    "\n",
    "# storage_client = storage.Client(\n",
    "#   project=project\n",
    "# )\n",
    "\n",
    "# bq_client = bigquery.Client(\n",
    "#     project=bq_project, location=location\n",
    "# )\n",
    "\n",
    "# df = pd.read_csv(f'gs://matching-engine-content/spotify-million-playlist/eda/track_audio_feat_{split_id}.csv', low_memory=False)\n",
    "# clean_art_pop = df['artist_pop'].replace('na', -1)\n",
    "# df['artist_pop'] = clean_art_pop\n",
    "# df = df.astype({'artist_pop': 'int32'})\n",
    "\n",
    "\n",
    "# df.to_gbq(\n",
    "#     destination_table=f'{bq_dataset}.track_audio_split_{split_id}', \n",
    "#     project_id=f'{bq_project}', # TODO: param\n",
    "#     location='us-central1', \n",
    "#     progress_bar=True, \n",
    "#     reauth=True, \n",
    "#     if_exists='replace',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khc39YNHy98Z"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "  USER_FLAG = ''\n",
    "else:\n",
    "  USER_FLAG = '--user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RRSdCB_HSBSl",
    "outputId": "b272ec83-d189-4a22-da3e-5ef650c574b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotipy\n",
      "  Downloading spotipy-2.19.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spotipy) (1.15.0)\n",
      "Collecting requests>=2.25.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
      "\u001b[?25hCollecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 19.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
      "Installing collected packages: urllib3, requests, spotipy\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed requests-2.27.1 spotipy-2.19.0 urllib3-1.26.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "requests",
         "urllib3"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.2.1-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 10.4 MB/s \n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.7.1-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 50.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
      "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-2.2.3-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.3.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 4.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.56.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
      "Installing collected packages: google-crc32c, google-api-core, google-resumable-media, google-cloud-core, google-cloud-storage\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.26.3\n",
      "    Uninstalling google-api-core-1.26.3:\n",
      "      Successfully uninstalled google-api-core-1.26.3\n",
      "  Attempting uninstall: google-resumable-media\n",
      "    Found existing installation: google-resumable-media 0.4.1\n",
      "    Uninstalling google-resumable-media-0.4.1:\n",
      "      Successfully uninstalled google-resumable-media-0.4.1\n",
      "  Attempting uninstall: google-cloud-core\n",
      "    Found existing installation: google-cloud-core 1.0.3\n",
      "    Uninstalling google-cloud-core-1.0.3:\n",
      "      Successfully uninstalled google-cloud-core-1.0.3\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 1.18.1\n",
      "    Uninstalling google-cloud-storage-1.18.1:\n",
      "      Successfully uninstalled google-cloud-storage-1.18.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n",
      "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.2 which is incompatible.\n",
      "google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.7.1 which is incompatible.\n",
      "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-api-core-2.7.1 google-cloud-core-2.2.3 google-cloud-storage-2.2.1 google-crc32c-1.3.0 google-resumable-media-2.3.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp\n",
      "  Downloading kfp-1.8.12.tar.gz (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 8.5 MB/s \n",
      "\u001b[?25hCollecting google-cloud-pipeline-components\n",
      "  Downloading google_cloud_pipeline_components-1.0.2-py3-none-any.whl (375 kB)\n",
      "\u001b[K     |████████████████████████████████| 375 kB 47.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.7/dist-packages (from kfp) (1.0.0)\n",
      "Collecting PyYAML<6,>=5.3\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 49.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from kfp) (2.7.1)\n",
      "Collecting google-cloud-storage<2,>=1.20.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 55.9 MB/s \n",
      "\u001b[?25hCollecting kubernetes<19,>=8.0.0\n",
      "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 57.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.7/dist-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from kfp) (1.35.0)\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
      "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.1.tar.gz (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
      "\u001b[?25hCollecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from kfp) (7.1.2)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.13.tar.gz (23 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.14\n",
      "  Downloading kfp_pipeline_spec-0.1.14-py3-none-any.whl (18 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 6.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from kfp) (3.17.3)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kfp) (3.0.1)\n",
      "Collecting pydantic<2,>=1.8.2\n",
      "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9 MB 47.5 MB/s \n",
      "\u001b[?25hCollecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py<2,>=0.9->kfp) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated<2,>=1.2.7->kfp) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.56.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.0.4)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.17.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp) (57.4.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.2.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp) (4.11.3)\n",
      "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.9)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.10)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Collecting google-cloud-notebooks>=0.4.0\n",
      "  Downloading google_cloud_notebooks-1.2.1-py2.py3-none-any.whl (343 kB)\n",
      "\u001b[K     |████████████████████████████████| 343 kB 68.9 MB/s \n",
      "\u001b[?25hCollecting google-cloud-aiplatform<2,>=1.11.0\n",
      "  Downloading google_cloud_aiplatform-1.11.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 43.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components) (1.21.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components) (21.3)\n",
      "Collecting proto-plus>=1.15.0\n",
      "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
      "\u001b[?25hCollecting grpcio-status<2.0dev,>=1.33.2\n",
      "  Downloading grpcio_status-1.44.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.44.0)\n",
      "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-2.34.3-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 49.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-aiplatform<2,>=1.11.0->google-cloud-pipeline-components) (3.0.7)\n",
      "Collecting protobuf<4,>=3.13.0\n",
      "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 57.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Building wheels for collected packages: kfp, docstring-parser, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kfp: filename=kfp-1.8.12-py3-none-any.whl size=419048 sha256=257d2efbc97c3c72a6dd15d544082bb7317c843433008010aed336e0da0ae5ed\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/0c/4a/3fc55077bc88cc17eacaae34c5fd3f6178c1d16d2ee3b0afdf\n",
      "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docstring-parser: filename=docstring_parser-0.13-py3-none-any.whl size=31866 sha256=b5255b4375974b284e2edfb1423d6f6638882ff0d6fec0e2b9e876728e3d47a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/88/3c/d1aa049309f7945178cac9fbe6561a86424f432da57c18ca0f\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=cf4c44139ac32a245d1406a50bf3f7a277e38c107db9ad75882a9661c15afb99\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.1-py3-none-any.whl size=95549 sha256=26ca0354d0825750b00d23e424bffd62cecc671eec075bada58b30c8a2d67a05\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/4e/2e/6795bd3ed456a43652e7de100aca275ec179c9a8dfbcc65626\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=9808eea00d34249ee71ed880ceb1dfeaab97528db959b6b1cc2eef42d488636f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
      "Successfully built kfp docstring-parser fire kfp-server-api strip-hints\n",
      "Installing collected packages: protobuf, grpcio-status, websocket-client, PyYAML, proto-plus, typer, strip-hints, requests-toolbelt, pydantic, kubernetes, kfp-server-api, kfp-pipeline-spec, jsonschema, google-cloud-storage, google-cloud-bigquery, fire, docstring-parser, Deprecated, cloudpickle, kfp, google-cloud-notebooks, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.3\n",
      "    Uninstalling protobuf-3.17.3:\n",
      "      Successfully uninstalled protobuf-3.17.3\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.3.3\n",
      "    Uninstalling jsonschema-4.3.3:\n",
      "      Successfully uninstalled jsonschema-4.3.3\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.2.1\n",
      "    Uninstalling google-cloud-storage-2.2.1:\n",
      "      Successfully uninstalled google-cloud-storage-2.2.1\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 1.21.0\n",
      "    Uninstalling google-cloud-bigquery-1.21.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.3.0\n",
      "    Uninstalling cloudpickle-1.3.0:\n",
      "      Successfully uninstalled cloudpickle-1.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.34.3 which is incompatible.\n",
      "nbclient 0.5.13 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
      "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed Deprecated-1.2.13 PyYAML-5.4.1 cloudpickle-2.0.0 docstring-parser-0.13 fire-0.4.0 google-cloud-aiplatform-1.11.0 google-cloud-bigquery-2.34.3 google-cloud-notebooks-1.2.1 google-cloud-pipeline-components-1.0.2 google-cloud-storage-1.44.0 grpcio-status-1.44.0 jsonschema-3.2.0 kfp-1.8.12 kfp-pipeline-spec-0.1.14 kfp-server-api-1.8.1 kubernetes-18.20.0 proto-plus-1.20.3 protobuf-3.20.0 pydantic-1.9.0 requests-toolbelt-0.9.1 strip-hints-0.1.10 typer-0.4.1 websocket-client-1.3.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (2.34.3)\n",
      "Requirement already satisfied: proto-plus>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (3.20.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.56.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.27.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.44.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.2.4)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-aiplatform) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.10)\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2022.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.44.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.35.0)\n",
      "Collecting aiohttp<4\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 12.2 MB/s \n",
      "\u001b[?25hCollecting fsspec==2022.3.0\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 57.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.6)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 45.3 MB/s \n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (3.10.0.2)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 59.4 MB/s \n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (2.0.12)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4->gcsfs) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.10.8)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (2.3.2)\n",
      "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (2.7.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (2.2.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (3.20.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage->gcsfs) (1.56.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage->gcsfs) (1.3.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, gcsfs\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 gcsfs-2022.3.0 multidict-6.0.2 yarl-1.7.2\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (2022.3.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'restart': True, 'status': 'ok'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spotify\n",
    "!pip install spotipy\n",
    "\n",
    "! pip3 install -U google-cloud-storage $USER_FLAG\n",
    "! pip3 install $USER kfp google-cloud-pipeline-components --upgrade\n",
    "# !git clone https://github.com/kubeflow/pipelines.git\n",
    "# !pip install pipelines/components/google-cloud/.\n",
    "\n",
    "# stable Vertex SDK\n",
    "!pip install google-cloud-aiplatform\n",
    "\n",
    "!pip install gcsfs\n",
    "!pip install fsspec\n",
    "\n",
    "# Download and install latest (preview) version of Vertex SDK\n",
    "# !pip install -U git+https://github.com/ivanmkc/python-aiplatform.git@imkc--matching-engine\n",
    "\n",
    "# OSS Scann for testing (OSS)\n",
    "# !pip install scann\n",
    "\n",
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irhbKrY3fcG8",
    "outputId": "2008a7ca-303d-4943-e56b-a57040c9abd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.12\n",
      "google_cloud_pipeline_components version: 1.0.2\n",
      "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
      "aiplatform SDK version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFyXP0_gYsGl",
    "outputId": "ea6ccb30-12b1-4537-efe3-acd3eeaa3fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [jtotten-project] or it does not exist.\n",
      "Are you sure you wish to set property [core/project] to jtotten-project?\n",
      "\n",
      "Do you want to continue (Y/n)?  Y\n",
      "\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "LOCATION = 'us-central1'\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "# PROJECT_ID = 'matching-engine-playlist'\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "\n",
    "import os\n",
    "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID\n",
    "\n",
    "# Required Pipeline Parameters\n",
    "PIPE_USER = 'jtott'  #  {type: 'string'} <--- TODO: CHANGE THIS\n",
    "\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "# BUCKET_NAME = 'spotify-million-playlists'\n",
    "\n",
    "GS_PIPELINE_ROOT_PATH = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, PIPE_USER)\n",
    "\n",
    "from google.colab import auth as colab_auth\n",
    "colab_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqhJlsodR-xX"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from io import BytesIO\n",
    "\n",
    "import time\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "# GCP\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rWNU-8n8__I"
   },
   "source": [
    "### clients & credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41vwz95o9TKr"
   },
   "source": [
    "Spotify credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKgfkqV49GIZ"
   },
   "outputs": [],
   "source": [
    "## jv.tott \n",
    "# client_id='2dce494e64a74be980138668f4402b97'\n",
    "# client_secret='1706fc14574a4fef9132aaaacb31aa1c'\n",
    "\n",
    "## jvt1865 1\n",
    "# client_id='52ca2066dfeb434ab832e6e9c709b9e7'\n",
    "# client_secret='86cb23965be04f458e412445d5a7d5af'\n",
    "\n",
    "## jvt1865 2\n",
    "# client_id='cdbcaab3757d40e6a2e5d1c03e072e5a'\n",
    "# client_secret='b05897a42de34e9290190a6acb44d875'\n",
    "\n",
    "## jvt1865 3\n",
    "# client_id='bc5bde5fae56491c997fb1e351560335'\n",
    "# client_secret='dce49e239da24d1fbe6b367df9c0b8eb'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuJk9A5I9ZfF"
   },
   "source": [
    "GCP clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCbHe1G_gICe",
    "outputId": "c3f7d046-4997-4b59-9bcc-44df8feba2ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Setup clients\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID\n",
    ")\n",
    "\n",
    "pipeline_client = pipelines_client.AIPlatformClient(\n",
    "  project_id=PROJECT_ID,\n",
    "  region=LOCATION,\n",
    ")\n",
    "\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvxKv0M49cMR"
   },
   "source": [
    "Pipeline stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMPDTywpgpu-",
    "outputId": "37f31e4a-65d0-465e-cfda-7c9610d9aad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINES_FILEPATH: gs://matching-engine-content/pipelines/pipelines.json\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Stuff\n",
    "import os\n",
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = f'gs://{BUCKET_NAME}/pipelines/pipelines.json' # <--- TODO: CHANGE THIS; can be blank json file\n",
    "print(\"PIPELINES_FILEPATH:\", PIPELINES_FILEPATH)\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "  with open(PIPELINES_FILEPATH) as f:\n",
    "    PIPELINES = json.load(f)\n",
    "else:\n",
    "  PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "  with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "    json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQJ5TUh2HXu7"
   },
   "outputs": [],
   "source": [
    "# !gsutil cp 'gs://spotify-million-playlists/upload_eda/all_tracks_v2.csv' 'gs://matching-engine-content/spotify-million-playlist/eda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbeNm6_whXMG"
   },
   "source": [
    "# Create Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcWOKbf6M41s"
   },
   "outputs": [],
   "source": [
    "# gcs_bucket = 'matching-engine-content'\n",
    "# gcs_prefix_eda = 'spotify-million-playlist/eda'\n",
    "# all_tracks_filename = 'all_tracks_v2.csv'\n",
    "# all_tracks_csv_gcs_uri = 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "l1n3xtq9JHAA",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "95c2ffe9-6689-4669-c1db-5040223e6002",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://matching-engine-content/spotify-million-playlist/spotify_million_playlist_dataset.zip...\n",
      "| [1 files][  5.4 GiB/  5.4 GiB]   47.6 MiB/s                                   \n",
      "Operation completed over 1 objects/5.4 GiB.                                      \n",
      "Archive:  spotify_million_playlist_dataset.zip\n",
      "  inflating: md5sums                 \n",
      "  inflating: README.md               \n",
      "  inflating: stats.txt               \n",
      "  inflating: license.txt             \n",
      "   creating: data/\n",
      "  inflating: data/mpd.slice.549000-549999.json  \n",
      "  inflating: data/mpd.slice.613000-613999.json  \n",
      "  inflating: data/mpd.slice.115000-115999.json  \n",
      "  inflating: data/mpd.slice.778000-778999.json  \n",
      "  inflating: data/mpd.slice.290000-290999.json  \n",
      "  inflating: data/mpd.slice.596000-596999.json  \n",
      "  inflating: data/mpd.slice.324000-324999.json  \n",
      "  inflating: data/mpd.slice.422000-422999.json  \n",
      "  inflating: data/mpd.slice.974000-974999.json  \n",
      "  inflating: data/mpd.slice.679000-679999.json  \n",
      "  inflating: data/mpd.slice.7000-7999.json  \n",
      "  inflating: data/mpd.slice.391000-391999.json  \n",
      "  inflating: data/mpd.slice.497000-497999.json  \n",
      "  inflating: data/mpd.slice.225000-225999.json  \n",
      "  inflating: data/mpd.slice.523000-523999.json  \n",
      "  inflating: data/mpd.slice.875000-875999.json  \n",
      "  inflating: data/mpd.slice.448000-448999.json  \n",
      "  inflating: data/mpd.slice.712000-712999.json  \n",
      "  inflating: data/mpd.slice.193000-193999.json  \n",
      "  inflating: data/mpd.slice.38000-38999.json  \n",
      "  inflating: data/mpd.slice.695000-695999.json  \n",
      "  inflating: data/mpd.slice.899000-899999.json  \n",
      "  inflating: data/mpd.slice.721000-721999.json  \n",
      "  inflating: data/mpd.slice.510000-510999.json  \n",
      "  inflating: data/mpd.slice.846000-846999.json  \n",
      "  inflating: data/mpd.slice.216000-216999.json  \n",
      "  inflating: data/mpd.slice.411000-411999.json  \n",
      "  inflating: data/mpd.slice.947000-947999.json  \n",
      "  inflating: data/mpd.slice.317000-317999.json  \n",
      "  inflating: data/mpd.slice.22000-22999.json  \n",
      "  inflating: data/mpd.slice.794000-794999.json  \n",
      "  inflating: data/mpd.slice.126000-126999.json  \n",
      "  inflating: data/mpd.slice.998000-998999.json  \n",
      "  inflating: data/mpd.slice.620000-620999.json  \n",
      "  inflating: data/mpd.slice.3000-3999.json  \n",
      "  inflating: data/mpd.slice.70000-70999.json  \n",
      "  inflating: data/mpd.slice.597000-597999.json  \n",
      "  inflating: data/mpd.slice.291000-291999.json  \n",
      "  inflating: data/mpd.slice.779000-779999.json  \n",
      "  inflating: data/mpd.slice.423000-423999.json  \n",
      "  inflating: data/mpd.slice.975000-975999.json  \n",
      "  inflating: data/mpd.slice.325000-325999.json  \n",
      "  inflating: data/mpd.slice.548000-548999.json  \n",
      "  inflating: data/mpd.slice.114000-114999.json  \n",
      "  inflating: data/mpd.slice.612000-612999.json  \n",
      "  inflating: data/mpd.slice.449000-449999.json  \n",
      "  inflating: data/mpd.slice.713000-713999.json  \n",
      "  inflating: data/mpd.slice.496000-496999.json  \n",
      "  inflating: data/mpd.slice.390000-390999.json  \n",
      "  inflating: data/mpd.slice.678000-678999.json  \n",
      "  inflating: data/mpd.slice.522000-522999.json  \n",
      "  inflating: data/mpd.slice.874000-874999.json  \n",
      "  inflating: data/mpd.slice.224000-224999.json  \n",
      "  inflating: data/mpd.slice.81000-81999.json  \n",
      "  inflating: data/mpd.slice.217000-217999.json  \n",
      "  inflating: data/mpd.slice.511000-511999.json  \n",
      "  inflating: data/mpd.slice.847000-847999.json  \n",
      "  inflating: data/mpd.slice.694000-694999.json  \n",
      "  inflating: data/mpd.slice.192000-192999.json  \n",
      "  inflating: data/mpd.slice.720000-720999.json  \n",
      "  inflating: data/mpd.slice.898000-898999.json  \n",
      "  inflating: data/mpd.slice.54000-54999.json  \n",
      "  inflating: data/mpd.slice.795000-795999.json  \n",
      "  inflating: data/mpd.slice.621000-621999.json  \n",
      "  inflating: data/mpd.slice.999000-999999.json  \n",
      "  inflating: data/mpd.slice.127000-127999.json  \n",
      "  inflating: data/mpd.slice.316000-316999.json  \n",
      "  inflating: data/mpd.slice.410000-410999.json  \n",
      "  inflating: data/mpd.slice.946000-946999.json  \n",
      "  inflating: data/mpd.slice.227000-227999.json  \n",
      "  inflating: data/mpd.slice.84000-84999.json  \n",
      "  inflating: data/mpd.slice.877000-877999.json  \n",
      "  inflating: data/mpd.slice.521000-521999.json  \n",
      "  inflating: data/mpd.slice.393000-393999.json  \n",
      "  inflating: data/mpd.slice.495000-495999.json  \n",
      "  inflating: data/mpd.slice.710000-710999.json  \n",
      "  inflating: data/mpd.slice.611000-611999.json  \n",
      "  inflating: data/mpd.slice.117000-117999.json  \n",
      "  inflating: data/mpd.slice.51000-51999.json  \n",
      "  inflating: data/mpd.slice.326000-326999.json  \n",
      "  inflating: data/mpd.slice.976000-976999.json  \n",
      "  inflating: data/mpd.slice.420000-420999.json  \n",
      "  inflating: data/mpd.slice.292000-292999.json  \n",
      "  inflating: data/mpd.slice.594000-594999.json  \n",
      "  inflating: data/mpd.slice.945000-945999.json  \n",
      "  inflating: data/mpd.slice.413000-413999.json  \n",
      "  inflating: data/mpd.slice.75000-75999.json  \n",
      "  inflating: data/mpd.slice.315000-315999.json  \n",
      "  inflating: data/mpd.slice.749000-749999.json  \n",
      "  inflating: data/mpd.slice.124000-124999.json  \n",
      "  inflating: data/mpd.slice.622000-622999.json  \n",
      "  inflating: data/mpd.slice.578000-578999.json  \n",
      "  inflating: data/mpd.slice.796000-796999.json  \n",
      "  inflating: data/mpd.slice.723000-723999.json  \n",
      "  inflating: data/mpd.slice.191000-191999.json  \n",
      "  inflating: data/mpd.slice.479000-479999.json  \n",
      "  inflating: data/mpd.slice.697000-697999.json  \n",
      "  inflating: data/mpd.slice.844000-844999.json  \n",
      "  inflating: data/mpd.slice.512000-512999.json  \n",
      "  inflating: data/mpd.slice.214000-214999.json  \n",
      "  inflating: data/mpd.slice.648000-648999.json  \n",
      "  inflating: data/mpd.slice.711000-711999.json  \n",
      "  inflating: data/mpd.slice.876000-876999.json  \n",
      "  inflating: data/mpd.slice.520000-520999.json  \n",
      "  inflating: data/mpd.slice.226000-226999.json  \n",
      "  inflating: data/mpd.slice.494000-494999.json  \n",
      "  inflating: data/mpd.slice.392000-392999.json  \n",
      "  inflating: data/mpd.slice.977000-977999.json  \n",
      "  inflating: data/mpd.slice.421000-421999.json  \n",
      "  inflating: data/mpd.slice.327000-327999.json  \n",
      "  inflating: data/mpd.slice.595000-595999.json  \n",
      "  inflating: data/mpd.slice.293000-293999.json  \n",
      "  inflating: data/mpd.slice.116000-116999.json  \n",
      "  inflating: data/mpd.slice.610000-610999.json  \n",
      "  inflating: data/mpd.slice.27000-27999.json  \n",
      "  inflating: data/mpd.slice.6000-6999.json  \n",
      "  inflating: data/mpd.slice.623000-623999.json  \n",
      "  inflating: data/mpd.slice.125000-125999.json  \n",
      "  inflating: data/mpd.slice.797000-797999.json  \n",
      "  inflating: data/mpd.slice.579000-579999.json  \n",
      "  inflating: data/mpd.slice.314000-314999.json  \n",
      "  inflating: data/mpd.slice.944000-944999.json  \n",
      "  inflating: data/mpd.slice.412000-412999.json  \n",
      "  inflating: data/mpd.slice.748000-748999.json  \n",
      "  inflating: data/mpd.slice.215000-215999.json  \n",
      "  inflating: data/mpd.slice.19000-19999.json  \n",
      "  inflating: data/mpd.slice.845000-845999.json  \n",
      "  inflating: data/mpd.slice.513000-513999.json  \n",
      "  inflating: data/mpd.slice.2000-2999.json  \n",
      "  inflating: data/mpd.slice.649000-649999.json  \n",
      "  inflating: data/mpd.slice.722000-722999.json  \n",
      "  inflating: data/mpd.slice.696000-696999.json  \n",
      "  inflating: data/mpd.slice.478000-478999.json  \n",
      "  inflating: data/mpd.slice.190000-190999.json  \n",
      "  inflating: data/mpd.slice.540000-540999.json  \n",
      "  inflating: data/mpd.slice.816000-816999.json  \n",
      "  inflating: data/mpd.slice.246000-246999.json  \n",
      "  inflating: data/mpd.slice.37000-37999.json  \n",
      "  inflating: data/mpd.slice.299000-299999.json  \n",
      "  inflating: data/mpd.slice.771000-771999.json  \n",
      "  inflating: data/mpd.slice.176000-176999.json  \n",
      "  inflating: data/mpd.slice.398000-398999.json  \n",
      "  inflating: data/mpd.slice.670000-670999.json  \n",
      "  inflating: data/mpd.slice.441000-441999.json  \n",
      "  inflating: data/mpd.slice.917000-917999.json  \n",
      "  inflating: data/mpd.slice.347000-347999.json  \n",
      "  inflating: data/mpd.slice.374000-374999.json  \n",
      "  inflating: data/mpd.slice.472000-472999.json  \n",
      "  inflating: data/mpd.slice.924000-924999.json  \n",
      "  inflating: data/mpd.slice.728000-728999.json  \n",
      "  inflating: data/mpd.slice.890000-890999.json  \n",
      "  inflating: data/mpd.slice.643000-643999.json  \n",
      "  inflating: data/mpd.slice.145000-145999.json  \n",
      "  inflating: data/mpd.slice.519000-519999.json  \n",
      "  inflating: data/mpd.slice.742000-742999.json  \n",
      "  inflating: data/mpd.slice.13000-13999.json  \n",
      "  inflating: data/mpd.slice.418000-418999.json  \n",
      "  inflating: data/mpd.slice.8000-8999.json  \n",
      "  inflating: data/mpd.slice.275000-275999.json  \n",
      "  inflating: data/mpd.slice.573000-573999.json  \n",
      "  inflating: data/mpd.slice.825000-825999.json  \n",
      "  inflating: data/mpd.slice.629000-629999.json  \n",
      "  inflating: data/mpd.slice.991000-991999.json  \n",
      "  inflating: data/mpd.slice.770000-770999.json  \n",
      "  inflating: data/mpd.slice.298000-298999.json  \n",
      "  inflating: data/mpd.slice.247000-247999.json  \n",
      "  inflating: data/mpd.slice.541000-541999.json  \n",
      "  inflating: data/mpd.slice.817000-817999.json  \n",
      "  inflating: data/mpd.slice.41000-41999.json  \n",
      "  inflating: data/mpd.slice.346000-346999.json  \n",
      "  inflating: data/mpd.slice.440000-440999.json  \n",
      "  inflating: data/mpd.slice.916000-916999.json  \n",
      "  inflating: data/mpd.slice.671000-671999.json  \n",
      "  inflating: data/mpd.slice.399000-399999.json  \n",
      "  inflating: data/mpd.slice.177000-177999.json  \n",
      "  inflating: data/mpd.slice.94000-94999.json  \n",
      "  inflating: data/mpd.slice.144000-144999.json  \n",
      "  inflating: data/mpd.slice.642000-642999.json  \n",
      "  inflating: data/mpd.slice.518000-518999.json  \n",
      "  inflating: data/mpd.slice.473000-473999.json  \n",
      "  inflating: data/mpd.slice.925000-925999.json  \n",
      "  inflating: data/mpd.slice.375000-375999.json  \n",
      "  inflating: data/mpd.slice.891000-891999.json  \n",
      "  inflating: data/mpd.slice.729000-729999.json  \n",
      "  inflating: data/mpd.slice.572000-572999.json  \n",
      "  inflating: data/mpd.slice.824000-824999.json  \n",
      "  inflating: data/mpd.slice.274000-274999.json  \n",
      "  inflating: data/mpd.slice.990000-990999.json  \n",
      "  inflating: data/mpd.slice.628000-628999.json  \n",
      "  inflating: data/mpd.slice.743000-743999.json  \n",
      "  inflating: data/mpd.slice.419000-419999.json  \n",
      "  inflating: data/mpd.slice.65000-65999.json  \n",
      "  inflating: data/mpd.slice.528000-528999.json  \n",
      "  inflating: data/mpd.slice.174000-174999.json  \n",
      "  inflating: data/mpd.slice.672000-672999.json  \n",
      "  inflating: data/mpd.slice.719000-719999.json  \n",
      "  inflating: data/mpd.slice.915000-915999.json  \n",
      "  inflating: data/mpd.slice.443000-443999.json  \n",
      "  inflating: data/mpd.slice.345000-345999.json  \n",
      "  inflating: data/mpd.slice.618000-618999.json  \n",
      "  inflating: data/mpd.slice.814000-814999.json  \n",
      "  inflating: data/mpd.slice.542000-542999.json  \n",
      "  inflating: data/mpd.slice.244000-244999.json  \n",
      "  inflating: data/mpd.slice.429000-429999.json  \n",
      "  inflating: data/mpd.slice.773000-773999.json  \n",
      "  inflating: data/mpd.slice.60000-60999.json  \n",
      "  inflating: data/mpd.slice.740000-740999.json  \n",
      "  inflating: data/mpd.slice.993000-993999.json  \n",
      "  inflating: data/mpd.slice.277000-277999.json  \n",
      "  inflating: data/mpd.slice.827000-827999.json  \n",
      "  inflating: data/mpd.slice.571000-571999.json  \n",
      "  inflating: data/mpd.slice.44000-44999.json  \n",
      "  inflating: data/mpd.slice.892000-892999.json  \n",
      "  inflating: data/mpd.slice.376000-376999.json  \n",
      "  inflating: data/mpd.slice.926000-926999.json  \n",
      "  inflating: data/mpd.slice.470000-470999.json  \n",
      "  inflating: data/mpd.slice.198000-198999.json  \n",
      "  inflating: data/mpd.slice.91000-91999.json  \n",
      "  inflating: data/mpd.slice.641000-641999.json  \n",
      "  inflating: data/mpd.slice.147000-147999.json  \n",
      "  inflating: data/mpd.slice.718000-718999.json  \n",
      "  inflating: data/mpd.slice.344000-344999.json  \n",
      "  inflating: data/mpd.slice.914000-914999.json  \n",
      "  inflating: data/mpd.slice.442000-442999.json  \n",
      "  inflating: data/mpd.slice.529000-529999.json  \n",
      "  inflating: data/mpd.slice.673000-673999.json  \n",
      "  inflating: data/mpd.slice.175000-175999.json  \n",
      "  inflating: data/mpd.slice.428000-428999.json  \n",
      "  inflating: data/mpd.slice.772000-772999.json  \n",
      "  inflating: data/mpd.slice.16000-16999.json  \n",
      "  inflating: data/mpd.slice.619000-619999.json  \n",
      "  inflating: data/mpd.slice.245000-245999.json  \n",
      "  inflating: data/mpd.slice.815000-815999.json  \n",
      "  inflating: data/mpd.slice.543000-543999.json  \n",
      "  inflating: data/mpd.slice.992000-992999.json  \n",
      "  inflating: data/mpd.slice.826000-826999.json  \n",
      "  inflating: data/mpd.slice.570000-570999.json  \n",
      "  inflating: data/mpd.slice.32000-32999.json  \n",
      "  inflating: data/mpd.slice.276000-276999.json  \n",
      "  inflating: data/mpd.slice.741000-741999.json  \n",
      "  inflating: data/mpd.slice.146000-146999.json  \n",
      "  inflating: data/mpd.slice.640000-640999.json  \n",
      "  inflating: data/mpd.slice.893000-893999.json  \n",
      "  inflating: data/mpd.slice.9000-9999.json  \n",
      "  inflating: data/mpd.slice.199000-199999.json  \n",
      "  inflating: data/mpd.slice.927000-927999.json  \n",
      "  inflating: data/mpd.slice.471000-471999.json  \n",
      "  inflating: data/mpd.slice.28000-28999.json  \n",
      "  inflating: data/mpd.slice.377000-377999.json  \n",
      "  inflating: data/mpd.slice.880000-880999.json  \n",
      "  inflating: data/mpd.slice.738000-738999.json  \n",
      "  inflating: data/mpd.slice.934000-934999.json  \n",
      "  inflating: data/mpd.slice.462000-462999.json  \n",
      "  inflating: data/mpd.slice.364000-364999.json  \n",
      "  inflating: data/mpd.slice.509000-509999.json  \n",
      "  inflating: data/mpd.slice.155000-155999.json  \n",
      "  inflating: data/mpd.slice.653000-653999.json  \n",
      "  inflating: data/mpd.slice.408000-408999.json  \n",
      "  inflating: data/mpd.slice.10000-10999.json  \n",
      "  inflating: data/mpd.slice.752000-752999.json  \n",
      "  inflating: data/mpd.slice.981000-981999.json  \n",
      "  inflating: data/mpd.slice.639000-639999.json  \n",
      "  inflating: data/mpd.slice.835000-835999.json  \n",
      "  inflating: data/mpd.slice.563000-563999.json  \n",
      "  inflating: data/mpd.slice.265000-265999.json  \n",
      "  inflating: data/mpd.slice.34000-34999.json  \n",
      "  inflating: data/mpd.slice.256000-256999.json  \n",
      "  inflating: data/mpd.slice.806000-806999.json  \n",
      "  inflating: data/mpd.slice.550000-550999.json  \n",
      "  inflating: data/mpd.slice.289000-289999.json  \n",
      "  inflating: data/mpd.slice.761000-761999.json  \n",
      "  inflating: data/mpd.slice.388000-388999.json  \n",
      "  inflating: data/mpd.slice.660000-660999.json  \n",
      "  inflating: data/mpd.slice.166000-166999.json  \n",
      "  inflating: data/mpd.slice.357000-357999.json  \n",
      "  inflating: data/mpd.slice.907000-907999.json  \n",
      "  inflating: data/mpd.slice.451000-451999.json  \n",
      "  inflating: data/mpd.slice.508000-508999.json  \n",
      "  inflating: data/mpd.slice.652000-652999.json  \n",
      "  inflating: data/mpd.slice.154000-154999.json  \n",
      "  inflating: data/mpd.slice.739000-739999.json  \n",
      "  inflating: data/mpd.slice.881000-881999.json  \n",
      "  inflating: data/mpd.slice.365000-365999.json  \n",
      "  inflating: data/mpd.slice.935000-935999.json  \n",
      "  inflating: data/mpd.slice.463000-463999.json  \n",
      "  inflating: data/mpd.slice.638000-638999.json  \n",
      "  inflating: data/mpd.slice.980000-980999.json  \n",
      "  inflating: data/mpd.slice.264000-264999.json  \n",
      "  inflating: data/mpd.slice.834000-834999.json  \n",
      "  inflating: data/mpd.slice.562000-562999.json  \n",
      "  inflating: data/mpd.slice.66000-66999.json  \n",
      "  inflating: data/mpd.slice.409000-409999.json  \n",
      "  inflating: data/mpd.slice.753000-753999.json  \n",
      "  inflating: data/mpd.slice.760000-760999.json  \n",
      "  inflating: data/mpd.slice.288000-288999.json  \n",
      "  inflating: data/mpd.slice.42000-42999.json  \n",
      "  inflating: data/mpd.slice.807000-807999.json  \n",
      "  inflating: data/mpd.slice.551000-551999.json  \n",
      "  inflating: data/mpd.slice.257000-257999.json  \n",
      "  inflating: data/mpd.slice.58000-58999.json  \n",
      "  inflating: data/mpd.slice.906000-906999.json  \n",
      "  inflating: data/mpd.slice.450000-450999.json  \n",
      "  inflating: data/mpd.slice.356000-356999.json  \n",
      "  inflating: data/mpd.slice.97000-97999.json  \n",
      "  inflating: data/mpd.slice.167000-167999.json  \n",
      "  inflating: data/mpd.slice.661000-661999.json  \n",
      "  inflating: data/mpd.slice.389000-389999.json  \n",
      "  inflating: data/mpd.slice.88000-88999.json  \n",
      "  inflating: data/mpd.slice.750000-750999.json  \n",
      "  inflating: data/mpd.slice.561000-561999.json  \n",
      "  inflating: data/mpd.slice.837000-837999.json  \n",
      "  inflating: data/mpd.slice.47000-47999.json  \n",
      "  inflating: data/mpd.slice.267000-267999.json  \n",
      "  inflating: data/mpd.slice.983000-983999.json  \n",
      "  inflating: data/mpd.slice.460000-460999.json  \n",
      "  inflating: data/mpd.slice.936000-936999.json  \n",
      "  inflating: data/mpd.slice.188000-188999.json  \n",
      "  inflating: data/mpd.slice.366000-366999.json  \n",
      "  inflating: data/mpd.slice.882000-882999.json  \n",
      "  inflating: data/mpd.slice.92000-92999.json  \n",
      "  inflating: data/mpd.slice.157000-157999.json  \n",
      "  inflating: data/mpd.slice.651000-651999.json  \n",
      "  inflating: data/mpd.slice.662000-662999.json  \n",
      "  inflating: data/mpd.slice.79000-79999.json  \n",
      "  inflating: data/mpd.slice.164000-164999.json  \n",
      "  inflating: data/mpd.slice.538000-538999.json  \n",
      "  inflating: data/mpd.slice.355000-355999.json  \n",
      "  inflating: data/mpd.slice.453000-453999.json  \n",
      "  inflating: data/mpd.slice.905000-905999.json  \n",
      "  inflating: data/mpd.slice.709000-709999.json  \n",
      "  inflating: data/mpd.slice.254000-254999.json  \n",
      "  inflating: data/mpd.slice.552000-552999.json  \n",
      "  inflating: data/mpd.slice.804000-804999.json  \n",
      "  inflating: data/mpd.slice.608000-608999.json  \n",
      "  inflating: data/mpd.slice.763000-763999.json  \n",
      "  inflating: data/mpd.slice.63000-63999.json  \n",
      "  inflating: data/mpd.slice.439000-439999.json  \n",
      "  inflating: data/mpd.slice.266000-266999.json  \n",
      "  inflating: data/mpd.slice.560000-560999.json  \n",
      "  inflating: data/mpd.slice.836000-836999.json  \n",
      "  inflating: data/mpd.slice.31000-31999.json  \n",
      "  inflating: data/mpd.slice.982000-982999.json  \n",
      "  inflating: data/mpd.slice.751000-751999.json  \n",
      "  inflating: data/mpd.slice.650000-650999.json  \n",
      "  inflating: data/mpd.slice.156000-156999.json  \n",
      "  inflating: data/mpd.slice.0-999.json  \n",
      "  inflating: data/mpd.slice.367000-367999.json  \n",
      "  inflating: data/mpd.slice.189000-189999.json  \n",
      "  inflating: data/mpd.slice.461000-461999.json  \n",
      "  inflating: data/mpd.slice.937000-937999.json  \n",
      "  inflating: data/mpd.slice.883000-883999.json  \n",
      "  inflating: data/mpd.slice.452000-452999.json  \n",
      "  inflating: data/mpd.slice.904000-904999.json  \n",
      "  inflating: data/mpd.slice.354000-354999.json  \n",
      "  inflating: data/mpd.slice.708000-708999.json  \n",
      "  inflating: data/mpd.slice.165000-165999.json  \n",
      "  inflating: data/mpd.slice.663000-663999.json  \n",
      "  inflating: data/mpd.slice.539000-539999.json  \n",
      "  inflating: data/mpd.slice.762000-762999.json  \n",
      "  inflating: data/mpd.slice.15000-15999.json  \n",
      "  inflating: data/mpd.slice.438000-438999.json  \n",
      "  inflating: data/mpd.slice.553000-553999.json  \n",
      "  inflating: data/mpd.slice.805000-805999.json  \n",
      "  inflating: data/mpd.slice.255000-255999.json  \n",
      "  inflating: data/mpd.slice.609000-609999.json  \n",
      "  inflating: data/mpd.slice.731000-731999.json  \n",
      "  inflating: data/mpd.slice.889000-889999.json  \n",
      "  inflating: data/mpd.slice.685000-685999.json  \n",
      "  inflating: data/mpd.slice.183000-183999.json  \n",
      "  inflating: data/mpd.slice.206000-206999.json  \n",
      "  inflating: data/mpd.slice.856000-856999.json  \n",
      "  inflating: data/mpd.slice.500000-500999.json  \n",
      "  inflating: data/mpd.slice.307000-307999.json  \n",
      "  inflating: data/mpd.slice.957000-957999.json  \n",
      "  inflating: data/mpd.slice.401000-401999.json  \n",
      "  inflating: data/mpd.slice.630000-630999.json  \n",
      "  inflating: data/mpd.slice.136000-136999.json  \n",
      "  inflating: data/mpd.slice.988000-988999.json  \n",
      "  inflating: data/mpd.slice.21000-21999.json  \n",
      "  inflating: data/mpd.slice.784000-784999.json  \n",
      "  inflating: data/mpd.slice.105000-105999.json  \n",
      "  inflating: data/mpd.slice.603000-603999.json  \n",
      "  inflating: data/mpd.slice.559000-559999.json  \n",
      "  inflating: data/mpd.slice.964000-964999.json  \n",
      "  inflating: data/mpd.slice.432000-432999.json  \n",
      "  inflating: data/mpd.slice.334000-334999.json  \n",
      "  inflating: data/mpd.slice.586000-586999.json  \n",
      "  inflating: data/mpd.slice.768000-768999.json  \n",
      "  inflating: data/mpd.slice.280000-280999.json  \n",
      "  inflating: data/mpd.slice.865000-865999.json  \n",
      "  inflating: data/mpd.slice.533000-533999.json  \n",
      "  inflating: data/mpd.slice.235000-235999.json  \n",
      "  inflating: data/mpd.slice.487000-487999.json  \n",
      "  inflating: data/mpd.slice.669000-669999.json  \n",
      "  inflating: data/mpd.slice.381000-381999.json  \n",
      "  inflating: data/mpd.slice.702000-702999.json  \n",
      "  inflating: data/mpd.slice.458000-458999.json  \n",
      "  inflating: data/mpd.slice.857000-857999.json  \n",
      "  inflating: data/mpd.slice.501000-501999.json  \n",
      "  inflating: data/mpd.slice.207000-207999.json  \n",
      "  inflating: data/mpd.slice.82000-82999.json  \n",
      "  inflating: data/mpd.slice.888000-888999.json  \n",
      "  inflating: data/mpd.slice.730000-730999.json  \n",
      "  inflating: data/mpd.slice.182000-182999.json  \n",
      "  inflating: data/mpd.slice.684000-684999.json  \n",
      "  inflating: data/mpd.slice.989000-989999.json  \n",
      "  inflating: data/mpd.slice.137000-137999.json  \n",
      "  inflating: data/mpd.slice.631000-631999.json  \n",
      "  inflating: data/mpd.slice.57000-57999.json  \n",
      "  inflating: data/mpd.slice.785000-785999.json  \n",
      "  inflating: data/mpd.slice.956000-956999.json  \n",
      "  inflating: data/mpd.slice.400000-400999.json  \n",
      "  inflating: data/mpd.slice.306000-306999.json  \n",
      "  inflating: data/mpd.slice.98000-98999.json  \n",
      "  inflating: data/mpd.slice.335000-335999.json  \n",
      "  inflating: data/mpd.slice.965000-965999.json  \n",
      "  inflating: data/mpd.slice.433000-433999.json  \n",
      "  inflating: data/mpd.slice.73000-73999.json  \n",
      "  inflating: data/mpd.slice.281000-281999.json  \n",
      "  inflating: data/mpd.slice.769000-769999.json  \n",
      "  inflating: data/mpd.slice.587000-587999.json  \n",
      "  inflating: data/mpd.slice.602000-602999.json  \n",
      "  inflating: data/mpd.slice.104000-104999.json  \n",
      "  inflating: data/mpd.slice.558000-558999.json  \n",
      "  inflating: data/mpd.slice.703000-703999.json  \n",
      "  inflating: data/mpd.slice.459000-459999.json  \n",
      "  inflating: data/mpd.slice.234000-234999.json  \n",
      "  inflating: data/mpd.slice.864000-864999.json  \n",
      "  inflating: data/mpd.slice.532000-532999.json  \n",
      "  inflating: data/mpd.slice.380000-380999.json  \n",
      "  inflating: data/mpd.slice.668000-668999.json  \n",
      "  inflating: data/mpd.slice.69000-69999.json  \n",
      "  inflating: data/mpd.slice.486000-486999.json  \n",
      "  inflating: data/mpd.slice.759000-759999.json  \n",
      "  inflating: data/mpd.slice.305000-305999.json  \n",
      "  inflating: data/mpd.slice.403000-403999.json  \n",
      "  inflating: data/mpd.slice.955000-955999.json  \n",
      "  inflating: data/mpd.slice.76000-76999.json  \n",
      "  inflating: data/mpd.slice.786000-786999.json  \n",
      "  inflating: data/mpd.slice.568000-568999.json  \n",
      "  inflating: data/mpd.slice.632000-632999.json  \n",
      "  inflating: data/mpd.slice.134000-134999.json  \n",
      "  inflating: data/mpd.slice.687000-687999.json  \n",
      "  inflating: data/mpd.slice.181000-181999.json  \n",
      "  inflating: data/mpd.slice.469000-469999.json  \n",
      "  inflating: data/mpd.slice.733000-733999.json  \n",
      "  inflating: data/mpd.slice.658000-658999.json  \n",
      "  inflating: data/mpd.slice.204000-204999.json  \n",
      "  inflating: data/mpd.slice.502000-502999.json  \n",
      "  inflating: data/mpd.slice.854000-854999.json  \n",
      "  inflating: data/mpd.slice.485000-485999.json  \n",
      "  inflating: data/mpd.slice.383000-383999.json  \n",
      "  inflating: data/mpd.slice.87000-87999.json  \n",
      "  inflating: data/mpd.slice.531000-531999.json  \n",
      "  inflating: data/mpd.slice.867000-867999.json  \n",
      "  inflating: data/mpd.slice.237000-237999.json  \n",
      "  inflating: data/mpd.slice.48000-48999.json  \n",
      "  inflating: data/mpd.slice.700000-700999.json  \n",
      "  inflating: data/mpd.slice.107000-107999.json  \n",
      "  inflating: data/mpd.slice.601000-601999.json  \n",
      "  inflating: data/mpd.slice.52000-52999.json  \n",
      "  inflating: data/mpd.slice.584000-584999.json  \n",
      "  inflating: data/mpd.slice.282000-282999.json  \n",
      "  inflating: data/mpd.slice.430000-430999.json  \n",
      "  inflating: data/mpd.slice.966000-966999.json  \n",
      "  inflating: data/mpd.slice.336000-336999.json  \n",
      "  inflating: data/mpd.slice.569000-569999.json  \n",
      "  inflating: data/mpd.slice.787000-787999.json  \n",
      "  inflating: data/mpd.slice.135000-135999.json  \n",
      "  inflating: data/mpd.slice.633000-633999.json  \n",
      "  inflating: data/mpd.slice.758000-758999.json  \n",
      "  inflating: data/mpd.slice.402000-402999.json  \n",
      "  inflating: data/mpd.slice.954000-954999.json  \n",
      "  inflating: data/mpd.slice.304000-304999.json  \n",
      "  inflating: data/mpd.slice.659000-659999.json  \n",
      "  inflating: data/mpd.slice.503000-503999.json  \n",
      "  inflating: data/mpd.slice.855000-855999.json  \n",
      "  inflating: data/mpd.slice.205000-205999.json  \n",
      "  inflating: data/mpd.slice.468000-468999.json  \n",
      "  inflating: data/mpd.slice.180000-180999.json  \n",
      "  inflating: data/mpd.slice.686000-686999.json  \n",
      "  inflating: data/mpd.slice.732000-732999.json  \n",
      "  inflating: data/mpd.slice.701000-701999.json  \n",
      "  inflating: data/mpd.slice.382000-382999.json  \n",
      "  inflating: data/mpd.slice.484000-484999.json  \n",
      "  inflating: data/mpd.slice.236000-236999.json  \n",
      "  inflating: data/mpd.slice.530000-530999.json  \n",
      "  inflating: data/mpd.slice.866000-866999.json  \n",
      "  inflating: data/mpd.slice.283000-283999.json  \n",
      "  inflating: data/mpd.slice.585000-585999.json  \n",
      "  inflating: data/mpd.slice.337000-337999.json  \n",
      "  inflating: data/mpd.slice.431000-431999.json  \n",
      "  inflating: data/mpd.slice.967000-967999.json  \n",
      "  inflating: data/mpd.slice.600000-600999.json  \n",
      "  inflating: data/mpd.slice.24000-24999.json  \n",
      "  inflating: data/mpd.slice.106000-106999.json  \n",
      "  inflating: data/mpd.slice.941000-941999.json  \n",
      "  inflating: data/mpd.slice.417000-417999.json  \n",
      "  inflating: data/mpd.slice.311000-311999.json  \n",
      "  inflating: data/mpd.slice.5000-5999.json  \n",
      "  inflating: data/mpd.slice.792000-792999.json  \n",
      "  inflating: data/mpd.slice.120000-120999.json  \n",
      "  inflating: data/mpd.slice.626000-626999.json  \n",
      "  inflating: data/mpd.slice.195000-195999.json  \n",
      "  inflating: data/mpd.slice.14000-14999.json  \n",
      "  inflating: data/mpd.slice.693000-693999.json  \n",
      "  inflating: data/mpd.slice.727000-727999.json  \n",
      "  inflating: data/mpd.slice.840000-840999.json  \n",
      "  inflating: data/mpd.slice.516000-516999.json  \n",
      "  inflating: data/mpd.slice.210000-210999.json  \n",
      "  inflating: data/mpd.slice.30000-30999.json  \n",
      "  inflating: data/mpd.slice.397000-397999.json  \n",
      "  inflating: data/mpd.slice.491000-491999.json  \n",
      "  inflating: data/mpd.slice.179000-179999.json  \n",
      "  inflating: data/mpd.slice.223000-223999.json  \n",
      "  inflating: data/mpd.slice.873000-873999.json  \n",
      "  inflating: data/mpd.slice.525000-525999.json  \n",
      "  inflating: data/mpd.slice.348000-348999.json  \n",
      "  inflating: data/mpd.slice.1000-1999.json  \n",
      "  inflating: data/mpd.slice.918000-918999.json  \n",
      "  inflating: data/mpd.slice.714000-714999.json  \n",
      "  inflating: data/mpd.slice.249000-249999.json  \n",
      "  inflating: data/mpd.slice.819000-819999.json  \n",
      "  inflating: data/mpd.slice.615000-615999.json  \n",
      "  inflating: data/mpd.slice.113000-113999.json  \n",
      "  inflating: data/mpd.slice.296000-296999.json  \n",
      "  inflating: data/mpd.slice.590000-590999.json  \n",
      "  inflating: data/mpd.slice.322000-322999.json  \n",
      "  inflating: data/mpd.slice.972000-972999.json  \n",
      "  inflating: data/mpd.slice.424000-424999.json  \n",
      "  inflating: data/mpd.slice.793000-793999.json  \n",
      "  inflating: data/mpd.slice.78000-78999.json  \n",
      "  inflating: data/mpd.slice.627000-627999.json  \n",
      "  inflating: data/mpd.slice.121000-121999.json  \n",
      "  inflating: data/mpd.slice.310000-310999.json  \n",
      "  inflating: data/mpd.slice.940000-940999.json  \n",
      "  inflating: data/mpd.slice.416000-416999.json  \n",
      "  inflating: data/mpd.slice.211000-211999.json  \n",
      "  inflating: data/mpd.slice.841000-841999.json  \n",
      "  inflating: data/mpd.slice.517000-517999.json  \n",
      "  inflating: data/mpd.slice.692000-692999.json  \n",
      "  inflating: data/mpd.slice.62000-62999.json  \n",
      "  inflating: data/mpd.slice.194000-194999.json  \n",
      "  inflating: data/mpd.slice.726000-726999.json  \n",
      "  inflating: data/mpd.slice.919000-919999.json  \n",
      "  inflating: data/mpd.slice.89000-89999.json  \n",
      "  inflating: data/mpd.slice.349000-349999.json  \n",
      "  inflating: data/mpd.slice.715000-715999.json  \n",
      "  inflating: data/mpd.slice.178000-178999.json  \n",
      "  inflating: data/mpd.slice.490000-490999.json  \n",
      "  inflating: data/mpd.slice.46000-46999.json  \n",
      "  inflating: data/mpd.slice.396000-396999.json  \n",
      "  inflating: data/mpd.slice.872000-872999.json  \n",
      "  inflating: data/mpd.slice.524000-524999.json  \n",
      "  inflating: data/mpd.slice.222000-222999.json  \n",
      "  inflating: data/mpd.slice.591000-591999.json  \n",
      "  inflating: data/mpd.slice.297000-297999.json  \n",
      "  inflating: data/mpd.slice.973000-973999.json  \n",
      "  inflating: data/mpd.slice.425000-425999.json  \n",
      "  inflating: data/mpd.slice.323000-323999.json  \n",
      "  inflating: data/mpd.slice.818000-818999.json  \n",
      "  inflating: data/mpd.slice.93000-93999.json  \n",
      "  inflating: data/mpd.slice.248000-248999.json  \n",
      "  inflating: data/mpd.slice.112000-112999.json  \n",
      "  inflating: data/mpd.slice.614000-614999.json  \n",
      "  inflating: data/mpd.slice.725000-725999.json  \n",
      "  inflating: data/mpd.slice.929000-929999.json  \n",
      "  inflating: data/mpd.slice.197000-197999.json  \n",
      "  inflating: data/mpd.slice.379000-379999.json  \n",
      "  inflating: data/mpd.slice.691000-691999.json  \n",
      "  inflating: data/mpd.slice.514000-514999.json  \n",
      "  inflating: data/mpd.slice.842000-842999.json  \n",
      "  inflating: data/mpd.slice.212000-212999.json  \n",
      "  inflating: data/mpd.slice.43000-43999.json  \n",
      "  inflating: data/mpd.slice.148000-148999.json  \n",
      "  inflating: data/mpd.slice.415000-415999.json  \n",
      "  inflating: data/mpd.slice.943000-943999.json  \n",
      "  inflating: data/mpd.slice.59000-59999.json  \n",
      "  inflating: data/mpd.slice.313000-313999.json  \n",
      "  inflating: data/mpd.slice.96000-96999.json  \n",
      "  inflating: data/mpd.slice.122000-122999.json  \n",
      "  inflating: data/mpd.slice.624000-624999.json  \n",
      "  inflating: data/mpd.slice.828000-828999.json  \n",
      "  inflating: data/mpd.slice.278000-278999.json  \n",
      "  inflating: data/mpd.slice.790000-790999.json  \n",
      "  inflating: data/mpd.slice.617000-617999.json  \n",
      "  inflating: data/mpd.slice.111000-111999.json  \n",
      "  inflating: data/mpd.slice.320000-320999.json  \n",
      "  inflating: data/mpd.slice.426000-426999.json  \n",
      "  inflating: data/mpd.slice.970000-970999.json  \n",
      "  inflating: data/mpd.slice.294000-294999.json  \n",
      "  inflating: data/mpd.slice.592000-592999.json  \n",
      "  inflating: data/mpd.slice.221000-221999.json  \n",
      "  inflating: data/mpd.slice.527000-527999.json  \n",
      "  inflating: data/mpd.slice.871000-871999.json  \n",
      "  inflating: data/mpd.slice.395000-395999.json  \n",
      "  inflating: data/mpd.slice.493000-493999.json  \n",
      "  inflating: data/mpd.slice.716000-716999.json  \n",
      "  inflating: data/mpd.slice.67000-67999.json  \n",
      "  inflating: data/mpd.slice.213000-213999.json  \n",
      "  inflating: data/mpd.slice.35000-35999.json  \n",
      "  inflating: data/mpd.slice.515000-515999.json  \n",
      "  inflating: data/mpd.slice.843000-843999.json  \n",
      "  inflating: data/mpd.slice.149000-149999.json  \n",
      "  inflating: data/mpd.slice.724000-724999.json  \n",
      "  inflating: data/mpd.slice.4000-4999.json  \n",
      "  inflating: data/mpd.slice.690000-690999.json  \n",
      "  inflating: data/mpd.slice.378000-378999.json  \n",
      "  inflating: data/mpd.slice.196000-196999.json  \n",
      "  inflating: data/mpd.slice.928000-928999.json  \n",
      "  inflating: data/mpd.slice.625000-625999.json  \n",
      "  inflating: data/mpd.slice.123000-123999.json  \n",
      "  inflating: data/mpd.slice.791000-791999.json  \n",
      "  inflating: data/mpd.slice.279000-279999.json  \n",
      "  inflating: data/mpd.slice.829000-829999.json  \n",
      "  inflating: data/mpd.slice.312000-312999.json  \n",
      "  inflating: data/mpd.slice.414000-414999.json  \n",
      "  inflating: data/mpd.slice.942000-942999.json  \n",
      "  inflating: data/mpd.slice.427000-427999.json  \n",
      "  inflating: data/mpd.slice.971000-971999.json  \n",
      "  inflating: data/mpd.slice.321000-321999.json  \n",
      "  inflating: data/mpd.slice.593000-593999.json  \n",
      "  inflating: data/mpd.slice.295000-295999.json  \n",
      "  inflating: data/mpd.slice.110000-110999.json  \n",
      "  inflating: data/mpd.slice.616000-616999.json  \n",
      "  inflating: data/mpd.slice.11000-11999.json  \n",
      "  inflating: data/mpd.slice.717000-717999.json  \n",
      "  inflating: data/mpd.slice.526000-526999.json  \n",
      "  inflating: data/mpd.slice.870000-870999.json  \n",
      "  inflating: data/mpd.slice.220000-220999.json  \n",
      "  inflating: data/mpd.slice.492000-492999.json  \n",
      "  inflating: data/mpd.slice.394000-394999.json  \n",
      "  inflating: data/mpd.slice.744000-744999.json  \n",
      "  inflating: data/mpd.slice.318000-318999.json  \n",
      "  inflating: data/mpd.slice.948000-948999.json  \n",
      "  inflating: data/mpd.slice.273000-273999.json  \n",
      "  inflating: data/mpd.slice.823000-823999.json  \n",
      "  inflating: data/mpd.slice.575000-575999.json  \n",
      "  inflating: data/mpd.slice.129000-129999.json  \n",
      "  inflating: data/mpd.slice.997000-997999.json  \n",
      "  inflating: data/mpd.slice.372000-372999.json  \n",
      "  inflating: data/mpd.slice.922000-922999.json  \n",
      "  inflating: data/mpd.slice.474000-474999.json  \n",
      "  inflating: data/mpd.slice.896000-896999.json  \n",
      "  inflating: data/mpd.slice.645000-645999.json  \n",
      "  inflating: data/mpd.slice.143000-143999.json  \n",
      "  inflating: data/mpd.slice.219000-219999.json  \n",
      "  inflating: data/mpd.slice.25000-25999.json  \n",
      "  inflating: data/mpd.slice.849000-849999.json  \n",
      "  inflating: data/mpd.slice.170000-170999.json  \n",
      "  inflating: data/mpd.slice.498000-498999.json  \n",
      "  inflating: data/mpd.slice.676000-676999.json  \n",
      "  inflating: data/mpd.slice.911000-911999.json  \n",
      "  inflating: data/mpd.slice.447000-447999.json  \n",
      "  inflating: data/mpd.slice.341000-341999.json  \n",
      "  inflating: data/mpd.slice.810000-810999.json  \n",
      "  inflating: data/mpd.slice.546000-546999.json  \n",
      "  inflating: data/mpd.slice.240000-240999.json  \n",
      "  inflating: data/mpd.slice.599000-599999.json  \n",
      "  inflating: data/mpd.slice.777000-777999.json  \n",
      "  inflating: data/mpd.slice.822000-822999.json  \n",
      "  inflating: data/mpd.slice.574000-574999.json  \n",
      "  inflating: data/mpd.slice.272000-272999.json  \n",
      "  inflating: data/mpd.slice.996000-996999.json  \n",
      "  inflating: data/mpd.slice.128000-128999.json  \n",
      "  inflating: data/mpd.slice.86000-86999.json  \n",
      "  inflating: data/mpd.slice.745000-745999.json  \n",
      "  inflating: data/mpd.slice.949000-949999.json  \n",
      "  inflating: data/mpd.slice.319000-319999.json  \n",
      "  inflating: data/mpd.slice.49000-49999.json  \n",
      "  inflating: data/mpd.slice.142000-142999.json  \n",
      "  inflating: data/mpd.slice.644000-644999.json  \n",
      "  inflating: data/mpd.slice.53000-53999.json  \n",
      "  inflating: data/mpd.slice.848000-848999.json  \n",
      "  inflating: data/mpd.slice.218000-218999.json  \n",
      "  inflating: data/mpd.slice.923000-923999.json  \n",
      "  inflating: data/mpd.slice.475000-475999.json  \n",
      "  inflating: data/mpd.slice.373000-373999.json  \n",
      "  inflating: data/mpd.slice.897000-897999.json  \n",
      "  inflating: data/mpd.slice.340000-340999.json  \n",
      "  inflating: data/mpd.slice.910000-910999.json  \n",
      "  inflating: data/mpd.slice.446000-446999.json  \n",
      "  inflating: data/mpd.slice.77000-77999.json  \n",
      "  inflating: data/mpd.slice.677000-677999.json  \n",
      "  inflating: data/mpd.slice.499000-499999.json  \n",
      "  inflating: data/mpd.slice.171000-171999.json  \n",
      "  inflating: data/mpd.slice.776000-776999.json  \n",
      "  inflating: data/mpd.slice.598000-598999.json  \n",
      "  inflating: data/mpd.slice.241000-241999.json  \n",
      "  inflating: data/mpd.slice.811000-811999.json  \n",
      "  inflating: data/mpd.slice.547000-547999.json  \n",
      "  inflating: data/mpd.slice.894000-894999.json  \n",
      "  inflating: data/mpd.slice.698000-698999.json  \n",
      "  inflating: data/mpd.slice.370000-370999.json  \n",
      "  inflating: data/mpd.slice.476000-476999.json  \n",
      "  inflating: data/mpd.slice.920000-920999.json  \n",
      "  inflating: data/mpd.slice.72000-72999.json  \n",
      "  inflating: data/mpd.slice.647000-647999.json  \n",
      "  inflating: data/mpd.slice.141000-141999.json  \n",
      "  inflating: data/mpd.slice.746000-746999.json  \n",
      "  inflating: data/mpd.slice.995000-995999.json  \n",
      "  inflating: data/mpd.slice.799000-799999.json  \n",
      "  inflating: data/mpd.slice.271000-271999.json  \n",
      "  inflating: data/mpd.slice.68000-68999.json  \n",
      "  inflating: data/mpd.slice.577000-577999.json  \n",
      "  inflating: data/mpd.slice.821000-821999.json  \n",
      "  inflating: data/mpd.slice.118000-118999.json  \n",
      "  inflating: data/mpd.slice.83000-83999.json  \n",
      "  inflating: data/mpd.slice.544000-544999.json  \n",
      "  inflating: data/mpd.slice.812000-812999.json  \n",
      "  inflating: data/mpd.slice.242000-242999.json  \n",
      "  inflating: data/mpd.slice.979000-979999.json  \n",
      "  inflating: data/mpd.slice.329000-329999.json  \n",
      "  inflating: data/mpd.slice.775000-775999.json  \n",
      "  inflating: data/mpd.slice.878000-878999.json  \n",
      "  inflating: data/mpd.slice.228000-228999.json  \n",
      "  inflating: data/mpd.slice.172000-172999.json  \n",
      "  inflating: data/mpd.slice.56000-56999.json  \n",
      "  inflating: data/mpd.slice.674000-674999.json  \n",
      "  inflating: data/mpd.slice.445000-445999.json  \n",
      "  inflating: data/mpd.slice.913000-913999.json  \n",
      "  inflating: data/mpd.slice.99000-99999.json  \n",
      "  inflating: data/mpd.slice.343000-343999.json  \n",
      "  inflating: data/mpd.slice.140000-140999.json  \n",
      "  inflating: data/mpd.slice.646000-646999.json  \n",
      "  inflating: data/mpd.slice.895000-895999.json  \n",
      "  inflating: data/mpd.slice.477000-477999.json  \n",
      "  inflating: data/mpd.slice.921000-921999.json  \n",
      "  inflating: data/mpd.slice.371000-371999.json  \n",
      "  inflating: data/mpd.slice.699000-699999.json  \n",
      "  inflating: data/mpd.slice.994000-994999.json  \n",
      "  inflating: data/mpd.slice.576000-576999.json  \n",
      "  inflating: data/mpd.slice.820000-820999.json  \n",
      "  inflating: data/mpd.slice.270000-270999.json  \n",
      "  inflating: data/mpd.slice.798000-798999.json  \n",
      "  inflating: data/mpd.slice.747000-747999.json  \n",
      "  inflating: data/mpd.slice.328000-328999.json  \n",
      "  inflating: data/mpd.slice.978000-978999.json  \n",
      "  inflating: data/mpd.slice.774000-774999.json  \n",
      "  inflating: data/mpd.slice.119000-119999.json  \n",
      "  inflating: data/mpd.slice.243000-243999.json  \n",
      "  inflating: data/mpd.slice.545000-545999.json  \n",
      "  inflating: data/mpd.slice.813000-813999.json  \n",
      "  inflating: data/mpd.slice.342000-342999.json  \n",
      "  inflating: data/mpd.slice.444000-444999.json  \n",
      "  inflating: data/mpd.slice.912000-912999.json  \n",
      "  inflating: data/mpd.slice.229000-229999.json  \n",
      "  inflating: data/mpd.slice.879000-879999.json  \n",
      "  inflating: data/mpd.slice.675000-675999.json  \n",
      "  inflating: data/mpd.slice.173000-173999.json  \n",
      "  inflating: data/mpd.slice.20000-20999.json  \n",
      "  inflating: data/mpd.slice.666000-666999.json  \n",
      "  inflating: data/mpd.slice.160000-160999.json  \n",
      "  inflating: data/mpd.slice.488000-488999.json  \n",
      "  inflating: data/mpd.slice.351000-351999.json  \n",
      "  inflating: data/mpd.slice.457000-457999.json  \n",
      "  inflating: data/mpd.slice.901000-901999.json  \n",
      "  inflating: data/mpd.slice.18000-18999.json  \n",
      "  inflating: data/mpd.slice.250000-250999.json  \n",
      "  inflating: data/mpd.slice.556000-556999.json  \n",
      "  inflating: data/mpd.slice.800000-800999.json  \n",
      "  inflating: data/mpd.slice.767000-767999.json  \n",
      "  inflating: data/mpd.slice.589000-589999.json  \n",
      "  inflating: data/mpd.slice.958000-958999.json  \n",
      "  inflating: data/mpd.slice.308000-308999.json  \n",
      "  inflating: data/mpd.slice.754000-754999.json  \n",
      "  inflating: data/mpd.slice.139000-139999.json  \n",
      "  inflating: data/mpd.slice.987000-987999.json  \n",
      "  inflating: data/mpd.slice.565000-565999.json  \n",
      "  inflating: data/mpd.slice.833000-833999.json  \n",
      "  inflating: data/mpd.slice.263000-263999.json  \n",
      "  inflating: data/mpd.slice.886000-886999.json  \n",
      "  inflating: data/mpd.slice.464000-464999.json  \n",
      "  inflating: data/mpd.slice.932000-932999.json  \n",
      "  inflating: data/mpd.slice.362000-362999.json  \n",
      "  inflating: data/mpd.slice.26000-26999.json  \n",
      "  inflating: data/mpd.slice.859000-859999.json  \n",
      "  inflating: data/mpd.slice.209000-209999.json  \n",
      "  inflating: data/mpd.slice.153000-153999.json  \n",
      "  inflating: data/mpd.slice.655000-655999.json  \n",
      "  inflating: data/mpd.slice.74000-74999.json  \n",
      "  inflating: data/mpd.slice.456000-456999.json  \n",
      "  inflating: data/mpd.slice.900000-900999.json  \n",
      "  inflating: data/mpd.slice.350000-350999.json  \n",
      "  inflating: data/mpd.slice.489000-489999.json  \n",
      "  inflating: data/mpd.slice.161000-161999.json  \n",
      "  inflating: data/mpd.slice.667000-667999.json  \n",
      "  inflating: data/mpd.slice.588000-588999.json  \n",
      "  inflating: data/mpd.slice.766000-766999.json  \n",
      "  inflating: data/mpd.slice.557000-557999.json  \n",
      "  inflating: data/mpd.slice.801000-801999.json  \n",
      "  inflating: data/mpd.slice.251000-251999.json  \n",
      "  inflating: data/mpd.slice.85000-85999.json  \n",
      "  inflating: data/mpd.slice.986000-986999.json  \n",
      "  inflating: data/mpd.slice.138000-138999.json  \n",
      "  inflating: data/mpd.slice.262000-262999.json  \n",
      "  inflating: data/mpd.slice.564000-564999.json  \n",
      "  inflating: data/mpd.slice.832000-832999.json  \n",
      "  inflating: data/mpd.slice.309000-309999.json  \n",
      "  inflating: data/mpd.slice.959000-959999.json  \n",
      "  inflating: data/mpd.slice.755000-755999.json  \n",
      "  inflating: data/mpd.slice.208000-208999.json  \n",
      "  inflating: data/mpd.slice.50000-50999.json  \n",
      "  inflating: data/mpd.slice.858000-858999.json  \n",
      "  inflating: data/mpd.slice.654000-654999.json  \n",
      "  inflating: data/mpd.slice.152000-152999.json  \n",
      "  inflating: data/mpd.slice.887000-887999.json  \n",
      "  inflating: data/mpd.slice.363000-363999.json  \n",
      "  inflating: data/mpd.slice.465000-465999.json  \n",
      "  inflating: data/mpd.slice.933000-933999.json  \n",
      "  inflating: data/mpd.slice.80000-80999.json  \n",
      "  inflating: data/mpd.slice.252000-252999.json  \n",
      "  inflating: data/mpd.slice.802000-802999.json  \n",
      "  inflating: data/mpd.slice.554000-554999.json  \n",
      "  inflating: data/mpd.slice.108000-108999.json  \n",
      "  inflating: data/mpd.slice.765000-765999.json  \n",
      "  inflating: data/mpd.slice.339000-339999.json  \n",
      "  inflating: data/mpd.slice.969000-969999.json  \n",
      "  inflating: data/mpd.slice.664000-664999.json  \n",
      "  inflating: data/mpd.slice.162000-162999.json  \n",
      "  inflating: data/mpd.slice.55000-55999.json  \n",
      "  inflating: data/mpd.slice.238000-238999.json  \n",
      "  inflating: data/mpd.slice.868000-868999.json  \n",
      "  inflating: data/mpd.slice.353000-353999.json  \n",
      "  inflating: data/mpd.slice.903000-903999.json  \n",
      "  inflating: data/mpd.slice.455000-455999.json  \n",
      "  inflating: data/mpd.slice.930000-930999.json  \n",
      "  inflating: data/mpd.slice.466000-466999.json  \n",
      "  inflating: data/mpd.slice.688000-688999.json  \n",
      "  inflating: data/mpd.slice.360000-360999.json  \n",
      "  inflating: data/mpd.slice.71000-71999.json  \n",
      "  inflating: data/mpd.slice.884000-884999.json  \n",
      "  inflating: data/mpd.slice.151000-151999.json  \n",
      "  inflating: data/mpd.slice.657000-657999.json  \n",
      "  inflating: data/mpd.slice.756000-756999.json  \n",
      "  inflating: data/mpd.slice.831000-831999.json  \n",
      "  inflating: data/mpd.slice.567000-567999.json  \n",
      "  inflating: data/mpd.slice.789000-789999.json  \n",
      "  inflating: data/mpd.slice.261000-261999.json  \n",
      "  inflating: data/mpd.slice.985000-985999.json  \n",
      "  inflating: data/mpd.slice.39000-39999.json  \n",
      "  inflating: data/mpd.slice.764000-764999.json  \n",
      "  inflating: data/mpd.slice.968000-968999.json  \n",
      "  inflating: data/mpd.slice.338000-338999.json  \n",
      "  inflating: data/mpd.slice.803000-803999.json  \n",
      "  inflating: data/mpd.slice.555000-555999.json  \n",
      "  inflating: data/mpd.slice.253000-253999.json  \n",
      "  inflating: data/mpd.slice.109000-109999.json  \n",
      "  inflating: data/mpd.slice.902000-902999.json  \n",
      "  inflating: data/mpd.slice.454000-454999.json  \n",
      "  inflating: data/mpd.slice.352000-352999.json  \n",
      "  inflating: data/mpd.slice.163000-163999.json  \n",
      "  inflating: data/mpd.slice.23000-23999.json  \n",
      "  inflating: data/mpd.slice.665000-665999.json  \n",
      "  inflating: data/mpd.slice.869000-869999.json  \n",
      "  inflating: data/mpd.slice.239000-239999.json  \n",
      "  inflating: data/mpd.slice.656000-656999.json  \n",
      "  inflating: data/mpd.slice.150000-150999.json  \n",
      "  inflating: data/mpd.slice.361000-361999.json  \n",
      "  inflating: data/mpd.slice.689000-689999.json  \n",
      "  inflating: data/mpd.slice.931000-931999.json  \n",
      "  inflating: data/mpd.slice.467000-467999.json  \n",
      "  inflating: data/mpd.slice.885000-885999.json  \n",
      "  inflating: data/mpd.slice.260000-260999.json  \n",
      "  inflating: data/mpd.slice.788000-788999.json  \n",
      "  inflating: data/mpd.slice.830000-830999.json  \n",
      "  inflating: data/mpd.slice.566000-566999.json  \n",
      "  inflating: data/mpd.slice.984000-984999.json  \n",
      "  inflating: data/mpd.slice.757000-757999.json  \n",
      "  inflating: data/mpd.slice.535000-535999.json  \n",
      "  inflating: data/mpd.slice.863000-863999.json  \n",
      "  inflating: data/mpd.slice.233000-233999.json  \n",
      "  inflating: data/mpd.slice.481000-481999.json  \n",
      "  inflating: data/mpd.slice.169000-169999.json  \n",
      "  inflating: data/mpd.slice.33000-33999.json  \n",
      "  inflating: data/mpd.slice.387000-387999.json  \n",
      "  inflating: data/mpd.slice.704000-704999.json  \n",
      "  inflating: data/mpd.slice.908000-908999.json  \n",
      "  inflating: data/mpd.slice.358000-358999.json  \n",
      "  inflating: data/mpd.slice.103000-103999.json  \n",
      "  inflating: data/mpd.slice.605000-605999.json  \n",
      "  inflating: data/mpd.slice.809000-809999.json  \n",
      "  inflating: data/mpd.slice.259000-259999.json  \n",
      "  inflating: data/mpd.slice.434000-434999.json  \n",
      "  inflating: data/mpd.slice.962000-962999.json  \n",
      "  inflating: data/mpd.slice.332000-332999.json  \n",
      "  inflating: data/mpd.slice.580000-580999.json  \n",
      "  inflating: data/mpd.slice.29000-29999.json  \n",
      "  inflating: data/mpd.slice.286000-286999.json  \n",
      "  inflating: data/mpd.slice.301000-301999.json  \n",
      "  inflating: data/mpd.slice.407000-407999.json  \n",
      "  inflating: data/mpd.slice.951000-951999.json  \n",
      "  inflating: data/mpd.slice.636000-636999.json  \n",
      "  inflating: data/mpd.slice.130000-130999.json  \n",
      "  inflating: data/mpd.slice.782000-782999.json  \n",
      "  inflating: data/mpd.slice.737000-737999.json  \n",
      "  inflating: data/mpd.slice.683000-683999.json  \n",
      "  inflating: data/mpd.slice.17000-17999.json  \n",
      "  inflating: data/mpd.slice.185000-185999.json  \n",
      "  inflating: data/mpd.slice.200000-200999.json  \n",
      "  inflating: data/mpd.slice.506000-506999.json  \n",
      "  inflating: data/mpd.slice.850000-850999.json  \n",
      "  inflating: data/mpd.slice.705000-705999.json  \n",
      "  inflating: data/mpd.slice.359000-359999.json  \n",
      "  inflating: data/mpd.slice.909000-909999.json  \n",
      "  inflating: data/mpd.slice.232000-232999.json  \n",
      "  inflating: data/mpd.slice.534000-534999.json  \n",
      "  inflating: data/mpd.slice.862000-862999.json  \n",
      "  inflating: data/mpd.slice.386000-386999.json  \n",
      "  inflating: data/mpd.slice.45000-45999.json  \n",
      "  inflating: data/mpd.slice.168000-168999.json  \n",
      "  inflating: data/mpd.slice.480000-480999.json  \n",
      "  inflating: data/mpd.slice.333000-333999.json  \n",
      "  inflating: data/mpd.slice.435000-435999.json  \n",
      "  inflating: data/mpd.slice.963000-963999.json  \n",
      "  inflating: data/mpd.slice.287000-287999.json  \n",
      "  inflating: data/mpd.slice.581000-581999.json  \n",
      "  inflating: data/mpd.slice.604000-604999.json  \n",
      "  inflating: data/mpd.slice.102000-102999.json  \n",
      "  inflating: data/mpd.slice.258000-258999.json  \n",
      "  inflating: data/mpd.slice.808000-808999.json  \n",
      "  inflating: data/mpd.slice.90000-90999.json  \n",
      "  inflating: data/mpd.slice.131000-131999.json  \n",
      "  inflating: data/mpd.slice.637000-637999.json  \n",
      "  inflating: data/mpd.slice.783000-783999.json  \n",
      "  inflating: data/mpd.slice.406000-406999.json  \n",
      "  inflating: data/mpd.slice.950000-950999.json  \n",
      "  inflating: data/mpd.slice.300000-300999.json  \n",
      "  inflating: data/mpd.slice.507000-507999.json  \n",
      "  inflating: data/mpd.slice.851000-851999.json  \n",
      "  inflating: data/mpd.slice.201000-201999.json  \n",
      "  inflating: data/mpd.slice.736000-736999.json  \n",
      "  inflating: data/mpd.slice.61000-61999.json  \n",
      "  inflating: data/mpd.slice.184000-184999.json  \n",
      "  inflating: data/mpd.slice.682000-682999.json  \n",
      "  inflating: data/mpd.slice.101000-101999.json  \n",
      "  inflating: data/mpd.slice.607000-607999.json  \n",
      "  inflating: data/mpd.slice.582000-582999.json  \n",
      "  inflating: data/mpd.slice.284000-284999.json  \n",
      "  inflating: data/mpd.slice.960000-960999.json  \n",
      "  inflating: data/mpd.slice.436000-436999.json  \n",
      "  inflating: data/mpd.slice.330000-330999.json  \n",
      "  inflating: data/mpd.slice.483000-483999.json  \n",
      "  inflating: data/mpd.slice.385000-385999.json  \n",
      "  inflating: data/mpd.slice.861000-861999.json  \n",
      "  inflating: data/mpd.slice.537000-537999.json  \n",
      "  inflating: data/mpd.slice.231000-231999.json  \n",
      "  inflating: data/mpd.slice.64000-64999.json  \n",
      "  inflating: data/mpd.slice.706000-706999.json  \n",
      "  inflating: data/mpd.slice.369000-369999.json  \n",
      "  inflating: data/mpd.slice.681000-681999.json  \n",
      "  inflating: data/mpd.slice.939000-939999.json  \n",
      "  inflating: data/mpd.slice.187000-187999.json  \n",
      "  inflating: data/mpd.slice.735000-735999.json  \n",
      "  inflating: data/mpd.slice.158000-158999.json  \n",
      "  inflating: data/mpd.slice.202000-202999.json  \n",
      "  inflating: data/mpd.slice.40000-40999.json  \n",
      "  inflating: data/mpd.slice.852000-852999.json  \n",
      "  inflating: data/mpd.slice.504000-504999.json  \n",
      "  inflating: data/mpd.slice.303000-303999.json  \n",
      "  inflating: data/mpd.slice.953000-953999.json  \n",
      "  inflating: data/mpd.slice.405000-405999.json  \n",
      "  inflating: data/mpd.slice.268000-268999.json  \n",
      "  inflating: data/mpd.slice.780000-780999.json  \n",
      "  inflating: data/mpd.slice.838000-838999.json  \n",
      "  inflating: data/mpd.slice.634000-634999.json  \n",
      "  inflating: data/mpd.slice.95000-95999.json  \n",
      "  inflating: data/mpd.slice.132000-132999.json  \n",
      "  inflating: data/mpd.slice.285000-285999.json  \n",
      "  inflating: data/mpd.slice.583000-583999.json  \n",
      "  inflating: data/mpd.slice.331000-331999.json  \n",
      "  inflating: data/mpd.slice.961000-961999.json  \n",
      "  inflating: data/mpd.slice.437000-437999.json  \n",
      "  inflating: data/mpd.slice.606000-606999.json  \n",
      "  inflating: data/mpd.slice.100000-100999.json  \n",
      "  inflating: data/mpd.slice.707000-707999.json  \n",
      "  inflating: data/mpd.slice.12000-12999.json  \n",
      "  inflating: data/mpd.slice.384000-384999.json  \n",
      "  inflating: data/mpd.slice.482000-482999.json  \n",
      "  inflating: data/mpd.slice.230000-230999.json  \n",
      "  inflating: data/mpd.slice.860000-860999.json  \n",
      "  inflating: data/mpd.slice.536000-536999.json  \n",
      "  inflating: data/mpd.slice.159000-159999.json  \n",
      "  inflating: data/mpd.slice.853000-853999.json  \n",
      "  inflating: data/mpd.slice.505000-505999.json  \n",
      "  inflating: data/mpd.slice.36000-36999.json  \n",
      "  inflating: data/mpd.slice.203000-203999.json  \n",
      "  inflating: data/mpd.slice.186000-186999.json  \n",
      "  inflating: data/mpd.slice.938000-938999.json  \n",
      "  inflating: data/mpd.slice.680000-680999.json  \n",
      "  inflating: data/mpd.slice.368000-368999.json  \n",
      "  inflating: data/mpd.slice.734000-734999.json  \n",
      "  inflating: data/mpd.slice.839000-839999.json  \n",
      "  inflating: data/mpd.slice.781000-781999.json  \n",
      "  inflating: data/mpd.slice.269000-269999.json  \n",
      "  inflating: data/mpd.slice.133000-133999.json  \n",
      "  inflating: data/mpd.slice.635000-635999.json  \n",
      "  inflating: data/mpd.slice.952000-952999.json  \n",
      "  inflating: data/mpd.slice.404000-404999.json  \n",
      "  inflating: data/mpd.slice.302000-302999.json  \n",
      "   creating: src/\n",
      "  inflating: src/show.py             \n",
      "  inflating: src/deeper_stats.py     \n",
      "  inflating: src/check.py            \n",
      "  inflating: src/print.py            \n",
      "  inflating: src/stats.py            \n",
      "  inflating: src/descriptions.py     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://matching-engine-content/spotify-million-playlist/spotify_million_playlist_dataset.zip .\n",
    "!unzip spotify_million_playlist_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f9vXfl2HL98P",
    "outputId": "46ed64f1-c0e7-4c14-fc3e-51c7888fe7a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.517000-517999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.877000-877999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:09,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.629000-629999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.155000-155999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.458000-458999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.278000-278999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.982000-982999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.807000-807999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:11, 11.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.434000-434999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.28000-28999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.165000-165999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:09,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.709000-709999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.895000-895999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.620000-620999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.970000-970999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.956000-956999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.365000-365999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.455000-455999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.699000-699999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.203000-203999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.746000-746999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.594000-594999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.891000-891999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:19, 19.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.722000-722999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.140000-140999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.45000-45999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.705000-705999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.606000-606999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.494000-494999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.202000-202999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.710000-710999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/mpd.slice.353000-353999.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 rows loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.93s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6f7779ad9de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mreauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     ) \n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_gbq\u001b[0;34m(self, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[1;32m   1938\u001b[0m             \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m             \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m         )\n\u001b[1;32m   1942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/gbq.py\u001b[0m in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, verbose, private_key)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m     )\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, dataframe, dataset_id, table_id, chunksize, schema, progress_bar)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mremaining_rows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 logger.info(\n\u001b[1;32m    608\u001b[0m                     \"\\r{} out of {} rows loaded.\".format(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_gbq/load.py\u001b[0m in \u001b[0;36mload_chunks\u001b[0;34m(client, dataframe, dataset_id, table_id, chunksize, schema, location)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mdestination_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             ).result()\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mload_table_from_file\u001b[0;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n\u001b[1;32m   2446\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAX_MULTIPART_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m                 response = self._do_resumable_upload(\n\u001b[0;32m-> 2448\u001b[0;31m                     \u001b[0mfile_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m                 )\n\u001b[1;32m   2450\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_do_resumable_upload\u001b[0;34m(self, stream, metadata, num_retries, timeout, project)\u001b[0m\n\u001b[1;32m   2867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2868\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2869\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransmit_next_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/resumable_media/requests/upload.py\u001b[0m in \u001b[0;36mtransmit_next_chunk\u001b[0;34m(self, transport, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         return _request_helpers.wait_and_retry(\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mretriable_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_status_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         )\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/resumable_media/requests/_request_helpers.py\u001b[0m in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_CONNECTION_ERROR_CLASSES\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# Fall through to retry, if there are retries left.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/resumable_media/requests/upload.py\u001b[0m in \u001b[0;36mretriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretriable_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             result = transport.request(\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m             )\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         \u001b[0mremaining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_files = os.listdir('data')\n",
    "# PROJECT_ID = 'jtotten-project'\n",
    "bq_dataset = 'mdp_eda'\n",
    "\n",
    "for filename in data_files:\n",
    "  with open(f'data/{filename}') as f:\n",
    "    print(f)\n",
    "    json_dict = json.load(f)\n",
    "    df = pd.DataFrame(json_dict['playlists'])\n",
    "    df.to_gbq(\n",
    "    destination_table=f'{bq_dataset}.playlists', \n",
    "    project_id=f'{PROJECT_ID}', # TODO: param\n",
    "    location='us-central1', \n",
    "    progress_bar=True, \n",
    "    reauth=True, \n",
    "    if_exists='append'\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDOhLGShyPH"
   },
   "source": [
    "## Parse the JSON from the uploaded table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-86R5ZGOhqqZ"
   },
   "outputs": [],
   "source": [
    "## Parse the JSON from the uploaded table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "id": "ue9RBrR1JCFm",
    "outputId": "7f990a02-3085-4713-c9d0-73fda6aba4d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 3/3 [00:00<00:00, 1033.67query/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c725d155-3149-4725-9f7a-40684f8c17ee\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c725d155-3149-4725-9f7a-40684f8c17ee')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c725d155-3149-4725-9f7a-40684f8c17ee button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c725d155-3149-4725-9f7a-40684f8c17ee');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create or replace table jtotten-project.spotify_mpd.playlists as (\n",
    "with json_parsed as (SELECT *, JSON_EXTRACT_ARRAY(tracks) as json_data FROM `jtotten-project.mdp_eda.playlists` )\n",
    "\n",
    "select json_parsed.* except(tracks, duration_ms, json_data),\n",
    "JSON_EXTRACT(jsn_line, \"$.pos\") as pos, \n",
    "JSON_EXTRACT(jsn_line, \"$.artist_name\") as artist_name,\n",
    "JSON_EXTRACT(jsn_line, \"$.track_uri\") as track_uri,\n",
    "JSON_EXTRACT(jsn_line, \"$.artist_uri\") as artist_uri,\n",
    "JSON_EXTRACT(jsn_line, \"$.track_name\") as track_name,\n",
    "JSON_EXTRACT(jsn_line, \"$.album_uri\") as album_uri,\n",
    "JSON_EXTRACT(jsn_line, \"$.duration_ms\") as duration_ms,\n",
    "JSON_EXTRACT(jsn_line, \"$.album_name\") as album_name,\n",
    "\n",
    "from json_parsed CROSS JOIN UNNEST(json_parsed.json_data) as jsn_line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HEriAdKNLiA"
   },
   "outputs": [],
   "source": [
    "## Adding a couple of tables for unique values to be used in the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "id": "_hNQwJMENSJ6",
    "outputId": "ec3365ed-b581-4a69-e40f-de3223cd8f07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 371.44query/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6089c8ce-edb9-4360-8bfb-c35bfd534b4a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6089c8ce-edb9-4360-8bfb-c35bfd534b4a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6089c8ce-edb9-4360-8bfb-c35bfd534b4a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6089c8ce-edb9-4360-8bfb-c35bfd534b4a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create or replace table `jtotten-project.spotify_mpd.unique_tracks` as (select distinct track_uri, cast(duration_ms as INT64) AS duration_ms from `jtotten-project.spotify_mpd.playlists` );\n",
    "create or replace table `jtotten-project.spotify_mpd.unique_artists` as (select distinct artist_uri, cast(duration_ms as INT64) AS duration_ms from `jtotten-project.spotify_mpd.playlists` );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_EBGIHEh08d"
   },
   "source": [
    "### Union all the slices for single artist and audio feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "N2vLEDqyi-uI",
    "outputId": "bb398872-35a0-44ea-ce4c-e07964cc51e0"
   },
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6bd630ee917b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m )  # Make an API request.\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mload_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Waits for the job to complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mdestination_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_id\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Make an API request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Not found: URI gs://matching-engine-content/spotify-million-playlist/eda/recco_songs_big.csv"
     ]
    }
   ],
   "source": [
    "# we will have to do this for the playlist songs!\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "# table_id = \"your-project.your_dataset.your_table_name\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"pos\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"artist_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"track_uri\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"artist_uri\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"track_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"album_uri\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"duration_ms\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"album_name\", \"STRING\"),\n",
    "\n",
    "    ],\n",
    "    skip_leading_rows=0,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "GCS_BUCKET = 'matching-engine-content'\n",
    "GCS_PREFIX_EDA = 'spotify-million-playlist/eda'\n",
    "gcs_bucket = GCS_BUCKET\n",
    "gcs_prefix_eda = GCS_PREFIX_EDA\n",
    "table_id = 'jtotten-project.spotify_mpd.playlists'\n",
    "\n",
    "\n",
    "uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/recco_songs_big.csv'\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "id": "VKyD_HCnhWCy",
    "outputId": "8c5fc121-01cb-4165-d548-6a567e47e3ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 3/3 [00:00<00:00, 559.29query/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f4561587-c234-463e-a476-db7d1403f1f5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4561587-c234-463e-a476-db7d1403f1f5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f4561587-c234-463e-a476-db7d1403f1f5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f4561587-c234-463e-a476-db7d1403f1f5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `jtotten-project.spotify_mpd.artists` as \n",
    "(select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_1`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_2`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_3`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_4`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_5`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_6`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_7`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_8`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_9`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_10`\n",
    "UNION ALL\n",
    "select * from\n",
    "`jtotten-project.spotify_mpd.artist_split_11`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWdHqXQdjsNm",
    "outputId": "1e4c36f0-12ea-497a-965a-7dc9f82ccb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: ec520a3f-5958-4b49-8ad8-bc1a22fc05a7\n",
      "Query executing: 0.50s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/jtotten-project/queries/ec520a3f-5958-4b49-8ad8-bc1a22fc05a7?maxResults=0&timeoutMs=400&location=us-central1: Column 28 in UNION ALL has incompatible types: INT64, INT64, INT64, STRING, INT64, INT64, INT64, INT64, INT64, STRING, INT64 at [5:1]\n",
      "\n",
      "(job ID: ec520a3f-5958-4b49-8ad8-bc1a22fc05a7)\n",
      "\n",
      "                      -----Query Job SQL Follows-----                      \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:CREATE OR REPLACE TABLE `jtotten-project.spotify_mpd.track_audio` as \n",
      "   2:(select * from\n",
      "   3:`jtotten-project.spotify_mpd.track_audio_split_1`\n",
      "   4:UNION ALL\n",
      "   5:select * from\n",
      "   6:`jtotten-project.spotify_mpd.track_audio_split_2`\n",
      "   7:UNION ALL\n",
      "   8:select * from\n",
      "   9:`jtotten-project.spotify_mpd.track_audio_split_3`\n",
      "  10:UNION ALL\n",
      "  11:select * except(artist_pop), CAST(artist_pop as INT64) artist_pop from\n",
      "  12:`jtotten-project.spotify_mpd.track_audio_split_4`\n",
      "  13:UNION ALL\n",
      "  14:select * from\n",
      "  15:`jtotten-project.spotify_mpd.track_audio_split_5`\n",
      "  16:UNION ALL\n",
      "  17:select * from\n",
      "  18:`jtotten-project.spotify_mpd.track_audio_split_6`\n",
      "  19:UNION ALL\n",
      "  20:select * from\n",
      "  21:`jtotten-project.spotify_mpd.track_audio_split_7`\n",
      "  22:UNION ALL\n",
      "  23:select * from\n",
      "  24:`jtotten-project.spotify_mpd.track_audio_split_8`\n",
      "  25:UNION ALL\n",
      "  26:select * from\n",
      "  27:`jtotten-project.spotify_mpd.track_audio_split_9`\n",
      "  28:UNION ALL\n",
      "  29:select * except(artist_pop), CAST(artist_pop as INT64) artist_pop from\n",
      "  30:`jtotten-project.spotify_mpd.track_audio_split_10`\n",
      "  31:UNION ALL\n",
      "  32:select * from\n",
      "  33:`jtotten-project.spotify_mpd.track_audio_split_11`\n",
      "  34:)\n",
      "    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `jtotten-project.spotify_mpd.track_audio` as \n",
    "(select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_1`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_2`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t, from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_3`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "case when artist_pop = 'na' then 0 else CAST(artist_pop as INT64) END as artist_pop,\n",
    "track_pop\t,\n",
    "genres\n",
    " from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_4`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_5`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_6`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_7`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_8`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_9`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "case when artist_pop = 'na' then 0 else CAST(artist_pop as INT64) END as artist_pop,\n",
    "track_pop\t,\n",
    "genres\n",
    "  from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_10`\n",
    "UNION ALL\n",
    "select artist_name\t,\n",
    "track_uri\t,\n",
    "artist_uri\t,\n",
    "track_name\t,\n",
    "album_uri\t,\n",
    "duration_ms_x\t,\n",
    "album_name\t,\n",
    "name\t,\n",
    "danceability\t,\n",
    "energy\t,\n",
    "key\t,\n",
    "loudness\t,\n",
    "mode\t,\n",
    "speechiness\t,\n",
    "acousticness\t,\n",
    "instrumentalness\t,\n",
    "liveness\t,\n",
    "valence\t,\n",
    "tempo\t,\n",
    "type\t,\n",
    "id\t,\n",
    "uri\t,\n",
    "track_href\t,\n",
    "analysis_url\t,\n",
    "duration_ms_y\t,\n",
    "time_signature\t,\n",
    "artist_pop\t,\n",
    "track_pop\t,\n",
    "genres\t from\n",
    "`jtotten-project.spotify_mpd.track_audio_split_11`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMg7EesFolfc"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## Split tracks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZnuGrDFLKS7"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                        #  'spotipy',\n",
    "                         'numpy','pandas','pyarrow',\n",
    "                         'absl-py',],\n",
    ")\n",
    "def split_tracks_data(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    all_tracks_filename: str,\n",
    ") -> NamedTuple('Outputs', [('all_tracks_split_1_gcs_uri', str),\n",
    "                            ('all_tracks_split_2_gcs_uri', str),\n",
    "                            ('all_tracks_split_3_gcs_uri', str),\n",
    "                            ('all_tracks_split_4_gcs_uri', str),\n",
    "                            ('all_tracks_split_5_gcs_uri', str),\n",
    "                            ('all_tracks_split_6_gcs_uri', str),\n",
    "                            ('all_tracks_split_7_gcs_uri', str),\n",
    "                            ('all_tracks_split_8_gcs_uri', str),\n",
    "                            ('all_tracks_split_9_gcs_uri', str),\n",
    "                            ('all_tracks_split_10_gcs_uri', str),\n",
    "                            ('all_tracks_split_11_gcs_uri', str),\n",
    "                            ]):\n",
    "  \n",
    "  import os\n",
    "  # import spotipy\n",
    "  # from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from absl import logging\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "\n",
    "  df = pd.read_csv(f'gs://{gcs_bucket}/{gcs_prefix_eda}/{all_tracks_filename}')\n",
    "  # print(f'Shape of {all_tracks_filename}: {df.shape}')\n",
    "  logging.info(f'Shape of {all_tracks_filename}: {df.shape}')\n",
    "  \n",
    "  all_tracks_split_1, all_tracks_split_2, all_tracks_split_3, all_tracks_split_4, all_tracks_split_5, all_tracks_split_6, all_tracks_split_7, all_tracks_split_8, all_tracks_split_9, all_tracks_split_10, all_tracks_split_11 = np.array_split(df, 11)#turning up to 11\n",
    "\n",
    "  # upload split to GCS\n",
    "  bucket = storage_client.get_bucket(f'{gcs_bucket}')\n",
    "\n",
    "  # ONE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_1.csv').upload_from_string(\n",
    "      all_tracks_split_1.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_1_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_1.csv'\n",
    "\n",
    "  # TWO\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_2.csv').upload_from_string(\n",
    "      all_tracks_split_2.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_2_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_2.csv'\n",
    "\n",
    "  # THREE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_3.csv').upload_from_string(\n",
    "      all_tracks_split_3.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_3_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_3.csv'\n",
    "\n",
    "  # FOUR\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_4.csv').upload_from_string(\n",
    "      all_tracks_split_4.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_4_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_4.csv'\n",
    "\n",
    "  logging.info(f'all_tracks_split_1_gcs_uri {all_tracks_split_1_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_2_gcs_uri {all_tracks_split_2_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_3_gcs_uri {all_tracks_split_3_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_4_gcs_uri {all_tracks_split_4_gcs_uri}')\n",
    "\n",
    "    # FIVE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_5.csv').upload_from_string(\n",
    "      all_tracks_split_5.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_5_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_5.csv'\n",
    "\n",
    "  # SIX\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_6.csv').upload_from_string(\n",
    "      all_tracks_split_6.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_6_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_6.csv'\n",
    "\n",
    "  # SEVEN\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_7.csv').upload_from_string(\n",
    "      all_tracks_split_7.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_7_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_7.csv'\n",
    "\n",
    "  # EIGHT\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_8.csv').upload_from_string(\n",
    "      all_tracks_split_8.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_8_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_8.csv'\n",
    "\n",
    "  logging.info(f'all_tracks_split_5_gcs_uri {all_tracks_split_5_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_6_gcs_uri {all_tracks_split_6_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_7_gcs_uri {all_tracks_split_7_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_8_gcs_uri {all_tracks_split_8_gcs_uri}')\n",
    "\n",
    "  # NINE\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_9.csv').upload_from_string(\n",
    "      all_tracks_split_9.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_9_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_9.csv'\n",
    "\n",
    "  # TEN\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_10.csv').upload_from_string(\n",
    "      all_tracks_split_10.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_10_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_10.csv'\n",
    "\n",
    "  # ELEVEN\n",
    "  bucket.blob(f'{gcs_prefix_eda}/all_tracks_split_11.csv').upload_from_string(\n",
    "      all_tracks_split_11.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  all_tracks_split_11_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/all_tracks_split_11.csv'\n",
    "\n",
    "\n",
    "  logging.info(f'all_tracks_split_9_gcs_uri {all_tracks_split_9_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_10_gcs_uri {all_tracks_split_10_gcs_uri}')\n",
    "  logging.info(f'all_tracks_split_11_gcs_uri {all_tracks_split_11_gcs_uri}')\n",
    "\n",
    "\n",
    "  return(\n",
    "      f'{all_tracks_split_1_gcs_uri}',\n",
    "      f'{all_tracks_split_2_gcs_uri}',\n",
    "      f'{all_tracks_split_3_gcs_uri}',\n",
    "      f'{all_tracks_split_4_gcs_uri}',\n",
    "      f'{all_tracks_split_5_gcs_uri}',\n",
    "      f'{all_tracks_split_6_gcs_uri}',\n",
    "      f'{all_tracks_split_7_gcs_uri}',\n",
    "      f'{all_tracks_split_8_gcs_uri}',\n",
    "      f'{all_tracks_split_9_gcs_uri}',\n",
    "      f'{all_tracks_split_10_gcs_uri}',\n",
    "      f'{all_tracks_split_11_gcs_uri}',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz3gXiBZo-s2"
   },
   "source": [
    "## Call Spotify Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m3D974DjTbE"
   },
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86ZuQqElhZrS"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec', 'google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4'])\n",
    "def call_spotify_api_split_audio(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    all_tracks_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: int,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_feat_split_1_gcs_uri', str),]):\n",
    "  print(f'pip install complete')\n",
    "  import os\n",
    "  import spotipy\n",
    "  from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import warnings\n",
    "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "  from absl import logging\n",
    "  from google.cloud import bigquery\n",
    "  import pandas_gbq\n",
    "\n",
    "  # print(f'package import complete')\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "  logging.info(f'package import complete')\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "  split=f'split_{split_id}'\n",
    "\n",
    "  # print(f'Extracting audio features and recommendations for {split} \\n')\n",
    "  logging.info(f'Extracting audio features and recommendations for {split} \\n')\n",
    "\n",
    "  # client_id='2dce494e64a74be980138668f4402b97'\n",
    "  # client_secret='1706fc14574a4fef9132aaaacb31aa1c'\n",
    "\n",
    "  logging.info(f'spotipy auth complete')\n",
    "  def spot_audio_features(uri, client_id, client_secret):\n",
    "    \n",
    "    # Authenticate\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=client_id, \n",
    "        client_secret=client_secret\n",
    "    )\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager = client_credentials_manager, \n",
    "        requests_timeout=10, \n",
    "        retries=10 )\n",
    "    ############################################################################\n",
    "    # Create Track Audio Features DF for Split\n",
    "    ############################################################################\n",
    "\n",
    "    #Audio features\n",
    "    uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "    a_feats = sp.audio_features(uri)\n",
    "    features = pd.json_normalize(a_feats, ).to_dict('list')\n",
    "    if features is None:\n",
    "      features = {}\n",
    "    #Artist of the track, for genres and popularity\n",
    "    popularity = []\n",
    "    #tracks API call\n",
    "    tracks = sp.tracks(uri)\n",
    "    # if tracks:\n",
    "    for track in tracks['tracks']:\n",
    "      if track is not None:\n",
    "        popularity.append(track['popularity'])\n",
    "      else:\n",
    "        popularity.append(-1)\n",
    "\n",
    "    audio_df = pd.DataFrame(features)\n",
    "    audio_df['popularity'] = popularity\n",
    "    audio_df['track_uri'] = uri\n",
    "    return audio_df\n",
    "\n",
    "  # logging.info(f'finna download ~large csv')\n",
    "  # df = pd.read_csv('gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_v2.csv')\n",
    "  # df = pd.read_csv(f'{all_tracks_split_1_gcs_uri}')\n",
    "  # REFACTOR TO READ FROM BQ TABLE\n",
    "\n",
    "  bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "  )\n",
    "\n",
    "  audio_featureDF = pd.DataFrame()\n",
    " \n",
    "  query = f\"\"\"select count(1) as count from `jtotten-project.spotify_mpd.unique_tracks` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.track_uri NOT IN (SELECT track_uri FROM `jtotten-project.spotify_mpd.track_audio_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "  uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "  uri_list_length = uri_list_length_df['count'][0]\n",
    "  \n",
    "  count = 1\n",
    "  uri_batch = []\n",
    "  # handling bad track/artist_uris\n",
    "\n",
    "  #refactor\n",
    "  schema = [{'name':'danceability', 'type': 'FLOAT'},\t\n",
    "            {'name':'energy', 'type': 'FLOAT'},\t\n",
    "            {'name':'key', 'type': 'FLOAT'},\t\n",
    "            {'name':'loudness', 'type': 'FLOAT'},\t\n",
    "            {'name':'mode', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'speechiness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'acousticness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'instrumentalness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'liveness', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'valence', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'followers', 'type': 'FLOAT'\t},\t\n",
    "            {'name':'tempo', 'type': 'FLOAT'},\n",
    "            {'name':'type', 'type': 'STRING'},\n",
    "            {'name':'id', 'type': 'STRING'},\n",
    "            {'name':'uri', 'type': 'STRING'},\n",
    "            {'name':'track_href', 'type': 'STRING'},\n",
    "            {'name':'analysis_url', 'type': 'STRING'},\n",
    "            {'name':'duration_ms_y', 'type': 'FLOAT'},\n",
    "            {'name':'time_signature', 'type': 'FLOAT'},\n",
    "            {'name':'popularity', 'type': 'INT64'},\n",
    "            {'name':'track_uri', 'type': 'STRING'},\n",
    "  ]\n",
    "  query = f\"\"\"select track_uri from `jtotten-project.spotify_mpd.unique_tracks` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.track_uri NOT IN (SELECT track_uri FROM `jtotten-project.spotify_mpd.track_audio_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "\n",
    "  tracks = bq_client.query(query).result().to_dataframe()\n",
    "  track_list = tracks.track_uri.to_list()\n",
    "  for uri in track_list:\n",
    "    if count % 50 == 0 or uri_list_length == count: #grab a batch of 50 songs\n",
    "      uri_batch.append(uri)\n",
    "      ### Try catch block for function\n",
    "      try:\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "        \n",
    "      except ReadTimeout:\n",
    "        logging.info(\"'Spotify timed out... trying again...'\")\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "      except HTTPError as err: #JW ADDED\n",
    "        logging.info(f\"HTTP Error: {err}\")\n",
    "      except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "        logging.info(f\"Spotify error: {spotify_error}\")\n",
    "      try:\n",
    "        audio_featureDF.to_gbq(\n",
    "            destination_table=f'spotify_mpd.track_audio_{split_id}', \n",
    "            project_id=f'{project}', # TODO: param\n",
    "            location='us-central1', \n",
    "            # table_schema=schema,\n",
    "            progress_bar=False, \n",
    "            reauth=False, \n",
    "            if_exists='append'\n",
    "            )\n",
    "      except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "        logging.info('invalid schema, skipping')\n",
    "        pass\n",
    "      logging.info(f'{count} of {uri_list_length} complete!')\n",
    "      uri_batch = []\n",
    "      count += 1\n",
    "      time.sleep(sleep_param)\n",
    "    else:\n",
    "      uri_batch.append(uri)\n",
    "      count += 1\n",
    "      \n",
    "      \n",
    "  logging.info(f'audio features appended')\n",
    "  # audio_featureDF = pd.DataFrame(audio_featureLIST)\n",
    "\n",
    "  # logging.info(f'Shape of {audio_featureDF}: {audio_featureDF.shape}')\n",
    "\n",
    "  # tracks_audio_feats_df = pd.merge(\n",
    "  #     df,audio_featureDF, left_on = \"track_uri\", right_on= \"id\"\n",
    "  # )\n",
    "  # logging.info(f'dataframes merged')\n",
    "  # bucket = storage_client.get_bucket(f'{gcs_bucket}')\n",
    "\n",
    "  # bucket.blob(f'{gcs_prefix_eda}/track_audio_feat_{split_id}.csv').upload_from_string(\n",
    "  #     tracks_audio_feats_df.to_csv(index=False), 'text/csv')\n",
    "\n",
    "  # logging.info(f'csv uploaded')\n",
    "  # track_audio_feat_split_1_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/track_audio_feat_{split_id}.csv'\n",
    "\n",
    "  ############################################################################\n",
    "  # Create Recommended Tracks Features DF for Split\n",
    "  ############################################################################\n",
    "\n",
    "\n",
    "  return (\n",
    "      f'DONE',\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnlgrgT0hvF2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hppPSwkh1x2"
   },
   "source": [
    "### Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYbgsLrtxPHl"
   },
   "outputs": [],
   "source": [
    "### Artist racks api call\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',' google-cloud-bigquery',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests','db-dtypes',\n",
    "                         'numpy','pandas','pyarrow','absl-py', 'pandas-gbq==0.17.4'])\n",
    "def call_spotify_api_split_artist(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    all_tracks_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: int,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_feat_split_1_gcs_uri', str),]):\n",
    "  print(f'pip install complete')\n",
    "  import os\n",
    "  import spotipy\n",
    "  from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import warnings\n",
    "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "  from absl import logging\n",
    "  from google.cloud import bigquery\n",
    "  import pandas_gbq\n",
    "  # print(f'package import complete')\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "  logging.info(f'package import complete')\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "  split='split_1'\n",
    "\n",
    "  # print(f'Extracting audio features and recommendations for {split} \\n')\n",
    "  logging.info(f'Extracting audio features and recommendations for {split} \\n')\n",
    "\n",
    "  # client_id='2dce494e64a74be980138668f4402b97'\n",
    "  # client_secret='1706fc14574a4fef9132aaaacb31aa1c'\n",
    "\n",
    "  logging.info(f'spotipy auth complete')\n",
    "  def spot_audio_features(uri, client_id, client_secret):\n",
    "    \n",
    "    # Authenticate\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=client_id, \n",
    "        client_secret=client_secret\n",
    "    )\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager = client_credentials_manager, \n",
    "        requests_timeout=10, \n",
    "        retries=10 )\n",
    "    ############################################################################\n",
    "    # Create Track Audio Features DF for Split\n",
    "    ############################################################################\n",
    "\n",
    "    #Audio features\n",
    "    # a_feats = sp.audio_features(uri)\n",
    "    # features = pd.json_normalize(a_feats, ).to_dict('list')\n",
    "    # if features is None:\n",
    "    #   features = {}\n",
    "    #Artist of the track, for genres and popularity\n",
    "    features = {}\n",
    "    # popularity = []\n",
    "    #tracks API call\n",
    "    # if tracks:\n",
    "\n",
    "    #artists api call\n",
    "    uri = [u.replace('\"', '') for u in uri] #fix the quotes \n",
    "    artists = sp.artists(uri)\n",
    "\n",
    "    artist_pop = []\n",
    "    artist_genres = []\n",
    "    followers = []\n",
    "    id_list = uri\n",
    "    for artist in artists['artists']:\n",
    "      if artist is not None:\n",
    "        artist_pop.append(artist['popularity'])\n",
    "        artist_genres.append(artist['genres'])\n",
    "        # if artist['followers']['total'] is None:\n",
    "        followers.append(artist['followers']['total'])\n",
    "        # else:\n",
    "        #   followers.append(-1)\n",
    "      else:\n",
    "        artist_pop.append(-1)\n",
    "        artist_genres.append('unknown')\n",
    "\n",
    "    # logging.info(print(f\"artist: {artist_pop}\"))\n",
    "    # logging.info(print(f\"genres: {artist_genres}\"))\n",
    "    # logging.info(print(f\"followers: {followers}\"))\n",
    "    features[\"artist_pop\"] = artist_pop\n",
    "    features[\"genres\"] = artist_genres\n",
    "    features['followers'] = followers\n",
    "    features['artist_uri'] = id_list\n",
    "    audio_df = pd.DataFrame(features)\n",
    "    audio_df['genres'] = audio_df['genres'].astype(str)\n",
    "    # logging.info(print(audio_df)) #logging\n",
    "    return audio_df\n",
    "\n",
    "  # logging.info(f'finna download ~large csv')\n",
    "  # # df = pd.read_csv('gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_v2.csv')\n",
    "  # df = pd.read_csv(f'{all_tracks_split_1_gcs_uri}')\n",
    "  # logging.info(f'Original shape of split: {df.shape}')\n",
    "  # logging.info(f'~large download complete')\n",
    "  # artist_set = set(df['artist_uri']) #create a distinct set\n",
    "  bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "  )\n",
    "\n",
    "  \n",
    "\n",
    "  logging.info(f'finished downloading tracks for split {split_id}')\n",
    "  query = f\"\"\"select count(1) as count from `jtotten-project.spotify_mpd.unique_artists` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.artist_uri NOT IN (SELECT artist_uri FROM `jtotten-project.spotify_mpd.track_artist_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "  uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "  n_artists = uri_list_length_df['count'][0]\n",
    "  logging.info(f'number of distinct artists: {n_artists}')\n",
    "  audio_featureDF = pd.DataFrame()\n",
    "  uri_list_length = n_artists\n",
    "  \n",
    "\n",
    "  schema = [{'name': 'artist_pop', 'type': \t'INTEGER'\t},\t\n",
    "            {'name':'genres', 'type': \t'STRING'\t},\t\n",
    "            {'name':'followers', 'type': \t'INTEGER'\t},\t\n",
    "            {'name':'artist_uri', 'type': 'STRING'}\n",
    "  ]\n",
    "  count = 1\n",
    "  uri_batch = []\n",
    "  # handling bad track/artist_uris\n",
    "  query = f\"\"\"select artist_uri from `jtotten-project.spotify_mpd.unique_artists` a where mod(a.duration_ms, 11) = {split_id}-1 \n",
    "  and a.artist_uri NOT IN (SELECT artist_uri FROM `jtotten-project.spotify_mpd.track_artist_{split_id}`)\"\"\" #excluding what we already loaded\n",
    "\n",
    "  ats = bq_client.query(query).result().to_dataframe()\n",
    "  artist_set = ats.artist_uri.to_list()\n",
    "  for uri in artist_set:\n",
    "    if count % 50 == 0 or uri_list_length == count: #grab a batch of 50 artists\n",
    "      uri_batch.append(uri)\n",
    "      ### Try catch block for function\n",
    "      try:\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "      except ReadTimeout:\n",
    "        logging.info(\"'Spotify timed out... trying again...'\")\n",
    "        audio_featureDF = spot_audio_features(uri_batch, client_id, client_secret)\n",
    "      except HTTPError as err: #JW ADDED\n",
    "        logging.info(f\"HTTP Error: {err}\")\n",
    "      except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "        logging.info(f\"Spotify error: {spotify_error}\")\n",
    "      try:\n",
    "        audio_featureDF.to_gbq(\n",
    "            destination_table=f'spotify_mpd.track_artist_{split_id}', \n",
    "            project_id=f'{project}', # TODO: param\n",
    "            location='us-central1', \n",
    "            # table_schema=schema,\n",
    "            progress_bar=False, \n",
    "            reauth=False, \n",
    "            if_exists='append'\n",
    "            )\n",
    "      except pandas_gbq.gbq.InvalidSchema as invalid_schema:\n",
    "        logging.info('invalid schema, skipping')\n",
    "        pass\n",
    "      logging.info(f'{count} of {uri_list_length} complete!')\n",
    "      uri_batch = []\n",
    "      count += 1\n",
    "\n",
    "      time.sleep(sleep_param)\n",
    "\n",
    "    else:\n",
    "      uri_batch.append(uri)\n",
    "      count += 1\n",
    "\n",
    "  # logging.info(f'artist features appended')\n",
    "  # # audio_featureDF = pd.DataFrame(audio_featureLIST)\n",
    "\n",
    "  # logging.info(f'Shape of {audio_featureDF}: {audio_featureDF.shape}')\n",
    "\n",
    "  # tracks_audio_feats_df = pd.merge(\n",
    "  #     df,audio_featureDF, left_on = \"artist_uri\", right_on= \"id\"\n",
    "  # )\n",
    "  # logging.info(f'dataframes merged')\n",
    "  # bucket = storage_client.get_bucket(f'{gcs_bucket}')\n",
    "\n",
    "  # bucket.blob(f'{gcs_prefix_eda}/artist_split_{split_id}.csv').upload_from_string(\n",
    "  #     tracks_audio_feats_df.to_csv(index=False), 'text/csv')\n",
    "\n",
    "  # logging.info(f'csv uploaded')\n",
    "  # track_audio_feat_split_1_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/artist_split_{split_id}.csv'\n",
    "\n",
    "  ############################################################################\n",
    "  # Create Recommended Tracks Features DF for Split\n",
    "  ############################################################################\n",
    "\n",
    "\n",
    "  return (\n",
    "      f'DONE',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyL6B5dfjE7r"
   },
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xiubx4i_-z7N"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'spotipy','requests',\n",
    "                         'numpy','pandas','pyarrow','absl-py'])\n",
    "def call_spotify_api_split_recommendations(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    all_tracks_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    client_id: str,\n",
    "    client_secret: str,\n",
    "    sleep_param: int,\n",
    "    split: int,\n",
    ") -> NamedTuple('Outputs', [('track_recommendations_split_1_gcs_uri', str)]):\n",
    "  print(f'pip install complete')\n",
    "  import os\n",
    "  import spotipy\n",
    "  from spotipy.oauth2 import SpotifyClientCredentials\n",
    "  import re\n",
    "  import pandas as pd\n",
    "  import warnings\n",
    "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "  import json\n",
    "  from io import BytesIO\n",
    "  import time\n",
    "  from google.cloud import storage\n",
    "  import gcsfs\n",
    "  import numpy as np\n",
    "  from requests.exceptions import ReadTimeout, HTTPError, ConnectionError, RequestException\n",
    "  from absl import logging\n",
    "  \n",
    "  client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=client_id, \n",
    "        client_secret=client_secret\n",
    "    )\n",
    "  sp = spotipy.Spotify(\n",
    "      client_credentials_manager = client_credentials_manager, \n",
    "      requests_timeout=10, \n",
    "      retries=10\n",
    "  )\n",
    "  \n",
    "  try:\n",
    "    genre_seeds = sp.recommendation_genre_seeds()# set this to get the right list of genres\n",
    "  except ReadTimeout:\n",
    "    logging.info('timeout on gettin genres, trying one more time...')\n",
    "    genre_seeds = sp.recommendation_genre_seeds()# set this to get the right list of genres\n",
    "\n",
    "  def spot_rec_features(uri, client_id, client_secret):\n",
    "    \n",
    "    # # Authenticate\n",
    "    client_credentials_manager = SpotifyClientCredentials(\n",
    "        client_id=client_id, \n",
    "        client_secret=client_secret\n",
    "    )\n",
    "    sp = spotipy.Spotify(\n",
    "        client_credentials_manager = client_credentials_manager, \n",
    "        requests_timeout=10, \n",
    "        retries=10\n",
    "    )\n",
    "    recommended_tracks_artist_name_list = []\n",
    "    recommended_tracks_track_name_list = []\n",
    "    recommended_tracks_track_uri_list = []\n",
    "    recommended_tracks_audio_features = []\n",
    "    seed_track_list = []\n",
    "\n",
    "    ###### recomemnded tracks for seed_track\n",
    "    returned_features_recommended = {}\n",
    "    # _track = sp.track(uri)\n",
    "    \n",
    "    # print(f'Recommended tracks & artists for {_track[\"name\"]} \\n')\n",
    "    start = time.time()\n",
    "    recommended_tracks_from_artist = sp.recommendations(\n",
    "        seed_tracks=[uri],\n",
    "        seed_genres=genre_seeds,\n",
    "        limit=30,\n",
    "    )\n",
    "    \n",
    "    for track in recommended_tracks_from_artist['tracks']:\n",
    "      if track is not None:\n",
    "        seed_track_list.append(uri)\n",
    "        recommended_tracks_artist_name_list.append(track[\"artists\"][0][\"name\"])\n",
    "        recommended_tracks_track_name_list.append(track['name'])\n",
    "        recommended_tracks_track_uri_list.append(track['uri'])\n",
    "      else:\n",
    "        recommended_tracks_artist_name_list.append('na')\n",
    "        recommended_tracks_track_name_list.append('na')\n",
    "        recommended_tracks_track_uri_list.append('na')\n",
    "\n",
    "    returned_features_recommended['seed_track'] = seed_track_list\n",
    "    returned_features_recommended['rec_artist_names'] = recommended_tracks_artist_name_list\n",
    "    returned_features_recommended['rec_track_names'] = recommended_tracks_track_name_list\n",
    "    returned_features_recommended['rec_track_uris'] = recommended_tracks_track_uri_list\n",
    "\n",
    "    returned_features_recommended = pd.DataFrame(returned_features_recommended)\n",
    "    return returned_features_recommended\n",
    "\n",
    "\n",
    "  logging.info(f'finna download ~large csv')\n",
    "  # df = pd.read_csv('gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_v2.csv')\n",
    "  df = pd.read_csv(f'{all_tracks_split_1_gcs_uri}')\n",
    "  logging.info(f'Original shape of split: {df.shape}')\n",
    "  logging.info(f'~large download complete')\n",
    "\n",
    "  rec_featureDF = pd.DataFrame()\n",
    "  uri_list_length = len(df['track_uri'])\n",
    "  \n",
    "  count = 1\n",
    "  uri_batch = []\n",
    "  # handling bad track/artist_uris\n",
    "    \n",
    "  for uri in df['track_uri']:\n",
    "    try:\n",
    "      recs = spot_rec_features(uri, client_id, client_secret)\n",
    "      rec_featureDF = rec_featureDF.append(recs)\n",
    "    except HTTPError as err: #JW ADDED\n",
    "      logging.info(f\"HTTP Error: {err}\")\n",
    "    except spotipy.exceptions.SpotifyException as spotify_error: #jw_added\n",
    "      logging.info(f\"Spotify error: {spotify_error}\")\n",
    "    except ReadTimeout:\n",
    "      logging.info(\"'Spotify timed out... trying again'\")\n",
    "      try:\n",
    "        recs = spot_rec_features(uri, client_id, client_secret)\n",
    "        rec_featureDF = rec_featureDF.append(recs)\n",
    "        logging.info(\"'recovered from timeout'\")\n",
    "      except:\n",
    "        logging.info(f\"'Writing partial results after failure - on record {count}'\")\n",
    "        bucket = storage_client.get_bucket(f'{gcs_bucket}')\n",
    "        bucket.blob(f'{gcs_prefix_eda}/track_reco_{split}_PARTIAL.csv').upload_from_string(\n",
    "        rec_featureDF.to_csv(index=False), 'text/csv')\n",
    "\n",
    "    count += 1\n",
    "    time.sleep(3)\n",
    "    if count % 50 == 0:\n",
    "      logging.info(f'{count} of {uri_list_length} complete!')\n",
    "    \n",
    "  print(f'recommendations appended')\n",
    "  print(f'Shape of {rec_featureDF}: {rec_featureDF.shape}')\n",
    "    \n",
    "  bucket = storage_client.get_bucket(f'{gcs_bucket}')\n",
    "\n",
    "  bucket.blob(f'{gcs_prefix_eda}/track_reco_{split}.csv').upload_from_string(\n",
    "        rec_featureDF.to_csv(index=False), 'text/csv')\n",
    "  \n",
    "  track_recommendations_split_1_gcs_uri = f'gs://{gcs_bucket}/{gcs_prefix_eda}/track_reco_{split}'\n",
    "\n",
    "  (\n",
    "      f'{track_recommendations_split_1_gcs_uri}',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMiZxvcYqa2J"
   },
   "source": [
    "### Send Split to BQ Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xss-bQRpjqE3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbd1OI_uqaIc"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'pandas-gbq==0.17.4',\n",
    "                         'google-cloud-bigquery',\n",
    "                         'numpy','pandas','pyarrow',\n",
    "                         'absl-py',],\n",
    ")\n",
    "def send_split_1_track_audio_to_bq(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    track_audio_feat_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_split_1_bq_uri', str)]):\n",
    "  \n",
    "  from google.cloud import storage\n",
    "  import pandas_gbq\n",
    "  import json\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from google.cloud import bigquery\n",
    "  import numpy as np\n",
    "  from absl import logging\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "\n",
    "  bq_client = bigquery.Client(\n",
    "      project=bq_project, location=location\n",
    "  )\n",
    "\n",
    "  \n",
    "  df = pd.read_csv(f'{track_audio_feat_split_1_gcs_uri}')\n",
    "\n",
    "  df.to_gbq(\n",
    "      destination_table=f'{bq_dataset}.track_audio_split_{split_id}', \n",
    "      project_id=f'{bq_project}', # TODO: param\n",
    "      location='us-central1', \n",
    "      progress_bar=True, \n",
    "      reauth=True, \n",
    "      if_exists='replace'\n",
    "  )\n",
    "  logging.info('table loaded to bq')\n",
    "  logging.info(f'debug:::: bq://{bq_project}:{bq_dataset}:track_audio_split_{split_id}')\n",
    "  return (\n",
    "      f'bq://{bq_project}:{bq_dataset}:track_audio_split_{split_id}',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UetQpoLZjw7j"
   },
   "source": [
    "### Send Split to BQ Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lngHI7se9bJ"
   },
   "outputs": [],
   "source": [
    "#### Artist BQ Upload\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'pandas-gbq==0.17.4',\n",
    "                         'google-cloud-bigquery',\n",
    "                         'numpy','pandas','pyarrow',\n",
    "                         'absl-py',],\n",
    ")\n",
    "def send_split_1_artist_to_bq(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    track_audio_feat_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_audio_split_1_bq_uri', str)]):\n",
    "  \n",
    "  from google.cloud import storage\n",
    "  import pandas_gbq\n",
    "  import json\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from google.cloud import bigquery\n",
    "  import numpy as np\n",
    "  from absl import logging\n",
    "\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "\n",
    "  bq_client = bigquery.Client(\n",
    "      project=bq_project, location=location\n",
    "  )\n",
    "\n",
    "  \n",
    "  df = pd.read_csv(f'{track_audio_feat_split_1_gcs_uri}')\n",
    "\n",
    "  df.to_gbq(\n",
    "      destination_table=f'{bq_dataset}.artist_split_{split_id}', \n",
    "      project_id=f'{bq_project}', # TODO: param\n",
    "      location='us-central1', \n",
    "      progress_bar=True, \n",
    "      reauth=True, \n",
    "      if_exists='replace'\n",
    "  )\n",
    "  logging.info('table loaded to bq')\n",
    "  logging.info(f'debug:::: bq://{bq_project}:{bq_dataset}:artist_split_{split_id}')\n",
    "  return (\n",
    "      str(f'bq://{bq_project}:{bq_dataset}:artist_split_{split_id}'),\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAFLFT5nj12c"
   },
   "source": [
    "### Send Split to BQ Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQLRBdCFs9D1"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['fsspec',\n",
    "                         'google-cloud-storage',\n",
    "                         'gcsfs',\n",
    "                         'pandas-gbq==0.17.4',\n",
    "                         'google-cloud-bigquery',\n",
    "                         'numpy','pandas','pyarrow',\n",
    "                         'absl-py',],\n",
    ")\n",
    "def send_split_1_track_recs_to_bq(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    track_recommendations_split_1_gcs_uri: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    split_id: int,\n",
    ") -> NamedTuple('Outputs', [('track_recommendations_split_1_bq_uri', str)]):\n",
    "  \n",
    "  from google.cloud import storage\n",
    "  import pandas_gbq\n",
    "  import json\n",
    "  import pandas as pd\n",
    "  import json\n",
    "  from google.cloud import bigquery\n",
    "  import numpy as np\n",
    "  from absl import logging\n",
    "  \n",
    "  logging.set_verbosity(logging.INFO)\n",
    "\n",
    "  storage_client = storage.Client(\n",
    "    project=project\n",
    "  )\n",
    "\n",
    "  bq_client = bigquery.Client(\n",
    "      project=bq_project, location=location\n",
    "  )\n",
    "\n",
    "  df = pd.read_csv(f'{track_recommendations_split_1_gcs_uri}')\n",
    "\n",
    "  df.to_gbq(\n",
    "      destination_table=f'{bq_dataset}.track_recs_split_{split_id}', \n",
    "      project_id=f'{bq_project}', # TODO: param\n",
    "      location='us-central1', \n",
    "      progress_bar=True, \n",
    "      reauth=True, \n",
    "      if_exists='replace'\n",
    "  )\n",
    "\n",
    "  return (\n",
    "      f'bq://{bq_project}:{bq_dataset}:track_recs_split_{split_id}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf1P9nMij4EI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJQo_FTzj5q_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma5qzpGkuYhD"
   },
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EFH8b10ucf3",
    "outputId": "44cd822f-2097-42ca-941b-d0a7ffb2a970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: v3-spotify-feature-enrich\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'jtotten-project'\n",
    "# PROJECT_ID = 'matching-engine-playlist'\n",
    "LOCATION = 'us-central1'\n",
    "BUCKET_NAME = 'matching-engine-content'\n",
    "# BUCKET_NAME = 'spotify-million-playlists'\n",
    "\n",
    "PIPELINE_VERSION = 'v3' # pipeline code\n",
    "PIPELINE_TAG = f'{PIPELINE_VERSION}-spotify-feature-enrich'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)\n",
    "\n",
    "VERSION = 'v5' # general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Buwtyt7rugt4"
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    gcs_bucket: str,\n",
    "    gcs_prefix_eda: str,\n",
    "    all_tracks_filename: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    sleep_param: int = 10,\n",
    "    parallel_creds: str = json.dumps([\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_1.csv',\n",
    "                                          'api_key': '3ab5af00e21b44b0bee976289d9da168',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 1\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_2.csv',\n",
    "                                          'api_key': '52ca2066dfeb434ab832e6e9c709b9e7',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 2\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_3.csv',\n",
    "                                          'api_key': '127935a08a294e5292a79cf54a4fcce2',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 3\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_4.csv',\n",
    "                                          'api_key': 'bc5bde5fae56491c997fb1e351560335',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 4\n",
    "                                      },\n",
    "                                      {\n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_5.csv',\n",
    "                                          'api_key': 'f6f2bc364a7b49bab47c1d6df9f1882a',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 5\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_6.csv',\n",
    "                                          'api_key': '7283d7c69e2f49dfbe81a07266e512e7',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 6\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_7.csv',\n",
    "                                          'api_key': '4ff7390e97f643c3a0b4ebc2fa7d9c99',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 7\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_8.csv',\n",
    "                                          'api_key': '8bf5485e4ee843da80c67da2906b616c',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 8\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_9.csv',\n",
    "                                          'api_key': '963f4982976443d89b7f052293f6e590',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 9\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_10.csv',\n",
    "                                          'api_key': '49efce4863e140c4944da92e53ac1200',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 10\n",
    "                                      },\n",
    "                                      { \n",
    "                                          'data': 'gs://matching-engine-content/spotify-million-playlist/eda/all_tracks_split_11.csv',\n",
    "                                          'api_key': '8cc933ca4892433b92d0478ee4a123e6',\n",
    "                                          'secret_': '',\n",
    "                                          'split': 11\n",
    "                                      }\n",
    "                                      ],\n",
    "                                     sort_keys=True)\n",
    "):\n",
    "\n",
    "  # split_tracks_data_op = split_tracks_data(\n",
    "  #     project=project,\n",
    "  #     location=location,\n",
    "  #     gcs_bucket=gcs_bucket,\n",
    "  #     gcs_prefix_eda=gcs_prefix_eda,\n",
    "  #     all_tracks_filename=all_tracks_filename,\n",
    "  # )\n",
    "\n",
    "\n",
    "  with dsl.ParallelFor(parallel_creds) as item:\n",
    "    call_spotify_api_split_artist_op = call_spotify_api_split_artist(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        all_tracks_split_1_gcs_uri=item.data,\n",
    "        gcs_bucket=gcs_bucket,\n",
    "        gcs_prefix_eda=gcs_prefix_eda,\n",
    "        client_id=item.api_key,\n",
    "        client_secret=item.secret_,\n",
    "        sleep_param=3,\n",
    "        split_id=item.split\n",
    "    )\n",
    "\n",
    "    # call_spotify_api_split_reco_op = call_spotify_api_split_recommendations(\n",
    "    #     project=project,\n",
    "    #     location=location,\n",
    "    #     all_tracks_split_1_gcs_uri=item.data,\n",
    "    #     gcs_bucket=gcs_bucket,\n",
    "    #     gcs_prefix_eda=gcs_prefix_eda,\n",
    "    #     client_id=item.api_key,\n",
    "    #     client_secret=item.secret_,\n",
    "    #     sleep_param=1,\n",
    "    #     split=item.split\n",
    "    # ).after(split_tracks_data_op) #doing this so we don't have issues with connection pools\n",
    "\n",
    "    call_spotify_api_split_audio_op = call_spotify_api_split_audio(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        all_tracks_split_1_gcs_uri=item.data,\n",
    "        gcs_bucket=gcs_bucket,\n",
    "        gcs_prefix_eda=gcs_prefix_eda,\n",
    "        client_id=item.api_key,\n",
    "        client_secret=item.secret_,\n",
    "        sleep_param=3,\n",
    "        split_id=item.split\n",
    "    )\n",
    "\n",
    "    # send_split_1_artist_to_bq_op = send_split_1_artist_to_bq(\n",
    "    #     project=project,\n",
    "    #     location=location,\n",
    "    #     track_audio_feat_split_1_gcs_uri=call_spotify_api_split_artist_op.outputs['track_audio_feat_split_1_gcs_uri'],\n",
    "    #     gcs_bucket=gcs_bucket,\n",
    "    #     gcs_prefix_eda=gcs_prefix_eda,\n",
    "    #     bq_project=bq_project,\n",
    "    #     bq_dataset=bq_dataset,\n",
    "    #     split_id=item.split\n",
    "    # )\n",
    "\n",
    "    # send_split_1_track_recs_to_bq_op = send_split_1_track_recs_to_bq(\n",
    "    #     project=project,\n",
    "    #     location=location,\n",
    "    #     track_recommendations_split_1_gcs_uri=call_spotify_api_split_reco_op.outputs['track_recommendations_split_1_gcs_uri'],\n",
    "    #     gcs_bucket=gcs_bucket,\n",
    "    #     gcs_prefix_eda=gcs_prefix_eda,\n",
    "    #     bq_project=bq_project,\n",
    "    #     bq_dataset=bq_dataset,\n",
    "    #     split_id=item.split\n",
    "    # )\n",
    "\n",
    "    # send_split_1_track_recs_to_bq_op = send_split_1_track_audio_to_bq(\n",
    "    #     project=project,\n",
    "    #     location=location,\n",
    "    #     track_audio_feat_split_1_gcs_uri=call_spotify_api_split_audio_op.outputs['track_audio_feat_split_1_gcs_uri'],\n",
    "    #     gcs_bucket=gcs_bucket,\n",
    "    #     gcs_prefix_eda=gcs_prefix_eda,\n",
    "    #     bq_project=bq_project,\n",
    "    #     bq_dataset=bq_dataset,\n",
    "    #     split_id=item.split\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoBsfT1IyIXd",
    "outputId": "50a65461-1c7c-44c0-9362-5524aaac21c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evUgOHllykr5"
   },
   "outputs": [],
   "source": [
    "# jtotten-project #\n",
    "PROJECT_ID = 'jtotten-project'\n",
    "LOCATION = 'us-central1'\n",
    "GCS_BUCKET = 'matching-engine-content'\n",
    "GCS_PREFIX_EDA = 'spotify-million-playlist/eda'\n",
    "ALL_TRACKS_FILENAME = 'all_tracks_v2.csv'\n",
    "BQ_PROJECT = 'jtotten-project' \n",
    "BQ_DATASET = 'spotify_mpd' # \n",
    "\n",
    "\n",
    "\n",
    "# matching-engine-playlist #\n",
    "# PROJECT_ID = 'matching-engine-playlist'\n",
    "# LOCATION = 'us-central1'\n",
    "# GCS_BUCKET = 'spotify-million-playlists'\n",
    "# GCS_PREFIX_EDA = 'upload_eda'\n",
    "# ALL_TRACKS_FILENAME = 'all_tracks_v2.csv'\n",
    "# BQ_PROJECT = 'matching-engine-playlist' # 'matching-engine-playlist'\n",
    "# BQ_DATASET = 'mdp_eda' # 'mdp_eda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTCHINT_1uti",
    "outputId": "c96f1c21-612f-4e5d-d33a-fd4d236e7b2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/v5-v3-spotify-feature-enrich-20220406144428?project=jtotten-project\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overwrite = True\n",
    "# overwrite = False\n",
    "\n",
    "if not PIPELINES.get('train') or overwrite:\n",
    "  response = pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path='custom_container_pipeline_spec.json',\n",
    "    parameter_values={\n",
    "        'project': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'gcs_bucket': GCS_BUCKET,\n",
    "        'gcs_prefix_eda': GCS_PREFIX_EDA,\n",
    "        'all_tracks_filename': ALL_TRACKS_FILENAME,\n",
    "        'bq_project': BQ_PROJECT,\n",
    "        'bq_dataset': BQ_DATASET,\n",
    "    },\n",
    "    pipeline_root=f'{GS_PIPELINE_ROOT_PATH}/{VERSION}',\n",
    "  )\n",
    "  PIPELINES['train'] = response['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGpjOAA9Xpun"
   },
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "qX6UVu1lGA2N",
    "outputId": "f574c1ca-2310-4028-ab11-d2ba353b2f4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/table.py:1567: UserWarning: Dependency google-cloud-bigquery-storage is outdated, please upgrade it to version >= 2.0.0 (version found: 0.0.0).\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6e75bf45-0b82-42d6-8448-e73ea9488104\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"spotify:track:5jym9AK0j4z3lWjXUF8JdG\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"spotify:track:7DgC5XdBniqaGvwCVS7HpT\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"spotify:track:5BAjp2szJU9yQOITfXyWp6\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"spotify:track:0W3uXC8Fu5ulBrnfU3V2UE\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"spotify:track:1sz0fuWEAcPkCfG5o7D9KP\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\"spotify:track:1m4yusBQYXV59jRLIKyGSG\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\"spotify:track:1n4ufxXDS1fuRSgifzNQPT\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\"spotify:track:7F9IBboVDxDbMpXCv6kFW0\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\"spotify:track:0OBlBwoqwQqdCaDmRokJfd\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\"spotify:track:5xPM06DYMg7OHOxOGuxbDf\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e75bf45-0b82-42d6-8448-e73ea9488104')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6e75bf45-0b82-42d6-8448-e73ea9488104 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6e75bf45-0b82-42d6-8448-e73ea9488104');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                     count\n",
       "0   \"spotify:track:5jym9AK0j4z3lWjXUF8JdG\"\n",
       "1   \"spotify:track:7DgC5XdBniqaGvwCVS7HpT\"\n",
       "2   \"spotify:track:5BAjp2szJU9yQOITfXyWp6\"\n",
       "3   \"spotify:track:0W3uXC8Fu5ulBrnfU3V2UE\"\n",
       "4   \"spotify:track:1sz0fuWEAcPkCfG5o7D9KP\"\n",
       "..                                     ...\n",
       "95  \"spotify:track:1m4yusBQYXV59jRLIKyGSG\"\n",
       "96  \"spotify:track:1n4ufxXDS1fuRSgifzNQPT\"\n",
       "97  \"spotify:track:7F9IBboVDxDbMpXCv6kFW0\"\n",
       "98  \"spotify:track:0OBlBwoqwQqdCaDmRokJfd\"\n",
       "99  \"spotify:track:5xPM06DYMg7OHOxOGuxbDf\"\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a slice of the bq data\n",
    "project=PROJECT_ID\n",
    "location=LOCATION\n",
    "from google.cloud import bigquery\n",
    "bq_client = bigquery.Client(\n",
    "    project=project, location=location\n",
    ")\n",
    "bq_client = bigquery.Client(\n",
    "      project=project, location=location\n",
    "  )\n",
    "\n",
    "query = f\"\"\"select track_uri as count from `jtotten-project.spotify_mpd.unique_tracks` a where mod(a.duration_ms, 11) = 1-1 \n",
    "  and a.track_uri NOT IN (SELECT track_uri FROM `jtotten-project.spotify_mpd.track_audio_1`) limit 100\"\"\" #excluding what we already loaded\n",
    "\n",
    "tracks = bq_client.query(query).result().to_dataframe()\n",
    "tracks\n",
    "# track_list = tracks.track_uri.to_list()\n",
    "\n",
    "# for t in track_list:\n",
    "#   print(t.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7cLbY-taEe4",
    "outputId": "c04de427-84ec-44c0-e185-8f96cb1db2ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/table.py:1567: UserWarning: Dependency google-cloud-bigquery-storage is outdated, please upgrade it to version >= 2.0.0 (version found: 0.0.0).\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "203201"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_query =   query = f\"select count(1) as count from `jtotten-project.spotify_mpd.unique_artists` where mod(duration_ms, 11) = 0\"\n",
    "uri_list_length_df = bq_client.query(query).result().to_dataframe()\n",
    "n_artists = uri_list_length_df['count'][0]\n",
    "n_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U78cwitKXorU"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'matching-engine-content'\n",
    "SAMPLE_FILENAME = 'spotify-million-playlist/data/mpd.slice.0-999.json'\n",
    "\n",
    "# storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(SAMPLE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6lqxufNZHpT"
   },
   "outputs": [],
   "source": [
    "raw_json = json.loads(blob.download_as_string(client=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Vm7JKIW3X7-i",
    "outputId": "5ff7d2b0-9cce-4aff-fd42-f9d0396e6151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-68a8e5ba-62c3-4638-a9d8-5e56936a4735\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>track_name</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>album_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Missy Elliott</td>\n",
       "      <td>spotify:track:0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "      <td>spotify:artist:2wIVse2owClT7go1WT98tk</td>\n",
       "      <td>Lose Control (feat. Ciara &amp; Fat Man Scoop)</td>\n",
       "      <td>spotify:album:6vV5UrXcfyQD1wu4Qo2I9K</td>\n",
       "      <td>226863</td>\n",
       "      <td>The Cookbook</td>\n",
       "      <td>Throwbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>spotify:track:6I9VzXrHxO9rA9A5euc8Ak</td>\n",
       "      <td>spotify:artist:26dSoYclwsYLMAKD3tpOr4</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>spotify:album:0z7pVBGOD7HCIB7S8eLkLI</td>\n",
       "      <td>198800</td>\n",
       "      <td>In The Zone</td>\n",
       "      <td>Throwbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>spotify:track:0WqIKmW4BTrj3eJFmnCKMv</td>\n",
       "      <td>spotify:artist:6vWDO969PvNqNYHIOW5v0m</td>\n",
       "      <td>Crazy In Love</td>\n",
       "      <td>spotify:album:25hVFAxTlDvXbx2X2QkUkE</td>\n",
       "      <td>235933</td>\n",
       "      <td>Dangerously In Love (Alben für die Ewigkeit)</td>\n",
       "      <td>Throwbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>spotify:track:1AWQoqb9bSvzTjaLralEkT</td>\n",
       "      <td>spotify:artist:31TPClRtHm23RisEBtV3X7</td>\n",
       "      <td>Rock Your Body</td>\n",
       "      <td>spotify:album:6QPkyl04rXwTGlGlcYaRoW</td>\n",
       "      <td>267266</td>\n",
       "      <td>Justified</td>\n",
       "      <td>Throwbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Shaggy</td>\n",
       "      <td>spotify:track:1lzr43nnXAijIGYnCT8M8H</td>\n",
       "      <td>spotify:artist:5EvFsr3kj42KNv97ZEnqij</td>\n",
       "      <td>It Wasn't Me</td>\n",
       "      <td>spotify:album:6NmFmPX56pcLBOFMhIiKvF</td>\n",
       "      <td>227600</td>\n",
       "      <td>Hot Shot</td>\n",
       "      <td>Throwbacks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68a8e5ba-62c3-4638-a9d8-5e56936a4735')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-68a8e5ba-62c3-4638-a9d8-5e56936a4735 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-68a8e5ba-62c3-4638-a9d8-5e56936a4735');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   pos        artist_name                             track_uri  \\\n",
       "0    0      Missy Elliott  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI   \n",
       "1    1     Britney Spears  spotify:track:6I9VzXrHxO9rA9A5euc8Ak   \n",
       "2    2            Beyoncé  spotify:track:0WqIKmW4BTrj3eJFmnCKMv   \n",
       "3    3  Justin Timberlake  spotify:track:1AWQoqb9bSvzTjaLralEkT   \n",
       "4    4             Shaggy  spotify:track:1lzr43nnXAijIGYnCT8M8H   \n",
       "\n",
       "                              artist_uri  \\\n",
       "0  spotify:artist:2wIVse2owClT7go1WT98tk   \n",
       "1  spotify:artist:26dSoYclwsYLMAKD3tpOr4   \n",
       "2  spotify:artist:6vWDO969PvNqNYHIOW5v0m   \n",
       "3  spotify:artist:31TPClRtHm23RisEBtV3X7   \n",
       "4  spotify:artist:5EvFsr3kj42KNv97ZEnqij   \n",
       "\n",
       "                                   track_name  \\\n",
       "0  Lose Control (feat. Ciara & Fat Man Scoop)   \n",
       "1                                       Toxic   \n",
       "2                               Crazy In Love   \n",
       "3                              Rock Your Body   \n",
       "4                                It Wasn't Me   \n",
       "\n",
       "                              album_uri  duration_ms  \\\n",
       "0  spotify:album:6vV5UrXcfyQD1wu4Qo2I9K       226863   \n",
       "1  spotify:album:0z7pVBGOD7HCIB7S8eLkLI       198800   \n",
       "2  spotify:album:25hVFAxTlDvXbx2X2QkUkE       235933   \n",
       "3  spotify:album:6QPkyl04rXwTGlGlcYaRoW       267266   \n",
       "4  spotify:album:6NmFmPX56pcLBOFMhIiKvF       227600   \n",
       "\n",
       "                                     album_name        name  \n",
       "0                                  The Cookbook  Throwbacks  \n",
       "1                                   In The Zone  Throwbacks  \n",
       "2  Dangerously In Love (Alben für die Ewigkeit)  Throwbacks  \n",
       "3                                     Justified  Throwbacks  \n",
       "4                                      Hot Shot  Throwbacks  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_json = json.loads(blob.download_as_string(client=None))\n",
    "\n",
    "playlists = raw_json[\"playlists\"]\n",
    "df = pd.json_normalize(playlists, record_path='tracks', meta=['name'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyunpQw7Z6Ke"
   },
   "source": [
    "Edit track uris format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxZAVfm_Z4E8"
   },
   "outputs": [],
   "source": [
    "df[\"track_uri\"] = df[\"track_uri\"].apply(lambda x: re.findall(r'\\w+$', x)[0])\n",
    "df[\"track_uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSRJc_cSW2d5"
   },
   "outputs": [],
   "source": [
    "# Grabbing a batch of 50 song uris\n",
    "song_ids = list(df[\"track_uri\"][:50].values)\n",
    "artist_ids = list(df[\"artist_uri\"][:50].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeKTZ_VDaPOV"
   },
   "source": [
    "## Extract Features from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvOiXAGxS7d5"
   },
   "outputs": [],
   "source": [
    "# be careful with these\n",
    "# client_id='8bf5485e4ee843da80c67da2906b616c'\n",
    "# client_secret='a985464c6aa9419693c1632c5836a15a'\n",
    "\n",
    "artist_name = 'Widespread Panic'\n",
    "panic_id = '54SHZF2YS3W87xuJKSvOVf'\n",
    "\n",
    "# Authenticate\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=client_id, client_secret=client_secret\n",
    ")\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager = client_credentials_manager,\n",
    "    requests_timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zlo2KsMtdqc"
   },
   "source": [
    "### Artists and Tracks Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBMaKqKAtfeL"
   },
   "outputs": [],
   "source": [
    "# artist_name = 'Widespread Panic'\n",
    "# panic_id = '54SHZF2YS3W87xuJKSvOVf'\n",
    "# split this stuff out:\n",
    "#   artist_pop = sp.artist(artist)[\"popularity\"] #artist to artists\n",
    "#   artist_genres = sp.artist(artist)[\"genres\"]\n",
    "\n",
    "artists = sp.artists(artist_ids)\n",
    "\n",
    "artist_pop = []\n",
    "artist_genres = []\n",
    "followers = []\n",
    "for artist in artists['artists']:\n",
    "  if artist is not None:\n",
    "    artist_pop.append(artist['popularity'])\n",
    "    artist_genres.append(artist['genres'])\n",
    "    followers.append(artist['followers']['total'])\n",
    "  else:\n",
    "    print('bla')\n",
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06va12B9hAVs"
   },
   "outputs": [],
   "source": [
    "#split out populatirty track_pop = sp.track(uri)[\"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LCWhB7CwV19"
   },
   "outputs": [],
   "source": [
    "tracks = sp.tracks(song_ids)\n",
    "popularity = []\n",
    "for track in tracks['tracks']:\n",
    "  popularity.append(track['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4W3JKJkpxnB"
   },
   "outputs": [],
   "source": [
    "# Audio features refactor\n",
    "import pandas as pd\n",
    "a_feats = sp.audio_features(song_ids) \n",
    "a_feats[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyxLJJx3J5um"
   },
   "outputs": [],
   "source": [
    "### refactor recommendation\n",
    "\n",
    "recommended_tracks_from_artist = sp.recommendations(\n",
    "        seed_tracks=artist_ids,\n",
    "        limit=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxI4I_arw_38"
   },
   "source": [
    "### Show artist top tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jY_LlajxCxK"
   },
   "outputs": [],
   "source": [
    "panic_id = '54SHZF2YS3W87xuJKSvOVf'\n",
    "\n",
    "response = sp.artist_top_tracks(panic_id)\n",
    "\n",
    "for track in response['tracks']:\n",
    "  # print(track)\n",
    "  print(f'{track[\"name\"]} ---> {track[\"uri\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STzBzerqtdnE"
   },
   "source": [
    "### Show related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td5sI3evup4s"
   },
   "outputs": [],
   "source": [
    "artist_name = 'Widespread Panic'\n",
    "result = sp.search(q='artist:' + artist_name, type='artist')\n",
    "\n",
    "name = result['artists']['items'][0]['name']\n",
    "artist_uri = result['artists']['items'][0]['uri']\n",
    "\n",
    "related_artists = sp.artist_related_artists(artist_uri)\n",
    "print(f'Related artists for {name} \\n')\n",
    "# related_artists\n",
    "related_artist_name_list = []\n",
    "related_artist_uri_list = []\n",
    "related_artist_genre_list = []\n",
    "related_artist_track_name_list = []\n",
    "related_artist_track_uri_list = []\n",
    "related_artist_track_audio_features_list = []\n",
    "\n",
    "# related_artist_dict = {}\n",
    "for artist in related_artists['artists']:\n",
    "  \n",
    "  artist_genres = artist[\"genres\"]\n",
    "\n",
    "  if artist_genres:\n",
    "    genre_case = \" \".join([re.sub(' ', '_', i) for i in artist_genres])\n",
    "  else:\n",
    "    genre_case = ''\n",
    "  \n",
    "  related_artist_genre_list.append(genre_case)\n",
    "\n",
    "  related_artist_name_list.append(artist['name'])\n",
    "  related_artist_uri_list.append(artist['uri'])\n",
    "\n",
    "  related_tracks_case = sp.artist_top_tracks(artist['uri'])\n",
    "  for track in related_tracks_case['tracks']:\n",
    "    related_artist_track_name_list.append(track['name'])\n",
    "    related_artist_track_uri_list.append(track['id'])\n",
    "\n",
    "print(f\"length of track name list: {len(related_artist_track_name_list)}\")\n",
    "print(f\"length of track uri list: {len(related_artist_track_uri_list)}\")\n",
    "\n",
    "for uri in related_artist_track_uri_list:\n",
    "  try:\n",
    "    # features = sp.audio_features(uri)[0]\n",
    "    features = {\n",
    "      'acousticness': features['acousticness'],\n",
    "      'danceability': features['danceability'],\n",
    "      'duration_ms': features['duration_ms'],\n",
    "      'energy': features['energy'],\n",
    "      'instrumentalness': features['instrumentalness'],\n",
    "      'key': features['key'],\n",
    "      'liveness': features['liveness'],\n",
    "      'loudness': features['loudness'],\n",
    "      'mode': features['mode'],\n",
    "      'speechiness': features['speechiness'],\n",
    "      'tempo': features['tempo'],\n",
    "      'time_signature': features['time_signature'],\n",
    "      'valence': features['valence'],\n",
    "      'uri': features['uri'],\n",
    "      'id': features['id'],\n",
    "  }\n",
    "  except:\n",
    "    features = {\n",
    "      'acousticness': features['acousticness'],\n",
    "      'danceability': features['danceability'],\n",
    "      'duration_ms': features['duration_ms'],\n",
    "      'energy': features['energy'],\n",
    "      'instrumentalness': features['instrumentalness'],\n",
    "      'key': features['key'],\n",
    "      'liveness': features['liveness'],\n",
    "      'loudness': features['loudness'],\n",
    "      'mode': features['mode'],\n",
    "      'speechiness': features['speechiness'],\n",
    "      'tempo': features['tempo'],\n",
    "      'time_signature': features['time_signature'],\n",
    "      'valence': features['valence'],\n",
    "      'uri': features['uri'],\n",
    "      'id': features['id'],\n",
    "  }\n",
    "\n",
    "  related_artist_track_audio_features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VdXmuu9eDqJ"
   },
   "outputs": [],
   "source": [
    "related_artist_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymarKJdveCVZ"
   },
   "outputs": [],
   "source": [
    "related_artist_uri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6uA2ddOd97c"
   },
   "outputs": [],
   "source": [
    "related_artist_genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Id64VIcd93_"
   },
   "outputs": [],
   "source": [
    "related_artist_track_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpyqN3VOd9uh"
   },
   "outputs": [],
   "source": [
    "related_artist_track_uri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cj5OSUWOdkXx"
   },
   "outputs": [],
   "source": [
    "related_artist_track_audio_features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCPfFN-ksend"
   },
   "source": [
    "### get artist albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4z4BJRBsgze"
   },
   "outputs": [],
   "source": [
    "def get_artist(name):\n",
    "    results = sp.search(q='artist:' + name, type='artist')\n",
    "    items = results['artists']['items']\n",
    "    if len(items) > 0:\n",
    "        return items[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def show_artist_albums(artist):\n",
    "    albums = []\n",
    "    results = sp.artist_albums(artist['id'], album_type='album')\n",
    "    albums.extend(results['items'])\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        albums.extend(results['items'])\n",
    "    seen = set()  # to avoid dups\n",
    "    albums.sort(key=lambda album: album['name'].lower())\n",
    "    for album in albums:\n",
    "        name = album['name']\n",
    "        if name not in seen:\n",
    "            print('ALBUM: %s', name)\n",
    "            seen.add(name)\n",
    "\n",
    "artist_name = 'Widespread Panic'\n",
    "artist = get_artist(artist_name)\n",
    "\n",
    "if artist:\n",
    "  show_artist_albums(artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6WCr0H3lRCz"
   },
   "source": [
    "get 30 second samples and cover art for the top 10 tracks for `artists`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zD_iHJd5lK8T"
   },
   "outputs": [],
   "source": [
    "led_uri = 'spotify:artist:36QJpDe2go2KgaRleHCDTp'\n",
    "results = sp.artist_top_tracks(led_uri)\n",
    "\n",
    "for track in results['tracks'][:10]:\n",
    "    print('track    : ' + track['name'])\n",
    "    print('audio    : ' + track['preview_url'])\n",
    "    print('cover art: ' + track['album']['images'][0]['url'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoMaVCM7mVKZ"
   },
   "source": [
    "get URL for an artist image given artists name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjE_AGv8mf3M"
   },
   "outputs": [],
   "source": [
    "artist_name = 'Widespread Panic'\n",
    "\n",
    "results = sp.search(q='artist:' + artist_name, type='artist')\n",
    "items = results['artists']['items']\n",
    "if len(items) > 0:\n",
    "    artist = items[0]\n",
    "    print(artist['name'], artist['images'][0]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS17_E5cpFrH"
   },
   "source": [
    "### get user info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-dlhihTo-qS"
   },
   "outputs": [],
   "source": [
    "jt_id = '5ey58uqdaf0py56boutmj0i4x'\n",
    "\n",
    "user = sp.user(jt_id)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG4nZ3TepTzD"
   },
   "source": [
    "### get audio features for a track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMpyCkwxpSDS"
   },
   "outputs": [],
   "source": [
    "track_uri='0UaMYEvWZi0ZqiDOoHU3YI'\n",
    "\n",
    "# features = sp.audio_features(track_uri)\n",
    "features = sp.audio_features(track_uri)[0]\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUuI1NX2QbDN"
   },
   "outputs": [],
   "source": [
    "features['acousticness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6NZmc6LrcDT"
   },
   "outputs": [],
   "source": [
    "# artist_name = 'Widespread Panic'\n",
    "\n",
    "# results = sp.search(q=artist_name, limit=50)\n",
    "# tids = []\n",
    "# for i, t in enumerate(results['tracks']['items']):\n",
    "#     print(' ', i, t['name'])\n",
    "#     tids.append(t['uri'])\n",
    "\n",
    "# start = time.time()\n",
    "# features = sp.audio_features(tids)\n",
    "# delta = time.time() - start\n",
    "# for feature in features:\n",
    "#     print(json.dumps(feature, indent=4))\n",
    "#     print()\n",
    "#     analysis = sp._get(feature['analysis_url'])\n",
    "#     print(json.dumps(analysis, indent=4))\n",
    "#     print()\n",
    "# print(\"features retrieved in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFa0dl-kqXx8"
   },
   "source": [
    "audio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLejXiURqjSR"
   },
   "outputs": [],
   "source": [
    "## returns a lot\n",
    "\n",
    "# track_uri='0UaMYEvWZi0ZqiDOoHU3YI'\n",
    "\n",
    "# start = time.time()\n",
    "# analysis = sp.audio_analysis(track_uri)\n",
    "# delta = time.time() - start\n",
    "# print(json.dumps(analysis, indent=4))\n",
    "# print(\"analysis retrieved in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16BgM3nomcX-"
   },
   "source": [
    "### test: extract features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqSUV3mUUB-U"
   },
   "outputs": [],
   "source": [
    "def spot_features(uri, client_id, client_secret):\n",
    "  \n",
    "  # Authenticate\n",
    "  client_credentials_manager = SpotifyClientCredentials(\n",
    "      client_id=client_id, client_secret=client_secret\n",
    "  )\n",
    "  sp = spotipy.Spotify(\n",
    "      client_credentials_manager = client_credentials_manager\n",
    "  )\n",
    "    \n",
    "  #Audio features\n",
    "  features = sp.audio_features(uri)[0]\n",
    "  \n",
    "  #Artist of the track, for genres and popularity\n",
    "  artist = sp.track(uri)[\"artists\"][0][\"id\"]\n",
    "  artist_pop = sp.artist(artist)[\"popularity\"]\n",
    "  artist_genres = sp.artist(artist)[\"genres\"]\n",
    "  \n",
    "  #Track popularity\n",
    "  track_pop = sp.track(uri)[\"popularity\"]\n",
    "  \n",
    "  #Add in extra features\n",
    "  features[\"artist_pop\"] = artist_pop\n",
    "  if artist_genres:\n",
    "      features[\"genres\"] = \" \".join([re.sub(' ','_',i) for i in artist_genres])\n",
    "  else:\n",
    "      features[\"genres\"] = \"unknown\"\n",
    "  features[\"track_pop\"] = track_pop\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4j6c6lysXVXl"
   },
   "outputs": [],
   "source": [
    "# preview \n",
    "spot_features(df['track_uri'][0], client_id, client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjxQSp6lG0C5"
   },
   "source": [
    "## Test recommended tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "Sqblkt9sG7_3",
    "outputId": "aad004fd-785a-47c2-df07-95aed8b1e3c3"
   },
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    340\u001b[0m             raise ReadTimeoutError(\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Read timed out. (read timeout=%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             )\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.spotify.com', port=443): Read timed out. (read timeout=5)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-ff01695d3ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mclient_credentials_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_credentials_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgenre_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation_genre_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# uri = df['track_uri'][22]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# recommended_tracks_from_artist = sp.recommendations(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spotipy/client.py\u001b[0m in \u001b[0;36mrecommendation_genre_seeds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \"\"\" Get a list of genres available for the recommendations function.\n\u001b[1;32m   1662\u001b[0m         \"\"\"\n\u001b[0;32m-> 1663\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recommendations/available-genre-seeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maudio_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, args, payload, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_internal_call\u001b[0;34m(self, method, url, payload, params)\u001b[0m\n\u001b[1;32m    240\u001b[0m             response = self._session.request(\n\u001b[1;32m    241\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             )\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.spotify.com', port=443): Read timed out. (read timeout=5)"
     ]
    }
   ],
   "source": [
    "# be careful with these\n",
    "client_id='3ab5af00e21b44b0bee976289d9da168'\n",
    "client_secret='34af528f936a4d8eba6be5f1c175c947'\n",
    "\n",
    "artist_name = 'Widespread Panic'\n",
    "panic_id = '54SHZF2YS3W87xuJKSvOVf'\n",
    "import spotipy as sp\n",
    "\n",
    "# Authenticate\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=client_id, client_secret=client_secret\n",
    ")\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager = client_credentials_manager,\n",
    ")\n",
    "genre_seeds = sp.recommendation_genre_seeds()\n",
    "# uri = df['track_uri'][22]\n",
    "# recommended_tracks_from_artist = sp.recommendations(\n",
    "#         seed_tracks=[uri],\n",
    "#         seed_genres=genre_seeds,\n",
    "#         limit=5,\n",
    "#     )\n",
    "\n",
    "# recommended_tracks_from_artist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuMf-9BmHs70",
    "outputId": "3e6e405a-d435-42df-8a1c-6421672e89a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hedley\n",
      "Cha-Ching\n",
      "spotify:track:6M0jqfkHce0Xb2GYDyIFlq\n",
      "All Time Low\n",
      "Something's Gotta Give\n",
      "spotify:track:1SeefzwSDiFCjRWaBslRIj\n",
      "Wheatus\n",
      "Teenage Dirtbag (2020)\n",
      "spotify:track:6JLP1BQhdXDe9WDje98HOF\n",
      "Rise Against\n",
      "Savior\n",
      "spotify:track:1vcxF91pWs9uNwDROuiCPB\n",
      "Matchbox Twenty\n",
      "Unwell - 2007 Remaster\n",
      "spotify:track:66s45uMhk7Y4z0xUgESdm3\n"
     ]
    }
   ],
   "source": [
    "for track in recommended_tracks_from_artist['tracks']:\n",
    "  print(track[\"artists\"][0][\"name\"])\n",
    "  print(track['name'])\n",
    "  print(track['uri'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJcSberQ0Kuu"
   },
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aT5LMcsykBL"
   },
   "source": [
    "### unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJz86XNmymSD"
   },
   "outputs": [],
   "source": [
    "BUCKET = 'matching-engine-content'\n",
    "ZIP_PATH = 'spotify-million-playlist/spotify_million_playlist_dataset.zip' # if the file is gs://mybucket/path/file.zip\n",
    "DEST_FOLDER = 'spotify-million-playlist/dataset-unzip' # folder to place unzipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4Dr7xqd0HHF"
   },
   "outputs": [],
   "source": [
    "# BUCKET = 'matching-engine-content'\n",
    "# ZIP_PATH = 'spotify-million-playlist/spotify_million_playlist_dataset_challenge.zip' # if the file is gs://mybucket/path/file.zip\n",
    "# DEST_FOLDER = 'challenge-unzip' # folder to place unzipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH1mAoZXzHXf"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from zipfile import ZipFile\n",
    "from zipfile import is_zipfile\n",
    "import io\n",
    "\n",
    "def zipextract(bucketname, zipfilename_with_path, destination_folder):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucketname)\n",
    "\n",
    "    destination_blob_pathname = zipfilename_with_path\n",
    "    \n",
    "    blob = bucket.blob(destination_blob_pathname)\n",
    "    zipbytes = io.BytesIO(blob.download_as_string())\n",
    "\n",
    "    if is_zipfile(zipbytes):\n",
    "        with ZipFile(zipbytes, 'r') as myzip:\n",
    "            for contentfilename in myzip.namelist():\n",
    "                contentfile = myzip.read(contentfilename)\n",
    "                blob = bucket.blob(destination_folder + \"/\" + contentfilename)\n",
    "                blob.upload_from_string(contentfile)\n",
    "\n",
    "# zipextract(\"mybucket\", \"path/file.zip\") # if the file is gs://mybucket/path/file.zip\n",
    "zipextract(BUCKET, ZIP_PATH, DEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgOzTnMczVtO"
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'gs://matching-engine-content/spotify-million-playlist/dataset-unzip/data'\n",
    "!gsutil ls $IMAGE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzBISkPjvaNh"
   },
   "source": [
    "### Copy data over to new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRdANxCVtnW7"
   },
   "outputs": [],
   "source": [
    "# !gsutil cp gs://matching-engine-content/spotify-million-playlist/README.md gs://spotify-million-playlists/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBherRgwt12i"
   },
   "outputs": [],
   "source": [
    "# !gsutil cp gs://matching-engine-content/spotify-million-playlist/md5sums gs://spotify-million-playlists\n",
    "# !gsutil cp gs://matching-engine-content/spotify-million-playlist/stats.txt gs://spotify-million-playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8YCsDoZrDmJ"
   },
   "outputs": [],
   "source": [
    "# # copy over to new bucket\n",
    "# !gsutil -m cp -r gs://matching-engine-content/spotify-million-playlist/data gs://spotify-million-playlists\n",
    "# !gsutil -m cp -r gs://matching-engine-content/spotify-million-playlist/src gs://spotify-million-playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TB4IIjC0rI_"
   },
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6BsGLTO0wIk"
   },
   "source": [
    "## The Million Playlist Dataset\n",
    "(Documentation updated Aug 5, 2020)\n",
    "\n",
    "The Million Playlist Dataset contains 1,000,000 playlists created by\n",
    "users on the Spotify platform.  It can be used by researchers interested\n",
    "in exploring how to improve the music listening experience.\n",
    "\n",
    "## What's in the Million Playlist Dataset (MPD)\n",
    "The MPD contains a million user-generated playlists. These playlists\n",
    "were created during the period of January 2010 through October 2017.\n",
    "Each playlist in the MPD contains a playlist title, the track list\n",
    "(including track metadata) editing information (last edit time, \n",
    "number of playlist edits) and other miscellaneous information \n",
    "about the playlist. See the **Detailed\n",
    "Description** section for more details.\n",
    "\n",
    "## License\n",
    "Usage of the Million Playlist Dataset is subject to these \n",
    "[license terms](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge/challenge_rules)\n",
    "\n",
    "## Citing the Million Playlist Dataset\n",
    "To use this dataset, please cite the following [paper](https://dl.acm.org/doi/abs/10.1145/3240323.3240342):\n",
    "\n",
    "*Ching-Wei Chen, Paul Lamere, Markus Schedl, and Hamed Zamani. Recsys Challenge 2018: Automatic Music Playlist Continuation. In Proceedings of the 12th ACM Conference on Recommender Systems (RecSys â€™18), 2018.*\n",
    "\n",
    "## Getting the dataset\n",
    "The dataset is available at [https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n",
    "\n",
    "## Verifying your dataset\n",
    "You can validate the dataset by checking the md5 hashes of the data.  From the top level directory of the MPD:\n",
    "   \n",
    "    % md5sum -c md5sums\n",
    "  \n",
    "This should print out OK for each of the 1,000 slice files in the dataset.\n",
    "\n",
    "You can also compute a number of statistics for the dataset as follows:\n",
    "\n",
    "    % python src/stats.py data\n",
    "  \n",
    "The output of this program should match what is in 'stats.txt'. Depending on how \n",
    "fast your computer is, stats.py can take 30 minutes or more to run.\n",
    "\n",
    "## Detailed description\n",
    "The Million Playlist Dataset consists of 1,000 slice files. These files have the naming convention of:\n",
    "\n",
    "mpd.slice._STARTING\\_PLAYLIST\\_ID\\_-\\_ENDING\\_PLAYLIST\\_ID_.json\n",
    "\n",
    "For example, the first 1,000 playlists in the MPD are in a file called \n",
    "`mpd.slice.0-999.json` and the last 1,000 playlists are in a file called\n",
    "`mpd.slice.999000-999999.json`.\n",
    "\n",
    "Each slice file is a JSON dictionary with two fields:\n",
    "*info* and *playlists*.\n",
    "\n",
    "### `info` Field\n",
    "The info field is a dictionary that contains general information about the particular slice:\n",
    "\n",
    "   * **slice** - the range of slices that in in this particular file - such as 0-999\n",
    "   * ***version*** -  - the current version of the MPD (which should be v1)\n",
    "   * ***description*** - a description of the MPD\n",
    "   * ***license*** - licensing info for the MPD\n",
    "   * ***generated_on*** - a timestamp indicating when the slice was generated.\n",
    "\n",
    "### `playlists` field \n",
    "This is an array that typically contains 1,000 playlists. Each playlist is a dictionary that contains the following fields:\n",
    "\n",
    "\n",
    "* ***pid*** - integer - playlist id - the MPD ID of this playlist. This is an integer between 0 and 999,999.\n",
    "* ***name*** - string - the name of the playlist \n",
    "* ***description*** - optional string - if present, the description given to the playlist.  Note that user-provided playlist descrptions are a relatively new feature of Spotify, so most playlists do not have descriptions.\n",
    "* ***modified_at*** - seconds - timestamp (in seconds since the epoch) when this playlist was last updated. Times are rounded to midnight GMT of the date when the playlist was last updated.\n",
    "* ***num_artists*** - the total number of unique artists for the tracks in the playlist.\n",
    "* ***num_albums*** - the number of unique albums for the tracks in the playlist\n",
    "* ***num_tracks*** - the number of tracks in the playlist\n",
    "* ***num_followers*** - the number of followers this playlist had at the time the MPD was created. (Note that the follower count does not including the playlist creator)\n",
    "* ***num_edits*** - the number of separate editing sessions. Tracks added in a two hour window are considered to be added in a single editing session.\n",
    "* ***duration_ms*** - the total duration of all the tracks in the playlist (in milliseconds)\n",
    "* ***collaborative*** -  boolean - if true, the playlist is a collaborative playlist. Multiple users may contribute tracks to a collaborative playlist.\n",
    "* ***tracks*** - an array of information about each track in the playlist. Each element in the array is a dictionary with the following fields:\n",
    "   * ***track_name*** - the name of the track\n",
    "   * ***track_uri*** - the Spotify URI of the track\n",
    "   * ***album_name*** - the name of the track's album\n",
    "   * ***album_uri*** - the Spotify URI of the album\n",
    "   * ***artist_name*** - the name of the track's primary artist\n",
    "   * ***artist_uri*** - the Spotify URI of track's primary artist\n",
    "   * ***duration_ms*** - the duration of the track in milliseconds\n",
    "   * ***pos*** - the position of the track in the playlist (zero-based)\n",
    "\n",
    "Here's an example of a typical playlist entry:\n",
    "  \n",
    "        {\n",
    "            \"name\": \"musical\",\n",
    "            \"collaborative\": \"false\",\n",
    "            \"pid\": 5,\n",
    "            \"modified_at\": 1493424000,\n",
    "            \"num_albums\": 7,\n",
    "            \"num_tracks\": 12,\n",
    "            \"num_followers\": 1,\n",
    "            \"num_edits\": 2,\n",
    "            \"duration_ms\": 2657366,\n",
    "            \"num_artists\": 6,\n",
    "            \"tracks\": [\n",
    "                {\n",
    "                    \"pos\": 0,\n",
    "                    \"artist_name\": \"Degiheugi\",\n",
    "                    \"track_uri\": \"spotify:track:7vqa3sDmtEaVJ2gcvxtRID\",\n",
    "                    \"artist_uri\": \"spotify:artist:3V2paBXEoZIAhfZRJmo2jL\",\n",
    "                    \"track_name\": \"Finalement\",\n",
    "                    \"album_uri\": \"spotify:album:2KrRMJ9z7Xjoz1Az4O6UML\",\n",
    "                    \"duration_ms\": 166264,\n",
    "                    \"album_name\": \"Dancing Chords and Fireflies\"\n",
    "                },\n",
    "                {\n",
    "                    \"pos\": 1,\n",
    "                    \"artist_name\": \"Degiheugi\",\n",
    "                    \"track_uri\": \"spotify:track:23EOmJivOZ88WJPUbIPjh6\",\n",
    "                    \"artist_uri\": \"spotify:artist:3V2paBXEoZIAhfZRJmo2jL\",\n",
    "                    \"track_name\": \"Betty\",\n",
    "                    \"album_uri\": \"spotify:album:3lUSlvjUoHNA8IkNTqURqd\",\n",
    "                    \"duration_ms\": 235534,\n",
    "                    \"album_name\": \"Endless Smile\"\n",
    "                },\n",
    "                {\n",
    "                    \"pos\": 2,\n",
    "                    \"artist_name\": \"Degiheugi\",\n",
    "                    \"track_uri\": \"spotify:track:1vaffTCJxkyqeJY7zF9a55\",\n",
    "                    \"artist_uri\": \"spotify:artist:3V2paBXEoZIAhfZRJmo2jL\",\n",
    "                    \"track_name\": \"Some Beat in My Head\",\n",
    "                    \"album_uri\": \"spotify:album:2KrRMJ9z7Xjoz1Az4O6UML\",\n",
    "                    \"duration_ms\": 268050,\n",
    "                    \"album_name\": \"Dancing Chords and Fireflies\"\n",
    "                },\n",
    "                // 8 tracks omitted\n",
    "                {\n",
    "                    \"pos\": 11,\n",
    "                    \"artist_name\": \"Mo' Horizons\",\n",
    "                    \"track_uri\": \"spotify:track:7iwx00eBzeSSSy6xfESyWN\",\n",
    "                    \"artist_uri\": \"spotify:artist:3tuX54dqgS8LsGUvNzgrpP\",\n",
    "                    \"track_name\": \"Fever 99\\u00b0\",\n",
    "                    \"album_uri\": \"spotify:album:2Fg1t2tyOSGWkVYHlFfXVf\",\n",
    "                    \"duration_ms\": 364320,\n",
    "                    \"album_name\": \"Come Touch The Sun\"\n",
    "                }\n",
    "            ],\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "## Tools\n",
    "There are some tools in the src/ directory that you can use with the dataset:\n",
    "+ check.py - checks to se that the MPD is correct\n",
    "+ deeper_stats.py - shows deep stats for the MPD\n",
    "+ descriptions.py - surfaces the most common descriptions in the MPD\n",
    "+ print.py - prints the full MPD\n",
    "+ show.py - shows playlists by id or id range in the MPD\n",
    "+ stats.py - iterates over the million playlist dataset and outputs info about what is in there.\n",
    "\n",
    "## How was the dataset built\n",
    "The Million Playist Dataset is created by sampling playlists from the billions of playlists that Spotify users have created over the years.  Playlists that meet the following criteria are selected at random:\n",
    "\n",
    " * Created by a user that resides in the United States and is at least 13 years old\n",
    " * Was a public playlist at the time the MPD was generated\n",
    " * Contains at least 5 tracks\n",
    " * Contains no more than 250 tracks\n",
    " * Contains at least 3 unique artists\n",
    " * Contains at least 2 unique albums\n",
    " * Has no local tracks (local tracks are non-Spotify tracks that a user has on their local device)\n",
    " * Has at least one follower (not including the creator)\n",
    " * Was created after January 1, 2010 and before December 1, 2017\n",
    " * Does not have an offensive title\n",
    " * Does not have an adult-oriented title if the playlist was created by a user under 18 years of age\n",
    "\n",
    "Additionally, some playlists have been modified as follows:\n",
    "\n",
    " * Potentially offensive playlist descriptions are removed\n",
    " * Tracks added on or after November 1, 2017 are removed\n",
    "\n",
    "Playlists are sampled randomly, for the most part, but with some dithering to disguise the true distribution of playlists within Spotify. [Paper tracks](https://en.wikipedia.org/wiki/Fictitious_entry) may be added to some playlists to help us identify improper/unlicensed use of the dataset.\n",
    "\n",
    "## Overall demographics of users contributing to the MPD\n",
    "\n",
    "### Gender\n",
    " * Male: 45%\n",
    " * Female: 54%\n",
    " * Unspecified: 0.5%\n",
    " * Nonbinary: 0.5%\n",
    "\n",
    "### Age\n",
    " * 13-17:  10%\n",
    " * 18-24:  43%\n",
    " * 25-34:  31%\n",
    " * 35-44:   9%\n",
    " * 45-54:   4%\n",
    " * 55+:     3%\n",
    "\n",
    "### Country\n",
    " * US: 100%\n",
    "\n",
    "\n",
    "## Who built the dataset\n",
    "The million playlist dataset was built by the following researchers @ Spotify:\n",
    "\n",
    "* Cedric De Boom\n",
    "* Paul Lamere\n",
    "* Ching-Wei Chen\n",
    "* Ben Carterette\n",
    "* Christophe Charbuillet\n",
    "* Jean Garcia-Gathright\n",
    "* James Kirk\n",
    "* James McInerney\n",
    "* Vidhya Murali\n",
    "* Hugh Rawlinson\n",
    "* Sravana Reddy\n",
    "* Marc Romejin\n",
    "* Romain Yon\n",
    "* Yu Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUm9SCCc3vCK"
   },
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHkuFqPf5hUc"
   },
   "outputs": [],
   "source": [
    "data_dir = 'gs://matching-engine-content/spotify-million-playlist/dataset-unzip/data/*.json'\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "bucket_name = 'matching-engine-content'\n",
    "prefix = 'spotify-million-playlist/dataset-unzip/data/'\n",
    "delimiter = '/'\n",
    "\n",
    "blobs = storage_client.list_blobs(bucket_name, prefix=prefix, delimiter=delimiter)\n",
    "print(\"Blobs:\")\n",
    "suffix = \".json\"\n",
    "for blob in blobs:\n",
    "  string = str(blob.name)\n",
    "  if string.endswith(suffix):\n",
    "    elems = string.split(\"/\")\n",
    "    print(elems[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m30Pzj5B8wwi"
   },
   "outputs": [],
   "source": [
    "fullpath = \"gs://matching-engine-content/spotify-million-playlist/dataset-unzip/data/mpd.slice.0-999.json\"\n",
    "# raw_json = json.loads(blob.download_as_string(client=None))\n",
    "\n",
    "playlists = raw_json[\"playlists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdTSiU873waF"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    iterates over the million playlist dataset and outputs info\n",
    "    about what is in there.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "        python stats.py path-to-mpd-data\n",
    "\"\"\"\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "total_playlists = 0\n",
    "total_tracks = 0\n",
    "tracks = set()\n",
    "artists = set()\n",
    "albums = set()\n",
    "titles = set()\n",
    "total_descriptions = 0\n",
    "ntitles = set()\n",
    "title_histogram = collections.Counter()\n",
    "artist_histogram = collections.Counter()\n",
    "track_histogram = collections.Counter()\n",
    "last_modified_histogram = collections.Counter()\n",
    "num_edits_histogram = collections.Counter()\n",
    "playlist_length_histogram = collections.Counter()\n",
    "num_followers_histogram = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8CfLO293zIi"
   },
   "outputs": [],
   "source": [
    "quick = False\n",
    "max_files_for_quick_processing = 5\n",
    "\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            process_info(mpd_slice[\"info\"])\n",
    "            for playlist in mpd_slice[\"playlists\"]:\n",
    "                process_playlist(playlist)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "    show_summary()\n",
    "\n",
    "def show_summary():\n",
    "    print()\n",
    "    print(\"number of playlists\", total_playlists)\n",
    "    print(\"number of tracks\", total_tracks)\n",
    "    print(\"number of unique tracks\", len(tracks))\n",
    "    print(\"number of unique albums\", len(albums))\n",
    "    print(\"number of unique artists\", len(artists))\n",
    "    print(\"number of unique titles\", len(titles))\n",
    "    print(\"number of playlists with descriptions\", total_descriptions)\n",
    "    print(\"number of unique normalized titles\", len(ntitles))\n",
    "    print(\"avg playlist length\", float(total_tracks) / total_playlists)\n",
    "    print()\n",
    "    print(\"top playlist titles\")\n",
    "    for title, count in title_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, title))\n",
    "\n",
    "    print()\n",
    "    print(\"top tracks\")\n",
    "    for track, count in track_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, track))\n",
    "\n",
    "    print()\n",
    "    print(\"top artists\")\n",
    "    for artist, count in artist_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, artist))\n",
    "\n",
    "    print()\n",
    "    print(\"numedits histogram\")\n",
    "    for num_edits, count in num_edits_histogram.most_common(20):\n",
    "        print(\"%7d %d\" % (count, num_edits))\n",
    "\n",
    "    print()\n",
    "    print(\"last modified histogram\")\n",
    "    for ts, count in last_modified_histogram.most_common(20):\n",
    "        print(\"%7d %s\" % (count, to_date(ts)))\n",
    "\n",
    "    print()\n",
    "    print(\"playlist length histogram\")\n",
    "    for length, count in playlist_length_histogram.most_common(20):\n",
    "        print(\"%7d %d\" % (count, length))\n",
    "\n",
    "    print()\n",
    "    print(\"num followers histogram\")\n",
    "    for followers, count in num_followers_histogram.most_common(20):\n",
    "        print(\"%7d %d\" % (count, followers))\n",
    "\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n",
    "\n",
    "\n",
    "def to_date(epoch):\n",
    "    return datetime.datetime.fromtimestamp(epoch).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def process_playlist(playlist):\n",
    "    global total_playlists, total_tracks, total_descriptions\n",
    "\n",
    "    total_playlists += 1\n",
    "    # print playlist['playlist_id'], playlist['name']\n",
    "\n",
    "    if \"description\" in playlist:\n",
    "        total_descriptions += 1\n",
    "\n",
    "    titles.add(playlist[\"name\"])\n",
    "    nname = normalize_name(playlist[\"name\"])\n",
    "    ntitles.add(nname)\n",
    "    title_histogram[nname] += 1\n",
    "\n",
    "    playlist_length_histogram[playlist[\"num_tracks\"]] += 1\n",
    "    last_modified_histogram[playlist[\"modified_at\"]] += 1\n",
    "    num_edits_histogram[playlist[\"num_edits\"]] += 1\n",
    "    num_followers_histogram[playlist[\"num_followers\"]] += 1\n",
    "\n",
    "    for track in playlist[\"tracks\"]:\n",
    "        total_tracks += 1\n",
    "        albums.add(track[\"album_uri\"])\n",
    "        tracks.add(track[\"track_uri\"])\n",
    "        artists.add(track[\"artist_uri\"])\n",
    "\n",
    "        full_name = track[\"track_name\"] + \" by \" + track[\"artist_name\"]\n",
    "        artist_histogram[track[\"artist_name\"]] += 1\n",
    "        track_histogram[full_name] += 1\n",
    "\n",
    "\n",
    "def process_info(_):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN2_nDASakYi"
   },
   "source": [
    "## JT optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiC-1t-EamYF"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "import pandas as pd\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7ePclUNaokV"
   },
   "outputs": [],
   "source": [
    "bucket_name = 'spotify-million-playlists'\n",
    "prefix = 'data/'\n",
    "delimiter = '/'\n",
    "path = f'gs://{bucket_name}/{prefix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjoNo8tXao2e"
   },
   "outputs": [],
   "source": [
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "# blob = bucket.blob(SAMPLE_FILENAME)\n",
    "\n",
    "blobs = storage_client.list_blobs(\n",
    "        bucket_name, prefix=prefix, delimiter=delimiter\n",
    "    )\n",
    "\n",
    "playlists = []\n",
    "suffix = \".json\"\n",
    "for blob in blobs:\n",
    "    string = str(blob.name)\n",
    "    \n",
    "    if string.endswith(suffix):\n",
    "        elems = string.split(\"/\")\n",
    "        _blob = bucket.blob(prefix + elems[1])\n",
    "        raw_json = json.loads(_blob.download_as_string(client=None))\n",
    "        \n",
    "        for play in raw_json['playlists']:\n",
    "            playlists.append(play)\n",
    "        \n",
    "        print(f'Finished blob: {elems[1]}; Playlist Length: {len(playlists)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JH5aO0yxarxs"
   },
   "outputs": [],
   "source": [
    "df = pd.json_normalize(playlists, record_path='tracks', meta=['name'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31TS6GA2Zpgp"
   },
   "source": [
    "### Jeremy Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQrgcE_k4O7t"
   },
   "outputs": [],
   "source": [
    "# create larger dataframe\n",
    "file=\"data/\"\n",
    "delimiter=\"/\"\n",
    "\n",
    "blobs=bucket.list_blobs(prefix=file, delimiter=delimiter) # Excluding folder inside bucket\n",
    "\n",
    "for blob in blobs:\n",
    "    raw = json.loads(blob.download_as_string(client=storage_client))\n",
    "    playlists = raw_json[\"playlists\"]\n",
    "    df_temp = pd.json_normalize(playlists, record_path='tracks', meta=['name'])\n",
    "    df_temp.to_gbq(destination_table='mdp_eda.all_slices_playlists', project_id='matching-engine-playlist', location='us-central1', progress_bar=True, reauth=True, if_exists='append')\n",
    "    print(f'Finished {blob} DF Shape = {df.shape}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract-spotify-features-pipeline-parallel-for.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
