{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8757f6-8f36-4b0d-8c37-ba31a1773f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform[prediction]>=1.16.0 fastapi nvtabular git+https://github.com/NVIDIA-Merlin/models.git --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Buidling a custom Vertex AI endpoint for Merlin Query Tower\n",
    "\n",
    "**IMPORTANT** Make sure you are running this notebook in a DLVM (e.g. tensorflow enterprise 2.8) to build the image\n",
    "\n",
    "________\n",
    "**This will not work in the training container**\n",
    "________\n",
    "\n",
    "Your output should look like this - you are going to use the query model endpoint to create a custom container\n",
    "\n",
    "![](img/merlin-bucket.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PROJECT = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "REGION = 'us-central1' \n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "REPOSITORY = 'merlin-spotify-cpr'\n",
    "ARTIFACT_URI = f'{BUCKET}/merlin-processed'\n",
    "MODEL_DIR = f'{BUCKET}/merlin-processed/query_model_merlin'\n",
    "PREFIX = 'merlin-spotify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b65e26b-31d7-459e-8f80-92e2c206fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://wortz-project-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5075f2f7-c075-4e56-a188-4adfee578a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !echo y | docker container prune\n",
    "# !echo y | docker image prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045aab2-d485-4bf1-9319-b7afc5cccb34",
   "metadata": {},
   "source": [
    "### Set up repo and configure Docker (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72acda9-ae76-4ce9-8600-71238d545f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# Create the repo if needed for the artifacts\n",
    "\n",
    "! gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1858a130-739b-4752-bf02-d0e8356a0829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf app\n",
    "! mkdir app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd404ace-87cc-4614-9bd0-cdd8f060ba51",
   "metadata": {},
   "source": [
    "### Dependency file\n",
    "The first few are for the server handling traffic\n",
    "Nvtabular was downgraded for this example, it may not be necessary in future versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/requirements.txt\n",
    "uvicorn[standard]==0.15.0\n",
    "gunicorn==20.1.0\n",
    "fastapi==0.68.1\n",
    "google-cloud-aiplatform\n",
    "git+https://github.com/NVIDIA-Merlin/models.git\n",
    "nvtabular==1.3.3\n",
    "gcsfs\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608f690-037f-4607-87cd-5ba72bd3dd16",
   "metadata": {},
   "source": [
    "### Predictor module and class\n",
    "This is an adaptation of the CPR examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d80c477-d403-4d39-9220-98d90511a180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/predictor.py\n",
    "\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "\n",
    "class Predictor():\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri):\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.models.load_model(os.path.join(artifacts_uri, \"query_model_merlin\" ))\n",
    "        self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\"))\n",
    "        self.workflow = self.workflow.remove_inputs(['track_pop_can', 'track_uri_can', 'duration_ms_can', \n",
    "                                      'track_name_can', 'artist_name_can','album_name_can',\n",
    "                                      'album_uri_can','artist_followers_can', 'artist_genres_can',\n",
    "                                      'artist_name_can', 'artist_pop_can','artist_pop_pl','artist_uri_can', \n",
    "                                      'artists_followers_pl'])  \n",
    "        return self\n",
    "        \n",
    "    def preprocess(self, prediction_input):\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        #handle different input types, can take a dict or list of dicts\n",
    "        TEST_INSTANCE = prediction_input\n",
    "        if type(TEST_INSTANCE) == list:\n",
    "            pandas_instance = pd.DataFrame.from_dict(TEST_INSTANCE[0], orient='index').T\n",
    "            if len(TEST_INSTANCE) > 1:\n",
    "                for ti in TEST_INSTANCE[0:]:\n",
    "                    pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(ti, orient='index').T)\n",
    "        else:\n",
    "            pandas_instance = pd.DataFrame.from_dict(TEST_INSTANCE, orient='index').T\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        transformed_instance = self.workflow.transform(transformed_inputs)\n",
    "        return transformed_instance\n",
    "\n",
    "    def predict(self, instances):\n",
    "        \"\"\"Performs prediction.\n",
    "        Args:\n",
    "            instances (Any):\n",
    "                Required. The instance(s) used for performing prediction.\n",
    "        Returns:\n",
    "            Prediction results.\n",
    "        \"\"\"  \n",
    "        \n",
    "        loader = mm.Loader(instances, batch_size=instances.num_rows, shuffle=False)\n",
    "        batch = next(iter(loader))\n",
    "        return self.model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9a8771-cae3-494d-a56b-060616889463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "from predictor import Predictor\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "predictor_instance = Predictor()\n",
    "loaded_predictor = predictor_instance.load(artifacts_uri = os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "\n",
    "    instances = body[\"instances\"]\n",
    "    # inputs = np.asarray(instances)\n",
    "    preprocessed_inputs = loaded_predictor.preprocess(instances)\n",
    "    outputs = loaded_predictor.predict(preprocessed_inputs)\n",
    "\n",
    "    return {\"predictions\": outputs.numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfde697-cec3-470c-9c6d-3be275ce6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486a3c72-75d0-45be-98e3-b8451ea7f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/instances.json\n",
    "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"album_uri_can\": \"spotify:album:5l83t3mbVgCrIe1VU9uJZR\", \"artist_followers_can\": 4339757.0, \"artist_genres_can\": \"'hawaiian hip hop', 'rap'\", \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_can\": \"Russ\", \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"artist_pop_pl\": [82.0, 80.0, 90.0, 87.0, 65.0], \"artist_uri_can\": \"spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS\", \"artists_followers_pl\": [4339757.0, 5611842.0, 15046756.0, 30713126.0, 603837.0], \"description_pl\": \"\", \"duration_ms_can\": 237322.0, \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_can\": \"We Just Havent Met Yet\", \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_can\": 57.0, \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_can\": \"spotify:track:0VzDv4wiuZsLsNOmfaUy2W\", \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970ed68e-37f6-406c-9615-3aab9570daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it a package\n",
    "!touch app/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb65bef-d269-4f80-a40b-e0b43f844c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
    "WORKDIR /app \n",
    "\n",
    "COPY ./app/requirements.txt /requirements.txt\n",
    "RUN pip install -r /requirements.txt\n",
    "\n",
    "COPY ./app /app\n",
    "EXPOSE 80\n",
    "    \n",
    "CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22af2064-0460-4dd5-b352-180f33fbdd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.442GB\n",
      "Step 1/7 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      " ---> ec90adb8185e\n",
      "Step 2/7 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> c54a8d620b68\n",
      "Step 3/7 : COPY ./app/requirements.txt /requirements.txt\n",
      " ---> Using cache\n",
      " ---> 89b93f7c10dd\n",
      "Step 4/7 : RUN pip install -r /requirements.txt\n",
      " ---> Using cache\n",
      " ---> 0d03b023e3a3\n",
      "Step 5/7 : COPY ./app /app\n",
      " ---> 267ef97b42f2\n",
      "Step 6/7 : EXPOSE 80\n",
      " ---> Running in 2f2dcd615a29\n",
      "Removing intermediate container 2f2dcd615a29\n",
      " ---> 195e9e1578e5\n",
      "Step 7/7 : CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]\n",
      " ---> Running in 0e29f8a9de1b\n",
      "Removing intermediate container 0e29f8a9de1b\n",
      " ---> 754e889372cb\n",
      "Successfully built 754e889372cb\n",
      "Successfully tagged us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr:latest\n"
     ]
    }
   ],
   "source": [
    "SERVER_IMAGE = \"merlin-prediction-cpr\"  # @param {type:\"string\"} \n",
    "REMOTE_IMAGE_NAME=f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{SERVER_IMAGE}\"\n",
    "\n",
    "!docker build -t $REMOTE_IMAGE_NAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db156d-4675-43cc-ac8f-305d5fc79230",
   "metadata": {},
   "source": [
    "#### If you are debugging, be sure to set `-d` detached flag off and run the commands in console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b2c6d-add5-4753-9069-8499b09ba5c6",
   "metadata": {},
   "source": [
    "### Copy/paste if you want to run from console for testing\n",
    "```python\n",
    "docker run --gpus all -p 80:8080 \\\n",
    "            --name=merlin-prediction-cpr \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=gs://spotify-beam-v3/merlin-processed \\\n",
    "            us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr\n",
    "```\n",
    "\n",
    "##### No GPU:\n",
    "```python\n",
    "docker run -p 80:8080 \\\n",
    "            --name=merlin-prediction-cpr \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=gs://spotify-beam-v3/merlin-processed \\\n",
    "            us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b072387-50e8-4a24-b61b-7c375534fb4a",
   "metadata": {},
   "source": [
    "## Stop the images if they are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52cf577-dcb3-4534-87a1-5acb460d9302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merlin-prediction-cpr\n",
      "merlin-prediction-cpr\n"
     ]
    }
   ],
   "source": [
    "! docker stop $SERVER_IMAGE\n",
    "! docker rm $SERVER_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae9f6a29-7e69-4bf6-bb22-926578ff1181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "! curl localhost/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae134d5-92da-48b5-afdb-7a330c88ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ground truth candidate:\n",
    "    # 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "    # 'artist_name_can': 'Russ', \n",
    "    # 'track_name_can': 'We Just Havent Met Yet', \n",
    "## TODO - we have to overload with candidate data because of the workflow transform, add overloaded values in the predictor\n",
    "TEST_INSTANCE = {'collaborative': 'false',\n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_songs_pl': [237506., 217200., 219080., 226400., 121739.], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_pl': [79., 58., 83., 71., 57.],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acde41b9-5025-4d57-80a9-b9f0213c2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"description_pl\": \"\", \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_instance = json.dumps({\"instances\": TEST_INSTANCE})\n",
    "print(json_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd77a2-7acb-48f8-9e5c-6bd688ee7431",
   "metadata": {},
   "source": [
    "### Copy paste above so json is properly formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c9659cb-5e93-4ecf-8553-9058934e090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile instances.json\n",
    "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"description_pl\": \"\", \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ca1d02-548d-4d5d-a09e-9a5a6ddf7f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\":[[0.5919173359870911,1.1092438697814941,0.0,0.5321710109710693,0.0,0.0,0.0,0.7351390719413757,0.0,0.4420093595981598,0.0,0.09786917269229889,0.11914101243019104,0.0,0.0,0.0,0.0,0.0,2.2194886207580566,0.0,0.3245813846588135,1.4900052547454834,0.0,1.1713331937789917,0.867906391620636,0.0,1.010358214378357,1.0915064811706543,0.6065486669540405,0.0,1.2675611972808838,0.0,0.0,0.0,0.0,3.3520569801330566,0.0,0.0,0.0,0.9523360133171082,0.7877380847930908,0.06262616068124771,0.08143562078475952,0.8745517134666443,2.8739030361175537,1.5691848993301392,0.6309142112731934,0.5168806910514832,0.0,0.7615355849266052,1.1100037097930908,0.20900781452655792,0.0,1.148346185684204,0.0,0.0,0.0,0.9303957223892212,0.0,0.0,0.2855423092842102,0.26085713505744934,0.0,0.45607706904411316,0.7987809181213379,1.007262110710144,0.0,1.4150218963623047,0.11576466262340546,0.0,3.5614173412323,0.0,0.0,1.4880270957946777,0.0,0.0,0.0,0.0,0.0,0.0,1.0274288654327393,0.0,1.6470527648925781,0.0,1.2647912502288818,0.45633432269096375,0.2748670279979706,0.0,0.0,1.1476340293884277,0.0,0.0,3.0344247817993164,0.9904715418815613,0.45293113589286804,3.8916711807250977,3.4132940769195557,0.9972118735313416,0.6069631576538086,0.8225669860839844,0.0,0.0,1.046805500984192,0.0,0.8828969597816467,0.0,0.0,1.6712911128997803,0.0,0.0,0.0,0.9217772483825684,0.0,0.6888653039932251,0.0,0.2225726991891861,1.146008014678955,0.5971589684486389,0.0,0.0,0.0964106097817421,1.1994199752807617,0.3218831419944763,0.0,1.552603840827942,0.0,1.127319097518921,0.0]]}"
     ]
    }
   ],
   "source": [
    "! curl -X POST \\\n",
    "      -d @instances.json \\\n",
    "      -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "      localhost/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd45707-2c87-4148-bf69-25feb40a74a3",
   "metadata": {},
   "source": [
    "### Push the container once ready and testing is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9cf27ed-0c42-4cee-8116-44962bb57c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr]\n",
      "\n",
      "\u001b[1B0e57dfe2: Preparing \n",
      "\u001b[1B733e01aa: Preparing \n",
      "\u001b[1B9b1aea92: Preparing \n",
      "\u001b[1Bfae79d69: Preparing \n",
      "\u001b[1B3aa55fbd: Preparing \n",
      "\u001b[1B9c500afd: Preparing \n",
      "\u001b[1Bca29c9f2: Preparing \n",
      "\u001b[1Bc8057c95: Preparing \n",
      "\u001b[1B555d3a5b: Preparing \n",
      "\u001b[1B7cf26842: Preparing \n",
      "\u001b[1B9b7c9426: Preparing \n",
      "\u001b[1Bb850bdf8: Preparing \n",
      "\u001b[1B12b87e2d: Preparing \n",
      "\u001b[1Bd4c011cd: Preparing \n",
      "\u001b[1B32bae622: Preparing \n",
      "\u001b[1B7dce553c: Preparing \n",
      "\u001b[1Bfd489635: Preparing \n",
      "\u001b[1B47e88671: Preparing \n",
      "\u001b[1B08bc66d2: Preparing \n",
      "\u001b[1B02ddb49b: Preparing \n",
      "\u001b[1B40bc31be: Preparing \n",
      "\u001b[1B3d22fc2d: Preparing \n",
      "\u001b[1Bd03b40d8: Preparing \n",
      "\u001b[1B4453f24a: Preparing \n",
      "\u001b[1Bb1d8d420: Preparing \n",
      "\u001b[1B80eb8994: Preparing \n",
      "\u001b[1B49e0fefd: Preparing \n",
      "\u001b[1B9a0c8694: Preparing \n",
      "\u001b[1B2f6543d2: Preparing \n",
      "\u001b[1B58199899: Preparing \n",
      "\u001b[1Bfaf5524c: Preparing \n",
      "\u001b[1B9dea71d9: Preparing \n",
      "\u001b[1Bb4fa6312: Preparing \n",
      "\u001b[1Bc5236059: Preparing \n",
      "\u001b[1Bfc353e53: Preparing \n",
      "\u001b[1Be1954466: Preparing \n",
      "\u001b[1B0d3a32ca: Preparing \n",
      "\u001b[1B9b216faa: Preparing \n",
      "\u001b[1B3f10d323: Preparing \n",
      "\u001b[1B452845b7: Preparing \n",
      "\u001b[1B0b8eda77: Preparing \n",
      "\u001b[1Ba17119ba: Preparing \n",
      "\u001b[1B9eaca829: Preparing \n",
      "\u001b[1Bfad7db12: Preparing \n",
      "\u001b[1B14ded07d: Preparing \n",
      "\u001b[1Bd2d578a6: Preparing \n",
      "\u001b[1Bd087086a: Preparing \n",
      "\u001b[1Be844e2ad: Preparing \n",
      "\u001b[1B3e44add1: Preparing \n",
      "\u001b[1B39c0455c: Preparing \n",
      "\u001b[1Bc052052a: Preparing \n",
      "\u001b[1B4f787b0f: Preparing \n",
      "\u001b[1B1106424f: Preparing \n",
      "\u001b[43B850bdf8: Waiting g \n",
      "\u001b[1B499564b0: Preparing \n",
      "\u001b[44B2b87e2d: Waiting g \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B47d5362d: Preparing \n",
      "\u001b[46B4c011cd: Waiting g \n",
      "\u001b[1Bb86c2dbe: Preparing \n",
      "\u001b[1Bb43dc9e0: Preparing \n",
      "\u001b[48B2bae622: Waiting g \n",
      "\u001b[1B4baf7a93: Preparing \n",
      "\u001b[1B1a588646: Preparing \n",
      "\u001b[50Bdce553c: Waiting g \n",
      "\u001b[1Bb05f2c3b: Preparing \n",
      "\u001b[51Bd489635: Waiting g \n",
      "\u001b[1B74ab1503: Preparing \n",
      "\u001b[1B544e7743: Preparing \n",
      "\u001b[1B1d77a5de: Layer already exists 2kB\u001b[66A\u001b[2K\u001b[63A\u001b[2K\u001b[60A\u001b[2K\u001b[57A\u001b[2K\u001b[70A\u001b[2K\u001b[52A\u001b[2K\u001b[47A\u001b[2K\u001b[42A\u001b[2K\u001b[36A\u001b[2K\u001b[31A\u001b[2K\u001b[26A\u001b[2K\u001b[20A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[3A\u001b[2Klatest: digest: sha256:12fbee354e4c836f6ee677c8cfe6397891d37870668fafee41388fc61a197b3d size: 15054\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "!docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9a707-6965-4b6f-a3fe-7312dfddbf24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b166b499-b407-4e3e-99f3-da3f3031a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/6129183588572200960/operations/5129689379614228480\n",
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/6129183588572200960@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/6129183588572200960@1')\n"
     ]
    }
   ],
   "source": [
    "MODEL_DISPLAY_NAME = \"Merlin Spotify Query Tower Model\"\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "        display_name=MODEL_DISPLAY_NAME,\n",
    "        artifact_uri=ARTIFACT_URI,\n",
    "        serving_container_image_uri=REMOTE_IMAGE_NAME,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        # serving_container_command=[\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80231d-0430-478e-989a-4802adca17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/7828738294044164096/operations/7936346741140357120\n",
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/7828738294044164096\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/7828738294044164096')\n",
      "Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/7828738294044164096\n",
      "Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/7828738294044164096/operations/3729984689176313856\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\",\n",
    "                        accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "                        accelerator_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8fa58-c587-4b5d-9958-8ed904e0c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.predict(instances=[TEST_INSTANCE])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
