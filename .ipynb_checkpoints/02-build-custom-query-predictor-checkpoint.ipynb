{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8757f6-8f36-4b0d-8c37-ba31a1773f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform[prediction]>=1.16.0 fastapi nvtabular git+https://github.com/NVIDIA-Merlin/models.git --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sklearn with Pandas - Custom Prediction Routine to get Merlin Model predictions\n",
    "\n",
    "Your output should look like this - you are going to use the query model endpoint to create a CPR Endpoing\n",
    "\n",
    "![](img/merlin-bucket.png)\n",
    "\n",
    "This is similar to [the other notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) except we will be using pandas and bigquery\n",
    "\n",
    "Topics covered\n",
    "* Training sklearn locally, deploying to endpoint\n",
    "* Saving data as CSV and doing batch predict from GCS\n",
    "* Loading data to BQ, using BQ magics\n",
    "* Running a batch prediction from BQ to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b65e26b-31d7-459e-8f80-92e2c206fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://wortz-project-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PROJECT = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "REGION = 'us-central1' \n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "REPOSITORY = 'merlin-spotify-cpr'\n",
    "ARTIFACT_URI = f'{BUCKET}/merlin-processed'\n",
    "MODEL_DIR = f'{BUCKET}/merlin-processed/query_model_merlin'\n",
    "PREFIX = 'merlin-spotify'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831cdd6-8d18-40aa-88ba-50889c3624a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# New section - preprocessor creation.\n",
    "\n",
    "In this section we will create a pipeline object that stores a standard scaler \n",
    "using the `PipeLine` class is important as it provides a lot of flexibility and conforms to sklearn's framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c749d4-18ca-46a0-91f9-432dbf1220e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "appapp## Create a generic sklearn container that returns instances\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb\n",
    "\n",
    "**highly recommend reviewing this notebook first as it breaks down the custom predictor interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf app\n",
    "! mkdir app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe604017-7d0f-4ef1-8fcc-1eec2e07e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/NVIDIA-Merlin/models.git nvtabular --user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/requirements.txt\n",
    "uvicorn\n",
    "fastapi\n",
    "git+https://github.com/NVIDIA-Merlin/models.git\n",
    "typing\n",
    "nvtabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c1627-edf8-4879-b1eb-10f28e19cb7a",
   "metadata": {},
   "source": [
    "### CPR Template from here https://cloud.google.com/vertex-ai/docs/predictions/custom-prediction-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d80c477-d403-4d39-9220-98d90511a180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/predictor.py\n",
    "\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from typing import Any\n",
    "#libs from base image (link to build in notebook 01 top)\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "# import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "\n",
    "class Predictor(Predictor):\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri: str) -> None:\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        self._model = tf.keras.models.load_model(os.path.join(artifacts_uri, \"query_model_merlin\" ))\n",
    "        self._workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\"))\n",
    "        self._workflow.remove_inputs(['track_pop_can', 'track_uri_can', \n",
    "                            'duration_ms_can', 'track_name_can', \n",
    "                            'artist_name_can','album_name_can',\n",
    "                            'album_uri_can','artist_followers_can',\n",
    "                            'artist_genres_can','artist_name_can',\n",
    "                            'artist_pop_can','artist_pop_pl','artist_uri_can',\n",
    "                            'artists_followers_pl',])  \n",
    "        return self\n",
    "        \n",
    "    def preprocess(self, prediction_input: Any) -> Any:\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        dict_input = json.loads(prediction_input)\n",
    "        #handle different input types, can take a dict or list of dicts\n",
    "        if type(dict_input) == list:\n",
    "            pandas_instance = pd.DataFrame.from_dict(dict_input[0], orient='index').T\n",
    "            if len(dict_input) > 1:\n",
    "                for ti in dict_input[0:]:\n",
    "                    pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(ti, orient='index').T)\n",
    "        if type(dict_input) == dict:\n",
    "            pandas_instance = pd.DataFrame.from_dict(dict_input, orient='index').T\n",
    "        else:\n",
    "            raise Exception(\"Data must be provided as a dict or list of dicts\")\n",
    "\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        transformed_instance = self._workflow.transform(transformed_inputs)\n",
    "        return transformed_instance\n",
    "\n",
    "    def predict(self, instances: Any) -> Any:\n",
    "        \"\"\"Performs prediction.\n",
    "        Args:\n",
    "            instances (Any):\n",
    "                Required. The instance(s) used for performing prediction.\n",
    "        Returns:\n",
    "            Prediction results.\n",
    "        \"\"\"  \n",
    "        \n",
    "        loader = mm.Loader(instances, batch_size=instances.num_rows, shuffle=False)\n",
    "        batch =next(iter(loader))\n",
    "        return self._model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9a8771-cae3-494d-a56b-060616889463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "from predictor import Predictor\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "loaded_predictor = Predictor.load(artifacts_uri = os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "\n",
    "    instances = body[\"instances\"]\n",
    "    # inputs = np.asarray(instances)\n",
    "    preprocessed_inputs = loaded_predictor.preprocess(inputs)\n",
    "    outputs = loaded_predictor.predict(preprocessed_inputs)\n",
    "\n",
    "    return {\"predictions\": outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfde697-cec3-470c-9c6d-3be275ce6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb65bef-d269-4f80-a40b-e0b43f844c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# FROM nvcr.io/nvidia/merlin/merlin-tensorflow:nightly\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9\n",
    "\n",
    "COPY ./app /app\n",
    "COPY /app/requirements.txt requirements.txt\n",
    "# EXPOSE 80\n",
    "# EXPOSE 8080\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "# RUN sh /app/prestart.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf9e40d-d251-4a9f-a548-675d7ac2040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import container_code.predictor as main_package\n",
    "\n",
    "# print(type(main_package))\n",
    "\n",
    "\n",
    "# base_image = 'us-central1-docker.pkg.dev/hybrid-vertex/workbench/merlin-tensorflow-22.09:latest'\n",
    "\n",
    "# dockerfile = google.cloud.aiplatform.docker_utils.make_dockerfile(\n",
    "#     base_image = base_image,\n",
    "#     main_package = container_code.predictor,\n",
    "#     container_workdir = 'container_code',\n",
    "#     # container_home: str,\n",
    "#     requirements_path = 'container_code/requirements.txt',\n",
    "#     # setup_path: Optional[str] = None,\n",
    "#     # extra_requirements: Optional[List[str]] = None,\n",
    "#     extra_packages = container_code.predictor,\n",
    "#     # extra_dirs: Optional[List[str]] = None,\n",
    "#     exposed_ports = [8080],\n",
    "#     # environment_variables: Optional[Dict[str, str]] = None,\n",
    "#     pip_command = \"pip\",\n",
    "#     python_command = \"python\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a17737-58ad-4819-9b2d-72de6fd6e827",
   "metadata": {},
   "source": [
    "### Build and push container to Artifact Registry\n",
    "#### Build your container\n",
    "To build a custom container, we also need to write an entrypoint of the image that starts the model server. However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e72acda9-ae76-4ce9-8600-71238d545f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# Create the repo if needed for the artifacts\n",
    "\n",
    "! gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1858a130-739b-4752-bf02-d0e8356a0829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af2064-0460-4dd5-b352-180f33fbdd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  82.81MB\n",
      "Step 1/4 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9\n",
      "python3.9: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
      "\n",
      "\u001b[1B90a8898b: Pulling fs layer \n",
      "\u001b[1Bb4cb554e: Pulling fs layer \n",
      "\u001b[1Bf5fceacd: Pulling fs layer \n",
      "\u001b[1B87cbeddc: Pulling fs layer \n",
      "\u001b[1Be6af58ed: Pulling fs layer \n",
      "\u001b[1Bd27b2d86: Pulling fs layer \n",
      "\u001b[1B01103bfe: Pulling fs layer \n",
      "\u001b[1B792d870b: Pulling fs layer \n",
      "\u001b[1B5f720735: Pulling fs layer \n",
      "\u001b[1B2c840886: Pulling fs layer \n",
      "\u001b[1B10954125: Pulling fs layer \n",
      "\u001b[1B61153047: Pulling fs layer \n",
      "\u001b[1B3b39ffd7: Pulling fs layer \n",
      "\u001b[1Ba527b766: Pulling fs layer \n",
      "\u001b[1B881b0164: Pulling fs layer \n",
      "\u001b[1B9f800d1f: Pulling fs layer \n",
      "\u001b[1B41da46f3: Pulling fs layer \n",
      "\u001b[1Bb85828c6: Pulling fs layer \n",
      "\u001b[1Bc5a6b82f: Pulling fs layer \n",
      "\u001b[1B4252b6f7: Pull complete  324B/324B1MBB\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[17A\u001b[2K\u001b[20A\u001b[2K\u001b[17A\u001b[2K\u001b[20A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2KDownloading  63.81kB/6.291MB\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[13A\u001b[2K\u001b[14A\u001b[2KExtracting  18.94MB/54.93MB\u001b[16A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[16A\u001b[2K\u001b[20A\u001b[2K\u001b[9A\u001b[2K\u001b[20A\u001b[2K\u001b[16A\u001b[2K\u001b[20A\u001b[2K\u001b[16A\u001b[2K\u001b[10A\u001b[2K\u001b[16A\u001b[2K\u001b[20A\u001b[2K\u001b[16A\u001b[2K\u001b[6A\u001b[2K\u001b[16A\u001b[2K\u001b[20A\u001b[2K\u001b[16A\u001b[2K\u001b[5A\u001b[2K\u001b[16A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[2A\u001b[2K\u001b[16A\u001b[2K\u001b[1A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:d0ffdbeffb4e713782dd776b1b46311cb94952f4d00098330c393b0b81ca2881\n",
      "Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.9\n",
      " ---> ae7af924b174\n",
      "Step 2/4 : COPY ./app /app\n",
      " ---> 1a28ff4d27f8\n",
      "Step 3/4 : COPY /app/requirements.txt requirements.txt\n",
      " ---> 61b98c05c1e9\n",
      "Step 4/4 : RUN pip install -r requirements.txt\n",
      " ---> Running in dd30423fc138\n",
      "Collecting git+https://github.com/NVIDIA-Merlin/models.git (from -r requirements.txt (line 3))\n",
      "  Cloning https://github.com/NVIDIA-Merlin/models.git to /tmp/pip-req-build-67ptbn2_\n",
      "\u001b[91m  Running command git clone -q https://github.com/NVIDIA-Merlin/models.git /tmp/pip-req-build-67ptbn2_\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "SERVER_IMAGE = \"merlin-prediction-cpr\"  # @param {type:\"string\"} \n",
    "REMOTE_IMAGE_NAME=f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{SERVER_IMAGE}\"\n",
    "\n",
    "!docker build -t $REMOTE_IMAGE_NAME ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52cf577-dcb3-4534-87a1-5acb460d9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker stop $SERVER_IMAGE\n",
    "! docker rm $SERVER_IMAGE\n",
    "! docker run -d -p 80:8080 \\\n",
    "            --name=$SERVER_IMAGE \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=$ARTIFACT_URI \\\n",
    "            $REMOTE_IMAGE_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f6a29-7e69-4bf6-bb22-926578ff1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl localhost/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efda6bd-b348-455d-807c-c3a8c6ba3082",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 75 file(s) totalling 10.1 MiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/home/jupyter/.config/gcloud/logs/2022.10.24/22.38.33.966069.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1666651115.0355-2461ee05131144b8ae3e06e712f0c53f.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/us-central1/builds/4ad3438b-7443-4a3a-a913-4be89e259766].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/4ad3438b-7443-4a3a-a913-4be89e259766?project=934903580331 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"4ad3438b-7443-4a3a-a913-4be89e259766\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1666651115.0355-2461ee05131144b8ae3e06e712f0c53f.tgz#1666651116569762\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1666651115.0355-2461ee05131144b8ae3e06e712f0c53f.tgz#1666651116569762...\n",
      "/ [1 files][  8.2 MiB/  8.2 MiB]                                                \n",
      "Operation completed over 1 objects/8.2 MiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  10.65MB\n",
      "Step 1/4 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:nightly\n",
      "nightly: Pulling from nvidia/merlin/merlin-tensorflow\n",
      "3b65ec22a9e9: Pulling fs layer\n",
      "fd80d866e8b2: Pulling fs layer\n",
      "a364ca75fd6d: Pulling fs layer\n",
      "3d4731d03623: Pulling fs layer\n",
      "53a5c2e0251f: Pulling fs layer\n",
      "b00ff40d02d9: Pulling fs layer\n",
      "3036e9b94123: Pulling fs layer\n",
      "453fdcdda788: Pulling fs layer\n",
      "35e12ec5e515: Pulling fs layer\n",
      "11f61a475a23: Pulling fs layer\n",
      "24280cf31c9a: Pulling fs layer\n",
      "79007799e2ed: Pulling fs layer\n",
      "03eb76abf1e5: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "5e9434e8ae41: Pulling fs layer\n",
      "88a3e778b5bf: Pulling fs layer\n",
      "54aa9ded3c47: Pulling fs layer\n",
      "6b340f3250bc: Pulling fs layer\n",
      "2dbeb3e009c2: Pulling fs layer\n",
      "b4ac54465689: Pulling fs layer\n",
      "dccdf8999222: Pulling fs layer\n",
      "d6cae6ada6c0: Pulling fs layer\n",
      "069ab532aef6: Pulling fs layer\n",
      "36222e49452b: Pulling fs layer\n",
      "4754d22d0da7: Pulling fs layer\n",
      "810fab1703b3: Pulling fs layer\n",
      "4301890e6cfd: Pulling fs layer\n",
      "c090c3f604dd: Pulling fs layer\n",
      "395a1abae210: Pulling fs layer\n",
      "b7f255732517: Pulling fs layer\n",
      "c0dd5b8b474a: Pulling fs layer\n",
      "08fb5576af28: Pulling fs layer\n",
      "2fd72f837eaf: Pulling fs layer\n",
      "f1ff7f880bcf: Pulling fs layer\n",
      "ca6f28c810da: Pulling fs layer\n",
      "6a5f821621e5: Pulling fs layer\n",
      "2c926d1fe341: Pulling fs layer\n",
      "69fd61daeb8e: Pulling fs layer\n",
      "a6ceb291e680: Pulling fs layer\n",
      "c3451cdf6c8b: Pulling fs layer\n",
      "f872f641875b: Pulling fs layer\n",
      "f64190c224a4: Pulling fs layer\n",
      "3a9103d7b114: Pulling fs layer\n",
      "eac4a85b4adb: Pulling fs layer\n",
      "6a666d373cd1: Pulling fs layer\n",
      "c46f6435a2b2: Pulling fs layer\n",
      "68b4f60b329b: Pulling fs layer\n",
      "ac3798dc5529: Pulling fs layer\n",
      "daa7230c3c2a: Pulling fs layer\n",
      "22047b594504: Pulling fs layer\n",
      "deffcd390e21: Pulling fs layer\n",
      "d4eea2d1f6b3: Pulling fs layer\n",
      "fdb82b53a405: Pulling fs layer\n",
      "23d03d154a04: Pulling fs layer\n",
      "640ac49c5475: Pulling fs layer\n",
      "62b3f3e23f8f: Pulling fs layer\n",
      "5e14bb41dc40: Pulling fs layer\n",
      "c6fc8e2bfecd: Pulling fs layer\n",
      "6368143d281c: Pulling fs layer\n",
      "56921fa9df92: Pulling fs layer\n",
      "3009ab45cae9: Pulling fs layer\n",
      "52a14b760307: Pulling fs layer\n",
      "f0cb158e3a4a: Pulling fs layer\n",
      "8a11065dbd40: Pulling fs layer\n",
      "3e1bf722f4be: Pulling fs layer\n",
      "c5d64ff35757: Pulling fs layer\n",
      "fcbdaf520295: Pulling fs layer\n",
      "40dd446cb396: Pulling fs layer\n",
      "91582a1519ad: Pulling fs layer\n",
      "b5f81464c753: Pulling fs layer\n",
      "438c4403c4dd: Pulling fs layer\n",
      "23326a7ff3fa: Pulling fs layer\n",
      "f7103be0567d: Pulling fs layer\n",
      "d4ed961f0fec: Pulling fs layer\n",
      "2895fdc0a943: Pulling fs layer\n",
      "085ab0dbe90a: Pulling fs layer\n",
      "658dda8ee29e: Pulling fs layer\n",
      "6a5f821621e5: Waiting\n",
      "2c926d1fe341: Waiting\n",
      "69fd61daeb8e: Waiting\n",
      "a6ceb291e680: Waiting\n",
      "c3451cdf6c8b: Waiting\n",
      "f872f641875b: Waiting\n",
      "f64190c224a4: Waiting\n",
      "3a9103d7b114: Waiting\n",
      "eac4a85b4adb: Waiting\n",
      "6a666d373cd1: Waiting\n",
      "c46f6435a2b2: Waiting\n",
      "68b4f60b329b: Waiting\n",
      "ac3798dc5529: Waiting\n",
      "daa7230c3c2a: Waiting\n",
      "22047b594504: Waiting\n",
      "deffcd390e21: Waiting\n",
      "d4eea2d1f6b3: Waiting\n",
      "fdb82b53a405: Waiting\n",
      "23d03d154a04: Waiting\n",
      "640ac49c5475: Waiting\n",
      "62b3f3e23f8f: Waiting\n",
      "5e14bb41dc40: Waiting\n",
      "c6fc8e2bfecd: Waiting\n",
      "6368143d281c: Waiting\n",
      "56921fa9df92: Waiting\n",
      "3009ab45cae9: Waiting\n",
      "52a14b760307: Waiting\n",
      "f0cb158e3a4a: Waiting\n",
      "8a11065dbd40: Waiting\n",
      "3e1bf722f4be: Waiting\n",
      "c5d64ff35757: Waiting\n",
      "40dd446cb396: Waiting\n",
      "91582a1519ad: Waiting\n",
      "b5f81464c753: Waiting\n",
      "438c4403c4dd: Waiting\n",
      "23326a7ff3fa: Waiting\n",
      "f7103be0567d: Waiting\n",
      "d4ed961f0fec: Waiting\n",
      "2895fdc0a943: Waiting\n",
      "085ab0dbe90a: Waiting\n",
      "658dda8ee29e: Waiting\n",
      "3d4731d03623: Waiting\n",
      "53a5c2e0251f: Waiting\n",
      "b00ff40d02d9: Waiting\n",
      "3036e9b94123: Waiting\n",
      "453fdcdda788: Waiting\n",
      "35e12ec5e515: Waiting\n",
      "11f61a475a23: Waiting\n",
      "24280cf31c9a: Waiting\n",
      "79007799e2ed: Waiting\n",
      "03eb76abf1e5: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "5e9434e8ae41: Waiting\n",
      "88a3e778b5bf: Waiting\n",
      "54aa9ded3c47: Waiting\n",
      "6b340f3250bc: Waiting\n",
      "2dbeb3e009c2: Waiting\n",
      "b4ac54465689: Waiting\n",
      "dccdf8999222: Waiting\n",
      "d6cae6ada6c0: Waiting\n",
      "069ab532aef6: Waiting\n",
      "36222e49452b: Waiting\n",
      "4754d22d0da7: Waiting\n",
      "810fab1703b3: Waiting\n",
      "4301890e6cfd: Waiting\n",
      "c090c3f604dd: Waiting\n",
      "395a1abae210: Waiting\n",
      "b7f255732517: Waiting\n",
      "c0dd5b8b474a: Waiting\n",
      "08fb5576af28: Waiting\n",
      "2fd72f837eaf: Waiting\n",
      "f1ff7f880bcf: Waiting\n",
      "ca6f28c810da: Waiting\n",
      "fcbdaf520295: Waiting\n",
      "3b65ec22a9e9: Verifying Checksum\n",
      "3b65ec22a9e9: Download complete\n",
      "3d4731d03623: Verifying Checksum\n",
      "3d4731d03623: Download complete\n",
      "fd80d866e8b2: Verifying Checksum\n",
      "fd80d866e8b2: Download complete\n",
      "a364ca75fd6d: Verifying Checksum\n",
      "a364ca75fd6d: Download complete\n",
      "b00ff40d02d9: Verifying Checksum\n",
      "b00ff40d02d9: Download complete\n",
      "3036e9b94123: Verifying Checksum\n",
      "3036e9b94123: Download complete\n",
      "453fdcdda788: Verifying Checksum\n",
      "453fdcdda788: Download complete\n",
      "35e12ec5e515: Download complete\n",
      "11f61a475a23: Verifying Checksum\n",
      "11f61a475a23: Download complete\n",
      "79007799e2ed: Verifying Checksum\n",
      "79007799e2ed: Download complete\n",
      "24280cf31c9a: Verifying Checksum\n",
      "24280cf31c9a: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "5e9434e8ae41: Verifying Checksum\n",
      "5e9434e8ae41: Download complete\n",
      "88a3e778b5bf: Verifying Checksum\n",
      "88a3e778b5bf: Download complete\n",
      "3b65ec22a9e9: Pull complete\n",
      "54aa9ded3c47: Verifying Checksum\n",
      "54aa9ded3c47: Download complete\n",
      "03eb76abf1e5: Verifying Checksum\n",
      "03eb76abf1e5: Download complete\n",
      "2dbeb3e009c2: Verifying Checksum\n",
      "2dbeb3e009c2: Download complete\n",
      "b4ac54465689: Verifying Checksum\n",
      "b4ac54465689: Download complete\n",
      "dccdf8999222: Download complete\n",
      "6b340f3250bc: Verifying Checksum\n",
      "6b340f3250bc: Download complete\n",
      "069ab532aef6: Verifying Checksum\n",
      "069ab532aef6: Download complete\n",
      "36222e49452b: Verifying Checksum\n",
      "36222e49452b: Download complete\n",
      "4754d22d0da7: Verifying Checksum\n",
      "4754d22d0da7: Download complete\n",
      "810fab1703b3: Verifying Checksum\n",
      "810fab1703b3: Download complete\n",
      "4301890e6cfd: Verifying Checksum\n",
      "4301890e6cfd: Download complete\n",
      "c090c3f604dd: Verifying Checksum\n",
      "c090c3f604dd: Download complete\n",
      "395a1abae210: Verifying Checksum\n",
      "395a1abae210: Download complete\n",
      "53a5c2e0251f: Verifying Checksum\n",
      "53a5c2e0251f: Download complete\n",
      "b7f255732517: Verifying Checksum\n",
      "b7f255732517: Download complete\n",
      "c0dd5b8b474a: Verifying Checksum\n",
      "c0dd5b8b474a: Download complete\n",
      "08fb5576af28: Verifying Checksum\n",
      "08fb5576af28: Download complete\n",
      "2fd72f837eaf: Verifying Checksum\n",
      "2fd72f837eaf: Download complete\n",
      "ca6f28c810da: Verifying Checksum\n",
      "ca6f28c810da: Download complete\n",
      "f1ff7f880bcf: Verifying Checksum\n",
      "f1ff7f880bcf: Download complete\n",
      "6a5f821621e5: Verifying Checksum\n",
      "6a5f821621e5: Download complete\n",
      "2c926d1fe341: Verifying Checksum\n",
      "2c926d1fe341: Download complete\n",
      "fd80d866e8b2: Pull complete\n",
      "d6cae6ada6c0: Verifying Checksum\n",
      "d6cae6ada6c0: Download complete\n",
      "c3451cdf6c8b: Verifying Checksum\n",
      "c3451cdf6c8b: Download complete\n",
      "a6ceb291e680: Verifying Checksum\n",
      "a6ceb291e680: Download complete\n",
      "f64190c224a4: Verifying Checksum\n",
      "f64190c224a4: Download complete\n",
      "f872f641875b: Verifying Checksum\n",
      "f872f641875b: Download complete\n",
      "3a9103d7b114: Verifying Checksum\n",
      "3a9103d7b114: Download complete\n",
      "eac4a85b4adb: Verifying Checksum\n",
      "eac4a85b4adb: Download complete\n",
      "6a666d373cd1: Verifying Checksum\n",
      "6a666d373cd1: Download complete\n",
      "c46f6435a2b2: Verifying Checksum\n",
      "c46f6435a2b2: Download complete\n",
      "68b4f60b329b: Verifying Checksum\n",
      "68b4f60b329b: Download complete\n",
      "ac3798dc5529: Verifying Checksum\n",
      "ac3798dc5529: Download complete\n",
      "daa7230c3c2a: Verifying Checksum\n",
      "daa7230c3c2a: Download complete\n",
      "22047b594504: Verifying Checksum\n",
      "22047b594504: Download complete\n",
      "69fd61daeb8e: Verifying Checksum\n",
      "69fd61daeb8e: Download complete\n",
      "deffcd390e21: Verifying Checksum\n",
      "deffcd390e21: Download complete\n",
      "fdb82b53a405: Verifying Checksum\n",
      "fdb82b53a405: Download complete\n",
      "d4eea2d1f6b3: Verifying Checksum\n",
      "d4eea2d1f6b3: Download complete\n",
      "23d03d154a04: Verifying Checksum\n",
      "23d03d154a04: Download complete\n",
      "a364ca75fd6d: Pull complete\n",
      "3d4731d03623: Pull complete\n",
      "62b3f3e23f8f: Download complete\n",
      "640ac49c5475: Verifying Checksum\n",
      "640ac49c5475: Download complete\n",
      "6368143d281c: Verifying Checksum\n",
      "6368143d281c: Download complete\n",
      "56921fa9df92: Verifying Checksum\n",
      "56921fa9df92: Download complete\n",
      "3009ab45cae9: Verifying Checksum\n",
      "3009ab45cae9: Download complete\n",
      "5e14bb41dc40: Verifying Checksum\n",
      "5e14bb41dc40: Download complete\n",
      "52a14b760307: Verifying Checksum\n",
      "52a14b760307: Download complete\n",
      "f0cb158e3a4a: Verifying Checksum\n",
      "f0cb158e3a4a: Download complete\n",
      "8a11065dbd40: Verifying Checksum\n",
      "8a11065dbd40: Download complete\n",
      "3e1bf722f4be: Verifying Checksum\n",
      "3e1bf722f4be: Download complete\n",
      "c5d64ff35757: Verifying Checksum\n",
      "c5d64ff35757: Download complete\n",
      "fcbdaf520295: Verifying Checksum\n",
      "fcbdaf520295: Download complete\n",
      "40dd446cb396: Verifying Checksum\n",
      "40dd446cb396: Download complete\n",
      "91582a1519ad: Verifying Checksum\n",
      "91582a1519ad: Download complete\n",
      "438c4403c4dd: Verifying Checksum\n",
      "438c4403c4dd: Download complete\n",
      "23326a7ff3fa: Verifying Checksum\n",
      "23326a7ff3fa: Download complete\n",
      "c6fc8e2bfecd: Verifying Checksum\n",
      "c6fc8e2bfecd: Download complete\n",
      "f7103be0567d: Download complete\n",
      "d4ed961f0fec: Verifying Checksum\n",
      "d4ed961f0fec: Download complete\n",
      "2895fdc0a943: Verifying Checksum\n",
      "2895fdc0a943: Download complete\n",
      "085ab0dbe90a: Verifying Checksum\n",
      "085ab0dbe90a: Download complete\n",
      "658dda8ee29e: Verifying Checksum\n",
      "658dda8ee29e: Download complete\n",
      "b5f81464c753: Verifying Checksum\n",
      "b5f81464c753: Download complete\n",
      "53a5c2e0251f: Pull complete\n",
      "b00ff40d02d9: Pull complete\n",
      "3036e9b94123: Pull complete\n",
      "453fdcdda788: Pull complete\n",
      "35e12ec5e515: Pull complete\n",
      "11f61a475a23: Pull complete\n",
      "24280cf31c9a: Pull complete\n",
      "79007799e2ed: Pull complete\n",
      "03eb76abf1e5: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "5e9434e8ae41: Pull complete\n",
      "88a3e778b5bf: Pull complete\n",
      "54aa9ded3c47: Pull complete\n",
      "6b340f3250bc: Pull complete\n",
      "2dbeb3e009c2: Pull complete\n",
      "b4ac54465689: Pull complete\n",
      "dccdf8999222: Pull complete\n",
      "d6cae6ada6c0: Pull complete\n",
      "069ab532aef6: Pull complete\n",
      "36222e49452b: Pull complete\n",
      "4754d22d0da7: Pull complete\n",
      "810fab1703b3: Pull complete\n",
      "4301890e6cfd: Pull complete\n",
      "c090c3f604dd: Pull complete\n",
      "395a1abae210: Pull complete\n",
      "b7f255732517: Pull complete\n",
      "c0dd5b8b474a: Pull complete\n",
      "08fb5576af28: Pull complete\n",
      "2fd72f837eaf: Pull complete\n",
      "f1ff7f880bcf: Pull complete\n",
      "ca6f28c810da: Pull complete\n",
      "6a5f821621e5: Pull complete\n",
      "2c926d1fe341: Pull complete\n",
      "69fd61daeb8e: Pull complete\n",
      "a6ceb291e680: Pull complete\n",
      "c3451cdf6c8b: Pull complete\n",
      "f872f641875b: Pull complete\n",
      "f64190c224a4: Pull complete\n",
      "3a9103d7b114: Pull complete\n",
      "eac4a85b4adb: Pull complete\n",
      "6a666d373cd1: Pull complete\n",
      "c46f6435a2b2: Pull complete\n",
      "68b4f60b329b: Pull complete\n",
      "ac3798dc5529: Pull complete\n",
      "daa7230c3c2a: Pull complete\n",
      "22047b594504: Pull complete\n",
      "deffcd390e21: Pull complete\n",
      "d4eea2d1f6b3: Pull complete\n",
      "fdb82b53a405: Pull complete\n",
      "23d03d154a04: Pull complete\n",
      "640ac49c5475: Pull complete\n",
      "62b3f3e23f8f: Pull complete\n",
      "5e14bb41dc40: Pull complete\n",
      "c6fc8e2bfecd: Pull complete\n",
      "6368143d281c: Pull complete\n",
      "56921fa9df92: Pull complete\n",
      "3009ab45cae9: Pull complete\n",
      "52a14b760307: Pull complete\n",
      "f0cb158e3a4a: Pull complete\n",
      "8a11065dbd40: Pull complete\n",
      "3e1bf722f4be: Pull complete\n",
      "c5d64ff35757: Pull complete\n",
      "fcbdaf520295: Pull complete\n",
      "40dd446cb396: Pull complete\n",
      "91582a1519ad: Pull complete\n",
      "b5f81464c753: Pull complete\n",
      "438c4403c4dd: Pull complete\n",
      "23326a7ff3fa: Pull complete\n",
      "f7103be0567d: Pull complete\n",
      "d4ed961f0fec: Pull complete\n",
      "2895fdc0a943: Pull complete\n",
      "085ab0dbe90a: Pull complete\n",
      "658dda8ee29e: Pull complete\n",
      "Digest: sha256:0e7b970acd5c7f832a68d76844aed26011c6cb837ace2f26f8822076a9006f6d\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/merlin/merlin-tensorflow:nightly\n",
      " ---> 4cd1121d6e62\n",
      "Step 2/4 : COPY ./app /app\n",
      " ---> 3a6b38ce0310\n",
      "Step 3/4 : COPY /app/requirements.txt requirements.txt\n",
      " ---> 6b1c757dbc49\n",
      "Step 4/4 : RUN pip install -r requirements.txt\n",
      " ---> Running in ba27daf2df1f\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --region={REGION} --tag=$REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af44323-4e94-43d0-9dc8-649879be77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! pip install google-cloud-aiplatform[prediction]>=1.16.0 --user\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05bf27d9-03c8-46e7-9dd3-45b6586f1316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from container_code.predictor import Predictor\n",
    "\n",
    "# from google.cloud.aiplatform.prediction import LocalModel\n",
    "# base_image = 'us-central1-docker.pkg.dev/hybrid-vertex/workbench/merlin-tensorflow-22.09:latest'\n",
    "\n",
    "# SERVER_IMAGE = \"merlin-prediction-cpr\"  # @param {type:\"string\"} \n",
    "\n",
    "# local_model = LocalModel.build_cpr_model(\n",
    "#     \"container_code\",\n",
    "#     f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{SERVER_IMAGE}\",\n",
    "#     predictor=Predictor,\n",
    "#     # base_image=base_image,\n",
    "#     requirements_path=\"container_code/requirements.txt\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80330616-933a-4ec9-9322-2dd5815c4947",
   "metadata": {},
   "source": [
    "### Test it out with a locally deployed endpoint\n",
    "Need to generate credentials to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fae134d5-92da-48b5-afdb-7a330c88ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {'collaborative': 'false',\n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 # 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "                 # 'artist_followers_can': 4339757.0, \n",
    "                 # 'artist_genres_can': \"'hawaiian hip hop', 'rap'\", \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 # 'artist_name_can': 'Russ', \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 # 'artist_pop_can': 82.0, \n",
    "                 # 'artist_pop_pl': [82., 80., 90., 87., 65.], \n",
    "                 # 'artist_uri_can': 'spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS', \n",
    "                 # 'artists_followers_pl': [ 4339757.,  5611842., 15046756., 30713126.,   603837.],  \n",
    "                 'description_pl': '', \n",
    "                 # 'duration_ms_can': 237322.0, \n",
    "                 #'duration_ms_songs_pl': [237506., 217200., 219080., 226400., 121739.], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 # 'track_name_can': 'We Just Havent Met Yet', \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 # 'track_pop_can': 57.0, \n",
    "                 #'track_pop_pl': [79., 58., 83., 71., 57.],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 # 'track_uri_can': 'spotify:track:0VzDv4wiuZsLsNOmfaUy2W', \n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acde41b9-5025-4d57-80a9-b9f0213c2e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"collaborative\": \"false\", \"album_name_pl\": [\"There\\'s Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"\\'hawaiian hip hop\\', \\'rap\\'\", \"\\'chicago rap\\', \\'dance pop\\', \\'pop\\', \\'pop rap\\', \\'r&b\\', \\'southern hip hop\\', \\'trap\\', \\'urban contemporary\\'\", \"\\'pop\\', \\'pop r&b\\'\", \"\\'dance pop\\', \\'pop\\', \\'r&b\\'\", \"\\'chill r&b\\', \\'pop\\', \\'pop r&b\\', \\'r&b\\', \\'urban contemporary\\'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\\\u00c3\\\\u00a9\", \"William Singe\"], \"description_pl\": \"\", \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json_instance = json.dumps(TEST_INSTANCE)\n",
    "json_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e25c00ba-55ac-429b-ad30-404e4df8c81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile instances.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\"collaborative\": \"false\", \"album_name_pl\": [\"There\\'s Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"\\'hawaiian hip hop\\', \\'rap\\'\", \"\\'chicago rap\\', \\'dance pop\\', \\'pop\\', \\'pop rap\\', \\'r&b\\', \\'southern hip hop\\', \\'trap\\', \\'urban contemporary\\'\", \"\\'pop\\', \\'pop r&b\\'\", \"\\'dance pop\\', \\'pop\\', \\'r&b\\'\", \"\\'chill r&b\\', \\'pop\\', \\'pop r&b\\', \\'r&b\\', \\'urban contemporary\\'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\\\u00c3\\\\u00a9\", \"William Singe\"], \"description_pl\": \"\", \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18ca1d02-548d-4d5d-a09e-9a5a6ddf7f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to 127.0.0.1 port 80: Connection refused\n"
     ]
    }
   ],
   "source": [
    "! curl -X POST \\\n",
    "      -d @instances.json \\\n",
    "      -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "      127.0.0.1/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9cf27ed-0c42-4cee-8116-44962bb57c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr]\n",
      "\n",
      "\u001b[1B5508d0e6: Preparing \n",
      "\u001b[1Bccbdf310: Preparing \n",
      "\u001b[1B5e7565f9: Preparing \n",
      "\u001b[1B7aeb0051: Preparing \n",
      "\u001b[1B2ebaf4ab: Preparing \n",
      "\u001b[1B6e06bc0f: Preparing \n",
      "\u001b[1B804a0fe1: Preparing \n",
      "\u001b[1Bf785a97f: Preparing \n",
      "\u001b[1B597a54aa: Preparing \n",
      "\u001b[1Bbcbe5a5c: Preparing \n",
      "\u001b[1B7a95f55b: Preparing \n",
      "\u001b[1B5c1009c6: Preparing \n",
      "\u001b[1Bf19bfc53: Preparing \n",
      "\u001b[1B743bb8d5: Preparing \n",
      "\u001b[1B993e895d: Preparing \n",
      "\u001b[1B72e9f3c9: Preparing \n",
      "\u001b[1B8a4a39ad: Preparing \n",
      "\u001b[1Be3edc1b9: Preparing \n",
      "\u001b[1Bc4928ae2: Preparing \n",
      "\u001b[1Bcdaa3b2f: Preparing \n",
      "\u001b[1B9142b563: Preparing \n",
      "\u001b[1B9e7ea093: Preparing \n",
      "\u001b[1Be442df15: Preparing \n",
      "\u001b[1B69be9532: Preparing \n",
      "\u001b[1B5a5611fe: Preparing \n",
      "\u001b[1B48e23e71: Preparing \n",
      "\u001b[1B7bd63e36: Preparing \n",
      "\u001b[1Bf105215c: Preparing \n",
      "\u001b[1Ba0838412: Preparing \n",
      "\u001b[1Bca890919: Preparing \n",
      "\u001b[1B95c32467: Preparing \n",
      "\u001b[1B81197dc8: Preparing \n",
      "\u001b[1Bad71d204: Preparing \n",
      "\u001b[1B2de713b7: Preparing \n",
      "\u001b[1B74fee031: Preparing \n",
      "\u001b[1Bdd49f68f: Preparing \n",
      "\u001b[1B000735fa: Preparing \n",
      "\u001b[1B4795120c: Preparing \n",
      "\u001b[1B45bbd242: Preparing \n",
      "\u001b[1B92632a9d: Preparing \n",
      "\u001b[1B327a78ad: Preparing \n",
      "\u001b[1B4b4ab6c5: Preparing \n",
      "\u001b[1B73665bc3: Preparing \n",
      "\u001b[1B49bbc886: Preparing \n",
      "\u001b[1B65ac30da: Preparing \n",
      "\u001b[1B0b75e6f0: Preparing \n",
      "\u001b[1B8c28669f: Preparing \n",
      "\u001b[1Bc28e3ff6: Preparing \n",
      "\u001b[1B1033cf45: Preparing \n",
      "\u001b[1Bcf25774c: Preparing \n",
      "\u001b[1Bdbd75cdd: Preparing \n",
      "\u001b[1Bf0b3b77f: Preparing \n",
      "\u001b[1Bce86c618: Preparing \n",
      "\u001b[1B85d475fa: Preparing \n",
      "\u001b[1Bc968e086: Preparing \n",
      "\u001b[1B5ffe819e: Preparing \n",
      "\u001b[1Bbe5f4b00: Preparing \n",
      "\u001b[1B2b1937cf: Preparing \n",
      "\u001b[1B04a986af: Preparing \n",
      "\u001b[1Bd892208c: Preparing \n",
      "\u001b[1B13a1a554: Preparing \n",
      "\u001b[40B442df15: Waiting g \n",
      "\u001b[1B89796b9d: Preparing \n",
      "\u001b[1B499564b0: Preparing \n",
      "\u001b[1Bbfae03e4: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B47d5362d: Preparing \n",
      "\u001b[45B9be9532: Waiting g \n",
      "\u001b[1Bb86c2dbe: Preparing \n",
      "\u001b[46Ba5611fe: Waiting g \n",
      "\u001b[1B80704277: Preparing \n",
      "\u001b[1B4baf7a93: Preparing \n",
      "\u001b[48B8e23e71: Waiting g \n",
      "\u001b[1Bf3b3096a: Preparing \n",
      "\u001b[70Be06bc0f: Waiting g \n",
      "\u001b[1Baed48cda: Preparing \n",
      "\u001b[1B74ab1503: Preparing \n",
      "\u001b[72B04a0fe1: Waiting g \n",
      "\u001b[79B508d0e6: Pushed   136.1MB/133.2MB2A\u001b[2K\u001b[78A\u001b[2K\u001b[66A\u001b[2K\u001b[61A\u001b[2K\u001b[59A\u001b[2K\u001b[57A\u001b[2K\u001b[78A\u001b[2K\u001b[50A\u001b[2K\u001b[45A\u001b[2K\u001b[41A\u001b[2K\u001b[38A\u001b[2K\u001b[30A\u001b[2K\u001b[25A\u001b[2K\u001b[21A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2K\u001b[79A\u001b[2Klatest: digest: sha256:4ed684ab51b80aff96e4defc26c8a44554672b1f6badd5b72b497d8c58c7e4b9 size: 16945\n"
     ]
    }
   ],
   "source": [
    "### push the container to registry\n",
    "!docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9a707-6965-4b6f-a3fe-7312dfddbf24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166b499-b407-4e3e-99f3-da3f3031a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DISPLAY_NAME = \"Merlin Spotify Query Tower Model\"\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=ARTIFACT_URI,\n",
    "    serving_container_image_uri=REMOTE_IMAGE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80231d-0430-478e-989a-4802adca17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8fa58-c587-4b5d-9958-8ed904e0c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.predict(instances=[json_instance])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c322126-7fca-4e71-ab14-96bd3facee99",
   "metadata": {},
   "source": [
    "### Generate credentials - use your \n",
    "\n",
    "Go to the console and search \"Service Accounts\" from there - select your compute account\n",
    "\n",
    "Then add a json key and upload back to this notebook, then cange the filename for `CREDENTIALS_FILE` below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a657cad4-c000-4539-b4c9-b853af79846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"hybrid-vertex-983c0966dff8.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9968407e-f579-44ab-ab1f-5b47db30c7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:google.cloud.aiplatform.prediction.local_endpoint:Exception during starting serving: ('The health check never succeeded.', '', 1).\n",
      "ERROR:google.cloud.aiplatform.prediction.local_endpoint:Exception during entering a context: ('The health check never succeeded.', '', 1).\n"
     ]
    },
    {
     "ename": "DockerError",
     "evalue": "('The health check never succeeded.', '', 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDockerError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19691/2697002770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m with local_model.deploy_to_local_endpoint(\n\u001b[1;32m      2\u001b[0m     \u001b[0martifact_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mARTIFACT_URI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     credential_path=CREDENTIALS_FILE) as local_endpoint:\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhealth_check_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_health_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;34m\"\"\"Enters the runtime context related to this object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception during entering a context: {exception}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_is_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Waits until the model server starts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_until_health_check_succeeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception during starting serving: {exception}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/prediction/local_endpoint.py\u001b[0m in \u001b[0;36m_wait_until_health_check_succeeds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Health check never succeeds, all container logs:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             )\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDockerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The health check never succeeded.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_stop_container_if_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDockerError\u001b[0m: ('The health check never succeeded.', '', 1)"
     ]
    }
   ],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=ARTIFACT_URI,\n",
    "    credential_path=CREDENTIALS_FILE) as local_endpoint:\n",
    "    health_check_response = local_endpoint.run_health_check()\n",
    "    prediction = local_endpoint.predict(json_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa05b7-4303-4655-9cc0-069be8bcf969",
   "metadata": {},
   "source": [
    "#### Only run once to generate creds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a979a4-48a8-4453-90a3-3629957bd878",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload the model to Vertex using new Prediction Route Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb3650-759a-40a1-bd2f-704daad82410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_model.push_image() #push to container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8e71d-9702-4c7d-bd15-925278f759d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "model = local_model.upload(\n",
    "        display_name='merlin spotify query model',\n",
    "        artifact_uri=ARTIFACT_URI,\n",
    "        description='two tower model using merlin models with spotify data',\n",
    "        labels= {'version': 'v1_00'}, \n",
    "              \n",
    "        sync=True, #false will not bind up your notebook instance with the creation operation\n",
    "    ) \n",
    "# model = aiplatform.Model('projects/679926387543/locations/us-central1/models/5966834099661307904')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bee664-c1bd-438a-b8e3-6bb2f09129a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/679926387543/locations/us-central1/endpoints/7051678242322776064/operations/1548668243755925504\n",
      "Endpoint created. Resource name: projects/679926387543/locations/us-central1/endpoints/7051678242322776064\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/679926387543/locations/us-central1/endpoints/7051678242322776064')\n",
      "Deploying model to Endpoint : projects/679926387543/locations/us-central1/endpoints/7051678242322776064\n",
      "Deploy Endpoint model backing LRO: projects/679926387543/locations/us-central1/endpoints/7051678242322776064/operations/5585582359740153856\n",
      "Endpoint model deployed. Resource name: projects/679926387543/locations/us-central1/endpoints/7051678242322776064\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")\n",
    "# endpoint = aiplatform.Endpoint('projects/679926387543/locations/us-central1/endpoints/8555880517864521728')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ca04949-78d9-4885-8b11-069bb12f9e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.79, 0.21], [0.24, 0.76]], deployed_model_id='2882294965424095232', explanations=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.predict(instances=[[47.7, 83.1, 38.7], [53.6, 76.1, 24.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ecbb6a-059e-4dee-bcb7-9974a518965c",
   "metadata": {},
   "source": [
    "# You should be able to see the logging ops by searching for `aiplatform.googleapis.com`\n",
    "+ Make sure you click `show query` slider in case there are other limitations\n",
    "![](images/log_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8328221-1c7c-4c65-bf71-59b59b75a7b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25239/4292456183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minstances_formatted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m predict_response = model.predict(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mrequest_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances_formatted_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,3)), # we will do batch predictions based on this\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3'],\n",
    "              dtype='float64')\n",
    "\n",
    "instances_formatted_data = df2.to_numpy().tolist()\n",
    "\n",
    "predict_response = model.predict(\n",
    "        request_file=instances_formatted_data,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f67d-b47e-43de-a41e-0e927bff6e43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expected output\n",
    "From documentation:\n",
    "```\n",
    "array([[0.8 , 0.2 ],\n",
    "       [0.38, 0.62],\n",
    "       [0.61, 0.39],\n",
    "       [0.65, 0.35],\n",
    "       [0.56, 0.44],\n",
    "       [0.63, 0.37],\n",
    "       [0.55, 0.45],\n",
    "       [0.43, 0.57],\n",
    "       [0.43, 0.57],\n",
    "       [0.38, 0.62]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994f47d-37e8-4992-9c38-762a713818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import csv\n",
    "\n",
    "# save the csv with the header, no index\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "\n",
    "data_directory = BUCKET + \"/data\"\n",
    "storage_path = os.path.join(data_directory, 'df2.csv')\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "blob.upload_from_filename(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a10c6c-18c1-4bf8-9641-61e4e1fe4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='pandas batch predict job sklearn - VALUES JSON',\n",
    "        gcs_source=storage_path,\n",
    "        gcs_destination_prefix=BUCKET+\"/predictions\",\n",
    "        machine_type='n1-standard-2',\n",
    "        instances_format='csv', #This is key to parsing CSV input\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903dc3b1-3458-447d-ab53-a25774d6c2d6",
   "metadata": {},
   "source": [
    "### When successful you should see this\n",
    "```\n",
    "{\"instance\": [16.0, 64.0, 61.0], \"prediction\": [0.63, 0.37]}\n",
    "{\"instance\": [83.0, 27.0, 87.0], \"prediction\": [0.35, 0.65]}\n",
    "{\"instance\": [96.0, 83.0, 57.0], \"prediction\": [0.68, 0.32]}\n",
    "{\"instance\": [11.0, 62.0, 17.0], \"prediction\": [0.89, 0.11]}\n",
    "{\"instance\": [61.0, 28.0, 1.0], \"prediction\": [0.36, 0.64]}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
