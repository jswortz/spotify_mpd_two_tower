{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8757f6-8f36-4b0d-8c37-ba31a1773f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform[prediction]>=1.16.0 fastapi nvtabular git+https://github.com/NVIDIA-Merlin/models.git --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Buidling a custom Vertex AI endpoint for Merlin Query Tower\n",
    "\n",
    "**IMPORTANT** Make sure you are running this notebook in a DLVM (e.g. tensorflow enterprise 2.8) to build the image\n",
    "\n",
    "________\n",
    "**This will not work in the training container**\n",
    "________\n",
    "\n",
    "Your output should look like this - you are going to use the query model endpoint to create a custom container\n",
    "\n",
    "![](img/merlin-bucket.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PROJECT = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "REGION = 'us-central1' \n",
    "BUCKET = 'gs://spotify-beam-v3'\n",
    "REPOSITORY = 'merlin-spotify-cpr'\n",
    "ARTIFACT_URI = f'{BUCKET}/merlin-processed'\n",
    "MODEL_DIR = f'{BUCKET}/merlin-processed/query_model_merlin'\n",
    "PREFIX = 'merlin-spotify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b65e26b-31d7-459e-8f80-92e2c206fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l us-central1 gs://wortz-project-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5075f2f7-c075-4e56-a188-4adfee578a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !echo y | docker container prune\n",
    "# !echo y | docker image prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045aab2-d485-4bf1-9319-b7afc5cccb34",
   "metadata": {},
   "source": [
    "### Set up repo and configure Docker (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72acda9-ae76-4ce9-8600-71238d545f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# Create the repo if needed for the artifacts\n",
    "\n",
    "! gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1858a130-739b-4752-bf02-d0e8356a0829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf app\n",
    "! mkdir app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd404ace-87cc-4614-9bd0-cdd8f060ba51",
   "metadata": {},
   "source": [
    "### Dependency file\n",
    "The first few are for the server handling traffic\n",
    "Nvtabular was downgraded for this example, it may not be necessary in future versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/requirements.txt\n",
    "uvicorn[standard]==0.15.0\n",
    "gunicorn==20.1.0\n",
    "fastapi==0.68.1\n",
    "google-cloud-aiplatform\n",
    "git+https://github.com/NVIDIA-Merlin/models.git\n",
    "nvtabular==1.3.3\n",
    "gcsfs\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608f690-037f-4607-87cd-5ba72bd3dd16",
   "metadata": {},
   "source": [
    "### Predictor module and class\n",
    "This is an adaptation of the CPR examples\n",
    "\n",
    "This was locally tested and created shortly after model creation in the [tensorflow-predict](tensorflow-predict.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3d80c477-d403-4d39-9220-98d90511a180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/predictor.py\n",
    "\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# These are helper functions that ensure the dictionary input is in a certain order and types are preserved\n",
    "# this is to get scalar values to appear first in the dict to not confuse pandas with lists https://github.com/pandas-dev/pandas/issues/46092\n",
    "reordered_keys = ['collaborative', 'album_name_pl', 'artist_genres_pl', \n",
    "                  'artist_name_pl', 'artist_pop_can', 'description_pl', \n",
    "                  'duration_ms_songs_pl', 'n_songs_pl', 'name', 'num_albums_pl', \n",
    "                  'num_artists_pl', 'track_name_pl', 'track_pop_pl', \n",
    "                  'duration_ms_seed_pl', 'pid', 'track_uri_pl']  \n",
    "\n",
    "float_num_fix = ['n_songs_pl','num_albums_pl','num_artists_pl','duration_ms_seed_pl']\n",
    "float_list_fix = ['track_pop_pl', 'duration_ms_songs_pl']\n",
    "    \n",
    "def fix_list_num_dtypes(num_list):\n",
    "    return [float(x) for x in num_list]\n",
    "\n",
    "def fix_num_dtypes(num):\n",
    "    return float(num)\n",
    "\n",
    "def fix_types(k, v):\n",
    "    if k in float_num_fix:\n",
    "        return fix_num_dtypes(v)\n",
    "    if k in float_list_fix:\n",
    "        return fix_list_num_dtypes(v)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def create_pandas_instance(inputs):\n",
    "    if type(inputs) == list:\n",
    "        header = inputs[0]\n",
    "        reordered_header_dict = {k: fix_types(k,header[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_header_dict, orient='index').T\n",
    "        if len(inputs) > 1:\n",
    "            for ti in inputs[1:]:\n",
    "                reordered_dict = {k: fix_types(k,ti[k]) for k in reordered_keys}\n",
    "                pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(reordered_dict, orient='index').T)\n",
    "    else:\n",
    "        reordered_dict = {k: fix_types(k,inputs[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_dict, orient='index').T\n",
    "    return pandas_instance\n",
    "\n",
    "class Predictor():\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri):\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.models.load_model(os.path.join(artifacts_uri, \"query_model_merlin\" ))\n",
    "        self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\"))\n",
    "        self.workflow = self.workflow.remove_inputs(['track_pop_can', 'track_uri_can', 'duration_ms_can', \n",
    "                                      'track_name_can', 'artist_name_can','album_name_can',\n",
    "                                      'album_uri_can','artist_followers_can', 'artist_genres_can',\n",
    "                                      'artist_name_can', 'artist_pop_can','artist_pop_pl','artist_uri_can', \n",
    "                                      'artists_followers_pl'])  \n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def preprocess(self, prediction_input):\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        # handle different input types, can take a dict or list of dicts\n",
    "        pandas_instance = create_pandas_instance(prediction_input[0])\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        transformed_instance = self.workflow.transform(transformed_inputs)\n",
    "        return transformed_instance\n",
    "\n",
    "    def predict(self, instances):\n",
    "        \"\"\"Performs prediction.\n",
    "        Args:\n",
    "            instances (Any):\n",
    "                Required. The instance(s) used for performing prediction.\n",
    "        Returns:\n",
    "            Prediction results.\n",
    "        \"\"\"  \n",
    "        \n",
    "        loader = mm.Loader(instances, batch_size=instances.num_rows, shuffle=False)\n",
    "        batch = next(iter(loader))\n",
    "        return self.model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2b9a8771-cae3-494d-a56b-060616889463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "from predictor import Predictor\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "predictor_instance = Predictor()\n",
    "loaded_predictor = predictor_instance.load(artifacts_uri = os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    preprocessed_inputs = loaded_predictor.preprocess(instances)\n",
    "    outputs = loaded_predictor.predict(preprocessed_inputs)\n",
    "\n",
    "    return {\"predictions\": outputs.numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2dfde697-cec3-470c-9c6d-3be275ce6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "486a3c72-75d0-45be-98e3-b8451ea7f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/instances.json\n",
    "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"album_uri_can\": \"spotify:album:5l83t3mbVgCrIe1VU9uJZR\", \"artist_followers_can\": 4339757.0, \"artist_genres_can\": \"'hawaiian hip hop', 'rap'\", \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_can\": \"Russ\", \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"artist_pop_pl\": [82.0, 80.0, 90.0, 87.0, 65.0], \"artist_uri_can\": \"spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS\", \"artists_followers_pl\": [4339757.0, 5611842.0, 15046756.0, 30713126.0, 603837.0], \"description_pl\": \"\", \"duration_ms_can\": 237322.0, \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_can\": \"We Just Havent Met Yet\", \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_can\": 57.0, \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_can\": \"spotify:track:0VzDv4wiuZsLsNOmfaUy2W\", \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "970ed68e-37f6-406c-9615-3aab9570daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it a package\n",
    "!touch app/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0cb65bef-d269-4f80-a40b-e0b43f844c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
    "WORKDIR /app \n",
    "\n",
    "COPY ./app/requirements.txt /requirements.txt\n",
    "RUN pip install -r /requirements.txt\n",
    "\n",
    "COPY ./app /app\n",
    "EXPOSE 80\n",
    "    \n",
    "CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "22af2064-0460-4dd5-b352-180f33fbdd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.442GB\n",
      "Step 1/7 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      " ---> ec90adb8185e\n",
      "Step 2/7 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> c54a8d620b68\n",
      "Step 3/7 : COPY ./app/requirements.txt /requirements.txt\n",
      " ---> Using cache\n",
      " ---> 89b93f7c10dd\n",
      "Step 4/7 : RUN pip install -r /requirements.txt\n",
      " ---> Using cache\n",
      " ---> 0d03b023e3a3\n",
      "Step 5/7 : COPY ./app /app\n",
      " ---> Using cache\n",
      " ---> 328d8bf15372\n",
      "Step 6/7 : EXPOSE 80\n",
      " ---> Using cache\n",
      " ---> 687e4682d2a4\n",
      "Step 7/7 : CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]\n",
      " ---> Using cache\n",
      " ---> 9d7689d56317\n",
      "Successfully built 9d7689d56317\n",
      "Successfully tagged us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr:latest\n"
     ]
    }
   ],
   "source": [
    "SERVER_IMAGE = \"merlin-prediction-cpr\"  # @param {type:\"string\"} \n",
    "REMOTE_IMAGE_NAME=f\"{REGION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{SERVER_IMAGE}\"\n",
    "\n",
    "!docker build -t $REMOTE_IMAGE_NAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db156d-4675-43cc-ac8f-305d5fc79230",
   "metadata": {},
   "source": [
    "#### If you are debugging, be sure to set `-d` detached flag off and run the commands in console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b2c6d-add5-4753-9069-8499b09ba5c6",
   "metadata": {},
   "source": [
    "### Copy/paste if you want to run from console for testing\n",
    "```python\n",
    "docker run --gpus all -p 80:8080 \\\n",
    "            --name=merlin-prediction-cpr \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=gs://spotify-beam-v3/merlin-processed \\\n",
    "            us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr\n",
    "```\n",
    "\n",
    "##### No GPU:\n",
    "```python\n",
    "docker run -p 80:8080 \\\n",
    "            --name=merlin-prediction-cpr \\\n",
    "            -e AIP_HTTP_PORT=8080 \\\n",
    "            -e AIP_HEALTH_ROUTE=/health \\\n",
    "            -e AIP_PREDICT_ROUTE=/predict \\\n",
    "            -e AIP_STORAGE_URI=gs://spotify-beam-v3/merlin-processed \\\n",
    "            us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b072387-50e8-4a24-b61b-7c375534fb4a",
   "metadata": {},
   "source": [
    "## Stop the images if they are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e52cf577-dcb3-4534-87a1-5acb460d9302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: No such container: merlin-prediction-cpr\n",
      "Error: No such container: merlin-prediction-cpr\n"
     ]
    }
   ],
   "source": [
    "! docker stop $SERVER_IMAGE\n",
    "! docker rm $SERVER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53532f-5b5a-4f70-9172-27347571c812",
   "metadata": {},
   "source": [
    "#### Test the health route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae9f6a29-7e69-4bf6-bb22-926578ff1181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "! curl localhost/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fae134d5-92da-48b5-afdb-7a330c88ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ground truth candidate:\n",
    "    # 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "    # 'artist_name_can': 'Russ', \n",
    "    # 'track_name_can': 'We Just Havent Met Yet', \n",
    "## TODO - we have to overload with candidate data because of the workflow transform, add overloaded values in the predictor\n",
    "TEST_INSTANCE = {'collaborative': 'false',\n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_songs_pl': [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_pl': [79.0, 58.0, 83.0, 71.0, 57.0],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acde41b9-5025-4d57-80a9-b9f0213c2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": [{\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"description_pl\": \"\", \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_instance = json.dumps({\"instances\": [TEST_INSTANCE]})\n",
    "print(json_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd77a2-7acb-48f8-9e5c-6bd688ee7431",
   "metadata": {},
   "source": [
    "### Copy paste above so json is properly formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c9659cb-5e93-4ecf-8553-9058934e090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile instances.json\n",
    "{\"instances\": [{\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"description_pl\": \"\", \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea4b39-7a0c-4417-afc9-72681f24a910",
   "metadata": {},
   "source": [
    "### Test the predict route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ca1d02-548d-4d5d-a09e-9a5a6ddf7f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\":[[0.5919173359870911,1.1092438697814941,0.0,0.5321710109710693,0.0,0.0,0.0,0.7351390719413757,0.0,0.4420093595981598,0.0,0.09786917269229889,0.11914101243019104,0.0,0.0,0.0,0.0,0.0,2.2194886207580566,0.0,0.3245813846588135,1.4900052547454834,0.0,1.1713331937789917,0.867906391620636,0.0,1.010358214378357,1.0915064811706543,0.6065486669540405,0.0,1.2675611972808838,0.0,0.0,0.0,0.0,3.3520569801330566,0.0,0.0,0.0,0.9523360133171082,0.7877380847930908,0.06262616068124771,0.08143562078475952,0.8745517134666443,2.8739030361175537,1.5691848993301392,0.6309142112731934,0.5168806910514832,0.0,0.7615355849266052,1.1100037097930908,0.20900781452655792,0.0,1.148346185684204,0.0,0.0,0.0,0.9303957223892212,0.0,0.0,0.2855423092842102,0.26085713505744934,0.0,0.45607706904411316,0.7987809181213379,1.007262110710144,0.0,1.4150218963623047,0.11576466262340546,0.0,3.5614173412323,0.0,0.0,1.4880270957946777,0.0,0.0,0.0,0.0,0.0,0.0,1.0274288654327393,0.0,1.6470527648925781,0.0,1.2647912502288818,0.45633432269096375,0.2748670279979706,0.0,0.0,1.1476340293884277,0.0,0.0,3.0344247817993164,0.9904715418815613,0.45293113589286804,3.8916711807250977,3.4132940769195557,0.9972118735313416,0.6069631576538086,0.8225669860839844,0.0,0.0,1.046805500984192,0.0,0.8828969597816467,0.0,0.0,1.6712911128997803,0.0,0.0,0.0,0.9217772483825684,0.0,0.6888653039932251,0.0,0.2225726991891861,1.146008014678955,0.5971589684486389,0.0,0.0,0.0964106097817421,1.1994199752807617,0.3218831419944763,0.0,1.552603840827942,0.0,1.127319097518921,0.0]]}"
     ]
    }
   ],
   "source": [
    "! curl -X POST \\\n",
    "      -d @instances.json \\\n",
    "      -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "      localhost/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd45707-2c87-4148-bf69-25feb40a74a3",
   "metadata": {},
   "source": [
    "### Push the container once ready and testing is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b9cf27ed-0c42-4cee-8116-44962bb57c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/hybrid-vertex/merlin-spotify-cpr/merlin-prediction-cpr]\n",
      "\n",
      "\u001b[1B343f9862: Preparing \n",
      "\u001b[1B733e01aa: Preparing \n",
      "\u001b[1B9b1aea92: Preparing \n",
      "\u001b[1Bfae79d69: Preparing \n",
      "\u001b[1B3aa55fbd: Preparing \n",
      "\u001b[1B9c500afd: Preparing \n",
      "\u001b[1Bca29c9f2: Preparing \n",
      "\u001b[1Bc8057c95: Preparing \n",
      "\u001b[1B555d3a5b: Preparing \n",
      "\u001b[1B7cf26842: Preparing \n",
      "\u001b[1B9b7c9426: Preparing \n",
      "\u001b[1Bb850bdf8: Preparing \n",
      "\u001b[1B12b87e2d: Preparing \n",
      "\u001b[1Bd4c011cd: Preparing \n",
      "\u001b[1B32bae622: Preparing \n",
      "\u001b[1B7dce553c: Preparing \n",
      "\u001b[1Bfd489635: Preparing \n",
      "\u001b[1B47e88671: Preparing \n",
      "\u001b[1B08bc66d2: Preparing \n",
      "\u001b[1B02ddb49b: Preparing \n",
      "\u001b[1B40bc31be: Preparing \n",
      "\u001b[1B3d22fc2d: Preparing \n",
      "\u001b[1Bd03b40d8: Preparing \n",
      "\u001b[1B4453f24a: Preparing \n",
      "\u001b[1Bb1d8d420: Preparing \n",
      "\u001b[1B80eb8994: Preparing \n",
      "\u001b[1B49e0fefd: Preparing \n",
      "\u001b[1B9a0c8694: Preparing \n",
      "\u001b[1B2f6543d2: Preparing \n",
      "\u001b[1B58199899: Preparing \n",
      "\u001b[1Bfaf5524c: Preparing \n",
      "\u001b[1B9dea71d9: Preparing \n",
      "\u001b[1Bb4fa6312: Preparing \n",
      "\u001b[1Bc5236059: Preparing \n",
      "\u001b[1Bfc353e53: Preparing \n",
      "\u001b[1Be1954466: Preparing \n",
      "\u001b[1B0d3a32ca: Preparing \n",
      "\u001b[1B9b216faa: Preparing \n",
      "\u001b[1B3f10d323: Preparing \n",
      "\u001b[1B452845b7: Preparing \n",
      "\u001b[1B0b8eda77: Preparing \n",
      "\u001b[1Ba17119ba: Preparing \n",
      "\u001b[1B9eaca829: Preparing \n",
      "\u001b[1Bfad7db12: Preparing \n",
      "\u001b[1B14ded07d: Preparing \n",
      "\u001b[1Bd2d578a6: Preparing \n",
      "\u001b[1Bd087086a: Preparing \n",
      "\u001b[1Be844e2ad: Preparing \n",
      "\u001b[1B3e44add1: Preparing \n",
      "\u001b[1B39c0455c: Preparing \n",
      "\u001b[1Bc052052a: Preparing \n",
      "\u001b[1B4f787b0f: Preparing \n",
      "\u001b[1B1106424f: Preparing \n",
      "\u001b[1B6fafb257: Preparing \n",
      "\u001b[1B499564b0: Preparing \n",
      "\u001b[1Bbfae03e4: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B47d5362d: Preparing \n",
      "\u001b[1B2804b89d: Preparing \n",
      "\u001b[1Bb86c2dbe: Preparing \n",
      "\u001b[1Bb43dc9e0: Preparing \n",
      "\u001b[1B80704277: Preparing \n",
      "\u001b[1B4baf7a93: Preparing \n",
      "\u001b[1B1a588646: Preparing \n",
      "\u001b[1Bf3b3096a: Preparing \n",
      "\u001b[1Bb05f2c3b: Preparing \n",
      "\u001b[1Baed48cda: Preparing \n",
      "\u001b[1B74ab1503: Preparing \n",
      "\u001b[1B544e7743: Preparing \n",
      "\u001b[2B544e7743: Layer already exists \u001b[65A\u001b[2K\u001b[60A\u001b[2K\u001b[55A\u001b[2K\u001b[49A\u001b[2K\u001b[42A\u001b[2K\u001b[37A\u001b[2K\u001b[35A\u001b[2K\u001b[28A\u001b[2K\u001b[21A\u001b[2K\u001b[16A\u001b[2K\u001b[12A\u001b[2K\u001b[4A\u001b[2Klatest: digest: sha256:bbf113a134077d32bcb3b8f19ff8aade8f56bfd50de9930dc24964e0be27d67c size: 15054\n"
     ]
    }
   ],
   "source": [
    "# ### push the container to registry\n",
    "!docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9a707-6965-4b6f-a3fe-7312dfddbf24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy to Vertex AI\n",
    "\n",
    "After the serving metadata is set below, the model is properly abstracted for use on Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b166b499-b407-4e3e-99f3-da3f3031a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/8411804912207265792/operations/1268978599050870784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/934903580331/locations/us-central1/models/8411804912207265792/operations/1268978599050870784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/8411804912207265792@1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/934903580331/locations/us-central1/models/8411804912207265792@1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this Model in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/8411804912207265792@1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/934903580331/locations/us-central1/models/8411804912207265792@1')\n"
     ]
    }
   ],
   "source": [
    "MODEL_DISPLAY_NAME = \"Merlin Spotify Query Tower Model\"\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "        display_name=MODEL_DISPLAY_NAME,\n",
    "        artifact_uri=ARTIFACT_URI,\n",
    "        serving_container_image_uri=REMOTE_IMAGE_NAME,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        serving_container_command=[\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9e80231d-0430-478e-989a-4802adca17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/494907775848022016/operations/5102104831896584192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/494907775848022016/operations/5102104831896584192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/494907775848022016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/494907775848022016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this Endpoint in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/494907775848022016')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/494907775848022016')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/494907775848022016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/494907775848022016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/494907775848022016/operations/8779856877598015488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/494907775848022016/operations/8779856877598015488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint model deployed. Resource name: projects/934903580331/locations/us-central1/endpoints/494907775848022016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/934903580331/locations/us-central1/endpoints/494907775848022016\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\",\n",
    "                        accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "                        accelerator_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "92eff127-d7d0-4cc1-b9b5-84ed9fc6dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/5290959904020889600')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b8b8fa58-c587-4b5d-9958-8ed904e0c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.5919172763824463, 1.109243750572205, 0.0, 0.5321711301803589, 0.0, 0.0, 0.0, 0.7351389527320862, 0.0, 0.4420092403888702, 0.0, 0.0978693813085556, 0.1191409155726433, 0.0, 0.0, 0.0, 0.0, 0.0, 2.219488620758057, 0.0, 0.3245813548564911, 1.490005373954773, 0.0, 1.171333074569702, 0.867906391620636, 0.0, 1.010358572006226, 1.091506361961365, 0.6065486669540405, 0.0, 1.267561197280884, 0.0, 0.0, 0.0, 0.0, 3.352057218551636, 0.0, 0.0, 0.0, 0.9523361921310425, 0.7877382040023804, 0.06262609362602234, 0.08143572509288788, 0.8745517134666443, 2.873902797698975, 1.56918478012085, 0.6309142708778381, 0.5168805122375488, 0.0, 0.7615354657173157, 1.110003709793091, 0.2090079486370087, 0.0, 1.148346304893494, 0.0, 0.0, 0.0, 0.9303956627845764, 0.0, 0.0, 0.2855423390865326, 0.260857105255127, 0.0, 0.4560772180557251, 0.7987809777259827, 1.007262229919434, 0.0, 1.415021777153015, 0.1157644838094711, 0.0, 3.5614173412323, 0.0, 0.0, 1.488027334213257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.027428984642029, 0.0, 1.647052764892578, 0.0, 1.264791250228882, 0.4563341736793518, 0.2748669385910034, 0.0, 0.0, 1.147633671760559, 0.0, 0.0, 3.034424543380737, 0.9904715418815613, 0.4529311656951904, 3.891671180725098, 3.413293838500977, 0.997211754322052, 0.606963038444519, 0.8225671052932739, 0.0, 0.0, 1.046805620193481, 0.0, 0.882897138595581, 0.0, 0.0, 1.671290993690491, 0.0, 0.0, 0.0, 0.9217772483825684, 0.0, 0.6888652443885803, 0.0, 0.2225726395845413, 1.146008014678955, 0.5971589684486389, 0.0, 0.0, 0.09641071408987045, 1.199419975280762, 0.3218831419944763, 0.0, 1.552604198455811, 0.0, 1.127318978309631, 0.0], [0.5919172763824463, 1.109243750572205, 0.0, 0.5321711301803589, 0.0, 0.0, 0.0, 0.7351389527320862, 0.0, 0.4420092403888702, 0.0, 0.0978693813085556, 0.1191409155726433, 0.0, 0.0, 0.0, 0.0, 0.0, 2.219488620758057, 0.0, 0.3245813548564911, 1.490005373954773, 0.0, 1.171333074569702, 0.867906391620636, 0.0, 1.010358572006226, 1.091506361961365, 0.6065486669540405, 0.0, 1.267561197280884, 0.0, 0.0, 0.0, 0.0, 3.352057218551636, 0.0, 0.0, 0.0, 0.9523361921310425, 0.7877382040023804, 0.06262609362602234, 0.08143572509288788, 0.8745517134666443, 2.873902797698975, 1.56918478012085, 0.6309142708778381, 0.5168805122375488, 0.0, 0.7615354657173157, 1.110003709793091, 0.2090079486370087, 0.0, 1.148346304893494, 0.0, 0.0, 0.0, 0.9303956627845764, 0.0, 0.0, 0.2855423390865326, 0.260857105255127, 0.0, 0.4560772180557251, 0.7987809777259827, 1.007262229919434, 0.0, 1.415021777153015, 0.1157644838094711, 0.0, 3.5614173412323, 0.0, 0.0, 1.488027334213257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.027428984642029, 0.0, 1.647052764892578, 0.0, 1.264791250228882, 0.4563341736793518, 0.2748669385910034, 0.0, 0.0, 1.147633671760559, 0.0, 0.0, 3.034424543380737, 0.9904715418815613, 0.4529311656951904, 3.891671180725098, 3.413293838500977, 0.997211754322052, 0.606963038444519, 0.8225671052932739, 0.0, 0.0, 1.046805620193481, 0.0, 0.882897138595581, 0.0, 0.0, 1.671290993690491, 0.0, 0.0, 0.0, 0.9217772483825684, 0.0, 0.6888652443885803, 0.0, 0.2225726395845413, 1.146008014678955, 0.5971589684486389, 0.0, 0.0, 0.09641071408987045, 1.199419975280762, 0.3218831419944763, 0.0, 1.552604198455811, 0.0, 1.127318978309631, 0.0]], deployed_model_id='3744659527274856448', model_version_id='1', model_resource_name='projects/934903580331/locations/us-central1/models/8411804912207265792', explanations=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c6edc-5687-47ea-871b-ac0b4bee1339",
   "metadata": {},
   "source": [
    "## Finished - now go on to the next notebook to create a matching engine notebook and test out the first end to end recommendation\n",
    "\n",
    "Be sure to use the output of the endpoint logs above to save the endpoint for use in the matching engine notebook\n",
    "\n",
    "e.g.:\n",
    "\n",
    "```python\n",
    "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
    "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/494907775848022016')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9a3ad-19f0-497e-9f85-28c8eedeed61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
