{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `two_tower_src/` for the source code and model code\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n",
    "\n",
    "We will use managed Tensorboard for training. Before beginning, create a new tensorboard instance by going to Vertex -> Experiments -> Tensorboard Instances -> Create\n",
    "\n",
    "![](img/create-a-tb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders google-cloud-aiplatform --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "#### Restart kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "path = 'gs://two-tower-models' #TODO change to your model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 21:48:57.786944: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Copying gs://two-tower-models/vocabs/vocab_dict.pkl...\n",
      "/ [1 files][ 18.5 MiB/ 18.5 MiB]                                                \n",
      "Operation completed over 1 objects/18.5 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from two_tower_jt import two_tower as tt\n",
    "#inside this tt module the data parsing functions, candidate dataset and model classes are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtwo_tower_src\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "├── task.py\n",
      "└── two_tower.py\n",
      "\n",
      "1 directory, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree two_tower_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024*16\n",
    "train_dir = 'spotify-data-regimes'\n",
    "train_dir_prefix = 'jtv8/train_flat_last_5_v8' # 'jtv8/train_flat_last_5_v8' | 'jtv8/train_subset'\n",
    "\n",
    "valid_dir = 'spotify-data-regimes'\n",
    "valid_dir_prefix = 'jtv8/train_flat_valid_last_5_v8' # 'jtv8/train_flat_valid_last_5_v8' 'jtv8/train_subset\n",
    "\n",
    "client = storage.Client()\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    " \n",
    "\n",
    "train_files = []\n",
    "for blob in client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)\n",
    "\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE).batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)\n",
    "\n",
    "# valid_dataset = valid_dataset.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fa77-6401-47bc-b198-14c1891ddcac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adapt the text vectorizors - copy/paste to run one time\n",
    "\n",
    "We are accessing the `TextVectorizor` layers in the model via the layer print-outs above\n",
    "\n",
    "```python\n",
    "# adpat the text vectorizors\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 5 # this is set upstream by the BigQuery max length\n",
    "    \n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['pl_name_src']))\n",
    "print('pl_name_src adapts complete')\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['track_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('track_name_pl adapts complete')\n",
    "model.query_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1]))) \n",
    "print('artist_name_pl adapts complete')\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['album_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('album_name_pl adapts complete')\n",
    "model.query_tower.layers[12].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_genres_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('artist_genres_pl adapts complete')\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['tracks_playlist_titles_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "# print('tracks_playlist_titles_pl adapts complete')\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['track_name_can'])) \n",
    "print('track_name_can adapts complete')\n",
    "model.candidate_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_name_can'])) \n",
    "print('artist_name_can adapts complete')\n",
    "model.candidate_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['album_name_can'])) \n",
    "print('album_name_can adapts complete')\n",
    "model.candidate_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_genres_can'])) \n",
    "print('artist_genres_can adapts complete')\n",
    "# model.candidate_tower.layers[11].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: x['track_pl_titles_can'])) \n",
    "# print('track_pl_titles_can adapts complete')\n",
    "```\n",
    "\n",
    "\n",
    "## Save the vocab dictionary for later so you will not have to adapt\n",
    "\n",
    "```python\n",
    "vocab_dict = {\n",
    "    'pl_name_src' : model.query_tower.layers[0].layers[0].get_vocabulary(),\n",
    "    'track_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(),\n",
    "    'artist_name_pl' : model.query_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'album_name_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(),\n",
    "    'artist_genres_pl' : model.query_tower.layers[12].layers[0].get_vocabulary(),\n",
    "    'tracks_playlist_titles_pl' : model.query_tower.layers[13].layers[0].get_vocabulary(),\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(),\n",
    "    'artist_name_can' : model.candidate_tower.layers[3].layers[0].get_vocabulary(),\n",
    "    'album_name_can' : model.candidate_tower.layers[5].layers[0].get_vocabulary(),\n",
    "    'artist_genres_can' : model.candidate_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'track_pl_titles_can' : model.candidate_tower.layers[11].layers[0].get_vocabulary(),\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### Save the vocabs\n",
    "\n",
    "```python\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl')\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[512,256]\n",
    "\n",
    "model = tt.TheTwoTowers(layer_sizes)\n",
    "\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_duration_ms_new_emb_model\n",
      "3 num_pl_songs_new_emb_model\n",
      "4 num_pl_artists_new_emb_model\n",
      "5 num_pl_albums_new_emb_model\n",
      "6 track_uri_pl_emb_model\n",
      "7 track_name_pl_emb_model\n",
      "8 artist_uri_pl_emb_model\n",
      "9 artist_name_pl_emb_model\n",
      "10 album_uri_pl_emb_model\n",
      "11 album_name_pl_emb_model\n",
      "12 artist_genres_pl_emb_model\n",
      "13 duration_ms_songs_pl_emb_model\n",
      "14 track_pop_pl_emb_model\n",
      "15 artist_pop_pl_emb_model\n",
      "16 artists_followers_pl_emb_model\n",
      "17 track_danceability_pl_emb_model\n",
      "18 track_energy_pl_emb_model\n",
      "19 track_key_pl_emb_model\n",
      "20 track_loudness_pl_emb_model\n",
      "21 track_mode_pl_emb_model\n",
      "22 track_speechiness_pl_emb_model\n",
      "23 track_acousticness_pl_emb_model\n",
      "24 track_instrumentalness_pl_emb_model\n",
      "25 track_liveness_pl_emb_model\n",
      "26 track_valence_pl_emb_model\n",
      "27 track_tempo_pl_emb_model\n",
      "28 time_signature_pl_emb_model\n",
      "29 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 time_signature_can_emb_model\n",
      "23 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Local Training\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "EXPERIMENT_NAME = f'spotify-nb-train-full-jt'\n",
    "RUN_NAME = EXPERIMENT_NAME+'run'+time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "LOG_DIR = path+\"/tb-logs/\"+EXPERIMENT_NAME\n",
    "# 'gs://two-tower-models/tb-logs/spotify-nb-train-full-jt'\n",
    "\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "vertex_ai.init(experiment=EXPERIMENT_NAME)\n",
    "    \n",
    "\n",
    "# we are going to ecapsulate this one-shot log uploader via a custom callback:\n",
    "\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cea523d-812a-4a67-a85f-58b9577a50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Training using tensorboard callback\n",
    "\n",
    "While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3707/Unknown - 13348s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 131082.8571 - regularization_loss: 0.0000e+00 - total_loss: 131082.8571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 01:32:05.571163: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W1228 01:32:07.206982 139740573251392 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-nb-train-full-jt\n",
      "\u001b[1m[2022-12-28T01:32:07]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-12-28T01:32:11]\u001b[0m Total uploaded: 24 scalars, 0 tensors, 3 binary objects (3.0 MB)\n",
      "3708/3708 [==============================] - 13357s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 131074.5407 - regularization_loss: 0.0000e+00 - total_loss: 131074.5407\n",
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/spotify-nb-train-full-jt-run-spotify-nb-train-full-jt-20221227-214932 to Experiment: spotify-nb-train-full-jt\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1\n",
    "RUN_NAME = f'run-{EXPERIMENT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'#be sure to think about run and experiment naming strategies so names don't collide\n",
    "\n",
    "#start the run to collect metrics - note `.log_parameters()` is available but not used\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "layer_history = model.fit(\n",
    "    train_dataset.unbatch().batch(batch_size),\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=3,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=2, #use this for development to run just a few steps\n",
    "    validation_steps = 100,\n",
    "    callbacks=[\n",
    "        tensorboard_callback,\n",
    "        UploadTBLogsBatchEnd()\n",
    "    ], #the tensorboard will be automatically associated with the experiment and log subsequent runs with this callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params({\"layers\": str(layer_sizes), \n",
    "                      \"learning_rate\": LR,\n",
    "                        \"num_epochs\": NUM_EPOCHS,\n",
    "                        \"batch_size\": batch_size,\n",
    "                     })\n",
    "\n",
    "#gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "vertex_ai.log_metrics(metrics_dict) # JT TODO removed for 'total_loss' getting nan\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:\n",
    "\n",
    "![](img/experiment-console.png)\n",
    "\n",
    "![](img/tensorboard.png)\n",
    "\n",
    "### Also, while this is running - check out the Tensorboard profiler in `utils`.\n",
    "\n",
    "![](img/tb-profiler.png)\n",
    "\n",
    "### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`\n",
    "\n",
    "![](img/nvtop-optimized.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 222 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ceb80-2365-4b85-8218-3f721ddebada",
   "metadata": {},
   "source": [
    "### When complete you get a decent model with around 30-40 hit rate for top 1\n",
    "\n",
    "![](img/tb-metrics.png)\n",
    "![](img/tb-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train-time-minutes': 222,\n",
       " 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.0,\n",
       " 'loss': 100245.734375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 100245.734375}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559139c-d669-43b1-8ac2-6155b10ef83e",
   "metadata": {},
   "source": [
    "### Now, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1957-1883-4527-83ee-fd5c9857f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the bucket to store the tensorflow models\n",
    "# ! gsutil mb -l us-central1 $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "559d57ed-540c-41f4-b7cf-d3dad716f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://two-tower-models/run-spotify-nb-train-full-jt-20221227-214932/query_model/assets\n",
      "INFO:tensorflow:Assets written to: gs://two-tower-models/run-spotify-nb-train-full-jt-20221227-214932/candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=path + f\"/{RUN_NAME}/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=path + f\"/{RUN_NAME}/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'candidate_embeddings.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File candidate_embeddings.json uploaded to run-spotify-nb-train-full-jt-20221227-214932/candidates/candidate_embeddings.json.\n"
     ]
    }
   ],
   "source": [
    "tt.upload_blob(\n",
    "    'two-tower-models', \n",
    "    'candidate_embeddings.json', \n",
    "    f'{RUN_NAME}/candidates/candidate_embeddings.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    "(base) jupyter@tf28-jsw-sep-a100:~/spotify_mpd_two_tower$ wc -l candidate_embeddings.json \n",
    "2249561 candidate_embeddings.json\n",
    "```\n",
    "\n",
    "### Finished\n",
    "\n",
    "Go on to the [03 notebook](03-matching-engine.ipynb)\n",
    "\n",
    "You should see results similar to the screenshot below\n",
    "![](img/embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2e2b2-74a8-4485-9db0-22146e4a5159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
