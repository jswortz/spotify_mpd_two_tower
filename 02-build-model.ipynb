{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `two_tower_src/` for the source code and model code\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n",
    "\n",
    "We will use managed Tensorboard for training. Before beginning, create a new tensorboard instance by going to Vertex -> Experiments -> Tensorboard Instances -> Create\n",
    "\n",
    "![](img/create-a-tb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders google-cloud-aiplatform --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "#### Restart kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "path = 'gs://two-tower-models' #TODO change to your model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 02:04:28.613539: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 02:04:28.754004: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-23 02:04:28.795116: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-23 02:04:29.492044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-23 02:04:29.492142: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-23 02:04:29.492152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.7/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "2022-12-23 02:04:32.276359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 02:04:32.947365: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-12-23 02:04:32.947544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
      "Copying gs://two-tower-models/vocabs/vocab_dict.pkl...\n",
      "/ [1 files][ 18.5 MiB/ 18.5 MiB]                                                \n",
      "Operation completed over 1 objects/18.5 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from two_tower_jt import two_tower as tt\n",
    "#inside this tt module the data parsing functions, candidate dataset and model classes are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtwo_tower_src\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "├── task.py\n",
      "└── two_tower.py\n",
      "\n",
      "1 directory, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree two_tower_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024*16\n",
    "train_dir = 'spotify-data-regimes'\n",
    "train_dir_prefix = 'jtv8/train_flat_last_5_v8'\n",
    "\n",
    "valid_dir = 'spotify-data-regimes'\n",
    "valid_dir_prefix = 'jtv8/train_flat_valid_last_5_v8' #spotify-data-regimes/jtv8/train_flat_valid_last_5_v8\n",
    "\n",
    "client = storage.Client()\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    " \n",
    "\n",
    "train_files = []\n",
    "for blob in client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)\n",
    "\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}'):\n",
    "    if '.tfrecords' in blob.name:\n",
    "        valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE).batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)\n",
    "\n",
    "valid_dataset = valid_dataset.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fa77-6401-47bc-b198-14c1891ddcac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adapt the text vectorizors - copy/paste to run one time\n",
    "\n",
    "We are accessing the `TextVectorizor` layers in the model via the layer print-outs above\n",
    "\n",
    "```python\n",
    "# adpat the text vectorizors\n",
    "\n",
    "MAX_PLAYLIST_LENGTH = 5 # this is set upstream by the BigQuery max length\n",
    "    \n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['pl_name_src']))\n",
    "print('pl_name_src adapts complete')\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['track_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('track_name_pl adapts complete')\n",
    "model.query_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1]))) \n",
    "print('artist_name_pl adapts complete')\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['album_name_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('album_name_pl adapts complete')\n",
    "model.query_tower.layers[12].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['artist_genres_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "print('artist_genres_pl adapts complete')\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: tf.reshape(x['tracks_playlist_titles_pl'], [-1, MAX_PLAYLIST_LENGTH, 1])))\n",
    "# print('tracks_playlist_titles_pl adapts complete')\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['track_name_can'])) \n",
    "print('track_name_can adapts complete')\n",
    "model.candidate_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_name_can'])) \n",
    "print('artist_name_can adapts complete')\n",
    "model.candidate_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['album_name_can'])) \n",
    "print('album_name_can adapts complete')\n",
    "model.candidate_tower.layers[9].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(10000).map(lambda x: x['artist_genres_can'])) \n",
    "print('artist_genres_can adapts complete')\n",
    "# model.candidate_tower.layers[11].layers[0].adapt(\n",
    "#     train_dataset.unbatch().batch(10000).map(lambda x: x['track_pl_titles_can'])) \n",
    "# print('track_pl_titles_can adapts complete')\n",
    "```\n",
    "\n",
    "\n",
    "## Save the vocab dictionary for later so you will not have to adapt\n",
    "\n",
    "```python\n",
    "vocab_dict = {\n",
    "    'pl_name_src' : model.query_tower.layers[0].layers[0].get_vocabulary(),\n",
    "    'track_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(),\n",
    "    'artist_name_pl' : model.query_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'album_name_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(),\n",
    "    'artist_genres_pl' : model.query_tower.layers[12].layers[0].get_vocabulary(),\n",
    "    'tracks_playlist_titles_pl' : model.query_tower.layers[13].layers[0].get_vocabulary(),\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(),\n",
    "    'artist_name_can' : model.candidate_tower.layers[3].layers[0].get_vocabulary(),\n",
    "    'album_name_can' : model.candidate_tower.layers[5].layers[0].get_vocabulary(),\n",
    "    'artist_genres_can' : model.candidate_tower.layers[9].layers[0].get_vocabulary(),\n",
    "    'track_pl_titles_can' : model.candidate_tower.layers[11].layers[0].get_vocabulary(),\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### Save the vocabs\n",
    "\n",
    "```python\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl')\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[512,256]\n",
    "\n",
    "model = tt.TheTwoTowers(layer_sizes)\n",
    "\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_duration_ms_new_emb_model\n",
      "3 num_pl_songs_new_emb_model\n",
      "4 num_pl_artists_new_emb_model\n",
      "5 num_pl_albums_new_emb_model\n",
      "6 track_uri_pl_emb_model\n",
      "7 track_name_pl_emb_model\n",
      "8 artist_uri_pl_emb_model\n",
      "9 artist_name_pl_emb_model\n",
      "10 album_uri_pl_emb_model\n",
      "11 album_name_pl_emb_model\n",
      "12 artist_genres_pl_emb_model\n",
      "13 duration_ms_songs_pl_emb_model\n",
      "14 track_pop_pl_emb_model\n",
      "15 artist_pop_pl_emb_model\n",
      "16 artists_followers_pl_emb_model\n",
      "17 track_danceability_pl_emb_model\n",
      "18 track_energy_pl_emb_model\n",
      "19 track_key_pl_emb_model\n",
      "20 track_loudness_pl_emb_model\n",
      "21 track_mode_pl_emb_model\n",
      "22 track_speechiness_pl_emb_model\n",
      "23 track_acousticness_pl_emb_model\n",
      "24 track_instrumentalness_pl_emb_model\n",
      "25 track_liveness_pl_emb_model\n",
      "26 track_valence_pl_emb_model\n",
      "27 track_tempo_pl_emb_model\n",
      "28 time_signature_pl_emb_model\n",
      "29 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 time_signature_can_emb_model\n",
      "23 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Local Training\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "EXPERIMENT_NAME = f'spotify-singe-node-train-large-data-jt'\n",
    "RUN_NAME = EXPERIMENT_NAME+'run'+time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "LOG_DIR = path+\"/tb-logs/\"+EXPERIMENT_NAME\n",
    "\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "vertex_ai.init(experiment=EXPERIMENT_NAME)\n",
    "    \n",
    "\n",
    "# we are going to ecapsulate this one-shot log uploader via a custom callback:\n",
    "\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cea523d-812a-4a67-a85f-58b9577a50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Training using tensorboard callback\n",
    "\n",
    "While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'playlist__model/track_danceability_pl_emb_model/discretization_8/Bucketize' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_17452/4163511936.py\", line 17, in <module>\n      verbose=1\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n      loss = self.compute_loss(inputs, training=True)\n    File \"/home/jupyter/spotify_mpd_two_tower/two_tower_jt/two_tower.py\", line 1289, in compute_loss\n      query_embeddings = self.query_tower(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jupyter/spotify_mpd_two_tower/two_tower_jt/two_tower.py\", line 781, in call\n      all_embs = tf.concat(\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/discretization.py\", line 435, in call\n      indices = bucketize(inputs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/discretization.py\", line 423, in bucketize\n      input=inputs, boundaries=self.bin_boundaries\nNode: 'playlist__model/track_danceability_pl_emb_model/discretization_8/Bucketize'\nExpected sorted boundaries\n\t [[{{node playlist__model/track_danceability_pl_emb_model/discretization_8/Bucketize}}]] [Op:__inference_train_function_11515]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17452/4163511936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     callbacks=[tensorboard_callback,\n\u001b[1;32m     16\u001b[0m                UploadTBLogsBatchEnd()], #the tensorboard will be automatically associated with the experiment and log subsequent runs with this callback\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'playlist__model/track_danceability_pl_emb_model/discretization_8/Bucketize' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_17452/4163511936.py\", line 17, in <module>\n      verbose=1\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jupyter/.local/lib/python3.7/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n      loss = self.compute_loss(inputs, training=True)\n    File \"/home/jupyter/spotify_mpd_two_tower/two_tower_jt/two_tower.py\", line 1289, in compute_loss\n      query_embeddings = self.query_tower(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jupyter/spotify_mpd_two_tower/two_tower_jt/two_tower.py\", line 781, in call\n      all_embs = tf.concat(\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/discretization.py\", line 435, in call\n      indices = bucketize(inputs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/discretization.py\", line 423, in bucketize\n      input=inputs, boundaries=self.bin_boundaries\nNode: 'playlist__model/track_danceability_pl_emb_model/discretization_8/Bucketize'\nExpected sorted boundaries\n\t [[{{node playlist__model/track_danceability_pl_emb_model/discretization_8/Bucketize}}]] [Op:__inference_train_function_11515]"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1\n",
    "RUN_NAME = f'run-{EXPERIMENT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'#be sure to think about run and experiment naming strategies so names don't collide\n",
    "\n",
    "#start the run to collect metrics - note `.log_parameters()` is available but not used\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "layer_history = model.fit(\n",
    "    train_dataset.unbatch().batch(batch_size),\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=3,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=2, #use this for development to run just a few steps\n",
    "    validation_steps = 100,\n",
    "    callbacks=[tensorboard_callback,\n",
    "               UploadTBLogsBatchEnd()], #the tensorboard will be automatically associated with the experiment and log subsequent runs with this callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params({\"layers\": str(layer_sizes), \n",
    "                      \"learning_rate\": LR,\n",
    "                        \"num_epochs\": epochs,\n",
    "                        \"batch_size\": batch_size,\n",
    "                     })\n",
    "\n",
    "#gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "vertex_ai.log_metrics(metrics_dict)\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:\n",
    "\n",
    "![](img/experiment-console.png)\n",
    "\n",
    "![](img/tensorboard.png)\n",
    "\n",
    "### Also, while this is running - check out the Tensorboard profiler in `utils`.\n",
    "\n",
    "![](img/tb-profiler.png)\n",
    "\n",
    "### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`\n",
    "\n",
    "![](img/nvtop-optimized.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ceb80-2365-4b85-8218-3f721ddebada",
   "metadata": {},
   "source": [
    "### When complete you get a decent model with around 30-40 hit rate for top 1\n",
    "\n",
    "![](img/tb-metrics.png)\n",
    "![](img/tb-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559139c-d669-43b1-8ac2-6155b10ef83e",
   "metadata": {},
   "source": [
    "### Now, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1957-1883-4527-83ee-fd5c9857f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the bucket to store the tensorflow models\n",
    "# ! gsutil mb -l us-central1 $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d57ed-540c-41f4-b7cf-d3dad716f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=path + \"/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=path + \"/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.upload_blob('two-tower-models', 'candidate_embeddings.json', 'candidates/candidate_embeddings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    "(base) jupyter@tf28-jsw-sep-a100:~/spotify_mpd_two_tower$ wc -l candidate_embeddings.json \n",
    "2249561 candidate_embeddings.json\n",
    "```\n",
    "\n",
    "### Finished\n",
    "\n",
    "Go on to the [03 notebook](03-matching-engine.ipynb)\n",
    "\n",
    "You should see results similar to the screenshot below\n",
    "![](img/embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2e2b2-74a8-4485-9db0-22146e4a5159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
