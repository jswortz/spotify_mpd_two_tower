{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `two_tower_src/` for the source code and model code\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n",
    "\n",
    "We will use managed Tensorboard for training. Before begininning, create a new tensorboard instance by going to Vertex -> Experiments -> Tensorboard Instances -> Create\n",
    "\n",
    "![](img/create-a-tb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders==0.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "path = 'gs://two-tower-models' #TODO change to your model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:15:44.577544: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-11 13:15:45.215830: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-10-11 13:15:45.216081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38238 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from two_tower_src import two_tower as tt\n",
    "#inside this tt module the data parsing functions, candidate dataset and model classes are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtwo_tower_src\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "└── two_tower.py\n",
      "\n",
      "1 directory, 4 files\n"
     ]
    }
   ],
   "source": [
    "!tree two_tower_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40000\n",
    "train_dir = 'spotify-beam-v3'\n",
    "train_dir_prefix = 'v6/train_last_5_v2/'\n",
    "\n",
    "valid_dir = 'spotify-beam-v3'\n",
    "valid_dir_prefix = 'v6/valid_last_5/'\n",
    "\n",
    "client = storage.Client()\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    " \n",
    "\n",
    "train_files = []\n",
    "for blob in client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}', delimiter=\"/\"):\n",
    "    train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.interleave(\n",
    "    full_parse,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "    batch_size \n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)\n",
    "\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.interleave(\n",
    "    full_parse,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    cycle_length=tf.data.AUTOTUNE, \n",
    "    deterministic=False,\n",
    ").map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE).batch(\n",
    "    batch_size\n",
    ").prefetch(\n",
    "    tf.data.AUTOTUNE,\n",
    ").with_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[256,128]\n",
    "model = tt.TheTwoTowers(layer_sizes)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_emb_model\n",
      "1 pl_collaborative_emb_model\n",
      "2 pl_track_uri_emb_model\n",
      "3 n_songs_pl_emb_model\n",
      "4 n_artists_pl_emb_model\n",
      "5 n_albums_pl_emb_model\n",
      "6 artist_name_pl_emb_model\n",
      "7 track_uri_pl_emb_model\n",
      "8 track_name_pl_emb_model\n",
      "9 duration_ms_songs_pl_emb_model\n",
      "10 album_name_pl_emb_model\n",
      "11 artist_pop_pl_emb_model\n",
      "12 artists_followers_pl_emb_model\n",
      "13 track_pop_pl_emb_model\n",
      "14 artist_genres_pl_emb_model\n",
      "15 pl_cross_layer\n",
      "16 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 artist_name_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 album_name_can_emb_model\n",
      "3 artist_uri_can_emb_model\n",
      "4 track_uri_can_emb_model\n",
      "5 album_uri_can_emb_model\n",
      "6 duration_ms_can_normalized\n",
      "7 track_pop_can_normalized\n",
      "8 artist_pop_can_normalized\n",
      "9 artist_followers_can_normalized\n",
      "10 artist_genres_can_emb_model\n",
      "11 can_cross_layer\n",
      "12 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {},
   "source": [
    "### Local training for ten Epochs\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "EXPERIMENT_NAME = f'spotify-singe-node-train-full-data-{invoke_time}'\n",
    "LOG_DIR = path+\"/tb-logs/\"+EXPERIMENT_NAME\n",
    "\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command():\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    \"\"\"\n",
    "    print(f\"\"\"Helper for copy/past TF log upload command:\n",
    "\n",
    "    tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} --one_shot=False\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cea523d-812a-4a67-a85f-58b9577a50cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:15:58.205900: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-10-11 13:15:58.205943: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-10-11 13:15:58.206044: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-10-11 13:15:58.207221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper for copy/past TF log upload command:\n",
      "\n",
      "    tb-gcp-uploader --tensorboard_resource_name=projects/934903580331/locations/us-central1/tensorboards/7336372589079560192       --logdir=gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552       --experiment_name=spotify-singe-node-train-full-data-20221011-131552 --one_shot=False\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:15:58.387966: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-10-11 13:15:58.388195: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "logs_dir = f'{path}/tb-logs/{EXPERIMENT_NAME}'\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logs_dir,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        profile_batch=(20,50) #run profiler on steps 20-40\n",
    "    )\n",
    "\n",
    "get_upload_logs_to_manged_tb_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Training using tensorboard callback\n",
    "\n",
    "While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:16:12.237968: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-10-11 13:16:12.238019: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-10-11 13:16:27.430554: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-10-11 13:16:27.430612: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-10-11 13:17:09.873017: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-10-11 13:17:10.247155: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-10-11 13:17:35.590855: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 44859 callback api events and 44828 activity events. \n",
      "2022-10-11 13:17:56.316286: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-10-11 13:18:37.769334: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56\n",
      "\n",
      "2022-10-11 13:18:42.019928: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.trace.json.gz\n",
      "2022-10-11 13:18:48.659461: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56\n",
      "\n",
      "2022-10-11 13:18:48.793287: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.memory_profile.json.gz\n",
      "2022-10-11 13:18:56.903445: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56\n",
      "Dumped tool data for xplane.pb to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.xplane.pb\n",
      "Dumped tool data for overview_page.pb to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to gs://two-tower-models/tb-logs/spotify-singe-node-train-full-data-20221011-131552/plugins/profile/2022_10_11_13_17_56/tf28-jsw-sep-a100.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 9\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "layer_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=3,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=2, #use this for development to run just a few steps\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=0\n",
    ")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "Open up the terminal and run the command from above - here's an example:\n",
    "\n",
    "![](img/upload-tb-logs.png)\n",
    "\n",
    "#### **Notice the link to the managed tensorboard**\n",
    "\n",
    "You can also access the experiment from the console via the name you just declared:\n",
    "\n",
    "![](img/experiment-console.png)\n",
    "\n",
    "![](img/tensorboard.png)\n",
    "\n",
    "### Also, while this is running - check out the Tensorboard profiler in `utils`.\n",
    "\n",
    "![](img/tb-profiler.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_keys = [v for v in layer_history.history.keys() if 'val' in v]\n",
    "print([(key, layer_history.history[key]) for key in val_keys])\n",
    "                      #'val_factorized_top_k/top_1_categorical_accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559139c-d669-43b1-8ac2-6155b10ef83e",
   "metadata": {},
   "source": [
    "### Now, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1957-1883-4527-83ee-fd5c9857f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the bucket to store the tensorflow models\n",
    "# ! gsutil mb -l us-central1 $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d57ed-540c-41f4-b7cf-d3dad716f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=path + \"/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=path + \"/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the required format\n",
    "\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'w') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "    # bucket_name = bucket_name.strip(\"gs://\")\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )\n",
    "upload_blob('two-tower-models', 'candidate_embeddings.json', 'candidates/candidate_embeddings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Finished\n",
    "\n",
    "Go on to the [03 notebook](03-matching-engine.ipynb)\n",
    "\n",
    "You should see results similar to the screenshot below\n",
    "![](img/embeddings.png)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
