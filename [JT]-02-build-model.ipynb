{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2804db33-2adb-4845-a6bb-087f168eb6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Build baseline tfrs model \n",
    "\n",
    "Look inside of `two_tower_src/` for the source code and model code\n",
    "\n",
    "This notebook constructs the two tower model and saves the model to GCS\n",
    "\n",
    "We will use managed Tensorboard for training. Before beginning, create a new tensorboard instance by going to Vertex -> Experiments -> Tensorboard Instances -> Create\n",
    "\n",
    "![](img/create-a-tb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c0d02-8de1-446e-9b2c-7366dfff042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-recommenders --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2a891-1129-480d-ad11-f8f78ce062b8",
   "metadata": {},
   "source": [
    "#### Restart kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9289ca69-cd66-4161-88b2-db58e9218b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "path = 'gs://jt-tfrs-output-v2' #TODO change to your model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d6dd36-f5ae-40cb-b76e-480b9782cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE']='gpu_private'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3417e6-72a8-48e2-ba9d-8fd207ab6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:07:13.034908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 16:07:13.666448: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-12-06 16:07:13.666712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38238 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# from two_tower_src import two_tower as tt\n",
    "from two_tower_jt import two_tower as tt\n",
    "#inside this tt module the data parsing functions, candidate dataset and model classes are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015b9c5-f6f8-46b3-998c-9ceb0ca65962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataset for local training and testing\n",
    "\n",
    "Inspect the contents of the directory - you can change parameters in the header of the `two_tower.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e48504-5598-4f8d-b996-9f0f9192e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtwo_tower_jt\u001b[00m\n",
      "├── __init__.py\n",
      "├── \u001b[01;34m__pycache__\u001b[00m\n",
      "│   ├── __init__.cpython-37.pyc\n",
      "│   └── two_tower.cpython-37.pyc\n",
      "├── task.py\n",
      "└── two_tower.py\n",
      "\n",
      "1 directory, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree two_tower_jt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984676ac-e3bc-4c34-9875-3113130e418b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Playlist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6b7ccd-03b3-4cf7-ab25-41701d10063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "batch_size = 1024*16\n",
    "\n",
    "client = storage.Client()\n",
    "# options = tf.data.Options()\n",
    "# options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n",
    "\n",
    "def full_parse(data):\n",
    "    # used for interleave - takes tensors and returns a tf.dataset\n",
    "    data = tf.data.TFRecordDataset(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0099fb-8f49-41e2-98ae-c75540def07f",
   "metadata": {},
   "source": [
    "### train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b03553df-06ea-4e76-b766-a8171acb2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dir = 'spotify-data-regimes'\n",
    "train_dir_prefix = 'jtv5/train_last_5_feats_v4/'\n",
    "\n",
    "train_files = []\n",
    "for blob in client.list_blobs(f'{train_dir}', prefix=f'{train_dir_prefix}', delimiter=\"/\"):\n",
    "    train_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "    \n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(train_files).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "# train_dataset = train_dataset.interleave(\n",
    "#     full_parse,\n",
    "#     cycle_length=tf.data.AUTOTUNE, \n",
    "#     num_parallel_calls=tf.data.AUTOTUNE,\n",
    "#     deterministic=False,\n",
    "# ).shuffle(batch_size*4, reshuffle_each_iteration=False).map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE,).batch(\n",
    "#     batch_size \n",
    "# ).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# ).with_options(options)\n",
    "\n",
    "# train_files = [\n",
    "#     'gs://spotify-data-regimes/jtv5/train_last_5_feats_v4/-00000-of-00899.tfrecords',\n",
    "#     'gs://spotify-data-regimes/jtv5/train_last_5_feats_v4/-00001-of-00899.tfrecords',\n",
    "# ]\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "train_parsed = train_dataset.map(tt.parse_tfrecord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0c549c-8844-4ff0-81cc-db39e224c44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'avg_art_followers_pl_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'avg_artist_pop_pl_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'avg_track_pop_pl_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_followers_src': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f5e263-3cd8-4672-863b-4d1077651b52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Al Principio'>,\n",
      " 'album_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Amor, Familia Y Respeto', b'Controlmania', b'Al Principio',\n",
      "       b'40 \\xc3\\x89xitos', b'Grandes Exitos', b'Desde La Cantina'],\n",
      "      dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:56cikzve6YOgyurLWMCcVP'>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:album:5XuNzqgx79H4Z2jhfdzFFQ',\n",
      "       b'spotify:album:2kwllRxwlNWED6dWA7jGqb',\n",
      "       b'spotify:album:56cikzve6YOgyurLWMCcVP',\n",
      "       b'spotify:album:7L9TeAqSwkvSkFzyogoVxd',\n",
      "       b'spotify:album:6jSBHoKlkbnoLzNKnvmr3R',\n",
      "       b'spotify:album:5516JjJfiO6IGxBuPjZIyy'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=116537.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'norteno', 'tejano', 'tex-mex'\">,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b\"'tejano', 'tropical'\", b\"'cumbia sonorense'\",\n",
      "       b\"'norteno', 'tejano', 'tex-mex'\", b\"'musica mexicana', 'norteno'\",\n",
      "       b\"'tejano', 'tex-mex'\",\n",
      "       b\"'musica mexicana', 'norteno', 'ranchera', 'tropical'\"],\n",
      "      dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Siggno'>,\n",
      " 'artist_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'A.B. Quintanilla III', b'Control', b'Siggno',\n",
      "       b'Ramon Ayala Y Sus Bravos Del Norte', b'Albert Zamora', b'Pesado'],\n",
      "      dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=51.0>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([59., 58., 51., 67., 30., 70.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:6RTlv2UCWtRggV0rIo5TrN'>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:artist:5MP9bH9aUryiKQeUvABLIU',\n",
      "       b'spotify:artist:69BX3Y0Y9rzA039eZX2hdx',\n",
      "       b'spotify:artist:6RTlv2UCWtRggV0rIo5TrN',\n",
      "       b'spotify:artist:5j9R5dTGerKvdXopZnfJh9',\n",
      "       b'spotify:artist:7lXqL62OtG8r86tC9Bwr55',\n",
      "       b'spotify:artist:4BwiodzEp9Hwes5HeFjMVK'], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([  89267.,   36532.,  116537.,  371549.,   36955., 1479129.],\n",
      "      dtype=float32)>,\n",
      " 'avg_art_followers_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=493153.75>,\n",
      " 'avg_artist_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=47.714287>,\n",
      " 'avg_track_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=31.446428>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=223840.0>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([208773., 192040., 223840., 182906., 231200., 222333.],\n",
      "      dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=52.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=38.0>,\n",
      " 'num_pl_followers_src': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=56.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=12208453.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'Practice'>,\n",
      " 'time_signature_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'4', b'4', b'4', b'4', b'4', b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.511>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.353, 0.185, 0.511, 0.476, 0.186, 0.27 ], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.557>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.832, 0.8  , 0.557, 0.75 , 0.756, 0.675], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.672>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.628, 0.861, 0.672, 0.732, 0.584, 0.667], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=6.38e-06>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([0.00e+00, 2.23e-04, 6.38e-06, 2.21e-05, 1.96e-04, 7.65e-05],\n",
      "      dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'10'>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'2', b'8', b'10', b'9', b'5', b'3'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.19>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.285 , 0.0414, 0.19  , 0.0641, 0.156 , 0.38  ], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-4.859>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([ -6.203,  -5.257,  -4.859,  -3.497, -10.925,  -6.963],\n",
      "      dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'0', b'1', b'1', b'1', b'1', b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Golpes En El Corazon'>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Az\\xc3\\xbacar', b'Viva El Amor', b'Golpes En El Corazon',\n",
      "       b'Qu\\xc3\\xa9 Casualidad', b'Prieta Casada',\n",
      "       b'Prenda Querida - Live At Nuevo Le\\xc3\\xb3n M\\xc3\\xa9xico/2009'],\n",
      "      dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=7.0>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([47., 34.,  7., 49.,  0., 51.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0355>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.0367, 0.048 , 0.0355, 0.0311, 0.0848, 0.108 ], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=181.047>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([ 97.987, 102.095, 181.047, 105.217,  97.664, 105.919],\n",
      "      dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:2cIhxAa5P2wadPkPSIrTTq'>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:track:3KdOm1GJJWYDTQmIbRIkcL',\n",
      "       b'spotify:track:3n1U6vEfRasKm4lz2wAmvh',\n",
      "       b'spotify:track:2cIhxAa5P2wadPkPSIrTTq',\n",
      "       b'spotify:track:2IeZVwidxkQVzmt4Lyza8m',\n",
      "       b'spotify:track:0eHCUL6N4UqUQP9Fn37pQd',\n",
      "       b'spotify:track:4KI8e27EBdJFTMkY01oauL'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.737>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.935, 0.763, 0.737, 0.888, 0.83 , 0.665], dtype=float32)>}\n",
      "_______________\n",
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Basket Case'>,\n",
      " 'album_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Come What(ever) May', b'Garage Inc.', b'Pisces Iscariot',\n",
      "       b'Home', b'Basket Case', b'Results May Vary'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:2A6dANZ8CTSUU4ehJ5rUgn'>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:album:0dZB8UHYsM7jKmm7ByzAVq',\n",
      "       b'spotify:album:3ZV7cKhLYQ8Z3p2oT36tZd',\n",
      "       b'spotify:album:0WMWadJs4xUOIv5bmgR79W',\n",
      "       b'spotify:album:1zgQkZFMRqx1Lz9GVXghLt',\n",
      "       b'spotify:album:2A6dANZ8CTSUU4ehJ5rUgn',\n",
      "       b'spotify:album:0qxadqjY5ZtZPw1kzjCUGp'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=4990191.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'metropopolis', 'modern rock', 'pop', 'pop rock'\">,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b\"'alternative metal', 'nu metal', 'post-grunge', 'rap rock', 'rock'\",\n",
      "       b\"'hard rock', 'metal', 'old school thrash', 'rock', 'thrash metal'\",\n",
      "       b\"'alternative metal', 'alternative rock', 'grunge', 'permanent wave', 'pop rock', 'rock'\",\n",
      "       b\"'country', 'country dawn'\",\n",
      "       b\"'metropopolis', 'modern rock', 'pop', 'pop rock'\",\n",
      "       b\"'alternative metal', 'funk metal', 'nu metal', 'rap metal'\"],\n",
      "      dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Bastille'>,\n",
      " 'artist_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Stone Sour', b'Metallica', b'The Smashing Pumpkins',\n",
      "       b'Dixie Chicks', b'Bastille', b'Limp Bizkit'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=80.0>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([68., 84., 75., 70., 80., 76.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:7EQ0qTo7fWT7DPxmxtSYEc'>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:artist:49qiE8dj4JuNdpYGRPdKbF',\n",
      "       b'spotify:artist:2ye2Wgw4gimLv2eAKyk1NB',\n",
      "       b'spotify:artist:40Yq4vzPs9VNUrIBG5Jr2i',\n",
      "       b'spotify:artist:25IG9fa7cbdmCIy3OnuH57',\n",
      "       b'spotify:artist:7EQ0qTo7fWT7DPxmxtSYEc',\n",
      "       b'spotify:artist:165ZgPlLkK7bf5bDoFc6Sb'], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([ 2485285., 20762412.,  3815292.,  1229029.,  4990191.,  4665904.],\n",
      "      dtype=float32)>,\n",
      " 'avg_art_followers_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=4401787.0>,\n",
      " 'avg_artist_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=70.13636>,\n",
      " 'avg_track_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=32.272728>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=153548.0>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([267253., 366466., 190586., 230549., 153548., 269973.],\n",
      "      dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=22.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=21.0>,\n",
      " 'num_pl_followers_src': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=22.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=5690013.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'Covers'>,\n",
      " 'time_signature_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'4', b'4', b'3', b'4', b'4', b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.412>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([6.44e-01, 1.94e-05, 8.96e-01, 5.34e-01, 4.12e-01, 4.89e-01],\n",
      "      dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.593>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.561, 0.426, 0.422, 0.571, 0.593, 0.589], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.58>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.337, 0.813, 0.208, 0.438, 0.58 , 0.484], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([8.79e-05, 2.20e-02, 2.65e-02, 1.56e-05, 0.00e+00, 0.00e+00],\n",
      "      dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'8', b'8', b'10', b'2', b'1', b'7'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0996>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.67  , 0.0937, 0.192 , 0.187 , 0.0996, 0.113 ], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-5.681>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([ -9.272,  -3.963, -15.886,  -7.007,  -5.681,  -6.622],\n",
      "      dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Basket Case - From \\xe2\\x80\\x98The Tick\\xe2\\x80\\x99 TV Series'>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Wicked Game - Live Acoustic', b'Turn The Page', b'Landslide',\n",
      "       b'Landslide',\n",
      "       b'Basket Case - From \\xe2\\x80\\x98The Tick\\xe2\\x80\\x99 TV Series',\n",
      "       b'Behind Blue Eyes'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([69.,  0.,  0., 71.,  0.,  0.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0913>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.0284, 0.0318, 0.0318, 0.0279, 0.0913, 0.0266], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=77.483>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([109.373, 149.013, 111.549, 145.948,  77.483, 120.258],\n",
      "      dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:2XbPIycgx6OkOXQ9IHbbmL'>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:track:3V1H6liHwCDcWeqdPJabOM',\n",
      "       b'spotify:track:5WpDQOIHa6ba3rJSay0udr',\n",
      "       b'spotify:track:2dc1BYopTHgviDXawShfME',\n",
      "       b'spotify:track:5hviCr3lgg6LY6noG6DPKs',\n",
      "       b'spotify:track:2XbPIycgx6OkOXQ9IHbbmL',\n",
      "       b'spotify:track:1KXrIYY9fvjI0wN4gc4BVN'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.397>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.273 , 0.228 , 0.354 , 0.444 , 0.397 , 0.0927], dtype=float32)>}\n",
      "_______________\n",
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Acoustic'>,\n",
      " 'album_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Slipknot', b'.5: The Gray Chapter', b'Acoustic', b'Iowa',\n",
      "       b'Iowa', b'All Hope Is Gone'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:1t0WDZ56KeBhQSLH3YeeUb'>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:album:5lOFvOWAdy9G6p44noRILU',\n",
      "       b'spotify:album:0ApKaazNHf0gzjAYZauexq',\n",
      "       b'spotify:album:1t0WDZ56KeBhQSLH3YeeUb',\n",
      "       b'spotify:album:5Zs0mNCTs73CqPKbZPWFX9',\n",
      "       b'spotify:album:5Zs0mNCTs73CqPKbZPWFX9',\n",
      "       b'spotify:album:0hFWapnP7orzXCMwNU5DuA'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=190284.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'alternative emo', 'emo', 'pop punk', 'post-hardcore', 'screamo'\">,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b\"'alternative metal', 'nu metal', 'rap metal'\",\n",
      "       b\"'alternative metal', 'nu metal', 'rap metal'\",\n",
      "       b\"'alternative emo', 'emo', 'pop punk', 'post-hardcore', 'screamo'\",\n",
      "       b\"'alternative metal', 'nu metal', 'rap metal'\",\n",
      "       b\"'alternative metal', 'nu metal', 'rap metal'\",\n",
      "       b\"'alternative metal', 'nu metal', 'rap metal'\"], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Bayside'>,\n",
      " 'artist_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Slipknot', b'Slipknot', b'Bayside', b'Slipknot', b'Slipknot',\n",
      "       b'Slipknot'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=55.0>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([80., 80., 55., 80., 80., 80.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:51J0q8S7W3kIEYHQi3EPqk'>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:artist:05fG473iIaoy82BF1aGhL8',\n",
      "       b'spotify:artist:05fG473iIaoy82BF1aGhL8',\n",
      "       b'spotify:artist:51J0q8S7W3kIEYHQi3EPqk',\n",
      "       b'spotify:artist:05fG473iIaoy82BF1aGhL8',\n",
      "       b'spotify:artist:05fG473iIaoy82BF1aGhL8',\n",
      "       b'spotify:artist:05fG473iIaoy82BF1aGhL8'], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([8186047., 8186047.,  190284., 8186047., 8186047., 8186047.],\n",
      "      dtype=float32)>,\n",
      " 'avg_art_followers_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=3118827.0>,\n",
      " 'avg_artist_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=71.74>,\n",
      " 'avg_track_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=44.02>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=205880.0>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([147840., 342821., 205880., 241466., 254000., 283400.],\n",
      "      dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=59.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=26.0>,\n",
      " 'num_pl_followers_src': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=100.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=23927056.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'good'>,\n",
      " 'time_signature_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'4', b'4', b'4', b'4', b'4', b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.676>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([2.08e-03, 5.91e-03, 6.76e-01, 7.03e-05, 5.62e-04, 2.52e-03],\n",
      "      dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.662>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.382, 0.398, 0.662, 0.229, 0.451, 0.576], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.419>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.996, 0.939, 0.419, 0.994, 0.993, 0.989], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=2.64e-05>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([0.00e+00, 8.81e-04, 2.64e-05, 5.48e-03, 4.79e-03, 3.20e-03],\n",
      "      dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'9'>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'7', b'9', b'9', b'6', b'1', b'2'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.105>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.417 , 0.357 , 0.105 , 0.318 , 0.152 , 0.0243], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-7.595>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([-4.119, -2.865, -7.595, -3.431, -4.143, -1.909], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'1', b'0', b'1', b'1', b'1', b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Megan'>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Wait And Bleed', b'The Devil In I', b'Megan', b'Left Behind',\n",
      "       b'The Heretic Anthem', b'Psychosocial'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=39.0>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([64., 75., 39., 66., 66., 69.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0291>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.104 , 0.0648, 0.0291, 0.22  , 0.185 , 0.112 ], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=138.016>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([ 93.345,  92.027, 138.016, 156.623, 100.827, 135.093],\n",
      "      dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:23PQ6hqh68lotMLk2ukhMY'>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:track:15DLl1r2zi07Ssq5RT1yT0',\n",
      "       b'spotify:track:5hheGdf1cb4rK0FNiedCfK',\n",
      "       b'spotify:track:23PQ6hqh68lotMLk2ukhMY',\n",
      "       b'spotify:track:4l3Vmsw0KO8HJqFtnbqaqu',\n",
      "       b'spotify:track:3OYZWMm5m2DEwq2Tc1ukTh',\n",
      "       b'spotify:track:2MvIMgtWyK88OiPi0J8Dg3'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.391>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.327, 0.235, 0.391, 0.115, 0.14 , 0.352], dtype=float32)>}\n",
      "_______________\n",
      "{'album_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'One Day Maybe'>,\n",
      " 'album_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'Mission Blvd.', b'No Shame', b'One Day Maybe', b'Representing',\n",
      "       b'Exodus', b'No Ceilings'], dtype=object)>,\n",
      " 'album_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:album:2jFQPbYW6oYn86f83Jsg4Q'>,\n",
      " 'album_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:album:1tSKnxizVUsc73EhRfOMKn',\n",
      "       b'spotify:album:1r1dc5yTdwHQk77JZibmCF',\n",
      "       b'spotify:album:2jFQPbYW6oYn86f83Jsg4Q',\n",
      "       b'spotify:album:24Nm4WqbpFrtAsgE5Ba3ab',\n",
      "       b'spotify:album:3q8y9MBuOdOzwJb8QJfwBG',\n",
      "       b'spotify:album:4VbS6wUqyJ6kYEfD41ichL'], dtype=object)>,\n",
      " 'artist_followers_can': <tf.Tensor: shape=(), dtype=float32, numpy=29848.0>,\n",
      " 'artist_genres_can': <tf.Tensor: shape=(), dtype=string, numpy=b\"'jawaiian', 'reggae rock'\">,\n",
      " 'artist_genres_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b\"'jawaiian', 'reggae rock'\", b\"'reggae fusion', 'reggae rock'\",\n",
      "       b\"'jawaiian', 'reggae rock'\",\n",
      "       b\"'modern reggae', 'reggae', 'reggae rock', 'roots reggae', 'west coast reggae'\",\n",
      "       b\"'reggae', 'roots reggae'\", b''], dtype=object)>,\n",
      " 'artist_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Sashamon'>,\n",
      " 'artist_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'One Drop', b'Pepper', b'Sashamon', b'Tribal Seeds',\n",
      "       b'Bob Marley & The Wailers', b'Foreign Talks'], dtype=object)>,\n",
      " 'artist_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=45.0>,\n",
      " 'artist_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([36., 60., 45., 57., 82., 26.], dtype=float32)>,\n",
      " 'artist_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:artist:3EogSxYXgnES1hVk0nxB8X'>,\n",
      " 'artist_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:artist:5pf5LNOq8NQJYCS44cF8Kw',\n",
      "       b'spotify:artist:1YK8JdPbiaMSnf4hrlBkGT',\n",
      "       b'spotify:artist:3EogSxYXgnES1hVk0nxB8X',\n",
      "       b'spotify:artist:7jgZFR40bWjwOrRCOZFB02',\n",
      "       b'spotify:artist:2QsynagSdAqZj3U9HgDzjD',\n",
      "       b'spotify:artist:51HbHoxcd4xNgXl0uxWXnj'], dtype=object)>,\n",
      " 'artists_followers_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([2.2204000e+04, 3.2526600e+05, 2.9848000e+04, 2.7366800e+05,\n",
      "       1.0417487e+07, 5.0400000e+03], dtype=float32)>,\n",
      " 'avg_art_followers_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=1457355.8>,\n",
      " 'avg_artist_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=60.09434>,\n",
      " 'avg_track_pop_pl_new': <tf.Tensor: shape=(), dtype=float32, numpy=29.150944>,\n",
      " 'duration_ms_can': <tf.Tensor: shape=(), dtype=float32, numpy=318893.0>,\n",
      " 'duration_ms_songs_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([281840., 218480., 318893., 341279., 172933., 179773.],\n",
      "      dtype=float32)>,\n",
      " 'num_pl_albums_new': <tf.Tensor: shape=(), dtype=float32, numpy=44.0>,\n",
      " 'num_pl_artists_new': <tf.Tensor: shape=(), dtype=float32, numpy=32.0>,\n",
      " 'num_pl_followers_src': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      " 'num_pl_songs_new': <tf.Tensor: shape=(), dtype=float32, numpy=53.0>,\n",
      " 'pl_collaborative_src': <tf.Tensor: shape=(), dtype=string, numpy=b'false'>,\n",
      " 'pl_duration_ms_new': <tf.Tensor: shape=(), dtype=float32, numpy=12998508.0>,\n",
      " 'pl_name_src': <tf.Tensor: shape=(), dtype=string, numpy=b'EZ'>,\n",
      " 'time_signature_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'4', b'4', b'4', b'4', b'4', b'4'], dtype=object)>,\n",
      " 'track_acousticness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.203>,\n",
      " 'track_acousticness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.139 , 0.0249, 0.203 , 0.161 , 0.0783, 0.457 ], dtype=float32)>,\n",
      " 'track_danceability_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.888>,\n",
      " 'track_danceability_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.907, 0.717, 0.888, 0.756, 0.725, 0.551], dtype=float32)>,\n",
      " 'track_energy_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.386>,\n",
      " 'track_energy_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.564, 0.728, 0.386, 0.539, 0.523, 0.658], dtype=float32)>,\n",
      " 'track_instrumentalness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0236>,\n",
      " 'track_instrumentalness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([2.56e-05, 0.00e+00, 2.36e-02, 2.78e-05, 0.00e+00, 0.00e+00],\n",
      "      dtype=float32)>,\n",
      " 'track_key_can': <tf.Tensor: shape=(), dtype=string, numpy=b'7'>,\n",
      " 'track_key_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'9', b'2', b'7', b'0', b'10', b'9'], dtype=object)>,\n",
      " 'track_liveness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0789>,\n",
      " 'track_liveness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.0721, 0.157 , 0.0789, 0.373 , 0.0665, 0.326 ], dtype=float32)>,\n",
      " 'track_loudness_can': <tf.Tensor: shape=(), dtype=float32, numpy=-9.636>,\n",
      " 'track_loudness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([-5.715, -5.597, -9.636, -8.017, -9.593, -6.689], dtype=float32)>,\n",
      " 'track_mode_can': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>,\n",
      " 'track_mode_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=array([b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object)>,\n",
      " 'track_name_can': <tf.Tensor: shape=(), dtype=string, numpy=b'Merry'>,\n",
      " 'track_name_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'No Good Reason', b'Rent', b'Merry', b'Moonlight',\n",
      "       b'One Love / People Get Ready', b'Cerveza'], dtype=object)>,\n",
      " 'track_pop_can': <tf.Tensor: shape=(), dtype=float32, numpy=40.0>,\n",
      " 'track_pop_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([42., 57., 40., 57.,  3., 27.], dtype=float32)>,\n",
      " 'track_speechiness_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.0694>,\n",
      " 'track_speechiness_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.0516, 0.0606, 0.0694, 0.0672, 0.324 , 0.0648], dtype=float32)>,\n",
      " 'track_tempo_can': <tf.Tensor: shape=(), dtype=float32, numpy=131.919>,\n",
      " 'track_tempo_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([125.891,  89.929, 131.919, 134.956,  76.292, 179.822],\n",
      "      dtype=float32)>,\n",
      " 'track_time_signature_can': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
      " 'track_uri_can': <tf.Tensor: shape=(), dtype=string, numpy=b'spotify:track:3difvrDmAiFsUOy6LCeML6'>,\n",
      " 'track_uri_pl': <tf.Tensor: shape=(6,), dtype=string, numpy=\n",
      "array([b'spotify:track:3Q3G4esp1k5rF4yLnZtk7S',\n",
      "       b'spotify:track:748pETtPvRIotGU9N3FgXH',\n",
      "       b'spotify:track:3difvrDmAiFsUOy6LCeML6',\n",
      "       b'spotify:track:5G8xknglIO3jFYIXS34YB2',\n",
      "       b'spotify:track:4OsZ1vrenrtSbqLJxOceKl',\n",
      "       b'spotify:track:2fBEeEGdMc42GgFZb01OUp'], dtype=object)>,\n",
      " 'track_valence_can': <tf.Tensor: shape=(), dtype=float32, numpy=0.779>,\n",
      " 'track_valence_pl': <tf.Tensor: shape=(6,), dtype=float32, numpy=array([0.69 , 0.547, 0.779, 0.741, 0.95 , 0.766], dtype=float32)>}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for features in train_parsed.skip(8).take(4):\n",
    "    pprint(features)\n",
    "    print(\"_______________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f446210b-db28-4a7c-bf71-c824b0abca16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"album_name_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Alex Goot & Friends, Vol. 3\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"album_name_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Be Not Nobody\"\n",
      "        value: \"Let Go\"\n",
      "        value: \"Goodbye Lullaby\"\n",
      "        value: \"The Best Damn Thing\"\n",
      "        value: \"Alex Goot & Friends, Vol. 3\"\n",
      "        value: \"Two Lanes Of Freedom\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"album_uri_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:album:0GhppB5IFroTmdP5HxQKE0\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"album_uri_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:album:7D6BFTArx2ajtkKRVXIKO2\"\n",
      "        value: \"spotify:album:7h6XeTzy0SRXDrFJeA9gO7\"\n",
      "        value: \"spotify:album:3WKHuDtWB0Ota02oXE9f9S\"\n",
      "        value: \"spotify:album:0XypvgyeJm4mNjH4QRHmYR\"\n",
      "        value: \"spotify:album:0GhppB5IFroTmdP5HxQKE0\"\n",
      "        value: \"spotify:album:1O3BsjGx9plSOJ036ZY4Fl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_followers_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 228756.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_genres_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\'post-teen pop\\', \\'viral pop\\'\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_genres_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\'lilith\\', \\'neo mellow\\', \\'piano rock\\', \\'pop rock\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'canadian pop\\', \\'candy pop\\', \\'dance pop\\', \\'pop\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'canadian pop\\', \\'candy pop\\', \\'dance pop\\', \\'pop\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'canadian pop\\', \\'candy pop\\', \\'dance pop\\', \\'pop\\', \\'post-teen pop\\'\"\n",
      "        value: \"\\'post-teen pop\\', \\'viral pop\\'\"\n",
      "        value: \"\\'contemporary country\\', \\'country\\', \\'country road\\'\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_name_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Alex Goot\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_name_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Vanessa Carlton\"\n",
      "        value: \"Avril Lavigne\"\n",
      "        value: \"Avril Lavigne\"\n",
      "        value: \"Avril Lavigne\"\n",
      "        value: \"Alex Goot\"\n",
      "        value: \"Tim McGraw\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_pop_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 57.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_pop_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 67.0\n",
      "        value: 82.0\n",
      "        value: 82.0\n",
      "        value: 82.0\n",
      "        value: 57.0\n",
      "        value: 75.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_uri_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:artist:66Fb5gJ9SX2WGlqDLUpjux\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artist_uri_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:artist:5ILrArfIV0tMURcHJN8Q07\"\n",
      "        value: \"spotify:artist:0p4nmQO2msCgU4IF37Wi3j\"\n",
      "        value: \"spotify:artist:0p4nmQO2msCgU4IF37Wi3j\"\n",
      "        value: \"spotify:artist:0p4nmQO2msCgU4IF37Wi3j\"\n",
      "        value: \"spotify:artist:66Fb5gJ9SX2WGlqDLUpjux\"\n",
      "        value: \"spotify:artist:6roFdX1y5BYSbp60OTJWMd\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"artists_followers_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 527127.0\n",
      "        value: 8536842.0\n",
      "        value: 8536842.0\n",
      "        value: 8536842.0\n",
      "        value: 228756.0\n",
      "        value: 3924742.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"avg_art_followers_pl_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 13801767.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"avg_artist_pop_pl_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 73.8125\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"avg_track_pop_pl_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 37.72916793823242\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"duration_ms_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 185893.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"duration_ms_songs_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 238440.0\n",
      "        value: 204000.0\n",
      "        value: 225680.0\n",
      "        value: 240866.0\n",
      "        value: 185893.0\n",
      "        value: 276880.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_albums_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 43.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_artists_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 31.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_followers_src\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"num_pl_songs_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 48.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pl_collaborative_src\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"false\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pl_duration_ms_new\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 10803409.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pl_name_src\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Twisted\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"time_signature_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"3\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_acousticness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.8270000219345093\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_acousticness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.22599999606609344\n",
      "        value: 6.790000043110922e-05\n",
      "        value: 0.03370000049471855\n",
      "        value: 0.20800000429153442\n",
      "        value: 0.8270000219345093\n",
      "        value: 0.02160000056028366\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_danceability_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.5830000042915344\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_danceability_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.3190000057220459\n",
      "        value: 0.4869999885559082\n",
      "        value: 0.4560000002384186\n",
      "        value: 0.4560000002384186\n",
      "        value: 0.5830000042915344\n",
      "        value: 0.4699999988079071\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_energy_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.45399999618530273\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_energy_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6710000038146973\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.8619999885559082\n",
      "        value: 0.7139999866485596\n",
      "        value: 0.45399999618530273\n",
      "        value: 0.7900000214576721\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_instrumentalness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_instrumentalness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_key_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"3\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_key_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"0\"\n",
      "        value: \"0\"\n",
      "        value: \"4\"\n",
      "        value: \"4\"\n",
      "        value: \"3\"\n",
      "        value: \"2\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_liveness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.08219999819993973\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_liveness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.16899999976158142\n",
      "        value: 0.3580000102519989\n",
      "        value: 0.1720000058412552\n",
      "        value: 0.29600000381469727\n",
      "        value: 0.08219999819993973\n",
      "        value: 0.08630000054836273\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_loudness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -8.517999649047852\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_loudness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -3.322999954223633\n",
      "        value: -4.416999816894531\n",
      "        value: -3.818000078201294\n",
      "        value: -3.9800000190734863\n",
      "        value: -8.517999649047852\n",
      "        value: -5.3520002365112305\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_mode_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_mode_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"1\"\n",
      "        value: \"1\"\n",
      "        value: \"1\"\n",
      "        value: \"0\"\n",
      "        value: \"1\"\n",
      "        value: \"1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_name_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Clarity\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_name_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Ordinary Day\"\n",
      "        value: \"Sk8er Boi\"\n",
      "        value: \"Wish You Were Here\"\n",
      "        value: \"When You\\'re Gone\"\n",
      "        value: \"Clarity\"\n",
      "        value: \"Highway Don\\'t Care\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_pop_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 32.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_pop_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 0.0\n",
      "        value: 32.0\n",
      "        value: 67.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_speechiness_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.03099999949336052\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_speechiness_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.03290000185370445\n",
      "        value: 0.04820000007748604\n",
      "        value: 0.05000000074505806\n",
      "        value: 0.03319999948143959\n",
      "        value: 0.03099999949336052\n",
      "        value: 0.039000000804662704\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_tempo_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 125.052001953125\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_tempo_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 185.25599670410156\n",
      "        value: 149.93699645996094\n",
      "        value: 165.99099731445312\n",
      "        value: 142.07200622558594\n",
      "        value: 125.052001953125\n",
      "        value: 158.06100463867188\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_time_signature_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"4\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_uri_can\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:track:6KJcEmFDUHX6zt8Rhuf0AW\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_uri_pl\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"spotify:track:0ua956J0x3UIq9xL4qtRcY\"\n",
      "        value: \"spotify:track:4omisSlTk6Dsq2iQD7MA07\"\n",
      "        value: \"spotify:track:3VcaQY2NiZuZEOKNghNhqe\"\n",
      "        value: \"spotify:track:4VdYpmlf6EDmqbAcWc2jt7\"\n",
      "        value: \"spotify:track:6KJcEmFDUHX6zt8Rhuf0AW\"\n",
      "        value: \"spotify:track:4wFUdSCer8bdQsrp1M90sa\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_valence_can\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6470000147819519\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"track_valence_pl\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.4090000092983246\n",
      "        value: 0.48399999737739563\n",
      "        value: 0.3370000123977661\n",
      "        value: 0.1550000011920929\n",
      "        value: 0.6470000147819519\n",
      "        value: 0.4950000047683716\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_record in train_dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec28160-b821-4220-aeba-3aba45156b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.935  0.763  0.737  0.888  0.83   0.665 ]\n",
      " [0.273  0.228  0.354  0.444  0.397  0.0927]\n",
      " [0.327  0.235  0.391  0.115  0.14   0.352 ]\n",
      " [0.69   0.547  0.779  0.741  0.95   0.766 ]], shape=(4, 6), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 15:52:59.171078: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    }
   ],
   "source": [
    "for x in train_parsed.batch(4).skip(2).take(1):\n",
    "    print(x['track_valence_pl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e606a196-04df-416a-a75c-10c4b5ca5ea0",
   "metadata": {},
   "source": [
    "### Validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3193429-b242-4b43-86ed-d83073471e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = 'spotify-data-regimes'\n",
    "valid_dir_prefix = 'jtv5/valid_last_5_feats_v4/'\n",
    "\n",
    "valid_files = []\n",
    "for blob in client.list_blobs(f'{valid_dir}', prefix=f'{valid_dir_prefix}', delimiter=\"/\"):\n",
    "    valid_files.append(blob.public_url.replace(\"https://storage.googleapis.com/\", \"gs://\"))\n",
    "\n",
    "\n",
    "# valid_dataset = tf.data.Dataset.from_tensor_slices(valid_files).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "# valid_dataset = valid_dataset.interleave(\n",
    "#     full_parse,\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE,\n",
    "#     cycle_length=tf.data.AUTOTUNE, \n",
    "#     deterministic=False,\n",
    "# ).map(tt.parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE).batch(\n",
    "#     batch_size\n",
    "# ).prefetch(\n",
    "#     tf.data.AUTOTUNE,\n",
    "# ).with_options(options)\n",
    "\n",
    "valid_dataset = tf.data.TFRecordDataset(valid_files)\n",
    "valid_parsed = valid_dataset.map(tt.parse_tfrecord)\n",
    "\n",
    "# valid_dataset = valid_dataset #.cache() #1gb machine mem + 400 MB in candidate ds (src/two-tower.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4abe2c8b-28c2-452b-8dbb-21d0565b8706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'album_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'album_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_followers_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_genres_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'artist_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'artist_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'avg_art_followers_pl_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'avg_artist_pop_pl_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'avg_track_pop_pl_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'duration_ms_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_albums_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_artists_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_followers_src': TensorSpec(shape=(), dtype=tf.float32, name=None), 'num_pl_songs_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_collaborative_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'pl_duration_ms_new': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pl_name_src': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_acousticness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_danceability_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_energy_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_instrumentalness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_key_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_liveness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_loudness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_mode_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_name_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_pop_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_speechiness_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_tempo_can': TensorSpec(shape=(), dtype=tf.float32, name=None), 'track_time_signature_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_uri_can': TensorSpec(shape=(), dtype=tf.string, name=None), 'track_valence_can': TensorSpec(shape=(), dtype=tf.float32, name=None)}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53daf45-1bf5-4909-8fbd-449ae5372d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b'spotify:track:203zTFd1zbfG0fiOG9OREv'\n",
      "  b'spotify:track:3uD4aRM8QoEAAhwpOke7QU'\n",
      "  b'spotify:track:6r7Pl4njxpio06Amy2fxrA'\n",
      "  b'spotify:track:3tZwKujD64Ad6vlDVxZOrg'\n",
      "  b'spotify:track:6KyOCzf2A2jjROH4ZokTEw'\n",
      "  b'spotify:track:6AwPEpVjrWnJ0Avv5Krvgr']\n",
      " [b'spotify:track:1d15QaDMYLlzPGaYWMEw06'\n",
      "  b'spotify:track:23aRQxzv8AbUOAV4czlNmp'\n",
      "  b'spotify:track:7zJg7aNCvTKW9EtG1Dvzkl'\n",
      "  b'spotify:track:7KVQiFRrq9UWYjgsbL8woP'\n",
      "  b'spotify:track:3yvMWXSQs2W5IVNBHkgZom'\n",
      "  b'spotify:track:5MCG4XcVcvCOXWpSg2cfRC']\n",
      " [b'spotify:track:1mqlc0vEP9mU1kZgTi6LIQ'\n",
      "  b'spotify:track:78WVLOP9pN0G3gRLFy1rAa'\n",
      "  b'spotify:track:44AyOl4qVkzS48vBsbNXaC'\n",
      "  b'spotify:track:3MrRksHupTVEQ7YbA0FsZK'\n",
      "  b'spotify:track:72xFgK8VpmUILQcXMNCLGN'\n",
      "  b'spotify:track:1OOtq8tRnDM8kG2gqUPjAj']], shape=(3, 6), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:05:31.440232: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_uri_pl.  Can't parse serialized Example.\n"
     ]
    }
   ],
   "source": [
    "for x in valid_parsed.batch(3).take(1):\n",
    "    print(x['track_uri_pl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2f2ac-e7d0-4e5c-9b7b-85ba395ecd36",
   "metadata": {},
   "source": [
    "### Candidate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11777fbe-a77c-4c7b-94d3-30b11b3f72f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# candidate_files = ['gs://spotify-data-regimes/jtv1-candidates/candidates-00000-of-00001.tfrecords'] # TODO: parametrize\n",
    "# candidate_files = ['gs://spotify-data-regimes/jtv5/candidates/candidates-00000-of-00001.tfrecords']   # removed track_playlist_titles\n",
    "candidate_files = ['gs://spotify-data-regimes/jtv5/candidates/candidates-00000-of-00001.tfrecords']\n",
    "\n",
    "candidate_dataset = tf.data.TFRecordDataset(candidate_files)\n",
    "parsed_candidate_dataset = candidate_dataset.map(tt.parse_candidate_tfrecord_fn)\n",
    "# parsed_candidate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcca25d-8a96-4bc9-bfcb-b7bac0524bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in parsed_candidate_dataset.batch(2).take(1):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e448-f833-421f-977d-f52b0db198c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Local Training\n",
    "\n",
    "Compile the model\n",
    "Review the details of the model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fa77-6401-47bc-b198-14c1891ddcac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adapt the text vectorizors - copy/paste to run one time\n",
    "\n",
    "We are accessing the `TextVectorizor` layers in the model via the layer print-outs above\n",
    "\n",
    "```python\n",
    "# adpat the text vectorizors\n",
    "model.query_tower.layers[3].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['artist_name_pl']) #artist name pl\n",
    "model.query_tower.layers[5].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['track_name_pl']) #track name pl\n",
    "model.query_tower.layers[7].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['album_name_pl']) #album name pl\n",
    "model.query_tower.layers[11].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['artist_genres_pl']) #artist genres pl\n",
    "\n",
    "model.candidate_tower.layers[1].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['track_name_can'])) #track name can\n",
    "model.candidate_tower.layers[2].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['album_name_can'])) #album name can\n",
    "model.candidate_tower.layers[10].layers[0].adapt(\n",
    "    train_dataset.unbatch().batch(40000).map(lambda x: x['artist_genres_can'])) #artist genres can\n",
    "```\n",
    "\n",
    "\n",
    "## Save the vocab dictionary for later so you will not have to adapt\n",
    "\n",
    "```python\n",
    "vocab_dict = {\n",
    "    'artist_name_pl' : model.query_tower.layers[3].layers[0].get_vocabulary(), #artist name pl\n",
    "    'track_name_pl' : model.query_tower.layers[5].layers[0].get_vocabulary(), #track name pl\n",
    "    'album_name_pl' : model.query_tower.layers[7].layers[0].get_vocabulary(), #album name pl\n",
    "    'artist_genres_pl' : model.query_tower.layers[11].layers[0].get_vocabulary(), #artist genres pl\n",
    "\n",
    "    'track_name_can' : model.candidate_tower.layers[1].layers[0].get_vocabulary(), #track name can\n",
    "    'album_name_can' : model.candidate_tower.layers[2].layers[0].get_vocabulary(), #album name can\n",
    "    'artist_genres_can' : model.candidate_tower.layers[10].layers[0].get_vocabulary(), #artist genres can\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### Save the vocabs\n",
    "\n",
    "```python\n",
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('vocab_dict.pkl', 'wb')\n",
    "pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "filehandler.close()\n",
    "\n",
    "tt.upload_blob('two-tower-models', 'vocab_dict.pkl', 'vocabs/vocab_dict.pkl')\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3068807-9e07-4c0b-ad9d-b9952ccc3441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # jw vocab\n",
    "# os.system('gsutil cp gs://two-tower-models/vocabs/vocab_dict.pkl .')\n",
    "\n",
    "# BUCKET_DATA_jw = 'two-tower-models'\n",
    "# VOCAB_LOCAL_FILE_jw = 'vocab_dict.pkl'\n",
    "# VOCAB_GCS_OBJ_jw = 'vocabs/vocab_dict.pkl'\n",
    "\n",
    "# filehandler = open(f'{VOCAB_LOCAL_FILE_jw}', 'rb')\n",
    "# vocab_dict_jw = pkl.load(filehandler)\n",
    "# filehandler.close()\n",
    "# vocab_dict_jw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc06d1-1936-405b-96ba-bc996f0f7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=20000 #50000\n",
    "\n",
    "# pl_name_src\n",
    "pl_name_src_text_layer = tf.keras.layers.TextVectorization() # max_tokens=MAX_TOKENS,ngrams=2,\n",
    "pl_name_src_text_layer.adapt(train_parsed.map(lambda x: x['pl_name_src'])) # lambda x, y: y[key name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052752dd-e156-4f74-9844-9931284bd8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd71dac-eb97-43c2-9016-884f57039fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 07:21:51.196080: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:51.405048: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:51.412763: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[StringSplit/StringSplitV2/_2]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_605]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27166/1913353400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pl_name_src\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpl_name_src_text_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TOKENS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpl_name_src_text_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_parsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pl_name_src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# track_name_pl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    426\u001b[0m           \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[StringSplit/StringSplitV2/_2]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 07:21:51.548160: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:51.749236: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.020817: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.020930: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.023126: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.250144: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.250906: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.397886: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.585969: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.694836: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:52.862954: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:53.035667: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:53.165490: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 07:21:53.167459: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    }
   ],
   "source": [
    "MAX_TOKENS=20000 #50000\n",
    "\n",
    "# ==========================================================================================\n",
    "# PLAYLIST TOWER\n",
    "# ==========================================================================================\n",
    "# pl_name_src\n",
    "pl_name_src_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "pl_name_src_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['pl_name_src']))\n",
    "\n",
    "# track_name_pl\n",
    "track_name_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "track_name_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_name_pl']))\n",
    "\n",
    "# artist_name_pl\n",
    "artist_name_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "artist_name_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_name_pl']))\n",
    "\n",
    "# album_name_pl\n",
    "album_name_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "album_name_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['album_name_pl']))\n",
    "\n",
    "# artist_genres_pl\n",
    "artist_genres_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "artist_genres_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_genres_pl']))\n",
    "\n",
    "# # tracks_playlist_titles_pl\n",
    "# tracks_playlist_titles_pl_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# tracks_playlist_titles_pl_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['tracks_playlist_titles_pl']))\n",
    "\n",
    "# ==========================================================================================\n",
    "# CANDIDATE TOWER\n",
    "# ==========================================================================================\n",
    "\n",
    "# track_name_can\n",
    "track_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "track_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_name_can']))\n",
    "\n",
    "# artist_name_can\n",
    "artist_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "artist_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_name_can']))\n",
    "\n",
    "# album_name_can\n",
    "album_name_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "album_name_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['album_name_can']))\n",
    "\n",
    "# artist_genres_can\n",
    "artist_genres_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "artist_genres_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['artist_genres_can']))\n",
    "\n",
    "# # track_pl_titles_can\n",
    "# track_pl_titles_can_text_layer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS,ngrams=2,)\n",
    "# track_pl_titles_can_text_layer.adapt(train_parsed.batch(1000).map(lambda x: x['track_pl_titles_can']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd814d96-66b1-40ef-a998-c60d1e2d07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st adapt\n",
    "# gsutil cp gs://spotify-data-regimes/jtv1/vocabs/vocab_dict.pkl .\n",
    "\n",
    "# BUCKET_DATA = 'spotify-data-regimes'\n",
    "# VOCAB_LOCAL_FILE = 'vocab_dict.pkl'\n",
    "# VOCAB_GCS_OBJ = 'jtv1/vocabs/vocab_dict.pkl'\n",
    "\n",
    "# vocab_dict = {\n",
    "#     'pl_name_src' : ['empty'],\n",
    "#     'track_name_pl' : ['empty'],\n",
    "#     'artist_name_pl' : ['empty'],\n",
    "#     'artist_genres_pl' : ['empty'],\n",
    "#     'tracks_playlist_titles_pl' : ['empty'],\n",
    "#     'track_name_can' : ['empty'],\n",
    "#     'artist_name_can' : ['empty'],\n",
    "#     'album_name_can' : ['empty'],\n",
    "#     'artist_genres_can' : ['empty'],\n",
    "#     'track_pl_titles_can' : ['empty'],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ac31d4-b174-4dbe-b9b6-1e3cbaadb4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File vocab_dict.pkl uploaded to jtv1/vocabs/vocab_dict.pkl.\n"
     ]
    }
   ],
   "source": [
    "# # write vocab to gcs\n",
    "\n",
    "# filehandler = open('vocab_dict.pkl', 'wb')\n",
    "\n",
    "# pkl.dump(vocab_dict, filehandler)\n",
    "\n",
    "# filehandler.close()\n",
    "\n",
    "# tt.upload_blob(f'{BUCKET_DATA}', f'{VOCAB_LOCAL_FILE}', f'{VOCAB_GCS_OBJ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17c7815f-f79f-4774-9be3-aeb0e9e74d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pl_name_src': ['empty'], 'track_name_pl': ['empty'], 'artist_name_pl': ['empty'], 'artist_genres_pl': ['empty'], 'tracks_playlist_titles_pl': ['empty'], 'track_name_can': ['empty'], 'artist_name_can': ['empty'], 'album_name_can': ['empty'], 'artist_genres_can': ['empty'], 'track_pl_titles_can': ['empty']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filehandler = open(f'{VOCAB_LOCAL_FILE}', 'rb')\n",
    "# vocab_dict_load = pkl.load(filehandler)\n",
    "# filehandler.close()\n",
    "# vocab_dict_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ec5d0c8-a4ae-451c-9056-fe5d9a8e4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_tower_jt import two_tower as tt\n",
    "\n",
    "layer_sizes=[512,256]\n",
    "\n",
    "model = tt.TheTwoTowers(layer_sizes) \n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11401be6-0f5f-4454-997a-862a58df2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist (query) Tower:\n",
      "0 pl_name_src_text_embedding\n",
      "1 pl_collaborative_emb_model\n",
      "2 num_pl_followers_src_emb_model\n",
      "3 pl_duration_ms_new_emb_model\n",
      "4 num_pl_songs_new_emb_model\n",
      "5 num_pl_artists_new_emb_model\n",
      "6 num_pl_albums_new_emb_model\n",
      "7 avg_track_pop_pl_new_emb_model\n",
      "8 avg_artist_pop_pl_new_emb_model\n",
      "9 avg_art_followers_pl_new_emb_model\n",
      "10 track_uri_pl_emb_model\n",
      "11 track_name_pl_emb_model\n",
      "12 artist_uri_pl_emb_model\n",
      "13 artist_name_pl_emb_model\n",
      "14 album_uri_pl_emb_model\n",
      "15 album_name_pl_emb_model\n",
      "16 artist_genres_pl_emb_model\n",
      "17 duration_ms_songs_pl_emb_model\n",
      "18 track_pop_pl_emb_model\n",
      "19 artist_pop_pl_emb_model\n",
      "20 artists_followers_pl_emb_model\n",
      "21 track_danceability_pl_emb_model\n",
      "22 track_energy_pl_emb_model\n",
      "23 track_key_pl_emb_model\n",
      "24 track_loudness_pl_emb_model\n",
      "25 track_mode_pl_emb_model\n",
      "26 track_speechiness_pl_emb_model\n",
      "27 track_acousticness_pl_emb_model\n",
      "28 track_instrumentalness_pl_emb_model\n",
      "29 track_liveness_pl_emb_model\n",
      "30 track_valence_pl_emb_model\n",
      "31 track_tempo_pl_emb_model\n",
      "32 time_signature_pl_emb_model\n",
      "33 pl_dense_layers\n"
     ]
    }
   ],
   "source": [
    "## Quick look at the layers\n",
    "print(\"Playlist (query) Tower:\")\n",
    "\n",
    "for i, l in enumerate(model.query_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4fb669-7c98-448a-a2bf-1559b0a4d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track (candidate) Tower:\n",
      "0 track_uri_can_emb_model\n",
      "1 track_name_can_emb_model\n",
      "2 artist_uri_can_emb_model\n",
      "3 artist_name_can_emb_model\n",
      "4 album_uri_can_emb_model\n",
      "5 album_name_can_emb_model\n",
      "6 duration_ms_can_emb_model\n",
      "7 track_pop_can_emb_model\n",
      "8 artist_pop_can_emb_model\n",
      "9 artist_genres_can_emb_model\n",
      "10 artists_followers_can_emb_model\n",
      "11 track_danceability_can_emb_model\n",
      "12 track_energy_can_emb_model\n",
      "13 track_key_can_emb_model\n",
      "14 track_loudness_can_emb_model\n",
      "15 track_mode_can_emb_model\n",
      "16 track_speechiness_can_emb_model\n",
      "17 track_acousticness_can_emb_model\n",
      "18 track_instrumentalness_can_emb_model\n",
      "19 track_liveness_can_emb_model\n",
      "20 track_valence_can_emb_model\n",
      "21 track_tempo_can_emb_model\n",
      "22 track_time_signature_can_emb_model\n",
      "23 candidate_dense_layers\n"
     ]
    }
   ],
   "source": [
    "print(\"Track (candidate) Tower:\")\n",
    "for i, l in enumerate(model.candidate_tower.layers):\n",
    "    print(i, l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e51ae0-18ba-4e66-aec5-15db2acf62e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f0e87c3b6d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.query_tower.layers[11].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed15009f-58fb-4054-ac5e-a85bac810e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 13:02:36.733498: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[None_lookup_table_find/LookupTableFindV2/_24]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_3911]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11576/1115475071.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # adpat the text vectorizors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.query_tower.layers[0].layers[0].adapt(\n\u001b[0;32m----> 3\u001b[0;31m     train_parsed.batch(1000).map(lambda x: x['pl_name_src']))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.query_tower.layers[11].layers[0].adapt(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    426\u001b[0m           \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n\t [[None_lookup_table_find/LookupTableFindV2/_24]]\n  (1) INVALID_ARGUMENT:  Key: track_valence_pl.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_3911]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 13:02:36.867952: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n",
      "2022-12-06 13:02:36.877955: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at example_parsing_ops.cc:94 : INVALID_ARGUMENT: Key: track_valence_pl.  Can't parse serialized Example.\n"
     ]
    }
   ],
   "source": [
    "# # adpat the text vectorizors\n",
    "model.query_tower.layers[0].layers[0].adapt(\n",
    "    train_parsed.batch(1000).map(lambda x: x['pl_name_src']))\n",
    "\n",
    "# model.query_tower.layers[11].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['track_name_pl']))\n",
    "\n",
    "# model.query_tower.layers[13].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_name_pl']))\n",
    "\n",
    "# model.query_tower.layers[15].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['album_name_pl']))\n",
    "\n",
    "# model.query_tower.layers[16].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_genres_pl']))\n",
    "\n",
    "# # model.query_tower.layers[17].layers[0].adapt(\n",
    "# #     train_parsed.batch(40000).map(lambda x: x['tracks_playlist_titles_pl']))\n",
    "    \n",
    "# # candidate tower layers\n",
    "# model.candidate_tower.layers[1].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['track_name_can']))\n",
    "\n",
    "# model.candidate_tower.layers[3].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_name_can']))\n",
    "\n",
    "# model.candidate_tower.layers[5].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['album_name_can']))\n",
    "\n",
    "# model.candidate_tower.layers[9].layers[0].adapt(\n",
    "#     train_parsed.batch(40000).map(lambda x: x['artist_genres_can']))\n",
    "\n",
    "# # model.candidate_tower.layers[11].layers[0].adapt(\n",
    "# #     train_parsed.batch(40000).map(lambda x: x['track_pl_titles_can']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855292d1-c069-4559-b598-e275e310826b",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aefbf5-7dea-4bbb-ac3a-6232062d29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "LR = .1\n",
    "opt = tf.keras.optimizers.Adagrad(LR)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a17df-2e2a-41e5-a0c6-ac2abc2ad135",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Local Training\n",
    "\n",
    "Setup tensorboard below so training is visible and we can inspect the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d62d539-6e29-4783-a358-1321f9521528",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_RESOURCE_NAME = 'projects/934903580331/locations/us-central1/tensorboards/7336372589079560192' #fqn - project number then tensorboard id\n",
    "invoke_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "EXPERIMENT_NAME = f'spotify-singe-node-train-full-data-v7-01'\n",
    "RUN_NAME = EXPERIMENT_NAME+'run'+time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "LOG_DIR = path+\"/tb-logs/\"+EXPERIMENT_NAME\n",
    "\n",
    "\n",
    "def get_upload_logs_to_manged_tb_command(ttl_hrs, oneshot=\"false\"):\n",
    "    \"\"\"\n",
    "    Run this and copy/paste the command into terminal to have \n",
    "    upload the tensorboard logs from this machine to the managed tb instance\n",
    "    Note that the log dir is at the granularity of the run to help select the proper\n",
    "    timestamped run in Tensorboard\n",
    "    You can also run this in one-shot mode after training is done \n",
    "    to upload all tb objects at once\n",
    "    \"\"\"\n",
    "    return(f\"\"\"tb-gcp-uploader --tensorboard_resource_name={TB_RESOURCE_NAME} \\\n",
    "      --logdir={LOG_DIR} \\\n",
    "      --experiment_name={EXPERIMENT_NAME} \\\n",
    "      --one_shot={oneshot} \\\n",
    "      --event_file_inactive_secs={60*60*ttl_hrs}\"\"\")\n",
    "\n",
    "vertex_ai.init(experiment=EXPERIMENT_NAME)\n",
    "    \n",
    "\n",
    "# we are going to ecapsulate this one-shot log uploader via a custom callback:\n",
    "\n",
    "class UploadTBLogsBatchEnd(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        os.system(get_upload_logs_to_manged_tb_command(ttl_hrs = 5, oneshot=\"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cea523d-812a-4a67-a85f-58b9577a50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=LOG_DIR,\n",
    "        histogram_freq=0, \n",
    "        write_graph=True, \n",
    "        # profile_batch=(20,50) #run profiler on steps 20-40 - enable this line if you want to run profiler from the utils/ notebook\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50177537-964d-4f49-9770-a880dd47fe10",
   "metadata": {},
   "source": [
    "### Training using tensorboard callback\n",
    "\n",
    "While profiling does not work for managed Tensorboard at this time, you can inspect the profiler with an [inline Tensorboard in another notebook](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks). You may be prompted to install the tensorflow profiler library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f592c-913c-45a9-a9eb-3ae1becefddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:34:46.515483: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-11-09 00:34:47.244207: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3707/Unknown - 4882s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 50909.8305 - regularization_loss: 0.0000e+00 - total_loss: 50909.8305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 01:55:59.926501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 01:56:00.062321: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 01:56:00.103058: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 01:56:00.841399: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 01:56:00.841494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 01:56:00.841504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T01:56:04]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T01:56:07]\u001b[0m Total uploaded: 8 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4893s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 50899.2761 - regularization_loss: 0.0000e+00 - total_loss: 50899.2761\n",
      "Epoch 2/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 11222.0707 - regularization_loss: 0.0000e+00 - total_loss: 11222.07078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 03:15:09.702038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 03:15:09.836815: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 03:15:09.879861: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 03:15:10.623233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 03:15:10.623324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 03:15:10.623334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 03:15:11.524794 139639993792320 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T03:15:11]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T03:15:17]\u001b[0m Total uploaded: 16 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4749s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 11221.1035 - regularization_loss: 0.0000e+00 - total_loss: 11221.1035\n",
      "Epoch 3/70\n",
      "3303/3708 [=========================>....] - ETA: 8:33 - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 8856.4106 - regularization_loss: 0.0000e+00 - total_loss: 8856.4106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:09:16.437085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 11:09:16.573402: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 11:09:16.616563: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 11:09:17.344141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 11:09:17.344239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 11:09:17.344250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 11:09:18.241973 140144034944832 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T11:09:18]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T11:09:26]\u001b[0m Total uploaded: 40 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 28448s 8s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 8803.8781 - regularization_loss: 0.0000e+00 - total_loss: 8803.8781 - val_batch_categorical_accuracy_at_1: 0.0000e+00 - val_batch_categorical_accuracy_at_5: 0.0000e+00 - val_factorized_top_k/top_1_categorical_accuracy: 0.7862 - val_factorized_top_k/top_5_categorical_accuracy: 0.9233 - val_factorized_top_k/top_10_categorical_accuracy: 0.9382 - val_loss: 10986.7881 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10986.7881\n",
      "Epoch 4/70\n",
      "1816/3708 [=============>................] - ETA: 40:59 - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 8198.6702 - regularization_loss: 0.0000e+00 - total_loss: 8198.6702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7889.6094 - regularization_loss: 0.0000e+00 - total_loss: 7889.6094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 13:48:14.090572: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 13:48:14.232195: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 13:48:14.274022: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 13:48:15.026854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 13:48:15.026949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 13:48:15.026960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 13:48:15.938464 139918749620032 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T13:48:16]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T13:48:26]\u001b[0m Total uploaded: 56 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4734s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7889.1334 - regularization_loss: 0.0000e+00 - total_loss: 7889.1334\n",
      "Epoch 6/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7800.3888 - regularization_loss: 0.0000e+00 - total_loss: 7800.3888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 15:07:11.962236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 15:07:12.099022: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 15:07:12.142491: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 15:07:12.893604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 15:07:12.893705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 15:07:12.893715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 15:07:13.799662 140111523784512 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T15:07:14]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T15:07:24]\u001b[0m Total uploaded: 64 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4738s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7799.9284 - regularization_loss: 0.0000e+00 - total_loss: 7799.9284\n",
      "Epoch 7/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7757.1865 - regularization_loss: 0.0000e+00 - total_loss: 7757.1865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 16:26:22.889692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 16:26:23.026815: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 16:26:23.067868: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 16:26:23.808168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 16:26:23.808258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 16:26:23.808268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 16:26:24.718955 140335566804800 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T16:26:25]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T16:26:35]\u001b[0m Total uploaded: 72 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4751s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7756.7933 - regularization_loss: 0.0000e+00 - total_loss: 7756.7933\n",
      "Epoch 8/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7737.3258 - regularization_loss: 0.0000e+00 - total_loss: 7737.3258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:45:56.065276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 17:45:56.208794: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 17:45:56.251314: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 17:45:56.992739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 17:45:56.992834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 17:45:56.992844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 17:45:57.893610 140106310330176 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T17:45:58]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2022-11-09T17:46:08]\u001b[0m Total uploaded: 80 scalars, 0 tensors, 12 binary objects (6.1 MB)\n",
      "3708/3708 [==============================] - 4773s 1s/step - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7736.9064 - regularization_loss: 0.0000e+00 - total_loss: 7736.9064\n",
      "Epoch 9/70\n",
      "3707/3708 [============================>.] - ETA: 1s - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7722.9688 - regularization_loss: 0.0000e+00 - total_loss: 7722.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 19:05:47.547252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 19:05:47.686335: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 19:05:47.730003: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 19:05:48.480374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 19:05:48.480468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-09 19:05:48.480478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "W1109 19:05:49.379873 140251568813888 uploader.py:379] Please consider uploading to a new experiment instead of an existing one, as the former allows for better upload performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View your Tensorboard at https://us-central1.tensorboard.googleusercontent.com/experiment/projects+934903580331+locations+us-central1+tensorboards+7336372589079560192+experiments+spotify-singe-node-train-full-data-v7-01\n",
      "\u001b[1m[2022-11-09T19:05:49]\u001b[0m Started scanning logdir.\n",
      "3608/3708 [============================>.] - ETA: 2:08 - batch_categorical_accuracy_at_1: 0.0000e+00 - batch_categorical_accuracy_at_5: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - loss: 7716.3438 - regularization_loss: 0.0000e+00 - total_loss: 7716.3438"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 70\n",
    "RUN_NAME = f'run-{EXPERIMENT_NAME}-{time.strftime(\"%Y%m%d-%H%M%S\")}'#be sure to think about run and experiment naming strategies so names don't collide\n",
    "\n",
    "#start the run to collect metrics - note `.log_parameters()` is available but not used\n",
    "\n",
    "#start the timer and training\n",
    "start_time = time.time()\n",
    "layer_history = model.fit(\n",
    "    train_dataset.unbatch().batch(batch_size),\n",
    "    validation_data=valid_dataset,\n",
    "    validation_freq=3,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # steps_per_epoch=2, #use this for development to run just a few steps\n",
    "    validation_steps = 100,\n",
    "    callbacks=[tensorboard_callback,\n",
    "               UploadTBLogsBatchEnd()], #the tensorboard will be automatically associated with the experiment and log subsequent runs with this callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "val_keys = [v for v in layer_history.history.keys()]\n",
    "runtime_mins = int((end_time - start_time) / 60)\n",
    "\n",
    "\n",
    "vertex_ai.start_run(RUN_NAME, tensorboard=TB_RESOURCE_NAME)\n",
    "\n",
    "vertex_ai.log_params({\"layers\": str(layer_sizes), \n",
    "                      \"learning_rate\": LR,\n",
    "                        \"num_epochs\": epochs,\n",
    "                        \"batch_size\": batch_size,\n",
    "                     })\n",
    "\n",
    "#gather the metrics for the last epoch to be saved in metrics\n",
    "metrics_dict = {\"train-time-minutes\": runtime_mins}\n",
    "_ = [metrics_dict.update({key: layer_history.history[key][-1]}) for key in val_keys]\n",
    "vertex_ai.log_metrics(metrics_dict)\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1cd-0e65-450b-9490-2f497ce65744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### You can access the experiment from the console via the experiment name you just declared:\n",
    "\n",
    "![](img/experiment-console.png)\n",
    "\n",
    "![](img/tensorboard.png)\n",
    "\n",
    "### Also, while this is running - check out the Tensorboard profiler in `utils`.\n",
    "\n",
    "![](img/tb-profiler.png)\n",
    "\n",
    "### Run `nvtop` - check out the installation script in `utils` - `install_nvtop.sh`\n",
    "\n",
    "![](img/nvtop-optimized.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8b573-ba18-4b2d-a507-daf95f9c9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total runtime: {runtime_mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ceb80-2365-4b85-8218-3f721ddebada",
   "metadata": {},
   "source": [
    "### When complete you get a decent model with around 30-40 hit rate for top 1\n",
    "\n",
    "![](img/tb-metrics.png)\n",
    "![](img/tb-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6170e-970e-4c7d-912f-3998adbd37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get metrics for the Vertex Experiment\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559139c-d669-43b1-8ac2-6155b10ef83e",
   "metadata": {},
   "source": [
    "### Now, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f1957-1883-4527-83ee-fd5c9857f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the bucket to store the tensorflow models\n",
    "# ! gsutil mb -l us-central1 $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d57ed-540c-41f4-b7cf-d3dad716f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the models\n",
    "\n",
    "tf.saved_model.save(model.query_tower, export_dir=path + \"/query_model\")\n",
    "tf.saved_model.save(model.candidate_tower, export_dir=path + \"/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4dd5-2003-472a-a501-19e029cd14df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the candidate embeddings to GCS for use in Matching Engine later\n",
    "These will be the files we use for the index\n",
    "\n",
    "This does the following\n",
    "1) Create a tf pipeline to convert embeddings to numpy\n",
    "2) Serialize the candidate song emgeddings with the song_uri index and save to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820278f-5dbf-4aca-858e-df32ee4abe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tf function to convert any bad null values\n",
    "def tf_if_null_return_zero(val):\n",
    "    \"\"\"\n",
    "    this function fills in nans to zeros - sometimes happens in embedding calcs.\n",
    "    this will clean the embedding inputs downstream\n",
    "    \"\"\"\n",
    "    return(tf.clip_by_value(val, -1e12, 1e12)) # a trick to remove NANs post tf2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e4e21-c560-4148-93ea-d30f5a946861",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_embeddings = tt.parsed_candidate_dataset.batch(10000).map(lambda x: [x['track_uri_can'], tf_if_null_return_zero(model.candidate_tower(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d452a-3137-41a5-a48a-92e686abafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the required format\n",
    "# make sure you start out with a clean empty file for the append write\n",
    "!rm candidate_embeddings.json > /dev/null \n",
    "!touch candidate_embeddings.json\n",
    "for batch in candidate_embeddings:\n",
    "    songs, embeddings = batch\n",
    "    with open(\"candidate_embeddings.json\", 'a') as f:\n",
    "        for song, emb in zip(songs.numpy(), embeddings.numpy()):\n",
    "            f.write('{\"id\":\"' + str(song) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(emb)) + ']}')\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7ce65-b1e5-49b9-824e-3cabedd656f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.upload_blob('two-tower-models', 'candidate_embeddings.json', 'candidates/candidate_embeddings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8cb39-707d-4dc9-9d80-32b198b5cdc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Do a quick line count from terminal - should look like this:\n",
    "\n",
    "```\n",
    "(base) jupyter@tf28-jsw-sep-a100:~/spotify_mpd_two_tower$ wc -l candidate_embeddings.json \n",
    "2249561 candidate_embeddings.json\n",
    "```\n",
    "\n",
    "### Finished\n",
    "\n",
    "Go on to the [03 notebook](03-matching-engine.ipynb)\n",
    "\n",
    "You should see results similar to the screenshot below\n",
    "![](img/embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2e2b2-74a8-4485-9db0-22146e4a5159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
